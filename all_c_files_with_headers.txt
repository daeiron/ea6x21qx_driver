===== ./drivers/skwifi/skw_tx.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/kthread.h>
#include <linux/ip.h>
#include <linux/ctype.h>

#include "skw_core.h"
#include "skw_tx.h"
#include "skw_msg.h"
#include "skw_iface.h"
#include "trace.h"

#define SKW_BASE_VO                    16
#define SKW_BASE_VI                    24
#define SKW_TX_TIMEOUT                 200
#define SKW_TX_RUNING_TIMES            20

struct skw_tx_info {
	int quota;
	bool reset;
	struct sk_buff_head *list;
};

struct skw_tx_lmac {
	bool reset;
	int cred;
	u16 txq_map;
	u16 nr_txq;
	int bk_tx_limit;
	int current_qlen;
	int ac_reset;
	int tx_count_limit;

	struct sk_buff_head tx_list;
	struct skw_tx_info tx[SKW_NR_IFACE];
};

unsigned int tx_wait_time;

static int skw_tx_time_show(struct seq_file *seq, void *data)
{
	seq_printf(seq, "current tx_wait_time = %dus\n", tx_wait_time);
	return 0;
}

static int skw_tx_time_open(struct inode *inode, struct file *file)
{
	return single_open(file, skw_tx_time_show, inode->i_private);
}

static ssize_t skw_tx_time_write(struct file *fp, const char __user *buf,
				size_t len, loff_t *offset)
{
	int i;
	char cmd[32] = {0};
	unsigned int res = 0;

	for (i = 0; i < 32; i++) {
		char c;

		if (get_user(c, buf))
			return -EFAULT;

		if (c == '\n' || c == '\0')
			break;

		if (isdigit(c) != 0)
			cmd[i] = c;
		else {
			skw_warn("set fail, not number\n");
			return -EFAULT;
		}
		buf++;
	}

	if (kstrtouint(cmd, 10, &res))
		return -EFAULT;

	skw_info("set tx_wait_time = %dus\n", res);
	tx_wait_time = res;

	return len;
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
static const struct proc_ops skw_tx_time_fops = {
	.proc_open = skw_tx_time_open,
	.proc_read = seq_read,
	.proc_release = single_release,
	.proc_write = skw_tx_time_write,
};
#else
static const struct file_operations skw_tx_time_fops = {
	.owner = THIS_MODULE,
	.open = skw_tx_time_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_tx_time_write,
};
#endif

#ifdef CONFIG_SKW_SKB_RECYCLE
void skw_recycle_skb_free(struct skw_core *skw, struct sk_buff *skb)
{
	if (!skb)
		return;
	skb->data = skb->head;
	skb_reset_tail_pointer(skb);

	skb->mac_header = (typeof(skb->mac_header))~0U;
	skb->transport_header = (typeof(skb->transport_header))~0U;
	skb->network_header = 0;

	skb->len = 0;

	skb_reserve(skb, NET_SKB_PAD);

	skb_queue_tail(&skw->skb_recycle_qlist, skb);

	return;
}

int skw_recycle_skb_copy(struct skw_core *skw, struct sk_buff *skb_recycle, struct sk_buff *skb)
{
	if (!skw || !skb_recycle || !skb)
		return -1;

	skb_recycle->dev = skb->dev;

	skb_reserve(skb_recycle, skw->skb_headroom);
	skb_put(skb_recycle, skb->len);
	memcpy(skb_recycle->data, skb->data, skb->len);

	skb_set_mac_header(skb_recycle, 0);
	skb_set_network_header(skb_recycle, ETH_HLEN);
	skb_set_transport_header(skb_recycle, skb->transport_header - skb->mac_header);
	if (skb->ip_summed == CHECKSUM_PARTIAL) {
		skb_recycle->ip_summed = skb->ip_summed;
		skb_recycle->csum_start = skb_headroom(skb_recycle) + skb_checksum_start_offset(skb);
	}

	return 0;
}

struct sk_buff *skw_recycle_skb_get(struct skw_core *skw)
{
	unsigned long flags;
	struct sk_buff *skb = NULL;

	spin_lock_irqsave(&skw->skb_recycle_qlist.lock, flags);
	if (skw->skb_recycle_qlist.qlen > 0) {
		skb = skb_peek(&skw->skb_recycle_qlist);
		__skb_unlink(skb, &skw->skb_recycle_qlist);
	}
	spin_unlock_irqrestore(&skw->skb_recycle_qlist.lock, flags);

	return skb;
}
#endif

void skw_skb_kfree(struct skw_core *skw, struct sk_buff *skb)
{
#ifdef CONFIG_SKW_SKB_RECYCLE
	if (1 == SKW_SKB_TXCB(skb)->recycle)
		skw_recycle_skb_free(skw, skb);
	else
		dev_kfree_skb_any(skb);
#else
	dev_kfree_skb_any(skb);
#endif
}

int skw_pcie_cmd_xmit(struct skw_core *skw, void *data, int data_len)
{
	skw->edma_cmd.hdr[0].data_len = data_len;
	skw_edma_set_data(priv_to_wiphy(skw), &skw->edma_cmd, data, data_len);

	return skw_edma_tx(priv_to_wiphy(skw), &skw->edma_cmd, data_len);
}

int skw_sdio_cmd_xmit(struct skw_core *skw, void *data, int data_len)
{
	int nr = 0, total_len;

	sg_init_table(skw->sgl_cmd, SKW_NR_SGL_CMD);
	sg_set_buf(&skw->sgl_cmd[nr++], data, data_len);
	total_len = data_len;

	skw_set_extra_hdr(skw, skw->eof_blk, skw->hw.cmd_port, skw->hw.align, 0, 1);
	sg_set_buf(&skw->sgl_cmd[nr++], skw->eof_blk, skw->hw.align);
	total_len += skw->hw.align;

	if (test_bit(SKW_CMD_FLAG_DISABLE_IRQ, &skw->cmd.flags))
		return skw->hw.cmd_disable_irq_xmit(skw, NULL, -1,
				skw->hw.cmd_port, skw->sgl_cmd, nr, total_len);
	else
		return skw->hw.cmd_xmit(skw, NULL, -1, skw->hw.cmd_port,
					skw->sgl_cmd, nr, total_len);
}

int skw_usb_cmd_xmit(struct skw_core *skw, void *data, int data_len)
{
	int nr = 0, total_len;

	sg_init_table(skw->sgl_cmd, SKW_NR_SGL_CMD);
	sg_set_buf(&skw->sgl_cmd[nr++], data, data_len);
	total_len = data_len;

	return skw->hw.cmd_xmit(skw, NULL, -1, skw->hw.cmd_port,
			skw->sgl_cmd, nr, total_len);
}

static int skw_sync_sdma_tx(struct skw_core *skw, struct sk_buff_head *list,
			int lmac_id, int port, struct scatterlist *sgl,
			int nents, int tx_len)
{
	int total_len;
	int ret;
	struct sk_buff *skb, *tmp;

	if (!skw->hw_pdata || !skw->hw_pdata->hw_sdma_tx)
		return -EINVAL;

	if (!skw->sdma_buff) {
		skw_err("invalid buff\n");
		return -ENOMEM;
	}

	total_len = sg_copy_to_buffer(sgl, nents, skw->sdma_buff,
				skw->hw_pdata->max_buffer_size);

	ret = skw->hw_pdata->hw_sdma_tx(port, skw->sdma_buff, total_len);

	if (list) {
		if (likely(ret == 0))
			skw_sub_credit(skw, lmac_id, skb_queue_len(list));

		skb_queue_walk_safe(list, skb, tmp) {
			if (likely(ret == 0)) {
				skb->dev->stats.tx_packets++;
				skb->dev->stats.tx_bytes += SKW_SKB_TXCB(skb)->skb_native_len;
			} else
				skb->dev->stats.tx_errors++;

			__skb_unlink(skb, list);
			//kfree_skb(skb);
			skw_skb_kfree(skw, skb);
		}
		//skw_sub_credit(skw, lmac_id, skb_queue_len(list));
		//__skb_queue_purge(list);
	}

	return ret;
}

static int skw_sync_sdma_cmd_disable_irq_tx(struct skw_core *skw,
		struct sk_buff_head *list, int lmac_id, int port,
		struct scatterlist *sgl, int nents, int tx_len)
{
	int total_len;

	if (!skw->hw_pdata || !skw->hw_pdata->suspend_sdma_cmd)
		return -EINVAL;

	if (!skw->sdma_buff) {
		skw_err("invalid buff\n");
		return -ENOMEM;
	}

	total_len = sg_copy_to_buffer(sgl, nents, skw->sdma_buff,
				skw->hw_pdata->max_buffer_size);

	return skw->hw_pdata->suspend_sdma_cmd(port, skw->sdma_buff, total_len);
}

static int skw_async_sdma_tx(struct skw_core *skw, struct sk_buff_head *list,
			int lmac_id, int port, struct scatterlist *sgl,
			int nents, int tx_len)
{
	void *buff;
	int ret, total_len;
	struct sk_buff *skb, *tmp;

	if (!skw->hw_pdata || !skw->hw_pdata->hw_sdma_tx_async)
		return -EINVAL;

	buff = SKW_ZALLOC(tx_len, GFP_KERNEL);
	if (!buff) {
		skw_err("invalid buffer\n");
		return -ENOMEM;
	}

	total_len = sg_copy_to_buffer(sgl, nents, buff, tx_len);
	ret = skw->hw_pdata->hw_sdma_tx_async(port, buff, total_len);
	if (ret < 0)
		SKW_KFREE(buff);

	if (list) {
		if (likely(ret == 0))
			skw_sub_credit(skw, lmac_id, skb_queue_len(list));

		skb_queue_walk_safe(list, skb, tmp) {
			if (likely(ret == 0)) {
				skb->dev->stats.tx_packets++;
				skb->dev->stats.tx_bytes += SKW_SKB_TXCB(skb)->skb_native_len;
			} else
				skb->dev->stats.tx_errors++;

			__skb_unlink(skb, list);
			//kfree_skb(skb);
			skw_skb_kfree(skw, skb);
		}

		//skw_sub_credit(skw, lmac_id, skb_queue_len(list));
		//__skb_queue_purge(list);
	}

	return ret;
}

static int skw_sync_adma_tx(struct skw_core *skw, struct sk_buff_head *list,
			int lmac_id, int port, struct scatterlist *sgl,
			int nents, int tx_len)
{
	struct sk_buff *skb, *tmp;
	int ret;
	unsigned long flags;

	if (!skw->hw_pdata || !skw->hw_pdata->hw_adma_tx)
		return -EINVAL;

	ret = skw->hw_pdata->hw_adma_tx(port, sgl, nents, tx_len);
	trace_skw_hw_adma_tx_done(nents);
	if (ret < 0)
		skw_err("failed, ret: %d nents:%d\n", ret, nents);

	if (list) {
		if (likely(ret == 0))
			skw_sub_credit(skw, lmac_id, skb_queue_len(list));
		else
			skb_queue_walk_safe(list, skb, tmp)
				SKW_SKB_TXCB(skb)->ret = ret;

		spin_lock_irqsave(&skw->kfree_skb_qlist.lock, flags);
		skb_queue_splice_tail_init(list, &skw->kfree_skb_qlist);
		spin_unlock_irqrestore(&skw->kfree_skb_qlist.lock, flags);
		schedule_work(&skw->kfree_skb_task);
	}

	return ret;
}

static int skw_sync_adma_cmd_disable_irq_tx(struct skw_core *skw,
		struct sk_buff_head *list, int lmac_id, int port,
		struct scatterlist *sgl, int nents, int tx_len)
{
	if (!skw->hw_pdata || !skw->hw_pdata->suspend_adma_cmd)
		return -EINVAL;

	return skw->hw_pdata->suspend_adma_cmd(port, sgl, nents, tx_len);
}

static int skw_async_adma_tx(struct skw_core *skw, struct sk_buff_head *list,
			int lmac_id, int port, struct scatterlist *sgl,
			int nents, int tx_len)
{
	int ret, idx;
	struct sk_buff *skb;
	struct scatterlist *sg_list, *sg;
	unsigned long *skb_addr, *sg_addr;

	if (!skw->hw_pdata || !skw->hw_pdata->hw_adma_tx_async)
		return -EINVAL;

	if (!sgl) {
		ret = -ENOMEM;
		skw_err("sgl is NULL\n");
		goto out;
	}

	sg_list = kcalloc(SKW_NR_SGL_DAT, sizeof(*sg_list), GFP_KERNEL);

	ret = skw->hw_pdata->hw_adma_tx_async(port, sgl, nents, tx_len);
	if (ret < 0) {
		skw_err("failed, ret: %d\n", ret);

		for_each_sg(sgl, sg, nents, idx) {
			sg_addr = (unsigned long *)sg_virt(sg);

			skb_addr = sg_addr - 1;
			skb = (struct sk_buff *)*skb_addr;

			skb->dev->stats.tx_errors++;
			//kfree_skb(skb);
			skw_skb_kfree(skw, skb);
		}

		SKW_KFREE(sgl);
	} else {
		atomic_add(nents, &skw->txqlen_pending);
		skw_sub_credit(skw, lmac_id, nents);
	}

	skw->sgl_dat = sg_list;
out:
	return ret;
}

static int skw_async_adma_tx_free(int id, struct scatterlist *sg, int nents,
			   void *data, int status)
{
	struct skw_sg_node node;
	struct skw_core *skw = data;
	struct wiphy *wiphy = priv_to_wiphy(skw);

	node.sg = sg;
	node.nents = nents;
	node.status = status;

	skw_queue_work(wiphy, NULL, SKW_WORK_TX_FREE, &node, sizeof(node));

	return 0;
}

static int skw_async_sdma_tx_free(int id,  void *buffer, int size,
			   void *data, int status)
{
	SKW_KFREE(buffer);

	return 0;
}

int skw_sdio_xmit(struct skw_core *skw, int lmac_id, struct sk_buff_head *txq)
{
	struct sk_buff *skb;
	int nents = 0, tx_bytes = 0;
	struct skw_lmac *lmac = &skw->hw.lmac[lmac_id];

	sg_init_table(skw->sgl_dat, SKW_NR_SGL_DAT);

	skb_queue_walk(txq, skb) {
		int aligned;
		struct skw_packet_header *extra_hdr;

		extra_hdr = (void *)skb_push(skb, SKW_EXTER_HDR_SIZE);

		aligned = round_up(skb->len, skw->hw.align);
		skw_set_extra_hdr(skw, extra_hdr, lmac->lport, aligned, 0, 0);

		sg_set_buf(&skw->sgl_dat[nents++], skb->data, aligned);

		tx_bytes += aligned;
	}

	skw_set_extra_hdr(skw, skw->eof_blk, lmac->lport, skw->hw.align, 0, 1);
	sg_set_buf(&skw->sgl_dat[nents++], skw->eof_blk, skw->hw.align);
	tx_bytes += skw->hw.align;
	skw_detail("nents:%d", nents);

	return skw->hw.dat_xmit(skw, txq, lmac_id, lmac->dport,
				skw->sgl_dat, nents, tx_bytes);
}

int skw_usb_xmit(struct skw_core *skw, int lmac_id, struct sk_buff_head *txq)
{
	struct sk_buff *skb, *tmp;
	int nents = 0, tx_bytes = 0;
	unsigned long *skb_addr;
	struct skw_lmac *lmac = &skw->hw.lmac[lmac_id];

	sg_init_table(skw->sgl_dat, SKW_NR_SGL_DAT);

	skb_queue_walk_safe(txq, skb, tmp) {
		int aligned;
		struct skw_packet_header *extra_hdr;

		extra_hdr = (void *)skb_push(skb, SKW_EXTER_HDR_SIZE);

		aligned = round_up(skb->len, skw->hw.align);
		skw_set_extra_hdr(skw, extra_hdr, lmac->lport, aligned, 0, 0);

		sg_set_buf(&skw->sgl_dat[nents++], skb->data, aligned);

		skb_addr = (unsigned long *)skb_push(skb, sizeof(unsigned long));
		*skb_addr = (unsigned long)skb;
		skb_pull(skb, sizeof(unsigned long));

		tx_bytes += aligned;

		if (skb && skw->hw.dma == SKW_ASYNC_ADMA_TX)
			__skb_unlink(skb, txq);
	}

	return skw->hw.dat_xmit(skw, txq, lmac_id, lmac->dport,
				skw->sgl_dat, nents, tx_bytes);
}

int skw_pcie_xmit(struct skw_core *skw, int lmac_id, struct sk_buff_head *txq)
{
	int ret, tx_bytes = 0;
	unsigned long flags;
	struct sk_buff *skb;
	struct skw_lmac *lmac = &skw->hw.lmac[lmac_id];
	struct wiphy *wiphy = priv_to_wiphy(skw);

	skb_queue_walk(txq, skb) {
		skw_edma_set_data(wiphy, &lmac->edma_tx_chn,
				&SKW_SKB_TXCB(skb)->e,
				sizeof(SKW_SKB_TXCB(skb)->e));

		tx_bytes += round_up(skb->len, skw->hw.align);
	}

	skb = skb_peek(txq);

	spin_lock_irqsave(&lmac->edma_free_list.lock, flags);
	skb_queue_splice_tail_init(txq, &lmac->edma_free_list);
	spin_unlock_irqrestore(&lmac->edma_free_list.lock, flags);

	ret = skw_edma_tx(wiphy, &lmac->edma_tx_chn, tx_bytes);
	if (ret < 0) {
		skw_err("failed, ret: %d\n", ret);
		// TODO:
		// release free list
	}

	return ret;
}

static inline int skw_bus_data_xmit(struct skw_core *skw, int mac_id,
			struct sk_buff_head *txq_list)
{
	int ret;

	if (!skb_queue_len(txq_list))
		return 0;

	skw->tx_packets += skb_queue_len(txq_list);

	skw->dbg.dat_idx = (skw->dbg.dat_idx + 1) % skw->dbg.nr_dat;
	skw->dbg.dat[skw->dbg.dat_idx].qlen = skb_queue_len(txq_list);
	skw->dbg.dat[skw->dbg.dat_idx].trigger = skw_local_clock();

	ret = skw->hw.bus_dat_xmit(skw, mac_id, txq_list);

	skw->dbg.dat[skw->dbg.dat_idx].done = skw_local_clock();

	return ret;
}

static inline int skw_bus_cmd_xmit(struct skw_core *skw, void *cmd, int cmd_len)
{
	int ret;
	unsigned long flags = READ_ONCE(skw->flags);

	if (test_bit(SKW_CMD_FLAG_IGNORE_BLOCK_TX, &skw->cmd.flags))
		flags &= ~BIT(SKW_FLAG_BLOCK_TX);

	if (!skw_tx_allowed(flags)) {
		skw_warn("cmd: %s[%d] not allowed, flags: 0x%lx, cmd flags: 0x%lx\n",
			 skw->cmd.name, skw->cmd.id, skw->flags, skw->cmd.flags);

		skw_abort_cmd(skw);

		return 0;
	}

	skw->dbg.cmd[skw->dbg.cmd_idx].xmit = skw_local_clock();
	skw->dbg.cmd[skw->dbg.cmd_idx].loop = atomic_read(&skw->dbg.loop);

	ret = skw->hw.bus_cmd_xmit(skw, cmd, cmd_len);

	skw->dbg.cmd[skw->dbg.cmd_idx].done = skw_local_clock();

	return ret;
}

static inline bool is_skw_same_tcp_stream(struct sk_buff *skb,
					struct sk_buff *next)
{
	return ip_hdr(skb)->saddr == ip_hdr(next)->saddr &&
	       ip_hdr(skb)->daddr == ip_hdr(next)->daddr &&
	       tcp_hdr(skb)->source == tcp_hdr(next)->source &&
	       tcp_hdr(skb)->dest == tcp_hdr(next)->dest;
}

static void skw_merge_pure_ack(struct skw_core *skw, struct sk_buff_head *ackq,
				struct sk_buff_head *txq)
{
	int i, drop = 0;
	struct sk_buff *skb, *tmp;

	while ((skb = __skb_dequeue_tail(ackq))) {
		for (i = 0; i < ackq->qlen; i++) {
			tmp = __skb_dequeue(ackq);
			if (!tmp)
				break;

			if (is_skw_same_tcp_stream(skb, tmp)) {
				if (tcp_optlen(tmp) == 0 &&
				    tcp_flag_word(tcp_hdr(tmp)) == TCP_FLAG_ACK) {
					skw_skb_kfree(skw, tmp);
					drop++;
				} else {
					__skb_queue_tail(txq, tmp);
				}
			} else {
				__skb_queue_tail(ackq, tmp);
			}
		}

		__skb_queue_tail(txq, skb);
	}
}

static bool is_skw_peer_data_valid(struct skw_core *skw, struct sk_buff *skb)
{
	struct skw_ctx_entry *entry;
	bool valid = true;
	int peer_idx = SKW_SKB_TXCB(skb)->peer_idx;

	rcu_read_lock();

	entry = rcu_dereference(skw->peer_ctx[peer_idx].entry);
	if (entry) {
		if (entry->peer) {
			entry->peer->tx.bytes += skb->len;
			entry->peer->tx.pkts++;

			if (entry->peer->flags & SKW_PEER_FLAG_DEAUTHED)
				valid = false;
		} else {
			if (is_unicast_ether_addr(eth_hdr(skb)->h_dest))
				valid = false;
		}
	}

	rcu_read_unlock();

	return valid;
}

static inline void skw_reset_ac(struct skw_tx_lmac *txlp)
{
	int i;

	for (i = 0; i < SKW_MAX_LMAC_SUPPORT; i++) {
		txlp->ac_reset = 0xF;
		txlp++;
	}
}

static void skw_kfree_skb_worker(struct work_struct *work)
{
	unsigned long flags;
	struct sk_buff *skb, *tmp;
	struct sk_buff_head qlist;
	struct skw_core *skw = container_of(work, struct skw_core, kfree_skb_task);

	__skb_queue_head_init(&qlist);

	while (!skb_queue_empty(&skw->kfree_skb_qlist)) {
		spin_lock_irqsave(&skw->kfree_skb_qlist.lock, flags);
		skb_queue_splice_tail_init(&skw->kfree_skb_qlist, &qlist);
		spin_unlock_irqrestore(&skw->kfree_skb_qlist.lock, flags);

		skb_queue_walk_safe(&qlist, skb, tmp) {
			if (likely(0 == SKW_SKB_TXCB(skb)->ret)) {
				skb->dev->stats.tx_packets++;
				skb->dev->stats.tx_bytes += SKW_SKB_TXCB(skb)->skb_native_len;
			} else
				skb->dev->stats.tx_errors++;

			__skb_unlink(skb, &qlist);
			skw_skb_kfree(skw, skb);
		}
	}

	return;
}

#ifdef CONFIG_SKW_TX_WORKQUEUE
void skw_tx_worker(struct work_struct *work)
{
	int i, ac, mac;
	int base = 0;
	unsigned long flags;
	int lmac_tx_capa;
	int qlen, pending_qlen = 0;
	int max_tx_count_limit = 0;
	struct sk_buff *skb;
	struct skw_iface *iface;
	struct sk_buff_head *qlist;
	struct netdev_queue *txq;
	struct skw_tx_lmac txl[SKW_MAX_LMAC_SUPPORT];
	struct skw_tx_lmac *txlp;
	struct sk_buff_head pure_ack_list;
	int xmit_tx_flag;
	struct skw_core *skw = container_of(to_delayed_work(work), struct skw_core, tx_worker);
	int all_credit, times = 0;

start:

	memset(txl, 0, sizeof(txl));
	skw_reset_ac(txl);

	max_tx_count_limit = skw->hw.pkt_limit;

	/* reserve one for eof block */
	if (skw->hw.bus == SKW_BUS_SDIO)
		max_tx_count_limit--;

	for (i = 0; i < skw->hw.nr_lmac; i++) {
		__skb_queue_head_init(&txl[i].tx_list);
		txl[i].tx_count_limit = max_tx_count_limit;
	}

	while (!atomic_read(&skw->exit)) {
		// TODO:
		/* CPU bind */
		/* check if frame in pending queue is timeout */

		atomic_inc(&skw->dbg.loop);

		if (test_and_clear_bit(SKW_CMD_FLAG_XMIT, &skw->cmd.flags)) {
			skw_bus_cmd_xmit(skw, skw->cmd.data, skw->cmd.data_len);

			if (test_bit(SKW_CMD_FLAG_NO_ACK, &skw->cmd.flags)) {
				set_bit(SKW_CMD_FLAG_DONE, &skw->cmd.flags);
				skw->cmd.callback(skw);
			}
		}

		if (!skw_tx_allowed(READ_ONCE(skw->flags))) {
			pending_qlen = 0;

			return;
		}

		pending_qlen = 0;

		all_credit = 0;
		for (mac = 0; mac < skw->hw.nr_lmac; mac++)
			if (skw_lmac_is_actived(skw, mac))
				all_credit += skw_get_hw_credit(skw, mac);

		if (all_credit == 0) {
			if (skw->hw.bus == SKW_BUS_SDIO || skw->hw.bus == SKW_BUS_SDIO2) {
				if (times++ > tx_wait_time)
					return;
				else
					goto start;
			}

			if (skw->hw.bus == SKW_BUS_PCIE)
				skw_wakeup_tx(skw, 0);
			return;
		}

		for (ac = 0; ac < SKW_WMM_AC_MAX; ac++) {
			int ac_qlen = 0;

			for (i = 0; i < SKW_NR_IFACE; i++) {
				iface = skw->vif.iface[i];
				// if (!iface || skw_lmac_is_actived(skw, iface->lmac_id))
				if (!iface || !iface->ndev)
					continue;

				if (ac == SKW_WMM_AC_BE && iface->txq[SKW_ACK_TXQ].qlen) {
					qlist = &iface->txq[SKW_ACK_TXQ];

					__skb_queue_head_init(&pure_ack_list);

					spin_lock_irqsave(&qlist->lock, flags);
					skb_queue_splice_tail_init(&iface->txq[SKW_ACK_TXQ],
								&pure_ack_list);
					spin_unlock_irqrestore(&qlist->lock, flags);

					skw_merge_pure_ack(skw, &pure_ack_list,
							&iface->tx_cache[ac]);
				}

				qlist = &iface->txq[ac];
				if (!skb_queue_empty(qlist)) {
					spin_lock_irqsave(&qlist->lock, flags);
					skb_queue_splice_tail_init(qlist,
							&iface->tx_cache[ac]);
					spin_unlock_irqrestore(&qlist->lock, flags);
				}

				if (READ_ONCE(iface->flags) & SKW_IFACE_FLAG_DEAUTH) {
					while ((skb = __skb_dequeue(&iface->tx_cache[ac])) != NULL)
						skw_skb_kfree(skw, skb);
				}

				qlen = skb_queue_len(&iface->tx_cache[ac]);
				if (qlen < SKW_TXQ_LOW_THRESHOLD) {
					txq = netdev_get_tx_queue(iface->ndev, ac);
					if (netif_tx_queue_stopped(txq)) {
						netif_tx_start_queue(txq);
						netif_schedule_queue(txq);
					}
				}

				if (qlen) {
					txlp = &txl[iface->lmac_id];
					txlp->current_qlen += qlen;

					txlp->txq_map |= BIT(txlp->nr_txq);

					txlp->tx[txlp->nr_txq].list = &iface->tx_cache[ac];
					txlp->tx[txlp->nr_txq].reset = true;
					txlp->reset = true;
					if (txlp->ac_reset & BIT(ac)) {
						txlp->tx[txlp->nr_txq].quota = iface->wmm.factor[ac];
						txlp->ac_reset ^= BIT(ac);
					}

					txlp->nr_txq++;
					ac_qlen += qlen;
				}
			}

			if (!ac_qlen)
				continue;

			pending_qlen += ac_qlen;

			lmac_tx_capa = 0;

			for (mac = 0; mac < skw->hw.nr_lmac; mac++) {
				int credit;

				txlp = &txl[mac];
				if (!txlp->txq_map)
					goto reset;

				credit = txlp->cred = skw_get_hw_credit(skw, mac);
				if (!txlp->cred)
					goto reset;

				if (txlp->reset) {
					switch (ac) {
					case SKW_WMM_AC_VO:
						base = SKW_BASE_VO;
						break;

					case SKW_WMM_AC_VI:
						base = SKW_BASE_VI;
						break;

					case SKW_WMM_AC_BK:
						if (txlp->bk_tx_limit) {
							base = min(txlp->cred, txlp->bk_tx_limit);
							txlp->bk_tx_limit = 0;
						} else {
							base = txlp->cred;
						}

						base = base / txlp->nr_txq;
						break;

					default:
						base = min(txlp->cred, txlp->current_qlen);
						base = base / txlp->nr_txq;
						txlp->bk_tx_limit = (txlp->cred + 1) >> 1;
						break;
					}

					base = base ? base : 1;
					txlp->reset = false;
				} else
					base = 0;

				for (i = 0; txlp->txq_map != 0; i++) {
					i = i % txlp->nr_txq;
					if (!(txlp->txq_map & BIT(i)))
						continue;

					if (!txlp->cred)
						break;

					if (txlp->tx[i].reset) {
						txlp->tx[i].quota += base;

						if (txlp->tx[i].quota < 0)
							txlp->tx[i].quota = 0;

						txlp->tx[i].reset = false;
					}

					skb = skb_peek(txlp->tx[i].list);
					if (!skb) {
						txlp->txq_map ^= BIT(i);
						continue;
					}

					if (!is_skw_peer_data_valid(skw, skb)) {
						skw_detail("drop dest: %pM\n",
							   eth_hdr(skb)->h_dest);

						__skb_unlink(skb, txlp->tx[i].list);
						skw_skb_kfree(skw, skb);

						continue;
					}

					if (!txlp->tx_count_limit--)
						break;

					if (txlp->tx[i].quota) {
						txlp->tx[i].quota--;
					} else {
						txlp->txq_map ^= BIT(i);
						continue;
					}

					if ((long)skb->data & SKW_DATA_ALIGN_MASK)
						skw_warn("address unaligned\n");

#if 0
					if (skb->len % skw->hw_pdata->align_value)
						skw_warn("len: %d unaligned\n", skb->len);
#endif

					__skb_unlink(skb, txlp->tx[i].list);
					__skb_queue_tail(&txlp->tx_list, skb);

					txlp->cred--;
				}

				pending_qlen = pending_qlen - credit + txlp->cred;

				trace_skw_tx_info(mac, ac, credit, credit - txlp->cred, txlp->current_qlen);

				if (skw_bus_data_xmit(skw, mac, &txlp->tx_list) >= 0)
					skw->trans_start = jiffies;

				txlp->tx_count_limit = max_tx_count_limit;

				if (txlp->cred)
					lmac_tx_capa |= BIT(mac);

reset:
				txlp->nr_txq = 0;
				txlp->txq_map = 0;
				txlp->current_qlen = 0;
			}

			if (!lmac_tx_capa)
				break;
		}

		if (ac == SKW_WMM_AC_MAX)
			skw_reset_ac(txl);

		if (pending_qlen == 0) {
			xmit_tx_flag = 0;

			for (ac = 0; ac < SKW_WMM_AC_MAX; ac++) {
				for (i = 0; i < SKW_NR_IFACE; i++) {
					iface = skw->vif.iface[i];
					if (!iface || !iface->ndev)
						continue;

					if (skb_queue_len(&iface->tx_cache[ac]) != 0) {
						xmit_tx_flag = 1;
						goto need_running;
					}

					spin_lock_irqsave(&iface->txq[ac].lock, flags);

					if (skb_queue_len(&iface->txq[ac]) != 0) {
						xmit_tx_flag = 1;
						spin_unlock_irqrestore(&iface->txq[ac].lock, flags);
						goto need_running;
					}

					spin_unlock_irqrestore(&iface->txq[ac].lock, flags);
				}
			}
need_running:
			if (test_bit(SKW_CMD_FLAG_XMIT, &skw->cmd.flags))
				xmit_tx_flag = 1;

			if (xmit_tx_flag == 0) {
				skw_start_dev_queue(skw);
				return;
			}
		}
	}
}


static int __skw_tx_init(struct skw_core *skw)
{
	//struct workqueue_attrs wq_attrs;
#ifdef CONFIG_SKW_SKB_RECYCLE
	int i;
	struct sk_buff *skb;
#endif

	skw->tx_wq = alloc_workqueue("skw_txwq.%d",
			WQ_UNBOUND | WQ_CPU_INTENSIVE | WQ_HIGHPRI | WQ_SYSFS,
			0, skw->idx);
	if (!skw->tx_wq) {
		skw_err("alloc skwtx_workqueue failed\n");
		return -EFAULT;
	}

	//memset(&wq_attrs, 0, sizeof(wq_attrs));

	//wq_attrs.nice = MIN_NICE;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 16, 0) && LINUX_VERSION_CODE <= KERNEL_VERSION(5, 2, 0)
	//apply_workqueue_attrs(skw->tx_wq, &wq_attrs);
#endif

	INIT_DELAYED_WORK(&skw->tx_worker, skw_tx_worker);
	queue_delayed_work(skw->tx_wq, &skw->tx_worker, msecs_to_jiffies(0));
	//queue_work_on(cpumask_last(cpu_online_mask), skw->tx_wq, &skw->tx_worker);
	skw->trans_start = 0;

	skb_queue_head_init(&skw->kfree_skb_qlist);
	INIT_WORK(&skw->kfree_skb_task, skw_kfree_skb_worker);

	skb_queue_head_init(&skw->skb_recycle_qlist);
#ifdef CONFIG_SKW_SKB_RECYCLE
	for (i = 0; i < SKW_SKB_RECYCLE_COUNT; i++) {
		skb = dev_alloc_skb(SKW_2K_SIZE);
		if (skb)
			skb_queue_tail(&skw->skb_recycle_qlist, skb);
		else {
			__skb_queue_purge(&skw->skb_recycle_qlist);
			destroy_workqueue(skw->tx_wq);
			skw_err("alloc skb recycle failed\n");
			return -ENOMEM;
		}
	}
#endif

	return 0;
}

static void __skw_tx_deinit(struct skw_core *skw)
{
	atomic_set(&skw->exit, 1);
	cancel_delayed_work(&skw->tx_worker);
	destroy_workqueue(skw->tx_wq);
	skb_queue_purge(&skw->skb_recycle_qlist);
}

#else

static int skw_tx_thread(void *data)
{
	struct skw_core *skw = data;
	int i, ac, mac;
	int base = 0;
	unsigned long flags;
	int lmac_tx_capa;
	int qlen, pending_qlen = 0;
	int max_tx_count_limit = 0;
	int lmac_tx_map = 0;
	struct sk_buff *skb;
	struct skw_iface *iface;
	struct sk_buff_head *qlist;
	struct skw_tx_lmac txl[SKW_MAX_LMAC_SUPPORT];
	struct skw_tx_lmac *txlp;
	struct sk_buff_head pure_ack_list;
	int xmit_tx_flag;
	int all_credit;

	memset(txl, 0, sizeof(txl));
	skw_reset_ac(txl);

	max_tx_count_limit = skw->hw.pkt_limit;

	/* reserve one for eof block */
	if (skw->hw.bus == SKW_BUS_SDIO)
		max_tx_count_limit--;

	for (i = 0; i < skw->hw.nr_lmac; i++) {
		__skb_queue_head_init(&txl[i].tx_list);
		txl[i].tx_count_limit = max_tx_count_limit;
	}

	while (!kthread_should_stop()) {
		// TODO:
		/* CPU bind */
		/* check if frame in pending queue is timeout */

		atomic_inc(&skw->dbg.loop);

		if (test_and_clear_bit(SKW_CMD_FLAG_XMIT, &skw->cmd.flags)) {
			skw_bus_cmd_xmit(skw, skw->cmd.data, skw->cmd.data_len);

			if (test_bit(SKW_CMD_FLAG_NO_ACK, &skw->cmd.flags)) {
				set_bit(SKW_CMD_FLAG_DONE, &skw->cmd.flags)
				skw->cmd.callback(skw);
			}
		}

		if (!skw_tx_allowed(skw->flags)) {
			set_current_state(TASK_INTERRUPTIBLE);
			schedule_timeout(msecs_to_jiffies(200));
			continue;
		}

		pending_qlen = 0;
		lmac_tx_map = 0;

		for (ac = 0; ac < SKW_WMM_AC_MAX; ac++) {
			int ac_qlen = 0;

			for (i = 0; i < SKW_NR_IFACE; i++) {
				iface = skw->vif.iface[i];
				// if (!iface || skw_lmac_is_actived(skw, iface->lmac_id))
				if (!iface || !iface->ndev)
					continue;

				if (ac == SKW_WMM_AC_BE && iface->txq[SKW_ACK_TXQ].qlen) {
					qlist = &iface->txq[SKW_ACK_TXQ];
					__skb_queue_head_init(&pure_ack_list);

					spin_lock_irqsave(&qlist->lock, flags);
					skb_queue_splice_tail_init(&iface->txq[SKW_ACK_TXQ],
								&pure_ack_list);
					spin_unlock_irqrestore(&qlist->lock, flags);

					skw_merge_pure_ack(&pure_ack_list, &iface->tx_cache[ac]);
				}

				qlist = &iface->txq[ac];
				if (!skb_queue_empty(qlist)) {
					spin_lock_irqsave(&qlist->lock, flags);
					skb_queue_splice_tail_init(qlist, &iface->tx_cache[ac]);
					spin_unlock_irqrestore(&qlist->lock, flags);
				}

				qlen = skb_queue_len(&iface->tx_cache[ac]);
				if (qlen) {
					txlp = &txl[iface->lmac_id];
					txlp->current_qlen += qlen;
					txlp->txq_map |= BIT(txlp->nr_txq);
					txlp->tx[txlp->nr_txq].list = &iface->tx_cache[ac];

					if (txlp->ac_reset & BIT(ac)) {
						txlp->tx[txlp->nr_txq].quota = iface->wmm.factor[ac];
						txlp->tx[txlp->nr_txq].reset = true;
						txlp->reset = true;
						txlp->ac_reset ^= BIT(ac);
					}

					txlp->nr_txq++;
					ac_qlen += qlen;
				}
			}

			if (!ac_qlen)
				continue;

			pending_qlen += ac_qlen;
			lmac_tx_capa = 0;

			all_credit = 0;
			for (mac = 0; mac < skw->hw.nr_lmac; mac++)
				all_credit += skw_get_hw_credit(skw, mac);

			if (all_credit == 0) {
				skw_stop_dev_queue(skw);
				wait_event_interruptible_exclusive(skw->tx_wait_q,
					atomic_xchg(&skw->tx_wake, 0) || atomic_xchg(&skw->exit, 0));
				skw_start_dev_queue(skw);
			}

			for (mac = 0; mac < skw->hw.nr_lmac; mac++) {
				int credit;

				txlp = &txl[mac];
				if (!txlp->txq_map)
					goto reset;

				credit = txlp->cred = skw_get_hw_credit(skw, mac);
				if (!txlp->cred)
					goto reset;

				if (txlp->reset) {
					switch (ac) {
					case SKW_WMM_AC_VO:
						base = SKW_BASE_VO;
						break;

					case SKW_WMM_AC_VI:
						base = SKW_BASE_VI;
						break;

					case SKW_WMM_AC_BK:
						if (txlp->bk_tx_limit) {
							base = min(txlp->cred, txlp->bk_tx_limit);
							txlp->bk_tx_limit = 0;
						} else {
							base = txlp->cred;
						}

						base = base / txlp->nr_txq;

						break;
					default:
						base = min(txlp->cred, txlp->current_qlen);
						base = base / txlp->nr_txq;
						txlp->bk_tx_limit = (txlp->cred + 1) >> 1;

						break;
					}

					base = base ? base : 1;
					txlp->reset = false;
				}

				for (i = 0; txlp->txq_map != 0; i++) {
					i = i % txlp->nr_txq;

					if (!(txlp->txq_map & BIT(i)))
						continue;

					if (!txlp->cred)
						break;

					if (txlp->tx[i].reset) {
						txlp->tx[i].quota += base;

						if (txlp->tx[i].quota < 0)
							txlp->tx[i].quota = 0;

						txlp->tx[i].reset = false;
					}

					skb = skb_peek(txlp->tx[i].list);
					if (!skb) {
						txlp->txq_map ^= BIT(i);
						continue;
					}

					if (!is_skw_peer_data_valid(skw, skb)) {
						skw_detail("drop dest: %pM\n",
							   eth_hdr(skb)->h_dest);

						__skb_unlink(skb, txlp->tx[i].list);
						kfree_skb(skb);

						continue;
					}

					if (!txlp->tx_count_limit--)
						break;

					if (txlp->tx[i].quota) {
						txlp->tx[i].quota--;
					} else {
						txlp->txq_map ^= BIT(i);
						continue;
					}

					if ((long)skb->data & SKW_DATA_ALIGN_MASK)
						skw_warn("address unaligned\n");
#if 0
					if (skb->len % skw->hw_pdata->align_value)
						skw_warn("len: %d unaligned\n", skb->len);
#endif
					__skb_unlink(skb, txlp->tx[i].list);
					__skb_queue_tail(&txlp->tx_list, skb);
					txlp->cred--;
				}

				pending_qlen = pending_qlen - credit + txlp->cred;

				trace_skw_tx_info(mac, ac, credit, credit - txlp->cred, txlp->current_qlen);

				// skw_lmac_tx(skw, mac, &txlp->tx_list);
				skw_bus_data_xmit(skw, mac, &txlp->tx_list);
				txlp->tx_count_limit = max_tx_count_limit;

				lmac_tx_map |= BIT(mac);

				if (txlp->cred)
					lmac_tx_capa |= BIT(mac);
reset:
				txlp->nr_txq = 0;
				txlp->txq_map = 0;
				txlp->current_qlen = 0;
			}

			if (!lmac_tx_capa)
				break;
		}

		if (ac == SKW_WMM_AC_MAX)
			skw_reset_ac(txl);

		if (pending_qlen == 0) {
			xmit_tx_flag = 0;

			for (ac = 0; ac < SKW_WMM_AC_MAX; ac++) {
				for (i = 0; i < SKW_NR_IFACE; i++) {
					iface = skw->vif.iface[i];
					if (!iface || !iface->ndev)
						continue;

					if (skb_queue_len(&iface->tx_cache[ac]) != 0) {
						xmit_tx_flag = 1;
						goto need_running;
					}

					spin_lock_irqsave(&iface->txq[ac].lock, flags);
					if (skb_queue_len(&iface->txq[ac]) != 0) {
						xmit_tx_flag = 1;
						spin_unlock_irqrestore(&iface->txq[ac].lock, flags);
						goto need_running;
					}
					spin_unlock_irqrestore(&iface->txq[ac].lock, flags);
				}
			}
need_running:

			if (xmit_tx_flag == 0) {
				//skw_start_dev_queue(skw);
				wait_event_interruptible_exclusive(skw->tx_wait_q,
					atomic_xchg(&skw->tx_wake, 0) || atomic_xchg(&skw->exit, 0));
			}
		}
	}

	skw_info("exit");

	return 0;
}

static int __skw_tx_init(struct skw_core *skw)
{
	skw->tx_thread = kthread_create(skw_tx_thread, skw, "skw_tx.%d", skw->idx);
	if (IS_ERR(skw->tx_thread)) {
		skw_err("create tx thread failed\n");
		return  PTR_ERR(skw->tx_thread);
	}

	//kthread_bind(skw->tx_thread, cpumask_last(cpu_online_mask));

	skw_set_thread_priority(skw->tx_thread, SCHED_RR, 1);
	set_user_nice(skw->tx_thread, MIN_NICE);
	wake_up_process(skw->tx_thread);

	return 0;
}

static void __skw_tx_deinit(struct skw_core *skw)
{
	if (skw->tx_thread) {
		atomic_set(&skw->exit, 1);
		kthread_stop(skw->tx_thread);
		skw->tx_thread = NULL;
	}
}

#endif

static int skw_register_tx_callback(struct skw_core *skw, void *func, void *data)
{
	int i, map, ret = 0;

	for (map = 0, i = 0; i < SKW_MAX_LMAC_SUPPORT; i++) {
		if (!(skw->hw.lmac[i].flags & SKW_LMAC_FLAG_TXCB))
			continue;

		ret = skw_register_tx_cb(skw, skw->hw.lmac[i].dport, func, data);
		if (ret < 0) {
			skw_err("chip: %d, hw mac: %d, port: %d failed, ret: %d\n",
				skw->idx, i, skw->hw.lmac[i].dport, ret);

			break;
		}

		map |= BIT(skw->hw.lmac[i].dport);
	}

	skw_dbg("chip: %d, %s data port: 0x%x\n",
		skw->idx, func ? "register" : "unregister", map);

	return ret;
}

int skw_hw_xmit_init(struct skw_core *skw, int dma)
{
	int ret = 0;

	skw_dbg("dma: %d\n", dma);

	switch (dma) {
	case SKW_SYNC_ADMA_TX:
		skw->hw.dat_xmit = skw_sync_adma_tx;
		skw->hw.cmd_xmit = skw_sync_adma_tx;
		skw->hw.cmd_disable_irq_xmit = skw_sync_adma_cmd_disable_irq_tx;
		break;

	case SKW_SYNC_SDMA_TX:
		skw->hw.dat_xmit = skw_sync_sdma_tx;
		skw->hw.cmd_xmit = skw_sync_sdma_tx;
		skw->hw.cmd_disable_irq_xmit = skw_sync_sdma_cmd_disable_irq_tx;

		if (skw->sdma_buff)
			break;
		skw->sdma_buff = SKW_ZALLOC(skw->hw_pdata->max_buffer_size, GFP_KERNEL);
		if (!skw->sdma_buff)
			ret = -ENOMEM;

		break;

	case SKW_ASYNC_ADMA_TX:
		skw->hw.dat_xmit = skw_async_adma_tx;
		skw->hw.cmd_xmit = skw_sync_adma_tx;
		skw->hw.cmd_disable_irq_xmit = NULL;

		ret = skw_register_tx_callback(skw, skw_async_adma_tx_free, skw);
		break;

	case SKW_ASYNC_SDMA_TX:
		skw->hw.dat_xmit = skw_async_sdma_tx;
		skw->hw.cmd_xmit = skw_sync_sdma_tx;
		skw->hw.cmd_disable_irq_xmit = NULL;

		ret = skw_register_tx_callback(skw, skw_async_sdma_tx_free, skw);

		if (skw->sdma_buff)
			break;
		skw->sdma_buff = SKW_ZALLOC(skw->hw_pdata->max_buffer_size, GFP_KERNEL);
		if (!skw->sdma_buff)
			ret = -ENOMEM;
		break;

	case SKW_ASYNC_EDMA_TX:
		skw->hw.dat_xmit = NULL;
		skw->hw.cmd_xmit = skw_sync_adma_tx;
		skw->hw.cmd_disable_irq_xmit = NULL;
		break;

	default:
		ret = -EINVAL;
		skw->hw.dat_xmit = NULL;
		skw->hw.cmd_xmit = NULL;
		break;
	}

	return ret;
}

int skw_tx_init(struct skw_core *skw)
{
	int ret;

	skw->skb_share_len = SKB_DATA_ALIGN(sizeof(struct skb_shared_info));
	skw->skb_headroom = sizeof(struct skw_tx_desc_hdr) +
			    sizeof(struct skw_tx_desc_conf) +
			    skw->hw.extra.hdr_len +
			    SKW_DATA_ALIGN_SIZE + sizeof(unsigned long);

	if (skw->hw.bus == SKW_BUS_SDIO) {
		skw->eof_blk = SKW_ZALLOC(skw->hw.align, GFP_KERNEL);
		if (!skw->eof_blk)
			return -ENOMEM;
	} else if (skw->hw.bus == SKW_BUS_PCIE) {
		skw->skb_headroom = sizeof(struct skw_tx_desc_conf) +
				    SKW_DATA_ALIGN_SIZE;
	}

	ret = skw_hw_xmit_init(skw, skw->hw.dma);
	if (ret < 0) {
		SKW_KFREE(skw->eof_blk);
		return ret;
	}

	ret = __skw_tx_init(skw);
	if (ret < 0) {
		SKW_KFREE(skw->eof_blk);
		SKW_KFREE(skw->sdma_buff);
	}

	tx_wait_time = SKW_TX_WAIT_TIME;
	skw_procfs_file(skw->pentry, "tx_wait_time", 0666, &skw_tx_time_fops, NULL);

	return ret;
}

int skw_tx_deinit(struct skw_core *skw)
{
	__skw_tx_deinit(skw);

	skw_register_tx_callback(skw, NULL, NULL);

	SKW_KFREE(skw->eof_blk);
	SKW_KFREE(skw->sdma_buff);

	return 0;
}
===== ./drivers/skwifi/skw_util.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/kernel.h>
#include <linux/etherdevice.h>

#include "skw_core.h"
#include "skw_util.h"
#include "skw_cfg80211.h"

#ifdef CONFIG_PRINTK_TIME_FROM_ARM_ARCH_TIMER
#include <clocksource/arm_arch_timer.h>
u64 skw_local_clock(void)
{
	u64 ns;

	ns = arch_timer_read_counter() * 1000;
	do_div(ns, 24);

	return ns;
}
#else
u64 skw_local_clock(void)
{
	return local_clock();
}
#endif

#ifdef SKW_IMPORT_NS
struct file *skw_file_open(const char *path, int flags, int mode)
{
	struct file *fp = NULL;

	fp = filp_open(path, flags, mode);
	if (IS_ERR(fp)) {
		skw_err("open fail\n");
		return NULL;
	}

	return fp;
}

int skw_file_read(struct file *fp, unsigned char *data,
		size_t size, loff_t offset)
{
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0)
	return kernel_read(fp, data, size, &offset);
#else
	return kernel_read(fp, offset, data, size);
#endif
}

int skw_file_write(struct file *fp, unsigned char *data,
		size_t size, loff_t offset)
{
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0)
	return kernel_write(fp, data, size, &offset);
#else
	return kernel_write(fp, data, size, offset);
#endif
}

int skw_file_sync(struct file *fp)
{
	return vfs_fsync(fp, 0);
}

void skw_file_close(struct file *fp)
{
	filp_close(fp, NULL);
}

MODULE_IMPORT_NS(VFS_internal_I_am_really_a_filesystem_and_am_NOT_a_driver);
#endif

void *skw_build_presp_frame(struct wiphy *wiphy, struct skw_iface *iface,
			u8 *da, u8 *sa, u8 *bssid, u8 *ssid, int ssid_len,
			u16 chan, struct ieee80211_supported_band *sband,
			u16 capa, u64 tsf, int beacon_int, void *ie, int ie_len)
{
	u8 *pos;
	int i, rate;
	struct skw_template *temp;
	struct ieee80211_mgmt *mgmt;

	skw_dbg("ssid: %s, bssid: %pM\n", ssid, bssid);

	temp = SKW_ZALLOC(1600, GFP_KERNEL);
	if (!temp)
		return NULL;

	mgmt = temp->mgmt;
	mgmt->frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT |
					IEEE80211_STYPE_PROBE_RESP);
	memcpy(mgmt->sa, sa, ETH_ALEN);
	memcpy(mgmt->da, da, ETH_ALEN);
	memcpy(mgmt->bssid, bssid, ETH_ALEN);

	mgmt->u.beacon.beacon_int = cpu_to_le16(beacon_int);
	mgmt->u.beacon.timestamp = cpu_to_le64(tsf);
	mgmt->u.beacon.capab_info = cpu_to_le16(capa);

	pos = mgmt->u.beacon.variable;

	*pos++ = WLAN_EID_SSID;
	*pos++ = ssid_len;
	memcpy(pos, ssid, ssid_len);
	pos += ssid_len;

	*pos++ = WLAN_EID_SUPP_RATES;
	*pos++ = SKW_BASIC_RATE_COUNT;
	for (i = 0; i < SKW_BASIC_RATE_COUNT; i++) {
		rate = DIV_ROUND_UP(sband->bitrates[i].bitrate, 5);
		if (sband->bitrates[i].flags & 0x1)
			rate |= 0x80;
		*pos++ = rate;
	}

#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 7, 0)
	if (sband->band == IEEE80211_BAND_2GHZ) {
#else
	if (sband->band == NL80211_BAND_2GHZ) {
#endif
		*pos++ = WLAN_EID_DS_PARAMS;
		*pos++ = 1;
		*pos++ = chan;
	}

	if (iface->wdev.iftype == NL80211_IFTYPE_ADHOC) {
		*pos++ = WLAN_EID_IBSS_PARAMS;
		*pos++ = 2;
		*pos++ = 0;
		*pos++ = 0;
	}

	*pos++ = WLAN_EID_EXT_SUPP_RATES;
	*pos++ = sband->n_bitrates - SKW_BASIC_RATE_COUNT;
	for (i = SKW_BASIC_RATE_COUNT; i < sband->n_bitrates; i++) {
		rate = DIV_ROUND_UP(sband->bitrates[i].bitrate, 5);
		if (sband->bitrates[i].flags & 0x1)
			rate |= 0x80;
		*pos++ = rate;
	}

	if (ie_len) {
		memcpy(pos, ie, ie_len);
	}

	return temp;
}

int skw_key_idx(u16 bitmap)
{
	static u8 idx[] = {0xff, 0x00, 0x01, 0xff,
			   0x02, 0xff, 0xff, 0xff,
			   0x03, 0xff, 0xff, 0xff,
			   0xff, 0xff, 0xff, 0xff};

	return idx[bitmap & 0xf];
}

int skw_build_deauth_frame(void *buf, int buf_len, u8 *da, u8 *sa,
			u8 *bssid, u16 reason_code)
{
	u16 fc = IEEE80211_FTYPE_MGMT | IEEE80211_STYPE_DEAUTH;
	struct ieee80211_mgmt *mgmt = buf;

	if (!buf || buf_len < SKW_DEAUTH_FRAME_LEN)
		return -EINVAL;

	mgmt->frame_control = cpu_to_le16(fc);
	mgmt->duration = 0;
	mgmt->seq_ctrl = 0;
	skw_ether_copy(mgmt->da, da);
	skw_ether_copy(mgmt->sa, sa);
	skw_ether_copy(mgmt->bssid, bssid);

	mgmt->u.deauth.reason_code = cpu_to_le16(reason_code);

	return SKW_DEAUTH_FRAME_LEN;
}

char *skw_mgmt_name(u16 fc)
{
#define SKW_STYPE_STR(n) {case IEEE80211_STYPE_##n: return #n; }

	switch (fc) {
	SKW_STYPE_STR(ASSOC_REQ);
	SKW_STYPE_STR(ASSOC_RESP);
	SKW_STYPE_STR(REASSOC_REQ);
	SKW_STYPE_STR(REASSOC_RESP);
	SKW_STYPE_STR(PROBE_REQ);
	SKW_STYPE_STR(PROBE_RESP);
	SKW_STYPE_STR(BEACON);
	SKW_STYPE_STR(ATIM);
	SKW_STYPE_STR(DISASSOC);
	SKW_STYPE_STR(AUTH);
	SKW_STYPE_STR(DEAUTH);
	SKW_STYPE_STR(ACTION);

	default:
		break;
	}

#undef SKW_STYPE_STR

	return "UNDEFINE";
}

int skw_freq_to_chn(int freq)
{
	if (freq == 2484)
		return 14;
	else if (freq >= 2407 && freq < 2484)
		return (freq - 2407) / 5;
	else if (freq >= 4910 && freq <= 4980)
		return (freq - 4000) / 5;
	else if (freq >= 5000 && freq <= 45000)
		return (freq - 5000) / 5;
	else if (freq >= 58320 && freq <= 64800)
		return (freq - 56160) / 2160;
	else
		return 0;
}

u32 skw_calc_rate(u64 bytes, u32 delta_ms)
{
	struct skw_tp_rate ret;
	u64 cal_bytes = bytes;
	u16 bps;
	u16 Kbps;
	u16 Mbps;
	u16 Gbps;
	u16 Tbps;

	ret.ret = 0;
	cal_bytes *= 8 * 1000;
	do_div(cal_bytes, delta_ms);
	bps = do_div(cal_bytes, 1 << 10);
	Kbps = do_div(cal_bytes, 1 << 10);
	Mbps = do_div(cal_bytes, 1 << 10);
	Gbps = do_div(cal_bytes, 1 << 10);
	Tbps = cal_bytes;

	if (Tbps) {
		ret.rate.value = Tbps;
		ret.rate.unit = 'T';
		ret.rate.two_dec = Gbps * 100 >> 10;
	} else if (Gbps) {
		ret.rate.value = Gbps;
		ret.rate.unit = 'G';
		ret.rate.two_dec = Mbps * 100 >> 10;
	} else if (Mbps) {
		ret.rate.value = Mbps;
		ret.rate.unit = 'M';
		ret.rate.two_dec = Kbps * 100 >> 10;
	} else {
		ret.rate.value = Kbps;
		ret.rate.unit = 'K';
		ret.rate.two_dec = bps * 100 >> 10;
	}

	return ret.ret;
}

static u32 skw_peer_rate(struct skw_stats_info *stat)
{
	u64 total_bytes, total_jiffies;

	total_bytes = stat->bytes - stat->cal_bytes;
	stat->cal_bytes = stat->bytes;
	total_jiffies = jiffies - stat->cal_time;
	stat->cal_time = jiffies;

	return skw_calc_rate(total_bytes, jiffies_to_msecs(total_jiffies));
}

int skw_tx_throughput(struct skw_iface *iface, u8 *mac)
{
	int ret = 0;
	struct skw_peer_ctx *ctx;

	if (!iface) {
		ret = -ENOENT;
		goto exit;
	}

	if (!mac || is_broadcast_ether_addr(mac)) {
		ret = -EINVAL;
		goto exit;
	}

	ctx = skw_peer_ctx(iface, mac);
	if (!ctx) {
		ret = -ENOENT;
		goto exit;
	}

	skw_peer_ctx_lock(ctx);

	if (ctx->peer)
		ret = skw_peer_rate(&ctx->peer->tx);

	skw_peer_ctx_unlock(ctx);

exit:
	return ret;
}

int skw_rx_throughput(struct skw_iface *iface, u8 *mac)
{
	int ret = 0;
	struct skw_peer_ctx *ctx;

	if (!iface) {
		ret = -ENOENT;
		goto exit;
	}

	if (!mac || is_broadcast_ether_addr(mac)) {
		ret = -EINVAL;
		goto exit;
	}

	ctx = skw_peer_ctx(iface, mac);
	if (!ctx) {
		ret = -ENOENT;
		goto exit;
	}

	skw_peer_ctx_lock(ctx);

	if (ctx->peer)
		ret = skw_peer_rate(&ctx->peer->rx);

	skw_peer_ctx_unlock(ctx);

exit:
	return ret;
}

int skw_tx_throughput_whole(struct skw_iface *iface, u32 *tp)
{
	int ret = 0;
	u32 peer_idx_map, idx;
	struct skw_peer_ctx *ctx;

	if (!iface) {
		ret = -ENOENT;
		goto exit;
	}

	peer_idx_map = atomic_read(&iface->peer_map);

	while (peer_idx_map) {
		idx = ffs(peer_idx_map) - 1;
		SKW_CLEAR(peer_idx_map, BIT(idx));

		ctx = &iface->skw->peer_ctx[idx];

		skw_peer_ctx_lock(ctx);

		if (ctx->peer)
			*(&tp[idx]) = skw_peer_rate(&ctx->peer->tx);

		skw_peer_ctx_unlock(ctx);
	}

exit:
	return ret;
}

int skw_rx_throughput_whole(struct skw_iface *iface, u32 *tp)
{
	int ret = 0;
	u32 peer_idx_map, idx;
	struct skw_peer_ctx *ctx;

	if (!iface) {
		ret = -ENOENT;
		goto exit;
	}

	peer_idx_map = atomic_read(&iface->peer_map);

	while (peer_idx_map) {
		idx = ffs(peer_idx_map) - 1;
		SKW_CLEAR(peer_idx_map, BIT(idx));

		ctx = &iface->skw->peer_ctx[idx];

		skw_peer_ctx_lock(ctx);

		if (ctx->peer)
			*(&tp[idx]) = skw_peer_rate(&ctx->peer->rx);

		skw_peer_ctx_unlock(ctx);
	}

exit:
	return ret;
}

const u8 *skw_find_ie_match(u8 eid, const u8 *ies, int len, const u8 *match,
			    int match_len, int match_offset)
{
	const struct skw_element *elem;

	/* match_offset can't be smaller than 2, unless match_len is
	 * zero, in which case match_offset must be zero as well.
	 */
	if (WARN_ON((match_len && match_offset < 2) ||
		    (!match_len && match_offset)))
		return NULL;

	skw_foreach_element_id(elem, eid, ies, len) {
		if (elem->datalen >= match_offset - 2 + match_len &&
		    !memcmp(elem->data + match_offset - 2, match, match_len))
			return (void *)elem;
	}

	return NULL;
}

bool skw_bss_check_vendor_name(struct cfg80211_bss *bss, const u8 *oui)
{
	const struct cfg80211_bss_ies *ies;
	const struct skw_element *elem;
	bool ret = false;
	u8 eid = WLAN_EID_VENDOR_SPECIFIC;

	ies = rcu_dereference(bss->beacon_ies);
	if (!ies)
		return false;

	skw_hex_dump("beacon ies:", ies->data, ies->len, false);

	skw_foreach_element_id(elem, eid, ies->data, ies->len) {
		if (!memcmp(elem->data, oui, 3)) {
			ret = true;
			break;
		}
	}

	return ret;
}

int skw_desc_get_rx_rate(struct skw_rate *rate, u8 bw, u8 mode, u8 gi,
		    u8 nss, u8 dcm, u16 data_rate)
{
	u16 skw_supp_bs_rate[] = {
		20, 55, 110,
		/*2M,5.5M,11M*/
	};
	u16 skw_supp_bl_rate[] = {
		10, 20, 55, 110,
		/*1M,2M,5.5M,11M*/
	};
	u16 skw_supp_g_rate[] = {
		60, 90, 120, 180, 240, 360, 480, 540,
		/*6M, 9M, 12M, 18M, 24M, 36M, 48M, 54M*/
	};

	memset(rate, 0x0, sizeof(struct skw_rate));

	rate->bw = bw;
	rate->nss = nss;

	switch (mode) {
	case SKW_PPDUMODE_HT_MIXED:
		rate->flags = SKW_RATE_INFO_FLAGS_HT;
		rate->mcs_idx = 0x3F & data_rate;
		rate->gi = gi;
		break;

	case SKW_PPDUMODE_VHT_SU:
	case SKW_PPDUMODE_VHT_MU:
		rate->flags = SKW_RATE_INFO_FLAGS_VHT;
		rate->mcs_idx = 0xF & data_rate;
		rate->gi = gi;
		break;

	case SKW_PPDUMODE_HE_SU:
	case SKW_PPDUMODE_HE_TB:
	case SKW_PPDUMODE_HE_ER_SU:
	case SKW_PPDUMODE_HE_MU:
		rate->flags = SKW_RATE_INFO_FLAGS_HE;
		rate->mcs_idx = 0xF & data_rate;

		if (dcm) {
			rate->mcs_idx = 0x3 & data_rate;
			rate->he_dcm = dcm;
		} else if (mode == SKW_PPDUMODE_HE_ER_SU) {
			rate->mcs_idx = 0x3 & data_rate;
		}

		rate->gi = gi;

		if (bw != SKW_DESC_BW_USED_RU)
			rate->he_ru = bw + 3;
		break;

	case SKW_PPDUMODE_11B_SHORT:
		rate->flags = SKW_RATE_INFO_FLAGS_LEGACY;

		if (data_rate < sizeof(skw_supp_bs_rate))
			rate->legacy_rate = skw_supp_bs_rate[data_rate];
		else
			skw_warn("illegal 11B_SHORT rate:%d\n", data_rate);
		break;

	case SKW_PPDUMODE_11B_LONG:
		rate->flags = SKW_RATE_INFO_FLAGS_LEGACY;

		if (data_rate < sizeof(skw_supp_bl_rate))
			rate->legacy_rate = skw_supp_bl_rate[data_rate];
		else
			skw_warn("illegal 11B_LONG rate:%d\n", data_rate);
		break;

	case SKW_PPDUMODE_11G:
		rate->flags = SKW_RATE_INFO_FLAGS_LEGACY;

		if (data_rate < sizeof(skw_supp_g_rate))
			rate->legacy_rate = skw_supp_g_rate[data_rate];
		else
			skw_warn("illegal 11G rate:%d\n", data_rate);
		break;

	default:
		skw_warn("unsupport ppdu mode:%d\n", mode);
		break;
	};

	return 0;
}

int skw_tlv_add(struct skw_tlv_conf *conf, int type, void *dat, int dat_len)
{
	struct skw_tlv *tlv;

	if (!conf || !conf->buff)
		return -EINVAL;

	if (conf->total_len + dat_len + 4 > conf->buff_len)
		return -ENOMEM;

	tlv = (struct skw_tlv *)((u8 *)conf->buff + conf->total_len);
	tlv->type = type;
	tlv->len = dat_len;
	memcpy(tlv->value, dat, dat_len);

	conf->total_len += dat_len + 4;

	return 0;
}

int skw_tlv_alloc(struct skw_tlv_conf *conf, int len, gfp_t gfp)
{
	if (!conf)
		return -EINVAL;

	conf->buff = SKW_ZALLOC(len, GFP_KERNEL);
	if (!conf->buff)
		return -ENOMEM;

	conf->total_len = 0;
	conf->buff_len = len;

	return 0;
}

void *skw_tlv_reserve(struct skw_tlv_conf *conf, int len)
{
	void *start = NULL;

	if (!conf || !conf->buff)
		return NULL;

	if (conf->total_len + len > conf->buff_len)
		return NULL;

	start = (u8 *)conf->buff + conf->total_len;
	conf->total_len += len;

	return start;
}

void skw_tlv_free(struct skw_tlv_conf *conf)
{
	if (conf) {
		SKW_KFREE(conf->buff);
		conf->total_len = 0;
		conf->buff_len = 0;
	}
}
===== ./drivers/skwifi/skw_rx.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/timer.h>
#include <linux/skbuff.h>
#include <linux/kthread.h>
#include <linux/cpumask.h>
#include <linux/ctype.h>
#include <linux/ip.h>
#include <linux/ipv6.h>
#include <net/ip6_checksum.h>
#include <net/tcp.h>

#include "skw_core.h"
#include "skw_msg.h"
#include "skw_cfg80211.h"
#include "skw_rx.h"
#include "skw_work.h"
#include "skw_tx.h"
#include "trace.h"

#define SKW_PN_U48(x)          (*(u64 *)(x) & 0xffffffffffff)
#define SKW_MSDU_HDR_LEN       6 /* ETH_HLEN - SKW_SNAP_HDR_LEN */

static u8 rx_reorder_flag;

static inline void skw_wake_lock_timeout(struct skw_core *skw, long timeout)
{
#ifdef CONFIG_HAS_WAKELOCK
	if (!wake_lock_active(&skw->rx_wlock))
		wake_lock_timeout(&skw->rx_wlock, msecs_to_jiffies(timeout));
#endif
}

static inline void skw_wake_lock_init(struct skw_core *skw, int type, const char *name)
{
#ifdef CONFIG_HAS_WAKELOCK
	wake_lock_init(&skw->rx_wlock, type, name);
#endif
}

static inline void skw_wake_lock_deinit(struct skw_core *skw)
{
#ifdef CONFIG_HAS_WAKELOCK
	wake_lock_destroy(&skw->rx_wlock);
#endif
}

static int skw_rx_reorder_show(struct seq_file *seq, void *data)
{
	if (rx_reorder_flag)
		seq_puts(seq, "enable\n");
	else
		seq_puts(seq, "disable\n");

	return 0;
}

static int skw_rx_reorder_open(struct inode *inode, struct file *file)
{
	return single_open(file, skw_rx_reorder_show, inode->i_private);
}

static ssize_t skw_rx_reorder_write(struct file *fp, const char __user *buf,
				size_t len, loff_t *offset)
{
	int i;
	char cmd[32] = {0};

	for (i = 0; i < len; i++) {
		char c;

		if (get_user(c, buf))
			return -EFAULT;

		if (c == '\n' || c == '\0')
			break;

		cmd[i] = tolower(c);
		buf++;
	}

	if (strcmp(cmd, "enable") == 0)
		rx_reorder_flag = true;
	else if (strcmp(cmd, "disable") == 0)
		rx_reorder_flag = false;
	else
		skw_warn("rx_reorder support setting values of \"enable\" or \"disbale\"\n");

	return len;
}

static const struct file_operations skw_rx_reorder_fops = {
	.owner = THIS_MODULE,
	.open = skw_rx_reorder_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_rx_reorder_write,
};

static inline struct skw_reorder_cb *SKW_SKB_RXCB(struct sk_buff *skb)
{
	return (struct skw_reorder_cb *)skb->cb;
}

static inline struct skw_rx_desc *skw_rx_desc_hdr(struct sk_buff *skb)
{
	return (struct skw_rx_desc *)(skb->data - SKW_SKB_RXCB(skb)->rx_desc_offset);
}

static void skw_tcpopt_window_handle(struct sk_buff *skb)
{
	unsigned int tcphoff, tcp_hdrlen, length;
	u8 *ptr;
	__sum16	check;
	struct tcphdr *tcph;
	struct ethhdr *eth = eth_hdr(skb);
	struct iphdr *iph = (struct iphdr *)(skb->data);

	if (eth->h_proto == htons(ETH_P_IP) && iph->protocol == IPPROTO_TCP) {
		if (skb->len < ntohs(iph->tot_len))
			return;

		tcphoff = iph->ihl * 4;
		tcph = (struct tcphdr *)(skb->data + tcphoff);

		if (!(tcp_flag_word(tcph) & TCP_FLAG_SYN)) {
			return;
		}
		//skw_dbg("skb->len:%d tot_len:%d\n", skb->len, ntohs(iph->tot_len));

		tcp_hdrlen = tcph->doff * 4;
		length = (tcph->doff - 5) * 4;
		ptr = (u8 *)tcph + tcp_hdrlen - length;
		while (length > 0) {
			int opcode = *ptr++;
			int opsize;

			switch (opcode) {
			case TCPOPT_EOL:
				return;
			case TCPOPT_NOP:	/* Ref: RFC 793 section 3.1 */
				length--;
				continue;
			default:
				if (length < 2)
					return;
				opsize =  *ptr++;
				if (opsize < 2) /* "silly options" */
					return;
				if (opsize > length)
					return;	/* don't parse partial options */

				if (opcode == TCPOPT_WINDOW &&
					opsize == TCPOLEN_WINDOW) {
					//skw_dbg("val:%d\n", *ptr);
					if (*ptr < 6) {
						*ptr = 6;
						tcph->check = 0;
						check = csum_partial(tcph, tcp_hdrlen, 0);
						tcph->check = csum_tcpudp_magic(iph->saddr,
							iph->daddr, tcp_hdrlen, IPPROTO_TCP, check);
					}
				}

				ptr += opsize - 2;
				length -= opsize;
			}
		}
	}
}

/*
 * To verify HW checksum for ipv6
 */
static void skw_csum_verify(struct skw_rx_desc *desc, struct sk_buff *skb)
{
	u16 data_len;
	__sum16 csum;
	unsigned int tcphoff;
	struct iphdr *iph;
	struct ipv6hdr *ip6h;
	struct ethhdr *eth = eth_hdr(skb);

	if (!skb->csum)
		return;

	switch (eth->h_proto) {
	case htons(ETH_P_IPV6):
		ip6h = (struct ipv6hdr *)(skb->data);
		tcphoff = sizeof(struct ipv6hdr);
		// tcph = (struct tcphdr *)(skb->data + tcphoff);

		// fixme:
		// minus the length of any extension headers present between the IPv6
		// header and the upper-layer header
		data_len = ntohs(ip6h->payload_len);

		if (skb->len != data_len + tcphoff) {
			skw_detail("ipv6 dummy pending: rx len: %d, tot_len: %d",
				   skb->len, data_len);

			skb->csum = csum_partial(skb->data + tcphoff,
						data_len, 0);

			skb_trim(skb, data_len + tcphoff);
		}

		csum = csum_ipv6_magic(&ip6h->saddr, &ip6h->daddr, data_len,
					ip6h->nexthdr, skb->csum);
		if (csum) {
			skw_detail("sa: %pI6, da: %pI6, proto: 0x%x, seq: %d, csum: 0x%x, result: 0x%x\n",
				&ip6h->saddr, &ip6h->daddr, ip6h->nexthdr,
				desc->sn, skb->csum, csum);

			skw_hex_dump("csum failed", skb->data, skb->len, false);

		} else {
			skb->ip_summed = CHECKSUM_UNNECESSARY;
		}

		break;

	case htons(ETH_P_IP):
		iph = (struct iphdr *)(skb->data);
		tcphoff = iph->ihl * 4;
		// tcph = (struct tcphdr *)(skb->data + tcphoff);

		data_len = ntohs(iph->tot_len);

		if (skb->len != data_len) {
			skw_detail("ipv4 dummy pending: rx len: %d, tot_len: %d",
				   skb->len, data_len);

			skb->csum = csum_partial(skb->data + tcphoff,
					data_len - tcphoff, 0);

			skb_trim(skb, data_len);
		}

		csum = csum_tcpudp_magic(iph->saddr, iph->daddr,
					data_len - tcphoff,
					iph->protocol, skb->csum);
		if (csum) {
			skw_detail("sa: %pI4, da: %pI4, proto: 0x%x, seq: %d, csum: 0x%x, result: 0x%x\n",
				&iph->saddr, &iph->daddr, iph->protocol,
				desc->sn, skb->csum, csum);

			skw_hex_dump("csum failed", skb->data, skb->len, false);
		}

		break;

	default:
		break;
	}
}

#ifdef CONFIG_RPS
int skw_init_rps_map(struct netdev_rx_queue *queue, int unmask)
{
	int i, cpu;
	struct rps_map *map, *old_map;
	static DEFINE_SPINLOCK(rps_map_lock);

	map = kzalloc(max_t(unsigned int,
			    RPS_MAP_SIZE(cpumask_weight(cpu_online_mask)), L1_CACHE_BYTES),
		      GFP_KERNEL);
	if (!map)
		return -ENOMEM;

	i = 0;
	for_each_cpu(cpu, cpu_online_mask)
		if (cpu != unmask)
			map->cpus[i++] = cpu;

	if (i) {
		map->len = i;
	} else {
		kfree(map);
		map = NULL;
	}

	spin_lock(&rps_map_lock);
	old_map = rcu_dereference_protected(queue->rps_map,
					    lockdep_is_held(&rps_map_lock));
	rcu_assign_pointer(queue->rps_map, map);
	spin_unlock(&rps_map_lock);

	if (map) {
#if (KERNEL_VERSION(5, 2, 0) <= LINUX_VERSION_CODE)
		static_key_slow_inc(&rps_needed.key);
#else
		static_key_slow_inc(&rps_needed);
#endif
	}

	if (old_map) {
#if (KERNEL_VERSION(5, 2, 0) <= LINUX_VERSION_CODE)
		static_key_slow_dec(&rps_needed.key);
#else
		static_key_slow_dec(&rps_needed);
#endif
		kfree_rcu(old_map, rcu);
	}

	return 0;
}
#endif

static void skw_deliver_skb(struct skw_iface *iface, struct sk_buff *skb)
{
	struct sk_buff *tx_skb = NULL;
	struct ethhdr *eth = (struct ethhdr *)skb->data;
	struct skw_rx_desc *desc = skw_rx_desc_hdr(skb);
	int mcast;
	unsigned int len = skb->len;
	int ret = NET_RX_DROP;

	if (ether_addr_equal(eth->h_source, iface->addr))
		goto stats;

	if (unlikely(!desc->snap_match)) {
		skw_detail("snap unmatch, sn: %d\n", desc->sn);

		skw_snap_unmatch_handler(skb);
	}

	/* forward for ap mode */
	mcast = is_multicast_ether_addr(skb->data);
	if (desc->need_forward && is_skw_ap_mode(iface) && !iface->sap.ap_isolate) {
		if (mcast) {
			tx_skb = skb_copy(skb, GFP_ATOMIC);
		} else if (skw_peer_ctx(iface, skb->data) != NULL) {
			tx_skb = skb;
			skb = NULL;
		}

		if (tx_skb) {
			tx_skb->priority += 256;
			tx_skb->protocol = htons(ETH_P_802_3);
			skb_reset_network_header(tx_skb);
			skb_reset_mac_header(tx_skb);
			dev_queue_xmit(tx_skb);
		}

		if (!skb) {
			ret = NET_RX_SUCCESS;
			goto stats;
			//return;
		}
	}

	if (unlikely(test_bit(SKW_FLAG_REPEATER, &iface->skw->flags)) && eth->h_proto == ntohs(ETH_P_ARP) &&
	    is_skw_sta_mode(iface) &&
	    iface->ndev->priv_flags & IFF_BRIDGE_PORT) {
		struct skw_arphdr *arp = skw_arp_hdr(skb);

		if (arp->ar_op == ntohs(ARPOP_REPLY)) {
			int i;
			bool found = false;
			struct skw_peer_ctx *ctx;

			for (i = 0; i < SKW_MAX_PEER_SUPPORT; i++) {
				ctx = &iface->skw->peer_ctx[i];

				mutex_lock(&ctx->lock);

				if (ctx->peer && ctx->peer->ip_addr == arp->ar_tip) {
					skw_ether_copy(eth->h_dest, ctx->peer->addr);
					skw_ether_copy(arp->ar_tha, ctx->peer->addr);
					found = true;
				}

				mutex_unlock(&ctx->lock);

				if (found)
					break;
			}
		}
	}

	skb->protocol = eth_type_trans(skb, iface->ndev);
	// TODO:
	// ipv6 csum check
	if (desc->csum_valid) {
		skb->csum = desc->csum;
		skb->ip_summed = CHECKSUM_COMPLETE;
		skw_csum_verify(desc, skb);
	} else {
		skb->csum = 0;
		skb->ip_summed = CHECKSUM_NONE;
	}

	ret = NET_RX_SUCCESS;

#ifdef CONFIG_RPS
	if (iface->cpu_id != raw_smp_processor_id()) {
		iface->cpu_id = raw_smp_processor_id();
		skw_init_rps_map(iface->ndev->_rx, iface->cpu_id);
	}
#endif

	skw_tcpopt_window_handle(skb);
#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 18, 0)
	netif_rx_ni(skb);
#else
	netif_rx(skb);
#endif

stats:
	if (unlikely(ret == NET_RX_DROP)) {
		iface->ndev->stats.rx_dropped++;
		dev_kfree_skb(skb);
	} else {
		iface->ndev->stats.rx_packets++;
		iface->ndev->stats.rx_bytes += len;
		if (mcast)
			iface->ndev->stats.multicast++;
	}
}

/*
 * get fragment entry
 * @tid & @sn as fragment entry match id
 * @active, if false, check duplicat first, then get an inactive fragment,
 *          else return the oldest active entry
 */
static struct skw_frag_entry *
skw_frag_get_entry(struct skw_iface *iface, u8 tid, u16 sn, bool active)
{
	int i;
	struct skw_frag_entry *entry = NULL, *oldest = NULL;
	struct skw_frag_entry *inactive = NULL;

	for (i = 0; i < SKW_MAX_DEFRAG_ENTRY; i++) {
		struct skw_frag_entry *e = &iface->frag[i];

		if (e->sn == sn && e->tid == tid) {
			entry = e;
			break;
		}

		if (!active) {
			// skw_dbg("i: %d,entry tid: %d, sn: %d, status: %d\n",
			//        i, e->tid, e->sn, e->status);

			if (!(e->status & SKW_FRAG_STATUS_ACTIVE)) {
				inactive = e;
				continue;
			}

			if (!oldest) {
				oldest = e;
				continue;
			}

			if (time_after(oldest->start, e->start))
				oldest = e;
		}
	}

	if (!active && !entry)
		entry = inactive ? inactive : oldest;

	return entry;
}

// Firmware will cover the exception that receiving a fragment
// frame while in a ba session
// Firmware will split A-MSDU frame to MSDU to Wi-Fi driver

static void skw_frag_init_entry(struct skw_iface *iface, struct sk_buff *skb)
{
	struct skw_frag_entry *entry = NULL;
	struct skw_rx_desc *desc = skw_rx_desc_hdr(skb);

	entry = skw_frag_get_entry(iface, desc->tid, desc->sn, false);
	if (entry->status & SKW_FRAG_STATUS_ACTIVE) {
		skw_warn("overwrite, entry: %d, tid: %d, sn: %d, time: %d ms\n",
			 entry->id, entry->tid, entry->sn,
			 jiffies_to_msecs(jiffies - entry->start));
	}

	if (!skb_queue_empty(&entry->skb_list))
		__skb_queue_purge(&entry->skb_list);

	entry->status = SKW_FRAG_STATUS_ACTIVE;
	entry->pending_len = 0;
	entry->start = jiffies;
	entry->tid = desc->tid;
	entry->sn = desc->sn;
	entry->frag_num = 0;

	if (iface->key_conf.skw_cipher == SKW_CIPHER_TYPE_CCMP ||
	    iface->key_conf.skw_cipher == SKW_CIPHER_TYPE_CCMP_256 ||
	    iface->key_conf.skw_cipher == SKW_CIPHER_TYPE_GCMP ||
	    iface->key_conf.skw_cipher == SKW_CIPHER_TYPE_GCMP_256) {
		memcpy(entry->last_pn, desc->pn, IEEE80211_CCMP_PN_LEN);
		SKW_SET(entry->status, SKW_FRAG_STATUS_CHK_PN);
	}

	__skb_queue_tail(&entry->skb_list, skb);
}

/*
 * if @skb is a fragment frame, start to defragment.
 * return skb buffer if all fragment frames have received, else return NULL
 */
static struct sk_buff *
skw_rx_defragment(struct skw_core *skw, struct skw_iface *iface,
				struct sk_buff *skb)
{
	struct sk_buff *pskb;
	struct skw_frag_entry *entry;
	struct skw_rx_desc *desc = skw_rx_desc_hdr(skb);

	if (likely(!desc->more_frag && !desc->frag_num))
		return skb;

	//skw_dbg("peer: %d, tid: %d, sn: %d, more frag: %d, frag num: %d\n",
	//	desc->peer_idx, desc->tid, desc->sn,
	//	desc->more_frag, desc->frag_num);

	if (desc->frag_num == 0) {
		desc->csum_valid = 0;
		desc->csum = 0;
		skw_frag_init_entry(iface, skb);

		return NULL;
	}

	entry = skw_frag_get_entry(iface, desc->tid, desc->sn, true);
	if (!entry || (entry->frag_num + 1 != desc->frag_num)) {
		//TBD: the frag num increased by 2 when it is WAPI
		skw_dbg("drop, entry: %d, tid: %d, sn: %d, frag num: %d\n",
			entry ? entry->id : -1, desc->tid,
			desc->sn, desc->frag_num);

		dev_kfree_skb(skb);
		return NULL;
	}

	/* check fragment frame PN if cipher is CCMP
	 * The PN shall be incremented in steps of 1 for constituent
	 * MPDUs of fragmented MSDUs and MMPDUs
	 */
	if (entry->status & SKW_FRAG_STATUS_CHK_PN) {
		if (SKW_PN_U48(entry->last_pn) + 1 != SKW_PN_U48(desc->pn)) {
			skw_dbg("drop frame last pn:%llu desc_pn:%llu\n",
				SKW_PN_U48(entry->last_pn),
				SKW_PN_U48(desc->pn));
			dev_kfree_skb(skb);
			return NULL;
		}

		memcpy(entry->last_pn, desc->pn, IEEE80211_CCMP_PN_LEN);
	}

	entry->frag_num++;

	/* remove mac address header -- SA & DA */
	skb_pull(skb, 12);

	entry->pending_len += skb->len;

	__skb_queue_tail(&entry->skb_list, skb);

	if (desc->more_frag)
		return NULL;

	pskb = __skb_dequeue(&entry->skb_list);
	if (skb_tailroom(pskb) < entry->pending_len) {
		if (unlikely(pskb_expand_head(pskb, 0, entry->pending_len,
						GFP_ATOMIC))) {
			skw_warn("drop: tailroom: %d, needed: %d\n",
				 skb_tailroom(pskb), entry->pending_len);

			__skb_queue_purge(&entry->skb_list);
			dev_kfree_skb(pskb);
			entry->status = 0;
			entry->tid = SKW_INVALID_ID;

			return NULL;
		}
	}

	while ((skb = __skb_dequeue(&entry->skb_list))) {
		/* snap unmatch */
		skw_put_skb_data(pskb, skb->data, skb->len);
		dev_kfree_skb(skb);
	}

	entry->status = 0;
	entry->tid = SKW_INVALID_ID;

	// Remove the mic value in the final fragment when encryption is TKIP
	if (iface->key_conf.skw_cipher == SKW_CIPHER_TYPE_TKIP)
		skb_trim(pskb, pskb->len - 8);

	return pskb;
}

static int skw_pn_allowed(struct skw_key *key, struct skw_rx_desc *desc, int queue)
{
	s64 ret;

	if (!key)
		return -EINVAL;

	ret = SKW_PN_U48(desc->pn) - SKW_PN_U48(key->rx_pn[queue]);
	if (ret < 0 && SKW_PN_U48(desc->pn) != 0) {
		/* SKW_PN_U48(desc->pn) = 0 allow workaround some devices pn=0*/

		/* failed that PN less than or equal to rx_pn */
		skw_warn("seq: %d, pn: 0x%llx, rx pn: 0x%llx\n",
			 desc->sn, SKW_PN_U48(key->rx_pn[queue]),
			 SKW_PN_U48(desc->pn));

		return -EINVAL;
	}

	return 0;
}

static int skw_replay_detect(struct skw_core *skw, struct skw_iface *iface,
			struct sk_buff *skb)
{
	s64 ret = 0;
	int key_idx, queue = -1;
	struct skw_key *key;
	struct skw_key_conf *conf;
	struct skw_peer_ctx *ctx;
	struct skw_rx_desc *desc = skw_rx_desc_hdr(skb);

	if (SKW_SKB_RXCB(skb)->skip_replay_detect)
		return 0;

	// fixme:
	ctx = &skw->peer_ctx[desc->peer_idx];
	if (!ctx->peer)
		return -EINVAL;

	if (desc->is_mc_addr) {
		return 0;
#if 0
		conf = &iface->key_conf;
		if (!conf->installed_bitmap)
			conf = &ctx->peer->gtk_conf;
#endif
	} else {
		conf = &ctx->peer->ptk_conf;
	}

	key_idx = skw_key_idx(conf->installed_bitmap);
	if (key_idx == SKW_INVALID_ID)
		return 0;

	switch (conf->skw_cipher) {
	case SKW_CIPHER_TYPE_CCMP:
	case SKW_CIPHER_TYPE_CCMP_256:
	case SKW_CIPHER_TYPE_GCMP:
	case SKW_CIPHER_TYPE_GCMP_256:
	case SKW_CIPHER_TYPE_TKIP:
		queue = desc->tid;
		break;

	case SKW_CIPHER_TYPE_AES_CMAC:
	case SKW_CIPHER_TYPE_BIP_CMAC_256:
	case SKW_CIPHER_TYPE_BIP_GMAC_128:
	case SKW_CIPHER_TYPE_BIP_GMAC_256:
		queue = -1;
		break;

	default:
		queue = -1;
		break;
	}

	if (queue < 0)
		return 0;

	rcu_read_lock();

	key = rcu_dereference(conf->key[key_idx]);
	if (key) {
		skw_detail("inst: %d, peer: %d, tid: %d, key_idx: %d, queue: %d, pn: 0x%llx, rx pn: 0x%llx\n",
			   desc->inst_id, desc->peer_idx, desc->tid, key_idx,
			   queue, SKW_PN_U48(key->rx_pn[queue]),
			   SKW_PN_U48(desc->pn));

		ret = skw_pn_allowed(key, desc, queue);
		if (!ret)
			memcpy(key->rx_pn[queue], desc->pn, SKW_PN_LEN);
	}
	rcu_read_unlock();

	return ret;
}

static void skw_rx_handler(struct skw_core *skw, struct sk_buff_head *list)
{
	struct sk_buff *skb;
	struct skw_iface *iface;
	struct skw_rx_desc *desc;
	struct sk_buff_head deliver_list;

	__skb_queue_head_init(&deliver_list);

	spin_lock_bh(&skw->rx_lock);

	while ((skb = __skb_dequeue(list))) {
		if (SKW_SKB_RXCB(skb)->skw_created) {
			dev_kfree_skb(skb);
			continue;
		}

		desc = skw_rx_desc_hdr(skb);

		trace_skw_rx_handler_seq(desc->sn, desc->msdu_filter);

		iface = to_skw_iface(skw, desc->inst_id);
		if (!iface) {
			dev_kfree_skb(skb);
			continue;
		}

		if (skw_replay_detect(skw, iface, skb) < 0) {
			dev_kfree_skb(skb);
			continue;
		}

		skb = skw_rx_defragment(skw, iface, skb);
		if (!skb)
			continue;

		skb->dev = iface->ndev;
		__skb_queue_tail(&deliver_list, skb);
	}

	spin_unlock_bh(&skw->rx_lock);

	while ((skb = __skb_dequeue(&deliver_list)))
		skw_deliver_skb(netdev_priv(skb->dev), skb);
}

static void skw_set_reorder_timer(struct skw_tid_rx *tid_rx, u16 sn)
{
	u16 index;
	struct sk_buff_head *list;
	unsigned long timeout = 0;
	struct skw_reorder_rx *reorder = tid_rx->reorder;

	smp_rmb();

	if (timer_pending(&reorder->timer) ||
	    atomic_read(&reorder->ref_cnt) != tid_rx->ref_cnt)
		return;

	index = sn % tid_rx->win_size;
	list = &tid_rx->reorder_buf[index];
	if (!list || skb_queue_empty(list)) {
		//skw_warn("invalid rx list, sn: %d\n", sn);
		return;
	}

	timeout = SKW_SKB_RXCB(skb_peek(list))->rx_time +
		  msecs_to_jiffies(CONFIG_SKW_RX_REORDER_TIMEOUT);

	trace_skw_rx_set_reorder_timer(reorder->inst, reorder->peer_idx,
				reorder->tid, sn, jiffies, timeout);

	if (time_before(jiffies, timeout)) {
		reorder->expired.sn = sn;
		reorder->expired.ref_cnt = tid_rx->ref_cnt;
		mod_timer(&reorder->timer, timeout);
	} else {
		spin_lock_bh(&reorder->todo.lock);

		if (!reorder->todo.actived) {
			reorder->todo.seq = sn;
			reorder->todo.actived = true;
			reorder->todo.reason = SKW_RELEASE_EXPIRED;
			skw_list_add(&reorder->skw->rx_todo_list, &reorder->todo.list);
		}

		spin_unlock_bh(&reorder->todo.lock);

		skw_wakeup_rx(reorder->skw);
	}
}

static inline bool is_skw_release_ready(struct sk_buff_head *list)
{
	struct sk_buff *skb = skb_peek(list);
	struct skw_reorder_cb *cb = NULL;

	if (!skb)
		return false;

	cb = SKW_SKB_RXCB(skb);
	if ((cb->amsdu_flags & SKW_AMSDU_FLAG_VALID) &&
	    (cb->amsdu_bitmap != cb->amsdu_mask))
		return false;

	return true;
}

static inline bool is_skw_msdu_timeout(struct sk_buff_head *list)
{
	struct sk_buff *skb;
	unsigned long timeout = 0;

	skb = skb_peek(list);
	if (skb) {
		timeout = SKW_SKB_RXCB(skb)->rx_time + CONFIG_SKW_RX_REORDER_TIMEOUT;
		if (time_after(jiffies, timeout))
			return true;
	}

	return false;
}

/* Force release frame in reorder buffer to to_sn*/
static void skw_reorder_force_release(struct skw_tid_rx *tid_rx,
		u16 to_sn, struct sk_buff_head *release_list, int reason)
{
	u16 index, target;
	struct sk_buff *skb, *pskb;

	if (!tid_rx)
		return;

	target = ieee80211_sn_inc(to_sn);

	smp_rmb();

	if (timer_pending(&tid_rx->reorder->timer) &&
	    atomic_read(&tid_rx->reorder->ref_cnt) == tid_rx->ref_cnt &&
	    (ieee80211_sn_less(tid_rx->reorder->expired.sn, to_sn) ||
	     ieee80211_sn_less(to_sn, tid_rx->win_start)))
		del_timer(&tid_rx->reorder->timer);

	while (ieee80211_sn_less(tid_rx->win_start, target)) {
		struct sk_buff_head *list;

		index = tid_rx->win_start % tid_rx->win_size;
		list = &tid_rx->reorder_buf[index];

		if (!tid_rx->stored_num) {
			tid_rx->win_start = to_sn;
			break;
		}

		skb = skb_peek(list);
		if (skb) {
			if (!is_skw_release_ready(list)) {
				skw_dbg("warn, seq: %d, amsdu bitmap: 0x%x\n",
					skw_rx_desc_hdr(skb)->sn,
					SKW_SKB_RXCB(skb)->amsdu_bitmap);
			}

			if (SKW_SKB_RXCB(skb)->amsdu_flags
					& SKW_AMSDU_FLAG_TAINT) {
				__skb_queue_purge(list);
			} else {
				while ((pskb = __skb_dequeue(list)))
					__skb_queue_tail(release_list, pskb);
			}

			tid_rx->stored_num--;
		}

		WARN_ON(!skb_queue_empty(list));

		tid_rx->win_start = ieee80211_sn_inc(tid_rx->win_start);

		trace_skw_rx_force_release(tid_rx->reorder->inst,
					tid_rx->reorder->peer_idx,
					tid_rx->reorder->tid,
					index, tid_rx->win_start, target,
					tid_rx->stored_num, reason);
	}
}

/*
 * release all ready skb in reorder buffer until a gap
 * if first ready skb is timeout, release all skb in reorder buffer,
 * else reset timer
 */
static void skw_reorder_release(struct skw_reorder_rx *reorder,
			struct sk_buff_head *release_list)
{
	bool release = true;

	u16 i, index;
	u16 win_start;
	struct sk_buff *skb;
	struct sk_buff_head *list;
	struct skw_tid_rx *tid_rx;

	tid_rx = rcu_dereference(reorder->tid_rx);
	if (!tid_rx)
		return;

	win_start = tid_rx->win_start;

	for (i = 0; i < tid_rx->win_size; i++) {
		if (tid_rx->stored_num == 0) {
			if (timer_pending(&reorder->timer))
				del_timer(&reorder->timer);

			break;
		}

		index = (win_start + i) % tid_rx->win_size;
		list = &tid_rx->reorder_buf[index];

		if (!skb_queue_len(list)) {
			if (timer_pending(&reorder->timer))
				break;

			release = false;
			continue;
		}

		/* release timeout skb and reset reorder timer */
		if (!release) {
			if (!is_skw_msdu_timeout(list)) {
				skw_set_reorder_timer(tid_rx, win_start + i);
				break;
			}

			skw_reorder_force_release(tid_rx, win_start + i,
					release_list, SKW_RELEASE_EXPIRED);
			release = true;
			continue;
		}

		if (release) {
			skb = skb_peek(list);

			if (timer_pending(&reorder->timer) &&
			    reorder->expired.sn == tid_rx->win_start)
				del_timer(&reorder->timer);

			if (SKW_SKB_RXCB(skb)->amsdu_flags & SKW_AMSDU_FLAG_TAINT) {
				__skb_queue_purge(list);
				release = false;
				continue;
			}

			if (is_skw_release_ready(list) || is_skw_msdu_timeout(list)) {
				struct sk_buff *pskb;

				while ((pskb = __skb_dequeue(list)))
					__skb_queue_tail(release_list, pskb);

				tid_rx->win_start = ieee80211_sn_inc(tid_rx->win_start);
				tid_rx->stored_num--;

				trace_skw_rx_reorder_release(reorder->inst,
						reorder->peer_idx, reorder->tid,
						win_start, win_start + i,
						index, tid_rx->win_start,
						tid_rx->stored_num);

			} else {
				/* AMSDU not ready and expired */
				if (!timer_pending(&reorder->timer))
					skw_set_reorder_timer(tid_rx, win_start + i);

				break;
			}
		}
	}
}

static void skw_ampdu_reorder(struct skw_core *skw, struct skw_rx_desc *desc,
			struct sk_buff *skb, struct sk_buff_head *release_list)
{
	u32 filter;
	u16 win_start, win_size;
	struct skw_ctx_entry *entry;
	struct skw_tid_rx *tid_rx;
	struct sk_buff_head *list = NULL;
	struct sk_buff *pskb;
	struct skw_peer *peer;
	struct skw_reorder_rx *reorder;
	bool release = false, drop = false;
	const u8 snap_hdr[] = {0xAA, 0xAA, 0x03, 0x0, 0x0, 0x0};

#define SKW_RXCB_AMSDU_LAST    BIT(0)

	if (!rx_reorder_flag) {
		__skb_queue_tail(release_list, skb);
		return;
	}

	entry = rcu_dereference(skw->peer_ctx[desc->peer_idx].entry);
	if (!entry) {
		__skb_queue_tail(release_list, skb);
		return;
	}

	peer = entry->peer;
	filter = atomic_read(&peer->rx_filter);
	if (filter && !(filter & BIT(desc->msdu_filter & 0x1F))) {
		skw_dbg("warn: rx filter: 0x%x, msdu filter: 0x%x\n",
			filter, desc->msdu_filter);

		kfree_skb(skb);
		return;
	}

	skw_update_peer_rx_rate(peer, desc);

	entry->peer->rx.bytes += skb->len;
	entry->peer->rx.pkts++;

	if (!desc->is_qos_data || desc->is_mc_addr) {
		__skb_queue_tail(release_list, skb);
		return;
	}

	/* if this mpdu is fragmented, skip reorder */
	if (desc->more_frag || desc->frag_num) {
		__skb_queue_tail(release_list, skb);
		return;
	}

	reorder = &peer->reorder[desc->tid];
	tid_rx = rcu_dereference(reorder->tid_rx);
	if (!tid_rx) {
		__skb_queue_tail(release_list, skb);
		return;
	}

	win_start = tid_rx->win_start;
	win_size = tid_rx->win_size;
	/* case:
	 * frame seqence number less than window start
	 */
	if (ieee80211_sn_less(desc->sn, win_start)) {
		if (SKW_RX_FILTER_EXCL & BIT(desc->msdu_filter & 0x1F)) {
			SKW_SKB_RXCB(skb)->skip_replay_detect = 1;
			__skb_queue_tail(release_list, skb);
			return;
		}

		skw_detail("drop: peer: %d, tid: %d, ssn: %d, seq: %d, amsdu idx: %d, filter: %d\n",
			   desc->peer_idx, desc->tid, win_start,
			   desc->sn, desc->amsdu_idx, desc->msdu_filter);

		drop = true;
		goto out;
	}

	/* case:
	 * frame sequence number exceeds window size
	 */
	if (!ieee80211_sn_less(desc->sn, win_start + win_size)) {
		win_start = ieee80211_sn_sub(desc->sn, win_size);

		skw_reorder_force_release(tid_rx, win_start, release_list,
						SKW_RELEASE_OOB);
		release = true;
		win_start = tid_rx->win_start;
	}

	/* dup check
	 */
	// index = desc->sn % win_size;
	list = &tid_rx->reorder_buf[desc->sn % win_size];
	pskb = skb_peek(list);

	if (desc->is_amsdu) {
		struct skw_reorder_cb *cb;

		if (!pskb) {
			pskb = skb;
			tid_rx->stored_num++;
		}

		cb = SKW_SKB_RXCB(pskb);
		if (cb->amsdu_bitmap & BIT(desc->amsdu_idx)) {
			drop = true;
			goto out;
		}

		cb->amsdu_bitmap |= BIT(desc->amsdu_idx);
		cb->amsdu_flags |= SKW_AMSDU_FLAG_VALID;
		__skb_queue_tail(list, skb);

		if (desc->amsdu_first_idx &&
		    ether_addr_equal(skb->data, snap_hdr)) {
			cb->amsdu_flags |= SKW_AMSDU_FLAG_TAINT;
			skw_hex_dump("attack", skb->data, 14, true);
		}

		if (desc->amsdu_last_idx) {
			cb->amsdu_mask = BIT(desc->amsdu_idx + 1) - 1;
			cb->amsdu_bitmap |= SKW_RXCB_AMSDU_LAST;
		}

		if (cb->amsdu_bitmap != cb->amsdu_mask)
			goto out;

		/* amsdu ready to release */
		tid_rx->stored_num--;

		if (cb->amsdu_flags & SKW_AMSDU_FLAG_TAINT) {
			__skb_queue_purge(list);
			tid_rx->win_start = ieee80211_sn_inc(tid_rx->win_start);
			drop = true;
			skb = NULL;

			goto out;
		}

	} else {
		if (pskb) {
			drop = true;
			goto out;
		}

		__skb_queue_tail(list, skb);
	}

	if (desc->sn == win_start) {
		while ((pskb = __skb_dequeue(list)))
			__skb_queue_tail(release_list, pskb);

		if (timer_pending(&reorder->timer) &&
			reorder->expired.sn == tid_rx->win_start)
			del_timer(&reorder->timer);

		tid_rx->win_start = ieee80211_sn_inc(tid_rx->win_start);

		release = true;

	} else {
		tid_rx->stored_num++;
	}

out:
	trace_skw_rx_reorder(desc->inst_id, desc->peer_idx, desc->tid,
			     desc->sn, desc->is_amsdu, desc->amsdu_idx,
			     tid_rx->win_size, tid_rx->win_start,
			     tid_rx->stored_num, release, drop);

	if (drop && skb) {
		dev_kfree_skb(skb);
		skb = NULL;
	}

	if (tid_rx->stored_num) {
		if (release)
			skw_reorder_release(reorder, release_list);
		else if (skb)
			skw_set_reorder_timer(tid_rx, desc->sn);
	} else {
		if (timer_pending(&reorder->timer))
			del_timer(&reorder->timer);
	}
}

static void skw_rx_todo(struct skw_list *todo_list)
{
	// u16 target;
	LIST_HEAD(list);
	struct sk_buff_head release;
	struct skw_reorder_rx *reorder;
	struct skw_tid_rx *tid_rx;

	if (likely(!todo_list->count))
		return;

	INIT_LIST_HEAD(&list);
	__skb_queue_head_init(&release);

	spin_lock_bh(&todo_list->lock);

	list_splice_init(&todo_list->list, &list);
	todo_list->count = 0;

	spin_unlock_bh(&todo_list->lock);

	while (!list_empty(&list)) {
		reorder = list_first_entry(&list, struct skw_reorder_rx,
					   todo.list);

		spin_lock_bh(&reorder->todo.lock);

		list_del(&reorder->todo.list);

		rcu_read_lock();
		tid_rx = rcu_dereference(reorder->tid_rx);
		skw_reorder_force_release(tid_rx, reorder->todo.seq,
					&release, reorder->todo.reason);
		rcu_read_unlock();

		reorder->todo.actived = false;

		spin_unlock_bh(&reorder->todo.lock);

		skw_reorder_release(reorder, &release);
		skw_rx_handler(reorder->skw, &release);

		trace_skw_rx_expired_release(reorder->inst, reorder->peer_idx,
					reorder->tid, reorder->todo.seq);
	}
}

static void skw_rx_handler_drop_info(struct skw_core *skw, struct sk_buff *pskb,
			int offset, struct sk_buff_head *release_list)
{
	int i, buff_len;
	int total_drop_sn;
	struct sk_buff *skb;
	struct skw_rx_desc *new_desc;
	struct skw_drop_sn_info *sn_info;
	static unsigned long j;

	total_drop_sn = *(int *)(pskb->data + offset);
	buff_len = pskb->len - offset;

	if (total_drop_sn > buff_len / sizeof(*sn_info)) {
		if (printk_timed_ratelimit(&j, 5000))
			skw_hex_dump("dump", pskb->data + offset, buff_len, true);

		// skw_hw_assert(skw, false);
		return;
	}

	sn_info = (struct skw_drop_sn_info *)(pskb->data + offset + 4);
	for (i = 0; i < total_drop_sn; i++) {
		trace_skw_rx_data(sn_info[i].inst, sn_info[i].peer_idx,
				  sn_info[i].tid, 0,
				  sn_info[i].sn, sn_info[i].qos,
				  0, sn_info[i].is_amsdu,
				  sn_info[i].amsdu_idx, sn_info[i].amsdu_first,
				  sn_info[i].amsdu_last, true);

		if (!sn_info[i].qos)
			continue;

		skb = dev_alloc_skb(sizeof(struct skw_rx_desc));
		if (skb) {
			SKW_SKB_RXCB(skb)->skw_created = 1;
			SKW_SKB_RXCB(skb)->rx_time = jiffies;

			new_desc = skw_put_skb_zero(skb, sizeof(struct skw_rx_desc));
			new_desc->inst_id = sn_info[i].inst;
			new_desc->peer_idx = sn_info[i].peer_idx;
			new_desc->tid = sn_info[i].tid;
			new_desc->is_qos_data = sn_info[i].qos;
			new_desc->sn = sn_info[i].sn;
			new_desc->is_amsdu = sn_info[i].is_amsdu;
			new_desc->amsdu_idx = sn_info[i].amsdu_idx;
			new_desc->amsdu_first_idx = sn_info[i].amsdu_first;
			new_desc->amsdu_last_idx = sn_info[i].amsdu_last;

			rcu_read_lock();
			skw_ampdu_reorder(skw, new_desc, skb, release_list);
			rcu_read_unlock();

			skw_rx_handler(skw, release_list);
		}
	}
}

static void skw_netif_monitor_rx(struct skw_core *skw, struct sk_buff *skb)
{
	struct skw_iface *iface;
	struct skw_rx_desc *desc;

	desc = (struct skw_rx_desc *)skb->data;
	if (unlikely(!desc->msdu_len)) {
		skw_detail("strip invalid pakcet\n");
		kfree_skb(skb);
		return;
	}

	skb_pull(skb, sizeof(struct skw_rx_desc));
	iface = to_skw_iface(skw, desc->inst_id);
	if (unlikely(!iface)) {
		skw_err("iface not valid\n");
		kfree_skb(skb);

		return;
	}

	__skb_trim(skb, desc->msdu_len);

	skb->dev = iface->ndev;
	skb_reset_mac_header(skb);
	skb->ip_summed = CHECKSUM_NONE;
	skb->pkt_type = PACKET_OTHERHOST;
	skb->protocol = htons(ETH_P_80211_RAW);
	netif_receive_skb(skb);
}

static void skw_rx_data_handler(struct skw_core *skw,
				struct sk_buff_head *rx_list)
{
	struct sk_buff_head release_list;
	struct skw_rx_desc *desc;
	struct sk_buff *skb;

	__skb_queue_head_init(&release_list);

	while ((skb = __skb_dequeue(rx_list))) {
		int msdu_offset = 0, msdu_len = 0;

		desc = (struct skw_rx_desc *)skb_pull(skb, skw->hw.rx_desc.hdr_offset);

		if (is_skw_monitor_data(skw, skb->data)) {
			skw_netif_monitor_rx(skw, skb);
			continue;
		}

		trace_skw_rx_data(desc->inst_id, desc->peer_idx, desc->tid,
				  desc->msdu_filter, desc->sn, desc->is_qos_data,
				  desc->retry_frame, desc->is_amsdu,
				  desc->amsdu_idx, desc->amsdu_first_idx,
				  desc->amsdu_last_idx, false);

		if (desc->peer_idx >= SKW_MAX_PEER_SUPPORT ||
		    desc->tid >= SKW_NR_TID) {
			skw_warn("invlid peer: %d, tid: %d\n",
				desc->peer_idx, desc->tid);

			kfree_skb(skb);
			continue;
		}

		msdu_offset = desc->msdu_offset -
			      skw->hw.rx_desc.msdu_offset -
			      skw->hw.rx_desc.hdr_offset;

		skb_pull(skb, msdu_offset);
		SKW_SKB_RXCB(skb)->rx_desc_offset = msdu_offset;
		SKW_SKB_RXCB(skb)->rx_time = jiffies;

		if (BIT(desc->msdu_filter & 0x1f) & SKW_RX_FILTER_DBG)
			skw_dbg("filter: %d, sn: %d, sa: %pM\n",
				desc->msdu_filter, desc->sn,
				skw_eth_hdr(skb)->h_source);

		msdu_len = desc->msdu_len + SKW_MSDU_HDR_LEN;

		if (desc->mac_drop_frag) {
			int offset = round_up(msdu_len + desc->msdu_offset, 4);

			offset -= desc->msdu_offset;
			skw_rx_handler_drop_info(skw, skb, offset, &release_list);
		}

		__skb_trim(skb, msdu_len);

		rcu_read_lock();

		skw_ampdu_reorder(skw, desc, skb, &release_list);

		rcu_read_unlock();

		skw_rx_handler(skw, &release_list);

		skw_rx_todo(&skw->rx_todo_list);
	}
}

static void skw_free_tid_rx(struct rcu_head *head)
{
	u16 win_end;
	struct skw_tid_rx *tid_rx;
	struct sk_buff_head release_list;

	tid_rx = container_of(head, struct skw_tid_rx, rcu_head);

	__skb_queue_head_init(&release_list);
	win_end = ieee80211_sn_add(tid_rx->win_start, tid_rx->win_size - 1);

	rcu_read_lock();

	skw_reorder_force_release(tid_rx, win_end, &release_list,
					SKW_RELEASE_FREE);

	rcu_read_unlock();

	skw_rx_handler(tid_rx->reorder->skw, &release_list);

	SKW_KFREE(tid_rx->reorder_buf);
	SKW_KFREE(tid_rx);
}

int skw_update_tid_rx(struct skw_peer *peer, u16 tid, u16 ssn, u16 win_size)
{
	struct skw_tid_rx *tid_rx;
	struct skw_reorder_rx *reorder;

	skw_dbg("inst: %d, peer: %d, tid: %d, ssn: %d, win size: %d\n",
		peer->iface->id, peer->idx, tid, ssn, win_size);

	trace_skw_rx_update_ba(peer->iface->id, peer->idx, tid, ssn);

	rcu_read_lock();

	reorder = &peer->reorder[tid];
	tid_rx = rcu_dereference(reorder->tid_rx);
	if (!tid_rx)
		goto unlock;

	spin_lock_bh(&reorder->todo.lock);

	/* force to update rx todo list */
	reorder->todo.seq = ssn;
	reorder->todo.reason = SKW_RELEASE_BAR;

	if (!reorder->todo.actived) {
		reorder->todo.actived = true;
		INIT_LIST_HEAD(&reorder->todo.list);
		skw_list_add(&reorder->skw->rx_todo_list, &reorder->todo.list);
	}

	spin_unlock_bh(&reorder->todo.lock);

	skw_wakeup_rx(reorder->skw);

unlock:
	rcu_read_unlock();

	return 0;
}

int skw_add_tid_rx(struct skw_peer *peer, u16 tid, u16 ssn, u16 buf_size)
{
	int i;
	u32 win_sz;
	struct skw_tid_rx *tid_rx;
	struct skw_reorder_rx *reorder;

	skw_dbg("peer: %d, tid: %d, ssn: %d, win size: %d\n",
		peer->idx, tid, ssn, buf_size);

	reorder = &peer->reorder[tid];

	tid_rx = rcu_dereference(reorder->tid_rx);
	if (tid_rx)
		return skw_update_tid_rx(peer, tid, ssn, buf_size);

	win_sz = buf_size > 64 ? buf_size : 64;
	win_sz <<= 1;

	trace_skw_rx_add_ba(peer->iface->id, peer->idx, tid, ssn, win_sz);

	tid_rx = SKW_ZALLOC(sizeof(*tid_rx), GFP_KERNEL);
	if (!tid_rx) {
		skw_err("alloc failed, len: %ld\n", (long)(sizeof(*tid_rx)));
		return -ENOMEM;
	}

	tid_rx->reorder_buf = kcalloc(win_sz, sizeof(struct sk_buff_head),
				      GFP_KERNEL);
	if (!tid_rx->reorder_buf) {
		SKW_KFREE(tid_rx);
		return -ENOMEM;
	}

	for (i = 0; i < win_sz; i++)
		__skb_queue_head_init(&tid_rx->reorder_buf[i]);

	tid_rx->win_start = ssn;
	tid_rx->win_size = win_sz;
	tid_rx->stored_num = 0;
	tid_rx->reorder = reorder;
	tid_rx->ref_cnt = atomic_read(&reorder->ref_cnt);

	reorder->inst = peer->iface->id;
	reorder->peer_idx = peer->idx;
	reorder->tid = tid;

	reorder->todo.seq = 0;
	reorder->todo.actived = false;
	reorder->todo.reason = SKW_RELEASE_INVALID;

	reorder->skw = peer->iface->skw;

	rcu_assign_pointer(reorder->tid_rx, tid_rx);

	return 0;
}

int skw_del_tid_rx(struct skw_peer *peer, u16 tid)
{
	struct skw_tid_rx *tid_rx;
	struct skw_reorder_rx *reorder;
	struct sk_buff_head release_list;

	reorder = &peer->reorder[tid];

	__skb_queue_head_init(&release_list);

	trace_skw_rx_del_ba(tid);

	spin_lock_bh(&reorder->lock);
	tid_rx = rcu_dereference_protected(reorder->tid_rx,
			lockdep_is_held(&reorder->lock));

	RCU_INIT_POINTER(reorder->tid_rx, NULL);

	atomic_inc(&reorder->ref_cnt);

	smp_wmb();

	del_timer_sync(&reorder->timer);

	if (tid_rx) {
#ifdef CONFIG_SKW_GKI_DRV
		skw_call_rcu(peer->iface->skw, &tid_rx->rcu_head, skw_free_tid_rx);
#else
		call_rcu(&tid_rx->rcu_head, skw_free_tid_rx);
#endif
	}

	spin_unlock_bh(&reorder->lock);

	return 0;
}

#ifdef SKW_RX_WORKQUEUE

void skw_rx_worker(struct work_struct *work)
{
	unsigned long flags;
	struct skw_core *skw;
	struct sk_buff_head qlist;

	skw = container_of(work, struct skw_core, rx_worker);
	__skb_queue_head_init(&qlist);

	while (skw->rx_todo_list.count || skb_queue_len(&skw->rx_dat_q)) {
		skw_rx_todo(&skw->rx_todo_list);

		if (skb_queue_empty(&skw->rx_dat_q))
			return;

		/*
		 * data frame format:
		 * RX_DESC_HEADER + ETHERNET
		 */
		spin_lock_irqsave(&skw->rx_dat_q.lock, flags);
		skb_queue_splice_tail_init(&skw->rx_dat_q, &qlist);
		spin_unlock_irqrestore(&skw->rx_dat_q.lock, flags);

		skw_rx_data_handler(skw, &qlist);
	}
}

static int __skw_rx_init(struct skw_core *skw)
{
	int cpu;
	struct workqueue_attrs wq_attrs;

	skw->rx_wq = alloc_workqueue("skw_rxwq.%d", WQ_UNBOUND | __WQ_ORDERED, 1, skw->idx);
	if (!skw->rx_wq) {
		skw_err("alloc skwrx_workqueue failed\n");
		return -EFAULT;
	}

	memset(&wq_attrs, 0, sizeof(wq_attrs));
	wq_attrs.nice = MIN_NICE;

	apply_workqueue_attrs(skw->rx_wq, &wq_attrs);

	INIT_WORK(&skw->rx_worker, skw_rx_worker);

	queue_work(skw->rx_wq, &skw->rx_worker);

	return 0;
}

static void __skw_rx_deinit(struct skw_core *skw)
{
	atomic_set(&skw->exit, 1);
	cancel_work_sync(&skw->rx_worker);
	destroy_workqueue(skw->rx_wq);
}

#else

/* RX data thread entry */
static int skw_rx_thread(void *data)
{
	unsigned long flags;
	struct skw_core *skw;
	struct sk_buff_head qlist;

	skw = (struct skw_core *)data;
	__skb_queue_head_init(&qlist);

	while (!kthread_should_stop()) {
		skw_rx_todo(&skw->rx_todo_list);

		if (skb_queue_empty(&skw->rx_dat_q)) {
			set_current_state(TASK_IDLE);
			schedule_timeout(msecs_to_jiffies(1));
		}

		/*
		 * data frame format:
		 * RX_DESC_HEADER + ETHERNET
		 */
		spin_lock_irqsave(&skw->rx_dat_q.lock, flags);
		skb_queue_splice_tail_init(&skw->rx_dat_q, &qlist);
		spin_unlock_irqrestore(&skw->rx_dat_q.lock, flags);

		skw_rx_data_handler(skw, &qlist);
	}

	skw_info("exit\n");

	return 0;
}

static int __skw_rx_init(struct skw_core *skw)
{
	//int cpu;

	skw->rx_thread = kthread_create(skw_rx_thread, skw, "skw_rx.%d", skw->idx);
	if (IS_ERR(skw->rx_thread)) {
		skw_err("create rx thread failed\n");

		return PTR_ERR(skw->rx_thread);
	}

	skw_set_thread_priority(skw->rx_thread, SCHED_RR, 1);
	set_user_nice(skw->rx_thread, MIN_NICE);
	wake_up_process(skw->rx_thread);

	return 0;
}

static void __skw_rx_deinit(struct skw_core *skw)
{
	if (skw->rx_thread) {
		atomic_set(&skw->exit, 1);
		kthread_stop(skw->rx_thread);
		skw->rx_thread = NULL;
	}
}

#endif

/*
 * callback function, invoked by bsp
 */
int skw_rx_cb(int port, struct scatterlist *sglist,
		     int nents, void *priv)
{
	int ret;
	bool rx_sdma;
	void *sg_addr;
	int idx, total_len;
	struct sk_buff *skb;
	struct scatterlist *sg;
	struct skw_msg *msg;
	struct skw_iface *iface;
	struct skw_event_work *work;
	struct skw_core *skw = (struct skw_core *)priv;

	rx_sdma = skw->hw_pdata->bus_type & RX_SDMA;

	for_each_sg(sglist, sg, nents, idx) {
		if (!sg || !sg->length) {
			skw_warn("sg: 0x%p, nents: %d, idx: %d, len: %d\n",
				sg, nents, idx, sg ? sg->length : 0);
			break;
		}

		sg_addr = sg_virt(sg);

		if (rx_sdma) {
			skb = dev_alloc_skb(sg->length);
			if (!skb) {
				skw_err("alloc skb failed, len: %d\n", sg->length);
				continue;
			}

			skw_put_skb_data(skb, sg_addr, sg->length);
		} else {
			total_len = SKB_DATA_ALIGN(sg->length) + skw->skb_share_len;
			if (unlikely(total_len > SKW_ADMA_BUFF_LEN)) {
				skw_warn("sg->length: %d, rx buff: %lu, share info: %d\n",
					 sg->length, (long)SKW_ADMA_BUFF_LEN, skw->skb_share_len);

				skw_compat_page_frag_free(sg_addr);
				continue;
			}

			skb = build_skb(sg_addr, total_len);
			if (!skb) {
				skw_err("build skb failed, len: %d\n", total_len);

				skw_compat_page_frag_free(sg_addr);
				continue;
			}

			skb_put(skb, sg->length);
		}

		trace_skw_rx_irq(nents, idx, port, sg->length);

		if (skw->hw.bus == SKW_BUS_SDIO)
			skb_pull(skb, 4);

		if (port == skw->hw_pdata->cmd_port) {
			msg = (struct skw_msg *)skb_pull(skb, 12);
			if (!msg) {
				dev_kfree_skb(skb);
				continue;
			}

			trace_skw_msg_rx(msg->inst_id, msg->type, msg->id,
					msg->seq, msg->total_len);

			switch (msg->type) {
			case SKW_MSG_CMD_ACK:
				skw_cmd_ack_handler(skw, skb->data, skb->len);
				kfree_skb(skb);

				break;

			case SKW_MSG_EVENT:
				if (++skw->skw_event_sn != msg->seq) {
					skw_warn("invalid event seq: %d, expect: %d\n",
						 msg->seq, skw->skw_event_sn);

					skw_hw_assert(skw, false);
					kfree_skb(skb);

					continue;
				}

				if (msg->id == SKW_EVENT_CREDIT_UPDATE) {
					skw_event_add_credit(skw, msg + 1);
					smp_wmb();
					kfree_skb(skb);

					continue;
				}

				iface = to_skw_iface(skw, msg->inst_id);
				if (iface)
					work = &iface->event_work;
				else
					work = &skw->event_work;

				ret = skw_queue_event_work(priv_to_wiphy(skw),
							work, skb);
				if (ret < 0) {
					skw_err("inst: %d, drop event %d\n",
						msg->inst_id, msg->id);
					kfree_skb(skb);
				}

				break;

			default:
				skw_warn("invalid: type: %d, id: %d, seq: %d\n",
					msg->type, msg->id, msg->seq);

				kfree_skb(skb);
				break;
			}

		} else {
			skw_data_add_credit(skw, skb->data);
			skb_queue_tail(&skw->rx_dat_q, skb);

			skw->rx_packets++;
			if (skw->hw.bus == SKW_BUS_SDIO || skw->hw.bus == SKW_BUS_SDIO2)
				set_cpus_allowed_ptr(skw->rx_thread, cpumask_of(task_cpu(current)));
			skw_wakeup_rx(skw);

			skw_wake_lock_timeout(skw, 400);
		}
	}

	return 0;
}

int skw_register_rx_callback(struct skw_core *skw, void *cmd_cb, void *cmd_ctx,
			void *dat_cb, void *dat_ctx)
{
	int i, map, ret = 0;

	if (skw->hw.bus == SKW_BUS_PCIE)
		return 0;

	ret = skw_register_rx_cb(skw, skw->hw.cmd_port, cmd_cb, cmd_ctx);
	if (ret < 0) {
		skw_err("failed, command port: %d, ret: %d\n",
			skw->hw.cmd_port, ret);

		return ret;
	}

	for (map = 0, i = 0; i < SKW_MAX_LMAC_SUPPORT; i++) {
		int port = skw->hw.lmac[i].dport;

		if (!(skw->hw.lmac[i].flags & SKW_LMAC_FLAG_RXCB))
			continue;

		ret = skw_register_rx_cb(skw, port, dat_cb, dat_ctx);
		if (ret < 0) {
			skw_err("failed, data port: %d, ret: %d\n", port, ret);

			break;
		}

		map |= BIT(port);
	}

	skw_dbg("%s cmd port: %d, data port bitmap: 0x%x\n",
		cmd_cb ? "register" : "unregister", skw->hw.cmd_port, map);

	return ret;
}

int skw_rx_init(struct skw_core *skw)
{
	int ret;

	skw_list_init(&skw->rx_todo_list);
	spin_lock_init(&skw->rx_lock);
	skw_wake_lock_init(skw, 0, "skw_rx_wlock");

	ret = skw_register_rx_callback(skw, skw_rx_cb, skw, skw_rx_cb, skw);
	if (ret < 0) {
		skw_err("register rx callback failed, ret: %d\n", ret);
		return ret;
	}

	ret = __skw_rx_init(skw);
	if (ret < 0)
		skw_register_rx_callback(skw, NULL, NULL, NULL, NULL);

	rx_reorder_flag = true;
	skw_debugfs_file(skw->dentry, "rx_reorder", 0666, &skw_rx_reorder_fops, NULL);

	return 0;
}

int skw_rx_deinit(struct skw_core *skw)
{
	skw_register_rx_callback(skw, NULL, NULL, NULL, NULL);

	__skw_rx_deinit(skw);
	skw_rx_todo(&skw->rx_todo_list);

	skw_wake_lock_deinit(skw);

	return 0;
}
===== ./drivers/skwifi/skw_edma.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/kernel.h>
#include <linux/percpu-defs.h>
#include <linux/skbuff.h>

#include "skw_core.h"
#include "skw_compat.h"
#include "skw_edma.h"
#include "skw_util.h"
#include "skw_log.h"
#include "skw_msg.h"
#include "skw_rx.h"
#include "skw_tx.h"
#include "trace.h"

static struct kmem_cache *skw_edma_node_cache;

static inline void skw_dma_free_coherent(struct skw_core *skw,
		dma_addr_t *dma_handle, void *cpu_addr, size_t size)
{
	struct device *dev = priv_to_wiphy(skw)->dev.parent;

	dma_free_coherent(dev, size, cpu_addr, *dma_handle);
}

static inline void *skw_dma_alloc_coherent(struct skw_core *skw,
		dma_addr_t *dma_handle, size_t size, gfp_t flag)
{
	struct device *dev = priv_to_wiphy(skw)->dev.parent;

	return dma_alloc_coherent(dev, size, dma_handle, flag);
}

struct skw_edma_node *skw_edma_next_node(struct skw_edma_chn *chn)
{
	unsigned long flags;

	chn->current_node->buffer_pa = skw_pci_map_single(chn->context.skw,
				chn->current_node->buffer,
				chn->current_node->buffer_len, DMA_TO_DEVICE);
	spin_lock_irqsave(&chn->edma_chan_lock, flags);
	//skw_dbg("channel:%d prev_cur id:%d used:%d current_node:%p\n",
	//		chn->channel, chn->current_node->node_id,
	//		chn->current_node->used, chn->current_node);
	if (list_is_last(&chn->current_node->list, &chn->node_list)) {
		chn->current_node = list_first_entry(&chn->node_list,
				struct skw_edma_node, list);
	} else {
		chn->current_node = list_next_entry(chn->current_node, list);
	}

	chn->current_node->used = 0;
	chn->tx_node_count++;
	atomic_dec(&chn->nr_node);
	//skw_dbg("channel:%d cur id:%d used:%d, current node:%p\n",
	//		chn->channel, chn->current_node->node_id,
	//		chn->current_node->used, chn->current_node);
	spin_unlock_irqrestore(&chn->edma_chan_lock, flags);
	return chn->current_node;
}

int
skw_edma_set_data(struct wiphy *wiphy, struct skw_edma_chn *edma,
		void *data, int len)
{
	struct skw_edma_node *node = edma->current_node;
	unsigned long flags;
	u8 *buff = NULL;

	spin_lock_irqsave(&edma->edma_chan_lock, flags);
	buff = (u8 *)node->buffer;
	skw_dbg("chan: %d node_id: %d node->used: %d buff: %pad used: %pad\n",
		edma->channel, node->node_id, node->used, (dma_addr_t *)buff,
		(dma_addr_t *)(buff + node->used));
	//skw_dbg("data:%p, data:0x%llx\n", data, (u64) data);
	memcpy(buff + node->used, data, len);
	//skw_dbg("%d channel:%d node:%p\n", __LINE__, edma->channel, node);
	node->used += len;
	edma->hdr[node->node_id].data_len = node->used;
	spin_unlock_irqrestore(&edma->edma_chan_lock, flags);
	BUG_ON(len > node->buffer_len);
	if (node->used + len > node->buffer_len)
		node = skw_edma_next_node(edma);

	return 0;
}

int skw_edma_tx(struct wiphy *wiphy, struct skw_edma_chn *edma, int tx_len)
{
	int tx_count;
	struct skw_core *skw = wiphy_priv(wiphy);
	u64 pa = 0;

	skw_edma_next_node(edma);
	tx_count = edma->tx_node_count;
	pa = edma->hdr->hdr_next;
	//skw_dbg("channel:%d tx_node_count:%d pa:0x%llx\n",
	//	edma->channel, tx_count, pa);
	edma->tx_node_count = 0;

	return  skw->hw_pdata->hw_adma_tx(edma->channel, NULL,
					tx_count, tx_len);
}

static void skw_edma_chn_deinit(struct skw_core *skw, struct skw_edma_chn *edma)
{
	struct skw_edma_node *node = NULL, *tmp = NULL;
	// TODO: stop edma channel transmit

	if (!edma) {
		skw_err("emda is null\n");
		return;
	}

	skw_dbg("chan:%d\n", edma->channel);

	list_for_each_entry_safe(node, tmp, &edma->node_list, list) {
		list_del(&node->list);
		skw_pci_unmap_single(skw, node->buffer_pa, node->buffer_len,
					DMA_TO_DEVICE);
		SKW_KFREE(node->buffer);
		kmem_cache_free(skw_edma_node_cache, node);
	}
	edma->current_node = NULL;
	atomic_set(&edma->nr_node, 0);
	skw_dma_free_coherent(skw, &edma->edma_hdr_pa, edma->hdr,
				edma->edma_hdr_size);
}

static int skw_edma_chn_init(struct skw_core *skw, struct skw_edma_chn *edma,
			int channel, int max_node, int node_buff_len,
			skw_edma_isr isr, skw_edma_empty_isr empty_isr)
{
	u64 tmp_pa;
	int i, size;
	int next_offset;
	struct skw_edma_node *node;
	u64 hdr_next;

	size = max_node * sizeof(struct skw_edma_hdr);
	edma->hdr = skw_dma_alloc_coherent(skw, &edma->edma_hdr_pa,
					size, GFP_DMA);
	if (!edma->hdr)
		return -ENOMEM;

	memset(edma->hdr, 0x6a, size);

	edma->max_node_num = max_node;
	edma->channel = channel;
	edma->tx_node_count = 0;
	spin_lock_init(&edma->edma_chan_lock);
	INIT_LIST_HEAD(&edma->node_list);

	skw_dbg("%d channel: %d edma->edma_hdr_pa: %pad\n",
		__LINE__, channel, (dma_addr_t *)edma->edma_hdr_pa);

	for (i = 0; i < max_node; i++) {
		next_offset = 8 +
			sizeof(struct skw_edma_hdr) * ((i + 1) % max_node);
		edma->hdr[i].hdr_next =
			skw->hw_pdata->phyaddr_to_pcieaddr(edma->edma_hdr_pa) +
			next_offset;
		hdr_next = edma->hdr[i].hdr_next;
		skw_dbg("hdr_next pa:0x%llx\n", hdr_next);

		node = kmem_cache_alloc(skw_edma_node_cache, GFP_KERNEL);
		node->buffer = kzalloc(node_buff_len, GFP_DMA);
		memset(node->buffer, 0x5a, node_buff_len);
		if (!node->buffer)
			goto failed;

		node->used = 0;
		node->node_id = i;
		node->buffer_len = node_buff_len;

		edma->hdr[i].buffer_pa =
			skw->hw_pdata->virtaddr_to_pcieaddr(node->buffer);
		tmp_pa = edma->hdr[i].buffer_pa;
		skw_dbg("channel:%d i:%d buffer pcie addr:0x%llx\n",
			channel, i, tmp_pa);

		INIT_LIST_HEAD(&node->list);
		list_add_tail(&node->list, &edma->node_list);
	}

	edma->edma_hdr_size = size;

	atomic_set(&edma->nr_node, max_node);
	edma->current_node = list_first_entry(&edma->node_list,
				struct skw_edma_node, list);

	edma->isr = isr;
	edma->empty_isr = empty_isr;

	return 0;

failed:
	skw_edma_chn_deinit(skw, edma);

	return -ENOMEM;
}

static int
skw_edma_tx_node_isr(void *priv, void *first_pa, void *last_pa, int count)
{
	struct skw_edma_context *context = (struct skw_edma_context *)priv;
	u16 channel = context->channel;
	struct skw_core *skw = context->skw;
	struct skw_edma_chn *edma_chn = NULL;
	struct skw_edma_hdr *edma_hdr = NULL;
	int i = 0;
	u64 pa = 0, hdr_next = 0;
	int offset = 0;
	unsigned long flags;

	//skw_dbg("channel:%d first_pa:%p , count:%d\n",
	//		channel, first_pa, count);

	if (channel == SKW_EDMA_WIFI_TX0_CHN)
		edma_chn = &skw->hw.lmac[0].edma_tx_chn;
	else if (channel == SKW_EDMA_WIFI_TX1_CHN)
		edma_chn  = &skw->hw.lmac[1].edma_tx_chn;
	else if (channel == SKW_EDMA_WIFI_CMD_CHN)
		edma_chn  = &skw->edma_cmd;
	else
		return 0;

	spin_lock_irqsave(&edma_chn->edma_chan_lock, flags);
	hdr_next = edma_chn->hdr->hdr_next;
	//skw_dbg("hdr_pa:0x%llx first_pa:0x%llx  chan:%d, hdr_next:0x%llx\n",
	//		edma_chn->edma_hdr_pa, ((u64 ) (first_pa)),
	//		edma_chn->channel, hdr_next);

	//offset = (u64)first_pa - (edma_chn->hdr->hdr_next - 16);
	offset = skw->hw_pdata->pcieaddr_to_phyaddr((dma_addr_t)first_pa)
					- 8 - edma_chn->edma_hdr_pa;
	//skw_dbg("offset:%d channel:%d\n", offset, edma_chn->channel);
	//edma_hdr = (struct skw_edma_hdr *) (phys_to_virt(first_pa) - 8);
	edma_hdr = (struct skw_edma_hdr *)((u8 *)edma_chn->hdr + offset);
	//skw_dbg("edma_hdr:%p\n", edma_hdr);
	while (i < count) {
		pa = edma_hdr->buffer_pa; //pcie address
		//skw_dbg("i:%d edma pcie addr:0x%llx, phy addrs:0x%llx\n",
		//		i, pa, skw->hw_pdata->pcieaddr_to_phyaddr(pa));
		skw_pci_unmap_single(skw,
			skw->hw_pdata->pcieaddr_to_phyaddr(edma_hdr->buffer_pa),
			edma_chn->current_node->buffer_len, DMA_TO_DEVICE);
		atomic_inc(&edma_chn->nr_node);
		edma_hdr++;
		i++;
	}
	spin_unlock_irqrestore(&edma_chn->edma_chan_lock, flags);

	//skw_dbg("cur node buffer_pa:0x%llx cur node buffer_len:%d\n",
	//	edma_chn->current_node->buffer_pa,
	//	edma_chn->current_node->buffer_len);
	//skw_pci_unmap_single(skw, edma_chn->current_node->buffer_pa,
	//		edma_chn->current_node->buffer_len, DMA_TO_DEVICE);

	return 0;
}

static void
skw_pci_edma_tx_free(struct skw_core *skw, struct sk_buff_head *free_list,
					void *data, u16 data_len)
{
	int count;
	unsigned long flags;
	struct sk_buff *skb, *tmp;
	struct sk_buff_head qlist;
	u64 *p = (u64 *)data;
	u64 p_data = 0;
	int i = 0, j = 0, m = 0;
	//u64 tmp_out = 0;

	__skb_queue_head_init(&qlist);

	spin_lock_irqsave(&free_list->lock, flags);
	skb_queue_splice_tail_init(free_list, &qlist);
	spin_unlock_irqrestore(&free_list->lock, flags);

	// trace_skw_tx_pcie_edma_free(data_len/8);
	for (count = 0; count < data_len; count = count + 8, p++) {
		p_data = *p & 0xFFFFFFFFFF;
		j++;
		skb_queue_walk_safe(&qlist, skb, tmp) {
			//tmp_out = SKW_SKB_TXCB(skb)->e.pa;
			//skw_dbg("SKW_SKB_TXCB(skb)->e.pa:0x%llx\n", tmp_out);
			//tmp_out = p_data & 0xFFFFFFFFFF;
			//skw_dbg("p_data:0x%llx\n",  tmp_out);
			if (skb && (SKW_SKB_TXCB(skb)->e.pa == (p_data & 0xFFFFFFFFFF))) {
				__skb_unlink(skb, &qlist);
				skw_pci_unmap_single(skw,
					SKW_SKB_TXCB(skb)->skb_data_pa,
					skb->len, DMA_TO_DEVICE);
				//skw_dbg("free skb %p\n", skb->data);
				//kfree_skb(skb);
				//dev_kfree_skb_any(skb);
				skw_skb_kfree(skw, skb);
				i++;
				continue;
			}
			m++;
		}
	}

	if (i != j) {
		skw_dbg("i:%d, j:%d\n", j, j);
		//WARN_ON(1);
	}

	//skw_dbg("i:%d, j:%d\n", i, j);
	if (qlist.qlen) {
		spin_lock_irqsave(&free_list->lock, flags);
		skb_queue_splice_tail_init(&qlist, free_list);
		spin_unlock_irqrestore(&free_list->lock, flags);
	}

	//skw_compat_page_frag_free(data);
}

static void skw_pci_edma_rx_data(struct skw_core *skw, void *data, int data_len)
{
#if 0
	struct skw_rx_desc *desc = NULL;
	struct sk_buff *skb;
	int i, total_len;
	u64 p_data = 0;
	u64 *p = NULL;
	u16 pkt_len = 0;

	for (i = 0; i < data_len; i += 8) {
		p = (u64 *)((u8 *)data + i);
		p_data = skw->hw_pdata->pcieaddr_to_virtaddr(*p & 0xFFFFFFFFFF);

		desc = (struct skw_rx_desc *)((u8 *) (p_data + 52));

		//FW use this way to return unused buff
		if (unlikely(!desc->msdu_len)) {
			skw_compat_page_frag_free((void *)p_data);
			continue;
		}

		//msdu_len+desc_len(72)+eth_hdr_len(14)+pad(2)-snap_hdr(8)
		if (desc->snap_match)
			pkt_len = desc->msdu_len + 80;
		else
			pkt_len = desc->msdu_len + 88;

		total_len = SKB_DATA_ALIGN(pkt_len) + skw->skb_share_len;

		if (unlikely(total_len > SKW_ADMA_BUFF_LEN)) {
			skw_hw_assert(skw, false);
			skw_warn("total len: %d\n", total_len);

			skw_compat_page_frag_free((void *)p_data);
			continue;
		}

		skb = build_skb((void *)p_data, total_len);
		if (!skb) {
			skw_err("build skb failed, len: %d\n", total_len);

			skw_compat_page_frag_free((void *)p_data);
			continue;
		}

		skb_put(skb, pkt_len);
		skb_pull(skb, 8);
		skb_queue_tail(&skw->rx_dat_q, skb);
		skw->rx_packets++;
		skw_wakeup_rx(skw);
	}
#endif
}

static void skw_pci_edma_rx_filter_data(struct skw_core *skw, void *data, int data_len)
{
	struct sk_buff *skb;
	int total_len;

	total_len = SKB_DATA_ALIGN(data_len) + skw->skb_share_len;

	if (unlikely(total_len > SKW_ADMA_BUFF_LEN)) {
		skw_warn("total_len: %d\n", total_len);
		skw_compat_page_frag_free(data);
		return;
	}

	skb = build_skb((void *)data, total_len);
	if (!skb) {
		skw_err("build skb failed, len: %d\n", total_len);

		skw_compat_page_frag_free(data);
		return;
	}

	skb_put(skb, data_len);

	skb_queue_tail(&skw->rx_dat_q, skb);
	skw->rx_packets++;
	skw_wakeup_rx(skw);
}

void skw_pcie_edma_rx_cb(void *priv, void *data, u16 data_len)
{
	u16 channel = 0;
	int ret = 0, total_len = 0;
	struct skw_edma_context *context = (struct skw_edma_context *)priv;
	struct skw_core *skw = (struct skw_core *)context->skw;
	struct skw_iface *iface = NULL;
	struct skw_event_work *work = NULL;
	struct sk_buff *skb = NULL;
	struct skw_msg *msg = NULL;

	channel = context->channel;

	//skw_dbg("phy data:0x%llx len:%u\n", virt_to_phys(data), data_len);
	//short & long event channel
	//skw_dbg("channel:%d\n", channel);
	if (channel == SKW_EDMA_WIFI_SHORT_EVENT_CHN || channel == SKW_EDMA_WIFI_LONG_EVENT_CHN) {
		//skw_hex_dump("rx_cb data", data, 16, 1);

		total_len = SKB_DATA_ALIGN(data_len) + skw->skb_share_len;
		if (unlikely(total_len > SKW_ADMA_BUFF_LEN)) {
			skw_warn("data: %d\n", data_len);
			skw_compat_page_frag_free(data);
			return;
		}

		skb = build_skb(data, total_len);
		if (!skb) {
			skw_compat_page_frag_free(data);
			skw_err("build skb failed, len: %d\n", data_len);
			return;
		}

		skb_put(skb, data_len);
		//skw_dbg("data len:%d\n", skb->len);
		//skw_hex_dump("event content", skb->data, 16, 1);
		msg = (struct skw_msg *)skb->data;
		switch (msg->type) {
		case SKW_MSG_CMD_ACK:
			skw_cmd_ack_handler(skw, skb->data, skb->len);
			kfree_skb(skb);
			break;

		case SKW_MSG_EVENT:
			if (++skw->skw_event_sn != msg->seq) {
				skw_warn("invalid event seq:%d, expect:%d\n",
					 msg->seq, skw->skw_event_sn);

				//skw_hw_assert(skw);
				//kfree_skb(skb);
				//break;
			}

			if (msg->id == SKW_EVENT_CREDIT_UPDATE) {
				skw_warn("PCIE doesn't support CREDIT");
				kfree_skb(skb);
				break;
			}

			iface = to_skw_iface(skw, msg->inst_id);
			if (iface)
				work = &iface->event_work;
			else
				work = &skw->event_work;

			ret = skw_queue_event_work(priv_to_wiphy(skw),
						work, skb);
			if (ret < 0) {
				skw_err("inst: %d, drop event %d\n",
					msg->inst_id, msg->id);
				kfree_skb(skb);
			}
			break;

		default:
			skw_warn("invalid: type: %d, id: %d, seq: %d\n",
						msg->type, msg->id, msg->seq);
			kfree_skb(skb);
			break;
		}
	} else if (channel == SKW_EDMA_WIFI_TX0_FREE_CHN ||
			channel == SKW_EDMA_WIFI_TX1_FREE_CHN) {
		struct sk_buff_head *edma_free_list = NULL;

		//skw_dbg("channel:%d received tx free data\n", channel);
		if (channel ==  SKW_EDMA_WIFI_TX1_FREE_CHN)
			edma_free_list = &skw->hw.lmac[1].edma_free_list;
		else
			edma_free_list = &skw->hw.lmac[0].edma_free_list;

		skw_pci_edma_tx_free(skw, edma_free_list, data, data_len);

	} else if (channel == SKW_EDMA_WIFI_RX0_CHN ||
			channel == SKW_EDMA_WIFI_RX1_CHN) {
		//skw_dbg("channel:%d received data\n", channel);
		skw_pci_edma_rx_data(skw, data, data_len);
	} else if (channel == SKW_EDMA_WIFI_RX0_FITER_CHN ||
			channel == SKW_EDMA_WIFI_RX1_FITER_CHN) {
		//skw_dbg("channel:%d received filter data\n", channel);
		//skw_hex_dump("filter data", data, data_len, 1);
		skw_pci_edma_rx_filter_data(skw, data, data_len);
	}
}

static int skw_edma_cache_init(struct skw_core *skw)
{
	if (skw->hw.bus != SKW_BUS_PCIE)
		return 0;

	skw_edma_node_cache = kmem_cache_create("skw_edma_node_cache",
						sizeof(struct skw_edma_node),
						0, 0, NULL);
	if (!skw_edma_node_cache)
		return -ENOMEM;

	return 0;
}

static void skw_edma_cache_deinit(struct skw_core *skw)
{
	if (skw->hw.bus == SKW_BUS_PCIE)
		kmem_cache_destroy(skw_edma_node_cache);
}

int skw_edma_cfg_chan(struct skw_core *skw, struct skw_edma_chn *edma_ch,
	struct skw_channel_cfg *cfg)
{
	int ret = 0;

	edma_ch->context.skw = skw;
	edma_ch->context.channel = edma_ch->channel;
	edma_ch->context.edma_ch_cfg = cfg;

	cfg->node_count = edma_ch->max_node_num;
	cfg->header = edma_ch->hdr[cfg->node_count - 1].hdr_next;
	skw_dbg("channel: %d header pa: %pad\n",
		edma_ch->context.channel, (dma_addr_t *)cfg->header);
	cfg->complete_callback = skw->edma_cmd.isr;
	cfg->rx_callback = skw_pcie_edma_rx_cb;
	cfg->context = &skw->edma_cmd.context;
	ret = skw->hw_pdata->hw_channel_init(edma_ch->channel, cfg, NULL);

	return ret;
}

int skw_edma_init(struct wiphy *wiphy)
{
	int ret, i;
	struct skw_channel_cfg ch_cfg;
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_lmac *lmac = NULL;

	ret = skw_edma_cache_init(skw);
	if (ret < 0) {
		skw_err("edma cached init failed, ret: %d\n", ret);
		return ret;
	}

	//cmd channel
	skw_edma_chn_init(skw, &skw->edma_cmd,
		SKW_EDMA_WIFI_CMD_CHN, 1,
		SKW_MSG_BUFFER_LEN, skw_edma_tx_node_isr, NULL);
	memset(&ch_cfg, 0, sizeof(struct skw_channel_cfg));
	ch_cfg.direction = 0;
	ch_cfg.priority = 0;
	ch_cfg.split = 1;
	ch_cfg.ring = 1;
	ch_cfg.req_mode = 1;
	ch_cfg.irq_threshold = 1;
	skw_edma_cfg_chan(skw, &skw->edma_cmd, &ch_cfg);

	//short event channel
	skw_edma_chn_init(skw, &skw->edma_short_event,
		SKW_EDMA_WIFI_SHORT_EVENT_CHN,
		SKW_EDMA_EVENT_CHN_NODE_NUM,
		SKW_MSG_BUFFER_LEN, NULL, NULL);
	memset(&ch_cfg, 0, sizeof(struct skw_channel_cfg));
	ch_cfg.direction = 1;
	ch_cfg.priority = 0;
	ch_cfg.split = 1;
	ch_cfg.ring = 0;
	ch_cfg.req_mode = 1;
	ch_cfg.irq_threshold = 1;
	skw_edma_cfg_chan(skw, &skw->edma_short_event, &ch_cfg);

	//long event channel
	skw_edma_chn_init(skw, &skw->edma_long_event,
		SKW_EDMA_WIFI_LONG_EVENT_CHN,
		SKW_EDMA_EVENT_CHN_NODE_NUM,
		SKW_MSG_BUFFER_LEN, NULL, NULL);

	memset(&ch_cfg, 0, sizeof(struct skw_channel_cfg));
	ch_cfg.direction = 1;
	ch_cfg.priority = 0;
	ch_cfg.split = 1;
	ch_cfg.ring = 0;
	ch_cfg.req_mode = 1;
	ch_cfg.irq_threshold = 1;
	skw_edma_cfg_chan(skw, &skw->edma_long_event, &ch_cfg);

	// data tx/rx channel
	for (i = 0; i < SKW_MAX_LMAC_SUPPORT; i++) {
		lmac = &skw->hw.lmac[i];

		// RX filter channel
		skw_edma_chn_init(skw,  &lmac->edma_filter_ch,
			SKW_EDMA_WIFI_RX0_FITER_CHN + i,
			SKW_EDMA_FILTER_CHN_NODE_NUM,
			SKW_MSG_BUFFER_LEN, NULL, NULL);
		memset(&ch_cfg, 0, sizeof(struct skw_channel_cfg));
		ch_cfg.direction = 1;
		ch_cfg.priority = 0;
		ch_cfg.split = 1;
		ch_cfg.ring = 0;
		ch_cfg.req_mode = 1;
		ch_cfg.irq_threshold = 1;
		skw_edma_cfg_chan(skw, &lmac->edma_filter_ch, &ch_cfg);

		//TX chan
		skw_edma_chn_init(skw, &lmac->edma_tx_chn,
			SKW_EDMA_WIFI_TX0_CHN + i,
			SKW_EDMA_TX_CHN_NODE_NUM,
			SKW_EDMA_DATA_LEN, skw_edma_tx_node_isr, NULL);
		memset(&ch_cfg, 0, sizeof(struct skw_channel_cfg));
		ch_cfg.direction = 0;
		ch_cfg.priority = 0;
		ch_cfg.split = 1;
		ch_cfg.ring = 1;
		ch_cfg.req_mode = 1;
		ch_cfg.irq_threshold = 1;
		skw_edma_cfg_chan(skw, &lmac->edma_tx_chn, &ch_cfg);

		//TX free chan
		skb_queue_head_init(&lmac->edma_free_list);

		skw_edma_chn_init(skw, &lmac->edma_tx_resp_chn,
			SKW_EDMA_WIFI_TX0_FREE_CHN + i,
			SKW_EDMA_TX_FREE_CHN_NODE_NUM,
			SKW_EDMA_DATA_LEN, NULL, NULL);
		memset(&ch_cfg, 0, sizeof(struct skw_channel_cfg));
		ch_cfg.direction = 1;
		ch_cfg.priority = 0;
		ch_cfg.split = 1;
		ch_cfg.ring = 1;
		ch_cfg.req_mode = 1;
		ch_cfg.irq_threshold = 1;
		skw_edma_cfg_chan(skw, &lmac->edma_tx_resp_chn, &ch_cfg);

		//RX chan
		skw_edma_chn_init(skw, &lmac->edma_rx_chn,
			SKW_EDMA_WIFI_RX0_CHN + i,
			SKW_EDMA_RX_CHN_NODE_NUM,
			SKW_EDMA_DATA_LEN, NULL, NULL);
		memset(&ch_cfg, 0, sizeof(struct skw_channel_cfg));
		ch_cfg.direction = 1;
		ch_cfg.priority = 0;
		ch_cfg.split = 1;
		ch_cfg.ring = 1;
		ch_cfg.req_mode = 1;
		ch_cfg.irq_threshold = 1;
		skw_edma_cfg_chan(skw, &lmac->edma_rx_chn, &ch_cfg);

		//RX free chan
		skw_edma_chn_init(skw, &lmac->edma_rx_req_chn,
			SKW_EDMA_WIFI_RX0_FREE_CHN + i,
			SKW_EDMA_RX_FREE_CHN_NODE_NUM,
			SKW_EDMA_DATA_LEN, NULL, NULL);
		memset(&ch_cfg, 0, sizeof(struct skw_channel_cfg));
		ch_cfg.direction = 0;
		ch_cfg.priority = 0;
		ch_cfg.split = 1;
		ch_cfg.ring = 1;
		ch_cfg.req_mode = 1;
		//mac0_rx_free_ch_cfg.irq_threshold = 1;
		skw_edma_cfg_chan(skw, &lmac->edma_rx_req_chn, &ch_cfg);

		lmac->flags = SKW_LMAC_FLAG_INIT;
	}

	return 0;
}

//TBD: Use macro to define the node number for each channel

void skw_edma_deinit(struct wiphy *wiphy)
{
	struct skw_core *skw = wiphy_priv(wiphy);
	int i = 0;
	struct skw_lmac *lmac = NULL;

	if (skw->hw.bus != SKW_BUS_PCIE)
		return;

	skw_edma_chn_deinit(skw, &skw->edma_cmd);
	skw_edma_chn_deinit(skw, &skw->edma_short_event);
	skw_edma_chn_deinit(skw, &skw->edma_long_event);

	for (i = 0; i < SKW_MAX_LMAC_SUPPORT; i++) {
		lmac = &skw->hw.lmac[i];
		skw_edma_chn_deinit(skw, &lmac->edma_tx_chn);
		skw_edma_chn_deinit(skw, &lmac->edma_tx_resp_chn);
		skw_edma_chn_deinit(skw, &lmac->edma_rx_chn);
		skw_edma_chn_deinit(skw, &lmac->edma_rx_req_chn);
		skb_queue_purge(&lmac->edma_free_list);
	}

	skw_edma_cache_deinit(skw);
}
===== ./drivers/skwifi/skw_vendor.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <net/cfg80211.h>
#include <net/genetlink.h>

#include "skw_vendor.h"
#include "skw_cfg80211.h"
#include "skw_core.h"
#include "skw_iface.h"
#include "skw_util.h"
#include "skw_regd.h"
#include "version.h"

const struct nla_policy
skw_set_country_policy[SKW_SET_COUNTRY_RULES] = {
	[SKW_ATTR_SET_COUNTRY] = {.type = NLA_STRING},
};

const struct nla_policy
skw_get_valid_channels_policy[SKW_GET_VALID_CHANNELS_RULES] = {
	[SKW_ATTR_GET_VALID_CHANNELS] = {.type = NLA_U32},
};

const struct nla_policy
skw_get_version_policy[SKW_GET_VERSION_RULES] = {
	[SKW_ATTR_VERSION_DRIVER] = {.type = NLA_U32},
	[SKW_ATTR_VERSION_FIRMWARE] = {.type = NLA_U32},
};

#if 0
static int skw_vendor_dbg_reset_logging(struct wiphy *wiphy,
	struct wireless_dev *wdev, const void  *data, int len)
{
	int ret = SKW_OK;

	skw_dbg("Enter\n");

	return ret;
}

static int skw_vendor_set_p2p_rand_mac(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void *data, int len)
{
	int type;
	//struct skw_iface *iface = netdev_priv(wdev->netdev);
	u8 mac_addr[6] = {0};

	skw_dbg("set skw mac addr\n");
	type = nla_type(data);

	if (type == SKW_ATTR_DRIVER_RAND_MAC) {
		memcpy(mac_addr, nla_data(data), 6);
		skw_dbg("mac:%pM\n", mac_addr);
	}

	return 0;
}

static int skw_vendor_set_rand_mac_oui(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void *data, int len)
{
	char *oui = nla_data(data);
	struct skw_iface *iface = SKW_WDEV_TO_IFACE(wdev);

	if (!oui || (nla_len(data) != DOT11_OUI_LEN))
		return -EINVAL;

	skw_dbg("%02x:%02x:%02x\n", oui[0], oui[1], oui[2]);

	memcpy(iface->rand_mac_oui, oui, DOT11_OUI_LEN);

	return 0;
}
#endif

static int skw_vendor_cmd_reply(struct wiphy *wiphy, const void *data, int len)
{
	struct sk_buff *skb;

	/* Alloc the SKB for vendor_event */
	skb = cfg80211_vendor_cmd_alloc_reply_skb(wiphy, len);
	if (unlikely(!skb)) {
		skw_err("skb alloc failed");
		return -ENOMEM;
	}

	/* Push the data to the skb */
	nla_put_nohdr(skb, len, data);

	return cfg80211_vendor_cmd_reply(skb);
}

static int skw_vendor_start_logging(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void  *data, int len)
{
	skw_dbg("inst: %d\n", SKW_WDEV_TO_IFACE(wdev)->id);

	return 0;
}

static int skw_vendor_get_wake_reason_stats(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void *data, int len)
{
	skw_dbg("inst: %d\n", SKW_WDEV_TO_IFACE(wdev)->id);

	return 0;
}

static int skw_vendor_get_apf_capabilities(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void *data, int len)
{
	struct sk_buff *skb;

	skb = cfg80211_vendor_cmd_alloc_reply_skb(wiphy, NLMSG_DEFAULT_SIZE);
	if (!skb)
		return -ENOMEM;

	if (nla_put_u32(skb, SKW_ATTR_APF_VERSION, 4) ||
	    nla_put_u32(skb, SKW_ATTR_APF_MAX_LEN, 1024))
		return -ENOMEM;

	return cfg80211_vendor_cmd_reply(skb);
}

static int skw_vendor_get_ring_buffer_data(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void  *data, int len)
{
	skw_dbg("inst: %d\n", SKW_WDEV_TO_IFACE(wdev)->id);

	return 0;
}

static int skw_vendor_get_firmware_dump(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void  *data, int len)
{
	skw_dbg("inst: %d\n", SKW_WDEV_TO_IFACE(wdev)->id);

	return 0;
}

static int skw_vendor_select_tx_power_scenario(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void *data, int len)
{
	skw_dbg("inst: %d\n", SKW_WDEV_TO_IFACE(wdev)->id);

	return 0;
}

static int skw_vendor_set_latency_mode(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void *data, int len)
{
	skw_dbg("inst: %d\n", SKW_WDEV_TO_IFACE(wdev)->id);

	return 0;
}

static int skw_vendor_get_feature_set(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void *data, int len)
{
	u32 feature_set = 0;

	/* Hardcoding these values for now, need to get
	 * these values from FW, will change in a later check-in
	 */
	feature_set |= WIFI_FEATURE_INFRA;
	feature_set |= WIFI_FEATURE_INFRA_5G;
	feature_set |= WIFI_FEATURE_P2P;
	feature_set |= WIFI_FEATURE_SOFT_AP;
	feature_set |= WIFI_FEATURE_AP_STA;
	//feature_set |= WIFI_FEATURE_TDLS;
	//feature_set |= WIFI_FEATURE_TDLS_OFFCHANNEL;
	//feature_set |= WIFI_FEATURE_NAN;
	//feature_set |= WIFI_FEATURE_HOTSPOT;
	//feature_set |= WIFI_FEATURE_LINK_LAYER_STATS; //TBC
	//feature_set |= WIFI_FEATURE_RSSI_MONITOR; //TBC with roaming
	//feature_set |= WIFI_FEATURE_MKEEP_ALIVE; //TBC compare with QUALCOM
	//feature_set |= WIFI_FEATURE_CONFIG_NDO; //TBC
	//feature_set |= WIFI_FEATURE_SCAN_RAND;
	//feature_set |= WIFI_FEATURE_RAND_MAC;
	//feature_set |= WIFI_FEATURE_P2P_RAND_MAC ;
	//feature_set |= WIFI_FEATURE_CONTROL_ROAMING;

	skw_dbg("feature: 0x%x\n", feature_set);

	return skw_vendor_cmd_reply(wiphy, &feature_set, sizeof(u32));
}

static int skw_vendor_set_country(struct wiphy *wiphy, struct wireless_dev *wdev,
				  const void *data, int data_len)
{
	char *country = nla_data(data);

	if (nla_type(data) != SKW_ATTR_SET_COUNTRY)
		skw_warn("attr mismatch, type: %d\n", nla_type(data));

	if (!country || strlen(country) != 2) {
		skw_err("invalid, country: %s\n", country ? country : "null");

		return -EINVAL;
	}

	skw_dbg("country: %c%c\n", country[0], country[1]);

	return skw_set_regdom(wiphy, country);
}

static int skw_vendor_get_version(struct wiphy *wiphy, struct wireless_dev *wdev,
				const void *data, int len)
{
	char version[64] = {0};
	struct skw_core *skw = wiphy_priv(wiphy);

	switch (nla_type(data)) {
	case SKW_ATTR_VERSION_DRIVER:
		strncpy(version, SKW_VERSION, sizeof(version));
		break;

	case SKW_ATTR_VERSION_FIRMWARE:
		snprintf(version, sizeof(version), "%s-%s",
			 skw->fw.plat_ver, skw->fw.wifi_ver);
		break;

	default:
		skw_err("invalid nla type\n");
		strcpy(version, "invalid");
		break;
	}

	return skw_vendor_cmd_reply(wiphy, version, sizeof(version));
}

static int skw_vendor_get_usable_channels(struct wiphy *wiphy,
			struct wireless_dev *wdev, const void *data, int len)
{
	int i, nr, max;
	struct sk_buff *skb;
	enum nl80211_band band;
	struct skw_usable_chan *chans;
	struct skw_usable_chan_req *req = (struct skw_usable_chan_req *)data;

	skw_dbg("band_mask: 0x%x\n", req->band_mask);

	max = ieee80211_get_num_supported_channels(wiphy);

	chans = SKW_ZALLOC(max * sizeof(*chans), GFP_KERNEL);
	if (!chans)
		return -ENOMEM;

	skb = cfg80211_vendor_cmd_alloc_reply_skb(wiphy, NLMSG_DEFAULT_SIZE);
	if (!skb) {
		SKW_KFREE(chans);
		return -ENOMEM;
	}

	for (nr = 0, band = 0; band < NUM_NL80211_BANDS; band++) {
		if (!(req->band_mask & BIT(to_skw_band(band))) ||
		    !wiphy->bands[band])
			continue;

		for (i = 0; i < wiphy->bands[band]->n_channels; i++) {
			struct ieee80211_channel *chan;

			chan = &wiphy->bands[band]->channels[i];

			if (chan->flags & IEEE80211_CHAN_DISABLED)
				continue;

			chans[nr].center_freq = chan->center_freq;
			chans[nr].band_width = SKW_CHAN_WIDTH_20;
			chans[nr].iface_mode_mask = BIT(SKW_STA_MODE) |
						    BIT(SKW_AP_MODE) |
						    BIT(SKW_GC_MODE) |
						    BIT(SKW_GO_MODE);
			nr++;
		}
	}

	if (nla_put_nohdr(skb, nr * sizeof(*chans), chans)) {
		SKW_KFREE(chans);
		kfree_skb(skb);

		return -ENOMEM;
	}

	SKW_KFREE(chans);

	return cfg80211_vendor_cmd_reply(skb);
}

static int skw_vendor_get_valid_channels(struct wiphy *wiphy,
		struct wireless_dev *wdev, const void *data, int len)
{
	int channels[32], size;
	int i, band, nr_channels;
	struct sk_buff *skb;

	if (nla_type(data) != SKW_ATTR_GET_VALID_CHANNELS)
		skw_warn("attr mismatch, type: %d", nla_type(data));

	band = nla_get_u32(data);
	if (band > NL80211_BAND_5GHZ) {
		skw_err("invalid band: %d\n", band);
		return -EINVAL;
	}

	skb = cfg80211_vendor_cmd_alloc_reply_skb(wiphy, NLMSG_DEFAULT_SIZE);
	if (!skb)
		return -ENOMEM;

	nr_channels = wiphy->bands[band]->n_channels;
	size = nr_channels * sizeof(int);

	for (i = 0; i < nr_channels; i++)
		channels[i] = wiphy->bands[band]->channels[i].hw_value;

	if (nla_put_u32(skb, SKW_ATTR_VALID_CHANNELS_COUNT, nr_channels) ||
	    nla_put(skb, SKW_ATTR_VALID_CHANNELS_LIST, size, channels)) {
		kfree_skb(skb);

		return -ENOMEM;
	}

	return cfg80211_vendor_cmd_reply(skb);
}

static int skw_vendor_get_ring_buffers_status(struct wiphy *wiphy,
			struct wireless_dev *wdev, const void  *data, int len)
{
	struct sk_buff *skb;
	struct skw_ring_buff_status status = {
		.name = "skw_drv",
		.flags = 0,
		.ring_id = 0,
		.ring_buffer_byte_size = 1024,
		.verbose_level = 0,
		.written_bytes = 0,
		.read_bytes = 0,
		.written_records = 0,
	};

	skb = cfg80211_vendor_cmd_alloc_reply_skb(wiphy, NLMSG_DEFAULT_SIZE);
	if (!skb)
		return -ENOMEM;

	if (nla_put_u32(skb, SKW_ATTR_RING_BUFFERS_COUNT, 1) ||
	    nla_put(skb, SKW_ATTR_RING_BUFFERS_STATUS, sizeof(status), &status))
		return -ENOMEM;

	return cfg80211_vendor_cmd_reply(skb);
}

static int skw_vendor_get_logger_feature(struct wiphy *wiphy,
			struct wireless_dev *wdev, const void  *data, int len)
{
	u32 features = 0;

	skw_dbg("features: 0x%x\n", features);

	return skw_vendor_cmd_reply(wiphy, &features, sizeof(features));
}

#if (KERNEL_VERSION(5, 3, 0) <= LINUX_VERSION_CODE)
#define SKW_VENDOR_CMD(oui, cmd, flag, func, nla_policy, max_attr)  \
{                                                                   \
	.info = {.vendor_id = oui, .subcmd = cmd},                  \
	.flags = flag,                                              \
	.doit = func,                                               \
	.policy = nla_policy,                                       \
	.maxattr = max_attr,                                        \
}
#else
#define SKW_VENDOR_CMD(oui, cmd, flag, func, nla_policy, max_attr)  \
{                                                                   \
	.info = {.vendor_id = oui, .subcmd = cmd},                  \
	.flags = flag,                                              \
	.doit = func,                                               \
}
#endif

#define SKW_VENDOR_DEFAULT_FLAGS (WIPHY_VENDOR_CMD_NEED_WDEV |      \
				  WIPHY_VENDOR_CMD_NEED_NETDEV)

static struct wiphy_vendor_command skw_vendor_cmds[] = {
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_GET_VALID_CHANNELS,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_get_valid_channels,
			skw_get_valid_channels_policy,
			SKW_GET_VALID_CHANNELS_RULES),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_GET_FEATURE_SET,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_get_feature_set,
			VENDOR_CMD_RAW_DATA, 0),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_GET_VERSION,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_get_version,
			skw_get_version_policy,
			SKW_GET_VERSION_RULES),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_GET_RING_BUFFERS_STATUS,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_get_ring_buffers_status,
			VENDOR_CMD_RAW_DATA, 0),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_GET_LOGGER_FEATURE,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_get_logger_feature,
			VENDOR_CMD_RAW_DATA, 0),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_GET_APF_CAPABILITIES,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_get_apf_capabilities,
			VENDOR_CMD_RAW_DATA, 0),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_GET_USABLE_CHANS,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_get_usable_channels,
			VENDOR_CMD_RAW_DATA, 0),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_SET_COUNTRY,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_set_country,
			skw_set_country_policy, SKW_SET_COUNTRY_RULES),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_START_LOGGING,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_start_logging,
			VENDOR_CMD_RAW_DATA, 0),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_GET_FIRMWARE_DUMP,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_get_firmware_dump,
			VENDOR_CMD_RAW_DATA, 0),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_GET_RING_BUFFER_DATA,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_get_ring_buffer_data,
			VENDOR_CMD_RAW_DATA, 0),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_GET_WAKE_REASON_STATS,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_get_wake_reason_stats,
			VENDOR_CMD_RAW_DATA, 0),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_SELECT_TX_POWER_SCENARIO,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_select_tx_power_scenario,
			VENDOR_CMD_RAW_DATA, 0),
	SKW_VENDOR_CMD(OUI_GOOGLE, SKW_VID_SET_LATENCY_MODE,
			SKW_VENDOR_DEFAULT_FLAGS,
			skw_vendor_set_latency_mode,
			VENDOR_CMD_RAW_DATA, 0),
};

static struct nl80211_vendor_cmd_info skw_vendor_events[] = {
	{
		.vendor_id = 0,
		.subcmd = 0,
	},
};

void skw_vendor_init(struct wiphy *wiphy)
{
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 14, 0)
	wiphy->vendor_commands = skw_vendor_cmds;
	wiphy->n_vendor_commands = ARRAY_SIZE(skw_vendor_cmds);
	wiphy->vendor_events = skw_vendor_events;
	wiphy->n_vendor_events = ARRAY_SIZE(skw_vendor_events);
#else
	skw_dbg("cmd: %d, event: %d\n", ARRAY_SIZE(skw_vendor_cmds),
		ARRAY_SIZE(skw_vendor_events));
#endif
}

void skw_vendor_deinit(struct wiphy *wiphy)
{
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 14, 0)
	wiphy->vendor_commands = NULL;
	wiphy->n_vendor_commands = 0;
#endif
}
===== ./drivers/skwifi/skw_iw.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/string.h>
#include <linux/ctype.h>
#include <net/iw_handler.h>
#include <linux/udp.h>
#include <linux/if_ether.h>
#include <linux/ip.h>
#include <net/cfg80211-wext.h>

#include "skw_core.h"
#include "skw_cfg80211.h"
#include "skw_iface.h"
#include "skw_iw.h"
#include "skw_log.h"

static int skw_iw_commit(struct net_device *dev, struct iw_request_info *info,
			 union iwreq_data *wrqu, char *extra)
{
	skw_dbg("traced\n");

	return 0;
}

static int skw_iw_get_name(struct net_device *dev, struct iw_request_info *info,
			   union iwreq_data *wrqu, char *extra)
{
	skw_dbg("traced\n");

	return 0;
}

static int skw_iw_set_freq(struct net_device *dev, struct iw_request_info *info,
			   union iwreq_data *wrqu, char *extra)
{
	skw_dbg("traced\n");

	return 0;
}

static int skw_iw_get_freq(struct net_device *dev, struct iw_request_info *info,
			   union iwreq_data *wrqu, char *extra)
{
	skw_dbg("traced\n");

	return 0;
}

static int skw_iw_set_mode(struct net_device *dev, struct iw_request_info *info,
			   union iwreq_data *wrqu, char *extra)
{
	skw_dbg("traced\n");

	return 0;
}

static int skw_iw_get_mode(struct net_device *dev, struct iw_request_info *info,
			   union iwreq_data *wrqu, char *extra)
{
	skw_dbg("traced\n");

	return 0;
}

static struct iw_statistics *skw_get_wireless_stats(struct net_device *dev)
{
	skw_dbg("traced\n");

	return NULL;
}

static const iw_handler skw_iw_standard_handlers[] = {
	IW_HANDLER(SIOCSIWCOMMIT, (iw_handler)skw_iw_commit),
	IW_HANDLER(SIOCGIWNAME, (iw_handler)skw_iw_get_name),
	IW_HANDLER(SIOCSIWFREQ, (iw_handler)skw_iw_set_freq),
	IW_HANDLER(SIOCGIWFREQ, (iw_handler)skw_iw_get_freq),
	IW_HANDLER(SIOCSIWMODE,	(iw_handler)skw_iw_set_mode),
	IW_HANDLER(SIOCGIWMODE,	(iw_handler)skw_iw_get_mode),
#ifdef CONFIG_CFG80211_WEXT_EXPORT
	IW_HANDLER(SIOCGIWRANGE, (iw_handler)cfg80211_wext_giwrange),
	IW_HANDLER(SIOCSIWSCAN,	(iw_handler)cfg80211_wext_siwscan),
	IW_HANDLER(SIOCGIWSCAN,	(iw_handler)cfg80211_wext_giwscan),
#endif
};

#ifdef CONFIG_WEXT_PRIV

#define SKW_SET_LEN_64                  64
#define SKW_SET_LEN_128                 128
#define SKW_SET_LEN_256                 256
#define SKW_SET_LEN_512                 512
#define SKW_GET_LEN_512                 512
#define SKW_SET_LEN_1024                1024
#define SKW_GET_LEN_1024                1024
#define SKW_KEEP_BUF_SIZE               1024

/* max to 16 commands */
#define SKW_IW_PRIV_SET                (SIOCIWFIRSTPRIV + 1)
#define SKW_IW_PRIV_GET                (SIOCIWFIRSTPRIV + 3)
#define SKW_IW_PRIV_AT                 (SIOCIWFIRSTPRIV + 5)
#define SKW_IW_PRIV_80211MODE          (SIOCIWFIRSTPRIV + 6)
#define SKW_IW_PRIV_GET_80211MODE      (SIOCIWFIRSTPRIV + 7)
#define SKW_IW_PRIV_KEEP_ALIVE         (SIOCIWFIRSTPRIV + 8)
#define SKW_IW_PRIV_WOW_FILTER         (SIOCIWFIRSTPRIV + 9)

#define SKW_IW_PRIV_LAST               SIOCIWLASTPRIV

static struct skw_keep_active_setup kp_set = {0,};
static u8 skw_wow_flted[256];

static int skw_keep_alive_add_checksum(u8 *buff, u32 len)
{
	u8 *ptr = buff;
	struct iphdr *ip;
	struct udphdr *udp;
	__sum16 sum, sum1;
	u32 udp_len;

	ptr += sizeof(struct ethhdr);
	ip = (struct iphdr *)ptr;
	ip->check = 0;
	ip->check = cpu_to_le16(ip_compute_csum(ip, 20));

	ptr += sizeof(struct iphdr);
	udp = (struct udphdr *)ptr;
	udp->check = 0;

	udp_len = len - sizeof(struct ethhdr)
		 - sizeof(struct iphdr);
	sum1 = csum_partial(ptr,
					udp_len, 0);
	sum = csum_tcpudp_magic(ip->saddr, ip->daddr,
				udp_len, IPPROTO_UDP, sum1);
	udp->check = cpu_to_le16(sum);

	skw_dbg("chsum %x %x\n", ip->check, sum);
	return 0;
}

static int skw_keep_active_rule_save(struct skw_core *skw,
	 struct skw_keep_active_rule *kp, u8 idx, u8 en, u32 flags)
{
	int ret;

	if (!skw || idx >= SKW_KEEPACTIVE_RULE_MAX) {
		ret = -EFAULT;
		return ret;
	}

	if (kp) {
		if (kp_set.rule[idx])
			SKW_KFREE(kp_set.rule[idx]);

		kp_set.rule[idx] = SKW_ZALLOC(kp->payload_len
			 + sizeof(*kp), GFP_KERNEL);
		memcpy(kp_set.rule[idx], kp, kp->payload_len + sizeof(*kp));
		skw_keep_alive_add_checksum(kp_set.rule[idx]->data[0].payload,
				kp_set.rule[idx]->payload_len
				- sizeof(struct skw_keep_active_rule_data));
		kp_set.rule[idx]->data[0].is_chksumed = 0;
		kp_set.flags[idx] = flags;
	}

	if (en)
		kp_set.en_bitmap |= BIT(idx);
	else
		kp_set.en_bitmap &= ~BIT(idx);

	skw_dbg("enable bitmap 0x%x\n", kp_set.en_bitmap);
	skw_hex_dump("kpsave", &kp_set, sizeof(kp_set), false);

	return 0;
}

static int skw_keep_active_disable_cmd(struct net_device *ndev,
	 u16 next_cmd, int next_rules)
{
	struct skw_spd_action_param spd;
	int ret = 0;

	if (!next_rules)
		spd.sub_cmd = ACTION_DIS_ALL_KEEPALIVE;
	else if (next_cmd == ACTION_EN_ALWAYS_KEEPALIVE)
		spd.sub_cmd = ACTION_DIS_KEEPALIVE;
	else
		spd.sub_cmd = ACTION_DIS_ALWAYS_KEEPALIVE;

	spd.len = 0;

	skw_hex_dump("dpdis:", &spd, sizeof(spd), true);
	ret = skw_send_msg(ndev->ieee80211_ptr->wiphy, ndev,
			 SKW_CMD_SET_SPD_ACTION, &spd, sizeof(spd), NULL, 0);
	if (ret)
		skw_err("failed, ret: %d\n", ret);

	return ret;
}

static int skw_keep_active_cmd(struct net_device *ndev, struct skw_core *skw,
		 u8 en, u32 flags)
{
	int ret = 0;
	u32 idx_map, idx, rules = 0;
	int total, fixed, len = 0, offset = 0;
	struct skw_spd_action_param *spd = NULL;
	struct skw_keep_active_param *kp_param = NULL;

	fixed = sizeof(struct skw_spd_action_param) +
		 sizeof(struct skw_keep_active_param);
	total = fixed + SKW_KEEPACTIVE_LENGTH_MAX;

	spd = SKW_ZALLOC(total, GFP_KERNEL);
	if (!spd) {
		skw_err("malloc failed, size: %d\n", total);
		return -ENOMEM;
	}

	kp_param = (struct skw_keep_active_param *)((u8 *)spd
			+ sizeof(*spd));
	offset = fixed;
	idx_map = kp_set.en_bitmap;

	while (idx_map) {
		idx = ffs(idx_map) - 1;
		SKW_CLEAR(idx_map, BIT(idx));

		if (!kp_set.rule[idx]) {
			skw_err("rule exception\n");
			break;
		}

		if (offset + sizeof(struct skw_keep_active_rule)
			 + kp_set.rule[idx]->payload_len > total)
			break;

		memcpy((u8 *)spd + offset, kp_set.rule[idx],
				 sizeof(struct skw_keep_active_rule)
				 + kp_set.rule[idx]->payload_len);

		offset += sizeof(struct skw_keep_active_rule)
			+ kp_set.rule[idx]->payload_len;

		if (kp_set.flags[idx] & SKW_KEEPALIVE_ALWAYS_FLAG)
			spd->sub_cmd = ACTION_EN_ALWAYS_KEEPALIVE;
		else
			spd->sub_cmd = ACTION_EN_KEEPALIVE;

		if (++rules > SKW_KEEPACTIVE_RULE_MAX)
			break;
	}

	kp_param->rule_num = rules;
	spd->len = offset - sizeof(struct skw_spd_action_param);
	len = offset;

	if (en) {
		if (flags & SKW_KEEPALIVE_ALWAYS_FLAG)
			spd->sub_cmd = ACTION_EN_ALWAYS_KEEPALIVE;
		else
			spd->sub_cmd = ACTION_EN_KEEPALIVE;
	}

	ret = skw_keep_active_disable_cmd(ndev, spd->sub_cmd, rules);

	skw_dbg("len:%d rule num:%d\n", len, rules);
	if (rules) {
		skw_hex_dump("actv:", spd, len, true);
		ret = skw_send_msg(ndev->ieee80211_ptr->wiphy, ndev,
				SKW_CMD_SET_SPD_ACTION, spd, len, NULL, 0);
		if (ret)
			skw_err("failed, ret: %d\n", ret);
	}

	SKW_KFREE(spd);
	return ret;
}

//iwpriv wlan0 keep_alive idx=0,en=1,period=1000,flags=0/1,
//pkt=7c:7a:3c:81:e5:72:00:0b
static int skw_keep_active_set(struct net_device *dev, u8 *param, int len)
{
	int result_len = 0;
	u8 *ch, *result_val;
	char *hex = NULL;
	u8 idx, en = 0, get_pkt = 0;
	u32 flags = 0;
	u8 keep_alive[SKW_KEEPACTIVE_LENGTH_MAX];
	struct skw_keep_active_rule *kp =
		(struct skw_keep_active_rule *)keep_alive;
	int pos = 0, ret = 0;
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_core *skw = iface->skw;

	memset(kp, 0, sizeof(*kp));

	hex = param;
	hex = strstr(hex, "idx=");
	if (hex) {
		ch = strsep(&hex, "=");
		if ((!ch) || (strlen(ch) == 0)) {
			skw_err("idx param\n");
			ret = -EFAULT;
			goto error;
		}

		ch = strsep(&hex, ",");
		if ((!ch) || (strlen(ch) == 0)) {
			skw_err("idx param\n");
			ret = -ERANGE;
			goto error;
		}

		ret = kstrtou8(ch, 0, &idx);
		if (ret) {
			skw_err("idx param\n");
			ret = -EINVAL;
			goto error;
		}
	} else {
		skw_err("idx not found\n");
		ret = -EFAULT;
		goto error;
	}

	if (!hex) {
		ret = -EBADF;
		goto error;
	}

	hex = strstr(hex, "en=");
	if (hex) {
		ch = strsep(&hex, "=");
		if ((!ch) || (strlen(ch) == 0)) {
			skw_err("en param\n");
			ret = -EFAULT;
			goto error;
		}

		ch = strsep(&hex, ",");
		if ((!ch) || (strlen(ch) == 0)) {
			skw_err("en param\n");
			ret = -ERANGE;
			goto error;
		}

		ret = kstrtou8(ch, 0, &en);
		if (ret) {
			skw_err("en param\n");
			ret = -EINVAL;
			goto error;
		}
	} else {
		skw_err("en not found\n");
		ret = -EFAULT;
		goto error;
	}

	if (!hex)
		goto done;

	hex = strstr(hex, "period=");
	if (hex) {
		ch = strsep(&hex, "=");
		if ((!ch) || (strlen(ch) == 0)) {
			skw_err("period param\n");
			ret = -EFAULT;
			goto error;
		}

		ch = strsep(&hex, ",");
		if ((!ch) || (strlen(ch) == 0)) {
			skw_err("period param\n");
			ret = -ERANGE;
			goto error;
		}

		ret = kstrtou32(ch, 0, &kp->keep_interval);
		if (ret) {
			skw_err("period param\n");
			ret = -EINVAL;
			goto error;
		}
	}

	if (!hex)
		goto done;

	hex = strstr(hex, "flags=");
	if (hex) {
		ch = strsep(&hex, "=");
		if ((!ch) || (strlen(ch) == 0)) {
			skw_err("flags param\n");
			ret = -EFAULT;
			goto error;
		}

		ch = strsep(&hex, ",");
		if ((!ch) || (strlen(ch) == 0)) {
			skw_err("flags param\n");
			ret = -ERANGE;
			goto error;
		}

		ret = kstrtou32(ch, 0, &flags);
		if (ret) {
			skw_err("flags param\n");
			ret = -EINVAL;
			goto error;
		}
	}

	if (!hex)
		goto done;

	hex = strstr(hex, "pkt=");
	if (hex) {
		ch = strsep(&hex, "=");
		if ((!ch) || (strlen(ch) == 0)) {
			skw_err("pkt param\n");
			ret = -EFAULT;
			goto error;
		}

		result_val = kp->data[0].payload;
		while (1) {
			u8 temp = 0;
			char *cp = strchr(hex, ':');

			if (cp) {
				*cp = 0;
				cp++;
			}

			ret = kstrtou8(hex, 16, &temp);
			if (ret) {
				skw_err("pkt param\n");
				ret = -EINVAL;
				goto error;
			}

			if (temp < 0 || temp > 255) {
				skw_err("pkt param\n");
				ret = -ERANGE;
				goto error;
			}

			result_val[pos] = temp;
			result_len++;
			pos++;

			if (!cp)
				break;

			if (result_len + sizeof(*kp) >=
				SKW_KEEPACTIVE_LENGTH_MAX)
				break;

			hex = cp;
		}
		get_pkt = 1;
	}

	kp->payload_len = result_len + sizeof(struct skw_keep_active_rule_data);

done:
	skw_dbg("idx:%d en:%d pr:%d pkt:%d len:%d\n", idx, en,
		 kp->keep_interval, get_pkt, result_len);
	skw_hex_dump("kp", kp, sizeof(*kp) + kp->payload_len, false);

	if (!(kp->keep_interval && get_pkt))
		kp = NULL;

	ret = skw_keep_active_rule_save(skw, kp, idx, en, flags);
	if (ret) {
		skw_err("save rule\n");
		goto error;
	}

	ret = skw_keep_active_cmd(dev, skw, en, flags);
	if (ret) {
		skw_err("send rule\n");
		goto error;
	}

	return 0;

error:
	skw_err("error:%d\n", ret);
	return ret;
}

//iwpriv wlan0 wow_filter enable,pattern=6+7c:7a:3c:81:e5:72#20+0b#20+!ee:66
//iwpriv wlan0 wow_filter disable
int skw_wow_filter_set(struct net_device *ndev, u8 *param, int len, char *resp)
{
	u8 *ch, *result_val;
	char *hex, *ptr;
	struct skw_spd_action_param *spd = NULL;
	struct skw_wow_input_param *wow_param = NULL;
	struct skw_wow_rule *rule = NULL;
	int pos = 0, ret = 0, rule_idx = 0, offset, total, result_len = 0;
	struct skw_pkt_pattern *ptn;
	u8 data[256];
	u32 temp, resp_len = 0, i;
	char help[] = "Usage:[list]|[disable]|[enable,pattern=6+10#23+!11,pattern=45+31:31]";

	memcpy(data, param, len);
	hex = data;
	ptr = hex;

	if (!strcmp(hex, "list")) {
		if (len != sizeof("list")) {
			resp_len = sprintf(resp, "ERROR: %s\n %s\n",
				"list cmd", help);
			return -EFAULT;
		}
		resp_len = sprintf(resp, "List: %s\n", skw_wow_flted);
		resp_len += sprintf(resp + resp_len, "%s\n", "OK");
		return ret;
	}

	if (!strcmp(hex, "disable")) {
		if (len != sizeof("disable")) {
			resp_len = sprintf(resp, "ERROR: %s\n %s\n",
				 "dis cmd", help);
			return -EFAULT;
		}
		ret = skw_wow_disable(ndev->ieee80211_ptr->wiphy);
		if (!ret) {
			memset(skw_wow_flted, 0, sizeof(skw_wow_flted));
			memcpy(skw_wow_flted, param, len);
		}

		resp_len = sprintf(resp, "%s\n", "OK");
		return ret;
	}

	ret = strncmp(hex, "enable", strlen("enable"));
	if (ret) {
		resp_len = sprintf(resp, "ERROR: %s\n %s\n",
			 "en cmd", help);
		return -EFAULT;
	}

	hex += strlen("enable");
	if (hex >= ptr + len - 1) {
		resp_len = sprintf(resp, "ERROR: %s\n %s\n",
			 "en cmd", help);
		return -EFAULT;
	}

	total = sizeof(struct skw_spd_action_param) +
		sizeof(struct skw_wow_input_param) +
		sizeof(struct skw_wow_rule) * SKW_MAX_WOW_RULE_NUM;

	spd = SKW_ZALLOC(total, GFP_KERNEL);
	if (!spd) {
		skw_err("malloc failed, size: %d\n", total);
		resp_len = sprintf(resp, "ERROR: %s\n", "malloc failed");
		return -ENOMEM;
	}

	wow_param = (struct skw_wow_input_param *)((u8 *)spd
		+ sizeof(*spd));
	spd->sub_cmd = ACTION_EN_WOW;
	wow_param->wow_flags |= SKW_WOW_BLACKLIST_FILTER;

	while (hex < ptr + len - 1) {
		rule = &wow_param->rules[rule_idx];
		result_len = 0;

		ret = strncmp(hex, ",pattern=", strlen(",pattern="));
		if (!ret) {
			hex += strlen(",pattern=");
			result_val = rule->rule;

			while (hex < ptr + len - 1) {
				ret = sscanf(hex, "%d+%02x",
					&offset, &temp);
				if (ret != 2) {
					ret = sscanf(hex, "%d+!%02x",
						&offset, &temp);
					if (ret != 2) {
						resp_len = sprintf(resp,
							"ERROR: %s\n",
							"match char + +!");
						ret = -EINVAL;
						goto err;
					}
				}

				if (offset > ETH_DATA_LEN) {
					resp_len = sprintf(resp,
						"ERROR: offset:%d over limit\n",
						offset);
					ret = -EINVAL;
					goto err;
				}

				ptn = (struct skw_pkt_pattern *)result_val;
				result_val += sizeof(*ptn);
				result_len += sizeof(*ptn);

				if (result_len >= sizeof(rule->rule)) {
					resp_len = sprintf(resp,
						"ERROR: %s\n",
						"ptn over limit\n");
					break;
				}

				ptn->op = PAT_TYPE_ETH;
				ptn->offset = offset;

				ch = strsep(&hex, "+");
				if ((!ch) || (strlen(ch) == 0)) {
					resp_len = sprintf(resp,
						"ERROR: %s\n",
						"match char +\n");
					ret = -EINVAL;
					goto err;
				}

				if (hex[0] == '!') {
					ptn->type_offset = PAT_OP_TYPE_DIFF;
					ch = strsep(&hex, "!");
				}

				pos = 0;
				while (hex < ptr + len - 1) {
					char *cp;

					if (isxdigit(hex[0]) &&
						isxdigit(hex[1]) &&
						(sscanf(hex, "%2x", &temp)
							== 1)) {
					} else {
						resp_len = sprintf(resp,
							"ERROR: match char %c%c end\n",
							hex[0], hex[1]);
						ret = -EINVAL;
						goto err;
					}

					result_val[pos] = temp;
					result_len++;
					pos++;

					if (result_len >= sizeof(rule->rule)) {
						resp_len = sprintf(resp,
							"ERROR: %s\n",
							"size over limit\n");
						break;
					}

					if (hex[2] == ',' || hex[2] == '#')
						break;
					else if (hex[2] == '\0') {
						hex += 2;
						break;
					} else  if (hex[2] != ':') {
						resp_len = sprintf(resp,
							"ERROR: char data %c\n",
							hex[2]);
						ret = -EINVAL;
						goto err;
					}

					cp = strchr(hex, ':');
					if (cp) {
						*cp = 0;
						cp++;
					}

					hex = cp;
				}
				result_val += pos;
				ptn->len = pos;

				if (hex[2] == ',') {
					hex += 2;
					break;
				} else if (hex[2] == '#')
					ch = strsep(&hex, "#");
			}
		} else {
			resp_len = sprintf(resp, "ERROR: %s\n",
				"match char pattern=\n");
			ret = -EINVAL;
			goto err;
		}

		rule->len = result_len;
		rule_idx++;
		skw_hex_dump("rule", rule, sizeof(*rule), false);

		if (rule_idx > SKW_MAX_WOW_RULE_NUM)
			break;
	}

	if (!rule_idx) {
		resp_len = sprintf(resp, "ERROR: %s\n", "no rule\n");
		ret = -EINVAL;
		goto err;
	}

	for (i = 0; i < rule_idx; i++)
		if (!wow_param->rules[i].len) {
			resp_len = sprintf(resp, "ERROR: %s\n", "rule len 0\n");
			ret = -EINVAL;
			goto err;
		}

	wow_param->rule_num = rule_idx;
	spd->len = sizeof(struct skw_wow_input_param) +
		sizeof(struct skw_wow_rule) * rule_idx;

	skw_dbg("len:%d %d\n", spd->len, total);
	skw_hex_dump("wow", spd, total, true);

	ret = skw_msg_xmit(ndev->ieee80211_ptr->wiphy, 0,
		 SKW_CMD_SET_SPD_ACTION, spd, total, NULL, 0);
	if (ret)
		skw_err("failed, ret: %d\n", ret);
	else {
		memset(skw_wow_flted, 0, sizeof(skw_wow_flted));
		memcpy(skw_wow_flted, param, len);
	}

err:
	if (ret)
		resp_len += sprintf(resp + resp_len, " %s\n", help);
	else
		resp_len = sprintf(resp, "%s\n", "OK");

	SKW_KFREE(spd);
	return ret;
}

static int skw_iwpriv_keep_alive(struct net_device *dev,
			struct iw_request_info *info,
			union iwreq_data *wrqu, char *extra)
{
	char *param;
	char help[] = "ERROR useage:[idx=0,en=0/1,period=100,flags=0/1,pkt=7c:11]";
	int ret = 0;

	WARN_ON(wrqu->data.length > SKW_KEEP_BUF_SIZE);

	param = SKW_ZALLOC(SKW_KEEP_BUF_SIZE, GFP_KERNEL);
	if (!param) {
		ret = -ENOMEM;
		goto out;
	}

	if (copy_from_user(param, wrqu->data.pointer, sizeof(param))) {
		skw_err("copy failed, length: %d\n",
			wrqu->data.length);

		ret = -EFAULT;
		goto free;
	}

	skw_dbg("cmd: 0x%x, (len: %d)\n",
		info->cmd, wrqu->data.length);
	skw_hex_dump("param:", param, sizeof(param), false);

	ret = skw_keep_active_set(dev, param, sizeof(param));
	if (ret)
		memcpy(extra, help, sizeof(help));
	else
		memcpy(extra, "OK", sizeof("OK"));

	wrqu->data.length = SKW_GET_LEN_512;

	skw_dbg("resp: %s\n", extra);

free:
	SKW_KFREE(param);

out:
	return ret;
}

static int skw_iwpriv_wow_filter(struct net_device *dev,
			struct iw_request_info *info,
			union iwreq_data *wrqu, char *extra)
{
	char param[256];

	WARN_ON(sizeof(param) < wrqu->data.length);

	if (copy_from_user(param, wrqu->data.pointer, sizeof(param))) {
		skw_err("copy failed, length: %d\n",
			wrqu->data.length);

		return -EFAULT;
	}

	param[255] = '\0';

	skw_dbg("cmd: 0x%x, (len: %d)\n",
		info->cmd, wrqu->data.length);
	skw_hex_dump("flt", param, sizeof(param), false);

	skw_wow_filter_set(dev, param, min_t(int, sizeof(param),
			(int)wrqu->data.length), extra);

	wrqu->data.length = SKW_GET_LEN_512;

	skw_dbg("resp: %s\n", extra);
	return 0;
}

static int skw_send_at_cmd(struct skw_core *skw, char *cmd, int cmd_len,
			char *buf, int buf_len)
{
	int ret, len, resp_len, offset;
	char *command, *resp;

	len = round_up(cmd_len, 4);
	if (len > SKW_SET_LEN_256)
		return -E2BIG;

	command = SKW_ZALLOC(SKW_SET_LEN_512, GFP_KERNEL);
	if (!command) {
		ret = -ENOMEM;
		goto out;
	}

	offset = (long)command & 0x7;
	if (offset) {
		offset = 8 - offset;
		skw_detail("command: %px, offset: %d\n", command, offset);
	}

	resp_len = round_up(buf_len, skw->hw_pdata->align_value);
	resp = SKW_ZALLOC(resp_len, GFP_KERNEL);
	if (!resp) {
		ret = -ENOMEM;
		goto fail_alloc_resp;
	}

	ret = skw_uart_open(skw);
	if (ret < 0)
		goto failed;

	memcpy(command + offset, cmd, cmd_len);
	ret = skw_uart_write(skw, command + offset, len);
	if (ret < 0)
		goto failed;

	ret = skw_uart_read(skw, resp, resp_len);
	if (ret < 0)
		goto failed;

	memcpy(buf, resp, buf_len);
	ret = 0;

failed:
	SKW_KFREE(resp);

fail_alloc_resp:
	SKW_KFREE(command);

out:
	if (ret < 0)
		skw_err("failed: ret: %d\n", ret);

	return ret;
}

static int skw_iwpriv_mode(struct net_device *dev,
			   struct iw_request_info *info,
			   union iwreq_data *wrqu, char *extra)
{
	int i;
	char param[32] = {0};
	struct skw_iface *iface = (struct skw_iface *)netdev_priv(dev);

	struct skw_iw_wireless_mode {
		char *name;
		enum skw_wireless_mode mode;
	} modes[] = {
		{"11B", SKW_WIRELESS_11B},
		{"11G", SKW_WIRELESS_11G},
		{"11A", SKW_WIRELESS_11A},
		{"11N", SKW_WIRELESS_11N},
		{"11AC", SKW_WIRELESS_11AC},
		{"11AX", SKW_WIRELESS_11AX},
		{"11G_ONLY", SKW_WIRELESS_11G_ONLY},
		{"11N_ONLY", SKW_WIRELESS_11N_ONLY},

		/*keep last*/
		{NULL, 0}
	};

	WARN_ON(sizeof(param) < wrqu->data.length);

	if (copy_from_user(param, wrqu->data.pointer, sizeof(param))) {
		skw_err("copy failed, length: %d\n",
			wrqu->data.length);

		return -EFAULT;
	}

	skw_dbg("cmd: 0x%x, %s(len: %d)\n",
		info->cmd, param, wrqu->data.length);

	for (i = 0; modes[i].name; i++) {
		if (!strcmp(modes[i].name, param)) {
			iface->extend.wireless_mode = modes[i].mode;
			return 0;
		}
	}

	return -EINVAL;
}

static int skw_iwpriv_get_mode(struct net_device *dev,
			struct iw_request_info *info,
			union iwreq_data *wrqu, char *extra)
{
	skw_dbg("traced\n");
	return 0;
}

static int skw_iwpriv_help(struct skw_iface *iface, void *param, char *args,
			char *resp, int resp_len)
{
	int len = 0;
	struct skw_iwpriv_cmd *cmd = param;

	len = sprintf(resp, " %s:\n", cmd->help_info);
	cmd++;

	while (cmd->handler) {
		len += sprintf(resp + len, "%-4.4s %s\n", "", cmd->help_info);
		cmd++;
	}

	return 0;
}

static int skw_iwpriv_set_bandcfg(struct skw_iface *iface, void *param,
		char *args, char *resp, int resp_len)
{
	u16 res;
	int ret;

	if (!args)
		return -EINVAL;

	ret = kstrtou16(args, 10, &res);
	if (!ret && res < 3) {
		if (res == 0)
			iface->extend.scan_band_filter = 0;
		else if (res == 1)
			iface->extend.scan_band_filter = BIT(NL80211_BAND_2GHZ);
		else if (res == 2)
			iface->extend.scan_band_filter = BIT(NL80211_BAND_5GHZ);

		sprintf(resp, "ok");
	} else
		sprintf(resp, "failed");

	return ret;
}

static int skw_iwpriv_get_bandcfg(struct skw_iface *iface, void *param,
		char *args, char *resp, int resp_len)
{
	if (!iface->extend.scan_band_filter)
		sprintf(resp, "bandcfg=%s", "Auto");
	else if (iface->extend.scan_band_filter & BIT(NL80211_BAND_2GHZ))
		sprintf(resp, "bandcfg=%s", "2G");
	else if (iface->extend.scan_band_filter & BIT(NL80211_BAND_5GHZ))
		sprintf(resp, "bandcfg=%s", "5G");

	return 0;
}

static struct skw_iwpriv_cmd skw_iwpriv_set_cmds[] = {
	/* keep first */
	{"help", skw_iwpriv_help, "usage"},
	{"bandcfg", skw_iwpriv_set_bandcfg, "bandcfg=0/1/2"},

	/*keep last*/
	{NULL, NULL, NULL}
};

static struct skw_iwpriv_cmd skw_iwpriv_get_cmds[] = {
	/* keep first */
	{"help", skw_iwpriv_help, "usage"},

	{"bandcfg", skw_iwpriv_get_bandcfg, "bandcfg"},

	/*keep last*/
	{NULL, NULL, NULL}
};

static struct skw_iwpriv_cmd *skw_iwpriv_cmd_match(struct skw_iwpriv_cmd *cmds,
					const char *key, int key_len)
{
	int i;

	for (i = 0; cmds[i].name; i++) {
		if (!memcmp(cmds[i].name, key, key_len))
			return &cmds[i];
	}

	return NULL;
}

static int skw_iwpriv_set(struct net_device *dev,
			   struct iw_request_info *info,
			   union iwreq_data *wrqu, char *extra)
{
	int ret = 0;
	int key_len;
	char param[128];
	char *token, *args;
	struct skw_iwpriv_cmd *iwpriv_cmd;
	struct skw_iface *iface = (struct skw_iface *)netdev_priv(dev);

	WARN_ON(sizeof(param) < wrqu->data.length);

	if (copy_from_user(param, wrqu->data.pointer, sizeof(param))) {
		skw_err("copy failed, length: %d\n",
			wrqu->data.length);

		return -EFAULT;
	}

	skw_dbg("cmd: 0x%x, %s(len: %d)\n",
		info->cmd, param, wrqu->data.length);

	token = strchr(param, '=');
	if (!token) {
		key_len = strlen(param);
		args = NULL;
	} else {
		key_len = token - param;
		args = token + 1;
	}

	iwpriv_cmd = skw_iwpriv_cmd_match(skw_iwpriv_set_cmds, param, key_len);
	if (iwpriv_cmd)
		ret = iwpriv_cmd->handler(iface, iwpriv_cmd, args,
				extra, SKW_GET_LEN_512);
	else
		ret = skw_iwpriv_help(iface, skw_iwpriv_set_cmds, NULL,
				extra, SKW_GET_LEN_512);

	if (ret < 0)
		sprintf(extra, " usage: %s\n", iwpriv_cmd->help_info);

	wrqu->data.length = SKW_GET_LEN_512;

	skw_dbg("resp: %s\n", extra);

	return 0;
}

static int skw_iwpriv_get(struct net_device *dev,
			   struct iw_request_info *info,
			   union iwreq_data *wrqu, char *extra)
{
	int ret;
	char cmd[128];
	struct skw_iwpriv_cmd *priv_cmd;
	struct skw_iface *iface = (struct skw_iface *)netdev_priv(dev);

	if (copy_from_user(cmd, wrqu->data.pointer, sizeof(cmd))) {
		skw_err("copy failed, length: %d\n",
			wrqu->data.length);

		return -EFAULT;
	}

	skw_dbg("cmd: 0x%x, %s(len: %d)\n", info->cmd, cmd, wrqu->data.length);

	priv_cmd = skw_iwpriv_cmd_match(skw_iwpriv_get_cmds, cmd, strlen(cmd));
	if (priv_cmd)
		ret = priv_cmd->handler(iface, priv_cmd, NULL, extra,
				SKW_GET_LEN_512);
	else
		ret = skw_iwpriv_help(iface, skw_iwpriv_get_cmds, NULL,
				extra, SKW_GET_LEN_512);

	wrqu->data.length = SKW_GET_LEN_512;

	skw_dbg("resp: %s\n", extra);

	return ret;
}

static int skw_iwpriv_at(struct net_device *dev,
			   struct iw_request_info *info,
			   union iwreq_data *wrqu, char *extra)
{
	int ret;
	char cmd[SKW_SET_LEN_256];
	int len = wrqu->data.length;
	struct skw_core *skw = ((struct skw_iface *)netdev_priv(dev))->skw;

	BUG_ON(sizeof(cmd) < len);

	if (copy_from_user(cmd, wrqu->data.pointer, sizeof(cmd))) {
		skw_err("copy failed, length: %d\n", len);

		return -EFAULT;
	}

	skw_dbg("cmd: %s, len: %d\n", cmd, len);

	if (len + 2 > sizeof(cmd))
		return -EINVAL;

	cmd[len - 1] = 0xd;
	cmd[len + 0] = 0xa;
	cmd[len + 1] = 0x0;

	ret = skw_send_at_cmd(skw, cmd, len + 2, extra, SKW_GET_LEN_512);

	wrqu->data.length = SKW_GET_LEN_512;

	skw_dbg("resp: %s", extra);

	return ret;
}

static struct iw_priv_args skw_iw_priv_args[] = {
	{
		SKW_IW_PRIV_SET,
		IW_PRIV_TYPE_CHAR | SKW_SET_LEN_128,
		IW_PRIV_TYPE_CHAR | SKW_GET_LEN_512,
		"set",
	},
	{
		SKW_IW_PRIV_GET,
		IW_PRIV_TYPE_CHAR | SKW_SET_LEN_128,
		IW_PRIV_TYPE_CHAR | SKW_GET_LEN_512,
		"get",
	},
	{
		SKW_IW_PRIV_AT,
		IW_PRIV_TYPE_CHAR | SKW_SET_LEN_256,
		IW_PRIV_TYPE_CHAR | SKW_GET_LEN_512,
		"at",
	},
	{
		SKW_IW_PRIV_80211MODE,
		IW_PRIV_TYPE_CHAR | SKW_SET_LEN_128,
		IW_PRIV_TYPE_CHAR | SKW_GET_LEN_512,
		"mode",
	},
	{
		SKW_IW_PRIV_GET_80211MODE,
		IW_PRIV_TYPE_CHAR | SKW_SET_LEN_128,
		IW_PRIV_TYPE_CHAR | SKW_GET_LEN_512,
		"get_mode",
	},
	{
		SKW_IW_PRIV_KEEP_ALIVE,
		IW_PRIV_TYPE_CHAR | SKW_SET_LEN_1024,
		IW_PRIV_TYPE_CHAR | SKW_GET_LEN_512,
		"keep_alive",
	},
	{
		SKW_IW_PRIV_WOW_FILTER,
		IW_PRIV_TYPE_CHAR | SKW_SET_LEN_512,
		IW_PRIV_TYPE_CHAR | SKW_GET_LEN_512,
		"wow_filter",
	},
	{0, 0, 0, {0}}
};

static const iw_handler skw_iw_priv_handlers[] = {
	NULL,
	skw_iwpriv_set,
	NULL,
	skw_iwpriv_get,
	NULL,
	skw_iwpriv_at,
	skw_iwpriv_mode,
	skw_iwpriv_get_mode,
	skw_iwpriv_keep_alive,
	skw_iwpriv_wow_filter,
};
#endif

static const struct iw_handler_def skw_iw_ops = {
	.standard = skw_iw_standard_handlers,
	.num_standard = ARRAY_SIZE(skw_iw_standard_handlers),
#ifdef CONFIG_WEXT_PRIV
	.private = skw_iw_priv_handlers,
	.num_private = ARRAY_SIZE(skw_iw_priv_handlers),
	.private_args = skw_iw_priv_args,
	.num_private_args = ARRAY_SIZE(skw_iw_priv_args),
#endif
	.get_wireless_stats = skw_get_wireless_stats,
};

const void *skw_iw_handlers(void)
{
#ifdef CONFIG_WIRELESS_EXT
	return &skw_iw_ops;
#else
	skw_info("CONFIG_WIRELESS_EXT not enabled\n");
	return NULL;
#endif
}
===== ./drivers/skwifi/skw_db.c =====
/*
 * DO NOT EDIT -- file generated from data in db.txt
 */

#include <linux/nl80211.h>
#include <net/cfg80211.h>
#include "skw_db.h"

// database 2024.10.07

static const struct ieee80211_regdomain regdom_XW = {
	.alpha2 = "XW",
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 20, 0, 0),
		REG_RULE_EXT(2457, 2482, 20, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(2474, 2494, 20, 0, 20, 0,
			SKW_RRF_NO_OFDM | 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(57240, 63720, 2160, 0, 0, 0, 0),
	},
	.n_reg_rules = 8
};

static const struct ieee80211_regdomain regdom_00 = {
	.alpha2 = "00",
	.reg_rules = {
		REG_RULE_EXT(755, 928, 2, 0, 20, 0,
			SKW_RRF_NO_IR | 0),
		REG_RULE_EXT(2402, 2472, 40, 0, 20, 0, 0),
		REG_RULE_EXT(2457, 2482, 20, 0, 20, 0,
			SKW_RRF_NO_IR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(2474, 2494, 20, 0, 20, 0,
			SKW_RRF_NO_IR |
			SKW_RRF_NO_OFDM | 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_NO_IR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_NO_IR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 20, 0,
			SKW_RRF_NO_IR |
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 20, 0,
			SKW_RRF_NO_IR | 0),
		REG_RULE_EXT(57240, 63720, 2160, 0, 0, 0, 0),
	},
	.n_reg_rules = 9
};

static const struct ieee80211_regdomain regdom_AD = {
	.alpha2 = "AD",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_AE = {
	.alpha2 = "AE",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 24, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_AF = {
	.alpha2 = "AF",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_AI = {
	.alpha2 = "AI",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_AL = {
	.alpha2 = "AL",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_AM = {
	.alpha2 = "AM",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 20, 0, 18, 0, 0),
		REG_RULE_EXT(5250, 5330, 20, 0, 18, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 3
};

static const struct ieee80211_regdomain regdom_AN = {
	.alpha2 = "AN",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_AR = {
	.alpha2 = "AR",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 7125, 320, 0, 12, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_AS = {
	.alpha2 = "AS",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_AT = {
	.alpha2 = "AT",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_AU = {
	.alpha2 = "AU",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(915, 920, 4, 0, 30, 0, 0),
		REG_RULE_EXT(920, 928, 8, 0, 30, 0, 0),
		REG_RULE_EXT(2400, 2483, 40, 0, 36, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW |
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5470, 5600, 80, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5650, 5730, 80, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5730, 5850, 80, 0, 36, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5850, 5875, 20, 0, 14, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5925, 6425, 160, 0, 24, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 71000, 2160, 0, 43, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 11
};

static const struct ieee80211_regdomain regdom_AW = {
	.alpha2 = "AW",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_AZ = {
	.alpha2 = "AZ",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 18, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 18, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
	},
	.n_reg_rules = 3
};

static const struct ieee80211_regdomain regdom_BA = {
	.alpha2 = "BA",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_BB = {
	.alpha2 = "BB",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_BD = {
	.alpha2 = "BD",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 2
};

static const struct ieee80211_regdomain regdom_BE = {
	.alpha2 = "BE",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_BF = {
	.alpha2 = "BF",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_BG = {
	.alpha2 = "BG",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_BH = {
	.alpha2 = "BH",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5350, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5470, 5725, 80, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_BL = {
	.alpha2 = "BL",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_BM = {
	.alpha2 = "BM",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_BN = {
	.alpha2 = "BN",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 20, 0, 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_BO = {
	.alpha2 = "BO",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 30, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 3
};

static const struct ieee80211_regdomain regdom_BR = {
	.alpha2 = "BR",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 27, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 27, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 30, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5925, 7125, 320, 0, 12, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_NO_IR | 0),
		REG_RULE_EXT(57000, 71000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_BS = {
	.alpha2 = "BS",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_BT = {
	.alpha2 = "BT",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_BY = {
	.alpha2 = "BY",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_BZ = {
	.alpha2 = "BZ",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 2
};

static const struct ieee80211_regdomain regdom_CA = {
	.alpha2 = "CA",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5600, 80, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5650, 5730, 80, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 7125, 320, 0, 12, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_CF = {
	.alpha2 = "CF",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 40, 0, 17, 0, 0),
		REG_RULE_EXT(5250, 5330, 40, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5490, 5730, 40, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 40, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_CH = {
	.alpha2 = "CH",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 71000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_CI = {
	.alpha2 = "CI",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_CL = {
	.alpha2 = "CL",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 20, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 12, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_CN = {
	.alpha2 = "CN",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 33, 0, 0),
		REG_RULE_EXT(57240, 59400, 2160, 0, 28, 0, 0),
		REG_RULE_EXT(59400, 63720, 2160, 0, 44, 0, 0),
		REG_RULE_EXT(63720, 65880, 2160, 0, 28, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_CO = {
	.alpha2 = "CO",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 7125, 320, 0, 12, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_CR = {
	.alpha2 = "CR",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 36, 0, 0),
		REG_RULE_EXT(5170, 5250, 20, 0, 30, 0, 0),
		REG_RULE_EXT(5250, 5330, 20, 0, 30, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5490, 5730, 20, 0, 30, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 20, 0, 36, 0, 0),
		REG_RULE_EXT(5875, 5925, 20, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 7125, 320, 0, 30, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_CU = {
	.alpha2 = "CU",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 23, 0, 0),
		REG_RULE_EXT(5150, 5350, 80, 0, 23, 0,
			SKW_RRF_NO_IR |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5470, 5725, 80, 0, 24, 0,
			SKW_RRF_NO_IR | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 23, 0, 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_CX = {
	.alpha2 = "CX",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_CY = {
	.alpha2 = "CY",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_CZ = {
	.alpha2 = "CZ",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_DE = {
	.alpha2 = "DE",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_DK = {
	.alpha2 = "DK",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_DM = {
	.alpha2 = "DM",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_DO = {
	.alpha2 = "DO",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 7125, 320, 0, 15, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_DZ = {
	.alpha2 = "DZ",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5670, 160, 0, 23, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_EC = {
	.alpha2 = "EC",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW |
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 21, 0,
			SKW_RRF_AUTO_BW |
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 21, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_EE = {
	.alpha2 = "EE",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_EG = {
	.alpha2 = "EG",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_ES = {
	.alpha2 = "ES",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_ET = {
	.alpha2 = "ET",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_FI = {
	.alpha2 = "FI",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_FM = {
	.alpha2 = "FM",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_FR = {
	.alpha2 = "FR",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 71000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_GB = {
	.alpha2 = "GB",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5730, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5925, 6425, 160, 0, 24, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 71000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_GD = {
	.alpha2 = "GD",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_GE = {
	.alpha2 = "GE",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 18, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 18, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_GF = {
	.alpha2 = "GF",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_GH = {
	.alpha2 = "GH",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_GL = {
	.alpha2 = "GL",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_GP = {
	.alpha2 = "GP",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_GR = {
	.alpha2 = "GR",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_GT = {
	.alpha2 = "GT",
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 27, 0, 0),
		REG_RULE_EXT(5150, 5350, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 24, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5725, 5850, 160, 0, 27, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(6425, 6525, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(6525, 6875, 320, 0, 22, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(6875, 7125, 320, 0, 22, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 13, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 9
};

static const struct ieee80211_regdomain regdom_GU = {
	.alpha2 = "GU",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 20, 0, 17, 0, 0),
		REG_RULE_EXT(5250, 5330, 20, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5490, 5730, 20, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 20, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_GY = {
	.alpha2 = "GY",
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 23, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_HK = {
	.alpha2 = "HK",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 36, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5470, 5730, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5730, 5850, 80, 0, 36, 0, 0),
		REG_RULE_EXT(5925, 6425, 160, 0, 14, 0, 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_HN = {
	.alpha2 = "HN",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 12, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_NO_IR | 0),
		REG_RULE_EXT(57240, 71000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_HR = {
	.alpha2 = "HR",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_HT = {
	.alpha2 = "HT",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_HU = {
	.alpha2 = "HU",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_ID = {
	.alpha2 = "ID",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 27, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5150, 5350, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5725, 5825, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 3
};

static const struct ieee80211_regdomain regdom_IE = {
	.alpha2 = "IE",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_IL = {
	.alpha2 = "IL",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5945, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_IN = {
	.alpha2 = "IN",
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_IR = {
	.alpha2 = "IR",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 2
};

static const struct ieee80211_regdomain regdom_IS = {
	.alpha2 = "IS",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_IT = {
	.alpha2 = "IT",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_JM = {
	.alpha2 = "JM",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_JO = {
	.alpha2 = "JO",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 80, 0, 27, 0,
			SKW_RRF_DFS |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 71000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_JP = {
	.alpha2 = "JP",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(2474, 2494, 20, 0, 20, 0,
			SKW_RRF_NO_OFDM | 0),
		REG_RULE_EXT(4910, 4990, 40, 0, 23, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 23, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 10, 0, 0),
	},
	.n_reg_rules = 8
};

static const struct ieee80211_regdomain regdom_KE = {
	.alpha2 = "KE",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 33, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 17, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 80, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 40, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_KH = {
	.alpha2 = "KH",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_KN = {
	.alpha2 = "KN",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 30, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5815, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_KP = {
	.alpha2 = "KP",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 20, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 20, 0, 20, 0, 0),
		REG_RULE_EXT(5250, 5330, 20, 0, 20, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5490, 5630, 20, 0, 30, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5815, 20, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_KR = {
	.alpha2 = "KR",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 23, 0, 0),
		REG_RULE_EXT(5150, 5230, 40, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5230, 5250, 20, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 20, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 23, 0, 0),
		REG_RULE_EXT(5925, 7125, 160, 0, 15, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 43, 0, 0),
	},
	.n_reg_rules = 8
};

static const struct ieee80211_regdomain regdom_KW = {
	.alpha2 = "KW",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 17, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5825, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_KY = {
	.alpha2 = "KY",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_KZ = {
	.alpha2 = "KZ",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_LB = {
	.alpha2 = "LB",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_LC = {
	.alpha2 = "LC",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 30, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5815, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_LI = {
	.alpha2 = "LI",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_LK = {
	.alpha2 = "LK",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 20, 0, 17, 0, 0),
		REG_RULE_EXT(5250, 5330, 20, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5490, 5730, 20, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 20, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_LS = {
	.alpha2 = "LS",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_LT = {
	.alpha2 = "LT",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_LU = {
	.alpha2 = "LU",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_LV = {
	.alpha2 = "LV",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_MA = {
	.alpha2 = "MA",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_MC = {
	.alpha2 = "MC",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_MD = {
	.alpha2 = "MD",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_ME = {
	.alpha2 = "ME",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_MF = {
	.alpha2 = "MF",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_MH = {
	.alpha2 = "MH",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_MK = {
	.alpha2 = "MK",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_MN = {
	.alpha2 = "MN",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 100, 0, 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_MO = {
	.alpha2 = "MO",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 23, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5730, 160, 0, 30, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 24, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_MP = {
	.alpha2 = "MP",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_MQ = {
	.alpha2 = "MQ",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_MR = {
	.alpha2 = "MR",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_MT = {
	.alpha2 = "MT",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_MU = {
	.alpha2 = "MU",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5945, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_MV = {
	.alpha2 = "MV",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 20, 0, 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_MW = {
	.alpha2 = "MW",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_MX = {
	.alpha2 = "MX",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 12, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_MY = {
	.alpha2 = "MY",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 27, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 30, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 30, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5650, 160, 0, 30, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_NA = {
	.alpha2 = "NA",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 21, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_NG = {
	.alpha2 = "NG",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 30, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 3
};

static const struct ieee80211_regdomain regdom_NI = {
	.alpha2 = "NI",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_NL = {
	.alpha2 = "NL",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_NO = {
	.alpha2 = "NO",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 71000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_NP = {
	.alpha2 = "NP",
	.dfs_region = NL80211_DFS_JP,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 20, 0, 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_NZ = {
	.alpha2 = "NZ",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 36, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 30, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 27, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5730, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 36, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 24, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 71000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_OM = {
	.alpha2 = "OM",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_PA = {
	.alpha2 = "PA",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 36, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 36, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 30, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 30, 0, 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 36, 0, 0),
		REG_RULE_EXT(57000, 64000, 2160, 0, 43, 0, 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_PE = {
	.alpha2 = "PE",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 7125, 320, 0, 12, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_PF = {
	.alpha2 = "PF",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_PG = {
	.alpha2 = "PG",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_PH = {
	.alpha2 = "PH",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 24, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 24, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 24, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_PK = {
	.alpha2 = "PK",
	.reg_rules = {
		REG_RULE_EXT(2400, 2500, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5945, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 3
};

static const struct ieee80211_regdomain regdom_PL = {
	.alpha2 = "PL",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_PM = {
	.alpha2 = "PM",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_PR = {
	.alpha2 = "PR",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_PT = {
	.alpha2 = "PT",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_PW = {
	.alpha2 = "PW",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_PY = {
	.alpha2 = "PY",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_QA = {
	.alpha2 = "QA",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_RE = {
	.alpha2 = "RE",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_RO = {
	.alpha2 = "RO",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_RS = {
	.alpha2 = "RS",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5850, 5875, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 8
};

static const struct ieee80211_regdomain regdom_RU = {
	.alpha2 = "RU",
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 100, 0, 0),
		REG_RULE_EXT(5150, 5350, 160, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5650, 5850, 160, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5925, 6425, 160, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_RW = {
	.alpha2 = "RW",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_SA = {
	.alpha2 = "SA",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5925, 7125, 320, 0, 24, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_SE = {
	.alpha2 = "SE",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_SG = {
	.alpha2 = "SG",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 23, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5730, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5945, 6425, 320, 0, 24, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_SI = {
	.alpha2 = "SI",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_SK = {
	.alpha2 = "SK",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5875, 80, 0, 14, 0, 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_SN = {
	.alpha2 = "SN",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_SR = {
	.alpha2 = "SR",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_SV = {
	.alpha2 = "SV",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 20, 0, 17, 0, 0),
		REG_RULE_EXT(5250, 5330, 20, 0, 23, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 20, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 7125, 320, 0, 12, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_SY = {
	.alpha2 = "SY",
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
	},
	.n_reg_rules = 1
};

static const struct ieee80211_regdomain regdom_TC = {
	.alpha2 = "TC",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_TD = {
	.alpha2 = "TD",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_TG = {
	.alpha2 = "TG",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5150, 5350, 80, 0, 20, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5470, 5850, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 0, 0, 0, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_TH = {
	.alpha2 = "TH",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 24, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_TN = {
	.alpha2 = "TN",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
	},
	.n_reg_rules = 3
};

static const struct ieee80211_regdomain regdom_TR = {
	.alpha2 = "TR",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5945, 6425, 160, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_TT = {
	.alpha2 = "TT",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_TW = {
	.alpha2 = "TW",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5730, 160, 0, 23, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 30, 0, 0),
		REG_RULE_EXT(5945, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 7
};

static const struct ieee80211_regdomain regdom_TZ = {
	.alpha2 = "TZ",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5945, 6425, 320, 0, 23, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_UA = {
	.alpha2 = "UA",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2400, 2483, 40, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5725, 160, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(5725, 5850, 80, 0, 20, 0,
			SKW_RRF_NO_OUTDOOR | 0),
		REG_RULE_EXT(57000, 66000, 2160, 0, 16, 0,
			SKW_RRF_NO_OUTDOOR | 0),
	},
	.n_reg_rules = 6
};

static const struct ieee80211_regdomain regdom_UG = {
	.alpha2 = "UG",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_US = {
	.alpha2 = "US",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(902, 904, 2, 0, 30, 0, 0),
		REG_RULE_EXT(904, 920, 16, 0, 30, 0, 0),
		REG_RULE_EXT(920, 928, 8, 0, 30, 0, 0),
		REG_RULE_EXT(2400, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5150, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5350, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5470, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5730, 5850, 80, 0, 30, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5850, 5895, 40, 0, 27, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_AUTO_BW |
			SKW_RRF_NO_IR | 0),
		REG_RULE_EXT(5925, 7125, 320, 0, 12, 0,
			SKW_RRF_NO_OUTDOOR |
			SKW_RRF_NO_IR | 0),
		REG_RULE_EXT(57240, 71000, 2160, 0, 40, 0, 0),
	},
	.n_reg_rules = 11
};

static const struct ieee80211_regdomain regdom_UY = {
	.alpha2 = "UY",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_UZ = {
	.alpha2 = "UZ",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
	},
	.n_reg_rules = 3
};

static const struct ieee80211_regdomain regdom_VC = {
	.alpha2 = "VC",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_VE = {
	.alpha2 = "VE",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 23, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 23, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_VI = {
	.alpha2 = "VI",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2472, 40, 0, 30, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 24, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_VN = {
	.alpha2 = "VN",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0, 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5490, 5730, 80, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_VU = {
	.alpha2 = "VU",
	.dfs_region = NL80211_DFS_FCC,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 17, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 24, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5730, 160, 0, 24, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5735, 5835, 80, 0, 30, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_WF = {
	.alpha2 = "WF",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_WS = {
	.alpha2 = "WS",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5250, 5330, 40, 0, 20, 0,
			SKW_RRF_DFS | 0),
		REG_RULE_EXT(5490, 5710, 40, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_YE = {
	.alpha2 = "YE",
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
	},
	.n_reg_rules = 1
};

static const struct ieee80211_regdomain regdom_YT = {
	.alpha2 = "YT",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

static const struct ieee80211_regdomain regdom_ZA = {
	.alpha2 = "ZA",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 30, 0, 0),
		REG_RULE_EXT(5925, 6425, 320, 0, 14, 0, 0),
	},
	.n_reg_rules = 5
};

static const struct ieee80211_regdomain regdom_ZW = {
	.alpha2 = "ZW",
	.dfs_region = NL80211_DFS_ETSI,
	.reg_rules = {
		REG_RULE_EXT(2402, 2482, 40, 0, 20, 0, 0),
		REG_RULE_EXT(5170, 5250, 80, 0, 20, 0,
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5250, 5330, 80, 0, 20, 0,
			SKW_RRF_DFS |
			SKW_RRF_AUTO_BW | 0),
		REG_RULE_EXT(5490, 5710, 160, 0, 27, 0,
			SKW_RRF_DFS | 0),
	},
	.n_reg_rules = 4
};

const struct ieee80211_regdomain *skw_regdb[] = {
	&regdom_XW,
	&regdom_00,
	&regdom_AD,
	&regdom_AE,
	&regdom_AF,
	&regdom_AI,
	&regdom_AL,
	&regdom_AM,
	&regdom_AN,
	&regdom_AR,
	&regdom_AS,
	&regdom_AT,
	&regdom_AU,
	&regdom_AW,
	&regdom_AZ,
	&regdom_BA,
	&regdom_BB,
	&regdom_BD,
	&regdom_BE,
	&regdom_BF,
	&regdom_BG,
	&regdom_BH,
	&regdom_BL,
	&regdom_BM,
	&regdom_BN,
	&regdom_BO,
	&regdom_BR,
	&regdom_BS,
	&regdom_BT,
	&regdom_BY,
	&regdom_BZ,
	&regdom_CA,
	&regdom_CF,
	&regdom_CH,
	&regdom_CI,
	&regdom_CL,
	&regdom_CN,
	&regdom_CO,
	&regdom_CR,
	&regdom_CU,
	&regdom_CX,
	&regdom_CY,
	&regdom_CZ,
	&regdom_DE,
	&regdom_DK,
	&regdom_DM,
	&regdom_DO,
	&regdom_DZ,
	&regdom_EC,
	&regdom_EE,
	&regdom_EG,
	&regdom_ES,
	&regdom_ET,
	&regdom_FI,
	&regdom_FM,
	&regdom_FR,
	&regdom_GB,
	&regdom_GD,
	&regdom_GE,
	&regdom_GF,
	&regdom_GH,
	&regdom_GL,
	&regdom_GP,
	&regdom_GR,
	&regdom_GT,
	&regdom_GU,
	&regdom_GY,
	&regdom_HK,
	&regdom_HN,
	&regdom_HR,
	&regdom_HT,
	&regdom_HU,
	&regdom_ID,
	&regdom_IE,
	&regdom_IL,
	&regdom_IN,
	&regdom_IR,
	&regdom_IS,
	&regdom_IT,
	&regdom_JM,
	&regdom_JO,
	&regdom_JP,
	&regdom_KE,
	&regdom_KH,
	&regdom_KN,
	&regdom_KP,
	&regdom_KR,
	&regdom_KW,
	&regdom_KY,
	&regdom_KZ,
	&regdom_LB,
	&regdom_LC,
	&regdom_LI,
	&regdom_LK,
	&regdom_LS,
	&regdom_LT,
	&regdom_LU,
	&regdom_LV,
	&regdom_MA,
	&regdom_MC,
	&regdom_MD,
	&regdom_ME,
	&regdom_MF,
	&regdom_MH,
	&regdom_MK,
	&regdom_MN,
	&regdom_MO,
	&regdom_MP,
	&regdom_MQ,
	&regdom_MR,
	&regdom_MT,
	&regdom_MU,
	&regdom_MV,
	&regdom_MW,
	&regdom_MX,
	&regdom_MY,
	&regdom_NA,
	&regdom_NG,
	&regdom_NI,
	&regdom_NL,
	&regdom_NO,
	&regdom_NP,
	&regdom_NZ,
	&regdom_OM,
	&regdom_PA,
	&regdom_PE,
	&regdom_PF,
	&regdom_PG,
	&regdom_PH,
	&regdom_PK,
	&regdom_PL,
	&regdom_PM,
	&regdom_PR,
	&regdom_PT,
	&regdom_PW,
	&regdom_PY,
	&regdom_QA,
	&regdom_RE,
	&regdom_RO,
	&regdom_RS,
	&regdom_RU,
	&regdom_RW,
	&regdom_SA,
	&regdom_SE,
	&regdom_SG,
	&regdom_SI,
	&regdom_SK,
	&regdom_SN,
	&regdom_SR,
	&regdom_SV,
	&regdom_SY,
	&regdom_TC,
	&regdom_TD,
	&regdom_TG,
	&regdom_TH,
	&regdom_TN,
	&regdom_TR,
	&regdom_TT,
	&regdom_TW,
	&regdom_TZ,
	&regdom_UA,
	&regdom_UG,
	&regdom_US,
	&regdom_UY,
	&regdom_UZ,
	&regdom_VC,
	&regdom_VE,
	&regdom_VI,
	&regdom_VN,
	&regdom_VU,
	&regdom_WF,
	&regdom_WS,
	&regdom_YE,
	&regdom_YT,
	&regdom_ZA,
	&regdom_ZW,
};

int skw_regdb_size = ARRAY_SIZE(skw_regdb);
===== ./drivers/skwifi/skw_tdls.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/kernel.h>
#include <linux/etherdevice.h>
#include <linux/ieee80211.h>

#include "skw_core.h"
#include "skw_cfg80211.h"
#include "skw_iface.h"
#include "skw_work.h"
#include "skw_log.h"
#include "skw_tx.h"
#include "skw_compat.h"
#include "skw_msg.h"
#include "skw_tdls.h"

static size_t skw_skip_ie(const u8 *ies, size_t ielen, size_t pos)
{
	/* we assume a validly formed IEs buffer */
	u8 len = ies[pos + 1];

	pos += 2 + len;

	/* the IE itself must have 255 bytes for fragments to follow */
	if (len < 255)
		return pos;

	while (pos < ielen && ies[pos] == SKW_WLAN_EID_FRAGMENT) {
		len = ies[pos + 1];
		pos += 2 + len;
	}

	return pos;
}

static bool skw_id_in_list(const u8 *ids, int n_ids, u8 id, bool id_ext)
{
	int i = 0;

	if (!ids || n_ids == 0)
    	return -EINVAL;

	/* Make sure array values are legal */
	if (WARN_ON(ids[n_ids - 1] == SKW_WLAN_EID_EXTENSION))
		return false;

	while (i < n_ids) {
		if (ids[i] == SKW_WLAN_EID_EXTENSION) {
			if (id_ext && (ids[i + 1] == id))
				return true;

			i += 2;
			continue;
		}

		if (ids[i] == id && !id_ext)
			return true;

		i++;
	}

	return false;
}

static size_t skw_ie_split_ric(const u8 *ies, size_t ielen,
			const u8 *ids, int n_ids,
			const u8 *after_ric, int n_after_ric,
			size_t offset)
{
	size_t pos = offset;

	while (pos < ielen) {
		u8 ext = 0;

		if (ies[pos] == SKW_WLAN_EID_EXTENSION)
			ext = 2;
		if ((pos + ext) >= ielen)
			break;

		if (!skw_id_in_list(ids, n_ids, ies[pos + ext],
					  ies[pos] == SKW_WLAN_EID_EXTENSION))
			break;

		if (ies[pos] == WLAN_EID_RIC_DATA && n_after_ric) {
			pos = skw_skip_ie(ies, ielen, pos);

			while (pos < ielen) {
				if (ies[pos] == SKW_WLAN_EID_EXTENSION)
					ext = 2;
				else
					ext = 0;

				if ((pos + ext) >= ielen)
					break;

				if (!skw_id_in_list(after_ric,
							  n_after_ric,
							  ies[pos + ext],
							  ext == 2))
					pos = skw_skip_ie(ies, ielen, pos);
				else
					break;
			}
		} else {
			pos = skw_skip_ie(ies, ielen, pos);
		}
	}

	return pos;
}

static bool skw_chandef_to_operating_class(struct cfg80211_chan_def *chandef,
					  u8 *op_class)
{
	u8 vht_opclass;
	u32 freq = chandef->center_freq1;

	if (freq >= 2412 && freq <= 2472) {
		if (chandef->width > NL80211_CHAN_WIDTH_40)
			return false;

		/* 2.407 GHz, channels 1..13 */
		if (chandef->width == NL80211_CHAN_WIDTH_40) {
			if (freq > chandef->chan->center_freq)
				*op_class = 83; /* HT40+ */
			else
				*op_class = 84; /* HT40- */
		} else {
			*op_class = 81;
		}

		return true;
	}

	if (freq == 2484) {
		if (chandef->width > NL80211_CHAN_WIDTH_40)
			return false;

		*op_class = 82; /* channel 14 */
		return true;
	}

	switch (chandef->width) {
	case NL80211_CHAN_WIDTH_80:
		vht_opclass = 128;
		break;
	case NL80211_CHAN_WIDTH_160:
		vht_opclass = 129;
		break;
	case NL80211_CHAN_WIDTH_80P80:
		vht_opclass = 130;
		break;
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 11, 0)
	case NL80211_CHAN_WIDTH_10:
	case NL80211_CHAN_WIDTH_5:
		return false; /* unsupported for now */
#endif
	default:
		vht_opclass = 0;
		break;
	}

	/* 5 GHz, channels 36..48 */
	if (freq >= 5180 && freq <= 5240) {
		if (vht_opclass) {
			*op_class = vht_opclass;
		} else if (chandef->width == NL80211_CHAN_WIDTH_40) {
			if (freq > chandef->chan->center_freq)
				*op_class = 116;
			else
				*op_class = 117;
		} else {
			*op_class = 115;
		}

		return true;
	}

	/* 5 GHz, channels 52..64 */
	if (freq >= 5260 && freq <= 5320) {
		if (vht_opclass) {
			*op_class = vht_opclass;
		} else if (chandef->width == NL80211_CHAN_WIDTH_40) {
			if (freq > chandef->chan->center_freq)
				*op_class = 119;
			else
				*op_class = 120;
		} else {
			*op_class = 118;
		}

		return true;
	}

	/* 5 GHz, channels 100..144 */
	if (freq >= 5500 && freq <= 5720) {
		if (vht_opclass) {
			*op_class = vht_opclass;
		} else if (chandef->width == NL80211_CHAN_WIDTH_40) {
			if (freq > chandef->chan->center_freq)
				*op_class = 122;
			else
				*op_class = 123;
		} else {
			*op_class = 121;
		}

		return true;
	}

	/* 5 GHz, channels 149..169 */
	if (freq >= 5745 && freq <= 5845) {
		if (vht_opclass) {
			*op_class = vht_opclass;
		} else if (chandef->width == NL80211_CHAN_WIDTH_40) {
			if (freq > chandef->chan->center_freq)
				*op_class = 126;
			else
				*op_class = 127;
		} else if (freq <= 5805) {
			*op_class = 124;
		} else {
			*op_class = 125;
		}

		return true;
	}

	/* 56.16 GHz, channel 1..4 */
	if (freq >= 56160 + 2160 * 1 && freq <= 56160 + 2160 * 4) {
		if (chandef->width >= NL80211_CHAN_WIDTH_40)
			return false;

		*op_class = 180;
		return true;
	}

	/* not supported yet */
	return false;
}

static void skw_tdls_add_link_ie(struct net_device *ndev, struct sk_buff *skb,
		const u8 *peer, bool initiator)
{
	struct skw_iface *iface = netdev_priv(ndev);
	struct ieee80211_tdls_lnkie *lnk;
	const u8 *src_addr, *dst_addr;

	if (initiator) {
		src_addr = ndev->dev_addr;
		dst_addr = peer;
	} else {
		src_addr = peer;
		dst_addr = ndev->dev_addr;
	}

	lnk = (struct ieee80211_tdls_lnkie *)skb_put(skb, sizeof(*lnk));

	lnk->ie_type = WLAN_EID_LINK_ID;
	lnk->ie_len = sizeof(struct ieee80211_tdls_lnkie) - 2;

	memcpy(lnk->bssid, iface->sta.core.bss.bssid, ETH_ALEN);
	memcpy(lnk->init_sta, src_addr, ETH_ALEN);
	memcpy(lnk->resp_sta, dst_addr, ETH_ALEN);
}

static int skw_add_srates_ie(struct net_device *ndev, struct sk_buff *skb,
		bool need_basic, enum nl80211_band band)
{
	struct ieee80211_supported_band *sband;
	struct skw_iface *iface = netdev_priv(ndev);
	int rate, shift = 0;
	u8 i, rates, *pos;
	//u32 basic_rates = sdata->vif.bss_conf.basic_rates;
	u32 basic_rates = 0xFFFF;
	u32 rate_flags = 0;

	//shift = ieee80211_vif_get_shift(&sdata->vif);
	//shift = ieee80211_vif_get_shift(&sdata->vif);
	//rate_flags = ieee80211_chandef_rate_flags(&sdata->vif.bss_conf.chandef);
	sband = iface->wdev.wiphy->bands[band];
	rates = 0;
	for (i = 0; i < sband->n_bitrates; i++) {
		if ((rate_flags & sband->bitrates[i].flags) != rate_flags)
			continue;
		rates++;
	}
	if (rates > 8)
		rates = 8;

	if (skb_tailroom(skb) < rates + 2)
		return -ENOMEM;

	pos = skb_put(skb, rates + 2);
	*pos++ = WLAN_EID_SUPP_RATES;
	*pos++ = rates;
	for (i = 0; i < rates; i++) {
		u8 basic = 0;

		if ((rate_flags & sband->bitrates[i].flags) != rate_flags)
			continue;

		if (need_basic && basic_rates & BIT(i))
			basic = 0x80;
		rate = DIV_ROUND_UP(sband->bitrates[i].bitrate,
				    5 * (1 << shift));
		*pos++ = basic | (u8)rate;
	}

	return 0;
}

static int skw_add_ext_srates_ie(struct net_device *ndev,
				struct sk_buff *skb, bool need_basic,
				enum nl80211_band band)
{
	struct ieee80211_supported_band *sband;
	int rate, shift = 0;
	u8 i, exrates, *pos;
	//u32 basic_rates = sdata->vif.bss_conf.basic_rates;
	u32 basic_rates = 0xFFFF;
	u32 rate_flags = 0;
	struct skw_iface *iface = netdev_priv(ndev);

	//rate_flags = ieee80211_chandef_rate_flags(&sdata->vif.bss_conf.chandef);
	//shift = ieee80211_vif_get_shift(&sdata->vif);

	sband = iface->wdev.wiphy->bands[band];
	exrates = 0;
	for (i = 0; i < sband->n_bitrates; i++) {
		if ((rate_flags & sband->bitrates[i].flags) != rate_flags)
			continue;
		exrates++;
	}

	if (exrates > 8)
		exrates -= 8;
	else
		exrates = 0;

	if (skb_tailroom(skb) < exrates + 2)
		return -ENOMEM;

	if (exrates) {
		pos = skb_put(skb, exrates + 2);
		*pos++ = WLAN_EID_EXT_SUPP_RATES;
		*pos++ = exrates;
		for (i = 8; i < sband->n_bitrates; i++) {
			u8 basic = 0;

			if ((rate_flags & sband->bitrates[i].flags)
			    != rate_flags)
				continue;
			if (need_basic && basic_rates & BIT(i))
				basic = 0x80;
			rate = DIV_ROUND_UP(sband->bitrates[i].bitrate,
					    5 * (1 << shift));
			*pos++ = basic | (u8)rate;
		}
	}

	return 0;
}

static u8
skw_tdls_add_subband(struct net_device *ndev, struct sk_buff *skb,
		u16 start, u16 end, u16 spacing)
{
	u8 subband_cnt = 0, ch_cnt = 0;
	struct ieee80211_channel *ch;
	struct cfg80211_chan_def chandef;
	int i, subband_start;
	struct skw_iface *iface = netdev_priv(ndev);
	struct wiphy *wiphy = iface->wdev.wiphy;

	for (i = start; i <= end; i += spacing) {
		if (!ch_cnt)
			subband_start = i;

		ch = ieee80211_get_channel(iface->wdev.wiphy, i);
		if (ch) {
			/* we will be active on the channel */
			cfg80211_chandef_create(&chandef, ch,
						NL80211_CHAN_NO_HT);
			if (skw_compat_reg_can_beacon(wiphy, &chandef,
						      iface->wdev.iftype)) {
				ch_cnt++;
				/*
				 * check if the next channel is also part of
				 * this allowed range
				 */
				continue;
			}
		}

		/*
		 * we've reached the end of a range, with allowed channels
		 * found
		 */
		if (ch_cnt) {
			u8 *pos = skb_put(skb, 2);
			*pos++ = skw_freq_to_chn(subband_start);
			*pos++ = ch_cnt;

			subband_cnt++;
			ch_cnt = 0;
		}
	}

	/* all channels in the requested range are allowed - add them here */
	if (ch_cnt) {
		u8 *pos = skb_put(skb, 2);
		*pos++ = skw_freq_to_chn(subband_start);
		*pos++ = ch_cnt;

		subband_cnt++;
	}

	return subband_cnt;
}

static void
skw_tdls_add_supp_channels(struct net_device *ndev, struct sk_buff *skb)
{
	/*
	 * Add possible channels for TDLS. These are channels that are allowed
	 * to be active.
	 */
	u8 subband_cnt;
	u8 *pos = skb_put(skb, 2);

	*pos++ = WLAN_EID_SUPPORTED_CHANNELS;

	/*
	 * 5GHz and 2GHz channels numbers can overlap. Ignore this for now, as
	 * this doesn't happen in real world scenarios.
	 */

	/* 2GHz, with 5MHz spacing */
	subband_cnt = skw_tdls_add_subband(ndev, skb, 2412, 2472, 5);

	/* 5GHz, with 20MHz spacing */
	subband_cnt += skw_tdls_add_subband(ndev, skb, 5000, 5825, 20);

	/* length */
	*pos = 2 * subband_cnt;
}

static void skw_tdls_add_ext_capab(struct net_device *ndev,
				struct sk_buff *skb)
{
	u8 cap;
	//struct ieee80211_supported_band *sband;
	//struct ieee80211_if_managed *ifmgd = &sdata->u.mgd;

	//bool wider_band = ieee80211_hw_check(&local->hw, TDLS_WIDER_BW) &&
			  //!ifmgd->tdls_wider_bw_prohibited;
	//bool buffer_sta = ieee80211_hw_check(&local->hw,
	//				     SUPPORTS_TDLS_BUFFER_STA);
#ifdef WLAN_EXT_CAPA8_TDLS_WIDE_BW_ENABLED
	struct skw_iface *iface = netdev_priv(ndev);
	enum nl80211_band band = iface->sta.core.bss.channel->band;
	struct ieee80211_supported_band *sband = iface->wdev.wiphy->bands[band];
	bool vht = sband && sband->vht_cap.vht_supported;
	bool wider_band = false;
#endif
	u8 *pos = skb_put(skb, 10);

	*pos++ = WLAN_EID_EXT_CAPABILITY;
	*pos++ = 8; /* len */
	*pos++ = 0x0;
	*pos++ = 0x0;
	*pos++ = 0x0;

	cap = 0;
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
	cap |= WLAN_EXT_CAPA4_TDLS_BUFFER_STA;

	if (iface->wdev.wiphy->features & NL80211_FEATURE_TDLS_CHANNEL_SWITCH)
		cap |= WLAN_EXT_CAPA4_TDLS_CHAN_SWITCH;
#endif
	*pos++ = cap;
	*pos++ = WLAN_EXT_CAPA5_TDLS_ENABLED;
	*pos++ = 0;
	*pos++ = 0;
#ifdef WLAN_EXT_CAPA8_TDLS_WIDE_BW_ENABLED
	*pos++ = (vht && wider_band) ? WLAN_EXT_CAPA8_TDLS_WIDE_BW_ENABLED : 0;
#else
	*pos++ = 0;
#endif
}

/**
 * @brief append wmm ie
 *
 * @param skb              A pointer to sk_buff structure
 * @param wmm_type         SKW_WMM_TYPE_INFO/SKW_WMM_TYPE_PARAMETER
 * @param pQosInfo         A pointer to qos info
 *
 * @return                      N/A
 */
static void
skw_add_wmm_ie(struct skw_iface *iface, struct sk_buff *skb,
		u8 wmm_type, u8 *pQosInfo)
{
	u8 wmmInfoElement[] = { 0x00, 0x50, 0xf2, 0x02, 0x00, 0x01 };
	u8 wmmParamElement[] = { 0x00, 0x50, 0xf2, 0x02, 0x01, 0x01};

	u8 qosInfo = 0x0;
	u8 reserved = 0;
	u8 wmmParamIe_len = 24;
	u8 wmmInfoIe_len = 7;
	u8 len = 0;
	u8 *pos;

	if (skb_tailroom(skb) < wmmParamIe_len + 2)
		return;

	qosInfo = (!pQosInfo) ? 0xf : (*pQosInfo);

	/*wmm parameter */
	if (wmm_type == SKW_WMM_TYPE_PARAMETER) {
		pos = skb_put(skb, wmmParamIe_len + 2);
		len = wmmParamIe_len;
	} else {
		pos = skb_put(skb, wmmInfoIe_len + 2);
		len = wmmInfoIe_len;
	}

	*pos++ = WLAN_EID_VENDOR_SPECIFIC;
	*pos++ = len;

	/*wmm parameter */
	if (wmm_type == SKW_WMM_TYPE_PARAMETER) {
		memcpy(pos, wmmParamElement, sizeof(wmmParamElement));
		pos += sizeof(wmmParamElement);
	} else {
		memcpy(pos, wmmInfoElement, sizeof(wmmInfoElement));
		pos += sizeof(wmmInfoElement);
	}
	*pos++ = qosInfo;

	/* wmm parameter */
	if (wmm_type == SKW_WMM_TYPE_PARAMETER) {
		*pos++ = reserved;
		/* Use the same WMM AC parameters as STA for TDLS link */
		memcpy(pos, &iface->wmm.ac[0], sizeof(struct skw_ac_param));
		pos += sizeof(struct skw_ac_param);
		memcpy(pos, &iface->wmm.ac[1], sizeof(struct skw_ac_param));
		pos += sizeof(struct skw_ac_param);
		memcpy(pos, &iface->wmm.ac[2], sizeof(struct skw_ac_param));
		pos += sizeof(struct skw_ac_param);
		memcpy(pos, &iface->wmm.ac[3], sizeof(struct skw_ac_param));
	}
}

static void
skw_tdls_add_oper_classes(struct net_device *ndev, struct sk_buff *skb)
{
	u8 *pos;
	u8 op_class;
	int freq;
	struct skw_iface *iface = netdev_priv(ndev);
	struct cfg80211_chan_def chandef;
	struct ieee80211_channel *channel;

	freq = skw_to_freq(iface->sta.core.bss.channel->hw_value);
	channel = ieee80211_get_channel(ndev->ieee80211_ptr->wiphy, freq);

	cfg80211_chandef_create(&chandef, channel, NL80211_CHAN_NO_HT);

	if (!skw_chandef_to_operating_class(&chandef, &op_class))
		return;

	pos = skb_put(skb, 4);
	*pos++ = WLAN_EID_SUPPORTED_REGULATORY_CLASSES;
	*pos++ = 2; /* len */

	*pos++ = op_class;
	*pos++ = op_class; /* give current operating class as alternate too */
}

#if 0
u8 *skw_ie_build_ht_cap(u8 *pos, struct ieee80211_sta_ht_cap *ht_cap,
			      u16 cap)
{
	__le16 tmp;

	*pos++ = WLAN_EID_HT_CAPABILITY;
	*pos++ = sizeof(struct ieee80211_ht_cap);
	memset(pos, 0, sizeof(struct ieee80211_ht_cap));

	/* capability flags */
	tmp = cpu_to_le16(cap);
	memcpy(pos, &tmp, sizeof(u16));
	pos += sizeof(u16);

	/* AMPDU parameters */
	*pos++ = ht_cap->ampdu_factor |
		 (ht_cap->ampdu_density <<
			IEEE80211_HT_AMPDU_PARM_DENSITY_SHIFT);

	/* MCS set */
	memcpy(pos, &ht_cap->mcs, sizeof(ht_cap->mcs));
	pos += sizeof(ht_cap->mcs);

	/* extended capabilities */
	pos += sizeof(__le16);

	/* BF capabilities */
	pos += sizeof(__le32);

	/* antenna selection */
	pos += sizeof(u8);

	return pos;
}

u8 *ieee80211_ie_build_vht_cap(u8 *pos, struct ieee80211_sta_vht_cap *vht_cap,
			       u32 cap)
{
	__le32 tmp;

	*pos++ = WLAN_EID_VHT_CAPABILITY;
	*pos++ = sizeof(struct ieee80211_vht_cap);
	memset(pos, 0, sizeof(struct ieee80211_vht_cap));

	/* capability flags */
	tmp = cpu_to_le32(cap);
	memcpy(pos, &tmp, sizeof(u32));
	pos += sizeof(u32);

	/* VHT MCS set */
	memcpy(pos, &vht_cap->vht_mcs, sizeof(vht_cap->vht_mcs));
	pos += sizeof(vht_cap->vht_mcs);

	return pos;
}
#endif

static void
skw_tdls_add_setup_start_ies(struct net_device *ndev, struct sk_buff *skb,
		const u8 *peer, u32 peer_cap, u8 action_code, bool initiator,
		const u8 *ies, size_t ies_len)
{
	struct ieee80211_supported_band *sband;
	//struct ieee80211_sta_ht_cap ht_cap;
	//struct ieee80211_sta_vht_cap vht_cap;
	size_t offset = 0, noffset;
	struct skw_iface *iface = netdev_priv(ndev);
	//u8 *pos;
	enum nl80211_band band;

	if (iface->sta.core.bss.channel) {
		band = iface->sta.core.bss.channel->band;
	} else {
		skw_err("bss is null\n");
		return;
	}

	sband = iface->wdev.wiphy->bands[band];
	if (!sband)
		return;

	skw_add_srates_ie(ndev, skb, false, band);
	skw_add_ext_srates_ie(ndev, skb, false, band);
	skw_tdls_add_supp_channels(ndev, skb);

	/* Add any custom IEs that go before Extended Capabilities */
	if (ies_len) {
		static const u8 before_ext_cap[] = {
			WLAN_EID_SUPP_RATES,
			WLAN_EID_COUNTRY,
			WLAN_EID_EXT_SUPP_RATES,
			WLAN_EID_SUPPORTED_CHANNELS,
			WLAN_EID_RSN,
		};
		noffset = skw_ie_split_ric(ies, ies_len, before_ext_cap,
				ARRAY_SIZE(before_ext_cap), NULL, 0, offset);
		skw_put_skb_data(skb, ies + offset, noffset - offset);
		offset = noffset;
	}

	skw_tdls_add_ext_capab(ndev, skb);

	/* add the QoS element if we support it */
	if (action_code != WLAN_PUB_ACTION_TDLS_DISCOVER_RES)
		skw_add_wmm_ie(iface, skb, SKW_WMM_TYPE_INFO, NULL);

	/* add any custom IEs that go before HT capabilities */
	if (ies_len) {
		static const u8 before_ht_cap[] = {
			WLAN_EID_SUPP_RATES,
			WLAN_EID_COUNTRY,
			WLAN_EID_EXT_SUPP_RATES,
			WLAN_EID_SUPPORTED_CHANNELS,
			WLAN_EID_RSN,
			WLAN_EID_EXT_CAPABILITY,
			WLAN_EID_QOS_CAPA,
			WLAN_EID_FAST_BSS_TRANSITION,
			WLAN_EID_TIMEOUT_INTERVAL,
			WLAN_EID_SUPPORTED_REGULATORY_CLASSES,
		};
		noffset = skw_ie_split_ric(ies, ies_len, before_ht_cap,
				ARRAY_SIZE(before_ht_cap), NULL, 0,  offset);
		skw_put_skb_data(skb, ies + offset, noffset - offset);
		offset = noffset;
	}

	skw_tdls_add_oper_classes(ndev, skb);
	skw_tdls_add_link_ie(ndev, skb, peer, initiator);

	/* add any remaining IEs */
	if (ies_len) {
		noffset = ies_len;
		skw_put_skb_data(skb, ies + offset, noffset - offset);
	}
}

static void
skw_tdls_add_setup_cfm_ies(struct net_device *ndev,
			struct sk_buff *skb, const u8 *peer,
			u32 peer_cap, bool initiator,
			const u8 *extra_ies, size_t extra_ies_len)
{
	struct skw_iface *iface = netdev_priv(ndev);
	size_t offset = 0, noffset;
	struct ieee80211_supported_band *sband = NULL;
	enum nl80211_band band;

	band = iface->sta.core.bss.channel->band;
	sband = iface->wdev.wiphy->bands[band];

	if (!sband)
		return;

	/* add any custom IEs that go before the QoS IE */
	if (extra_ies_len) {
		static const u8 before_qos[] = {
			WLAN_EID_RSN,
		};
		noffset = skw_ie_split_ric(extra_ies, extra_ies_len,
					     before_qos,
					     ARRAY_SIZE(before_qos),
					     NULL, 0,
					     offset);
		skw_put_skb_data(skb, extra_ies + offset, noffset - offset);
		offset = noffset;
	}
	/* add the QoS param IE if both the peer and we support it */
	if (peer_cap & SKW_TDLS_PEER_WMM)
		skw_add_wmm_ie(iface, skb, SKW_WMM_TYPE_PARAMETER, NULL);

	/* add any custom IEs that go before HT operation */
	if (extra_ies_len) {
		static const u8 before_ht_op[] = {
			WLAN_EID_RSN,
			WLAN_EID_QOS_CAPA,
			WLAN_EID_FAST_BSS_TRANSITION,
			WLAN_EID_TIMEOUT_INTERVAL,
		};
		noffset = skw_ie_split_ric(extra_ies, extra_ies_len,
					     before_ht_op,
					     ARRAY_SIZE(before_ht_op),
					     NULL, 0,
					     offset);
		skw_put_skb_data(skb, extra_ies + offset, noffset - offset);
		offset = noffset;
	}

	skw_tdls_add_link_ie(ndev, skb, peer, initiator);

	/* add any remaining IEs */
	if (extra_ies_len) {
		noffset = extra_ies_len;
		skw_put_skb_data(skb, extra_ies + offset, noffset - offset);
	}
}

static void skw_tdls_add_chan_switch_req_ies(struct net_device *ndev,
				       struct sk_buff *skb, const u8 *peer,
				       bool initiator, const u8 *extra_ies,
				       size_t extra_ies_len, u8 oper_class,
				       struct cfg80211_chan_def *chandef)
{
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
	struct ieee80211_tdls_data *tf;
	size_t offset = 0, noffset;

	if (WARN_ON_ONCE(!chandef))
		return;

	tf = (void *)skb->data;
	tf->u.chan_switch_req.target_channel =
		skw_freq_to_chn(chandef->chan->center_freq);
	tf->u.chan_switch_req.oper_class = oper_class;

	if (extra_ies_len) {
		static const u8 before_lnkie[] = {
			WLAN_EID_SECONDARY_CHANNEL_OFFSET,
		};
		noffset = skw_ie_split_ric(extra_ies, extra_ies_len,
					     before_lnkie,
					     ARRAY_SIZE(before_lnkie),
					     NULL, 0,
					     offset);
		skw_put_skb_data(skb, extra_ies + offset, noffset - offset);
		offset = noffset;
	}

	skw_tdls_add_link_ie(ndev, skb, peer, initiator);

	/* add any remaining IEs */
	if (extra_ies_len) {
		noffset = extra_ies_len;
		skw_put_skb_data(skb, extra_ies + offset, noffset - offset);
	}
#endif
}

static void skw_tdls_add_ies(struct net_device *ndev, struct sk_buff *skb,
		const u8 *peer, u8 action, u16 status_code, u32 peer_cap,
		bool initiator, const u8 *ies, size_t ies_len)
{
	switch (action) {
	case WLAN_TDLS_SETUP_REQUEST:
	case WLAN_TDLS_SETUP_RESPONSE:
	case WLAN_PUB_ACTION_TDLS_DISCOVER_RES:
		if (status_code == 0)
			skw_tdls_add_setup_start_ies(ndev, skb, peer, peer_cap,
				action, initiator, ies, ies_len);
		break;
	case WLAN_TDLS_SETUP_CONFIRM:
		if (status_code == 0)
			skw_tdls_add_setup_cfm_ies(ndev, skb, peer, peer_cap,
				initiator, ies, ies_len);
		break;
	case WLAN_TDLS_TEARDOWN:
	case WLAN_TDLS_DISCOVERY_REQUEST:
		if (ies_len)
			skw_put_skb_data(skb, ies, ies_len);

		if (status_code == 0 || action == WLAN_TDLS_TEARDOWN)
			skw_tdls_add_link_ie(ndev, skb, peer, initiator);
		break;
	case WLAN_TDLS_CHANNEL_SWITCH_REQUEST:
		skw_tdls_add_chan_switch_req_ies(ndev, skb, peer,
			initiator, ies, ies_len, 0, NULL);
		break;
	default:
		break;
	}
}

static int
skw_tdls_build_send_encap_data(struct net_device *ndev,
		const u8 *peer, u8 action_code, u8 dialog_token,
		u16 status_code, u32 peer_cap, struct sk_buff *skb,
		bool initiator, const u8 *ies, size_t ies_len)
{
	int offset;
	struct ieee80211_tdls_data *td = NULL;

	offset = offsetof(struct ieee80211_tdls_data, u);
	td = (struct ieee80211_tdls_data *)skb_put(skb, offset);

	memcpy(td->da, peer, ETH_ALEN);
	memcpy(td->sa, ndev->dev_addr, ETH_ALEN);
	td->ether_type = cpu_to_be16(ETH_P_TDLS);
	td->payload_type = WLAN_TDLS_SNAP_RFTYPE;

	skb_set_network_header(skb, ETH_HLEN);

	switch (action_code) {
	case WLAN_TDLS_SETUP_REQUEST:
		td->category = WLAN_CATEGORY_TDLS;
		td->action_code = WLAN_TDLS_SETUP_REQUEST;

		skb_put(skb, sizeof(td->u.setup_req));
		td->u.setup_req.dialog_token = dialog_token;
		td->u.setup_req.capability = 0;
		break;

	case WLAN_TDLS_SETUP_RESPONSE:
		td->category = WLAN_CATEGORY_TDLS;
		td->action_code = WLAN_TDLS_SETUP_RESPONSE;

		skb_put(skb, sizeof(td->u.setup_resp));
		td->u.setup_resp.status_code = cpu_to_le16(status_code);
		td->u.setup_resp.dialog_token = dialog_token;

		td->u.setup_resp.capability = 0;
		break;

	case WLAN_TDLS_SETUP_CONFIRM:
		td->category = WLAN_CATEGORY_TDLS;
		td->action_code = WLAN_TDLS_SETUP_CONFIRM;

		skb_put(skb, sizeof(td->u.setup_cfm));
		td->u.setup_cfm.status_code = cpu_to_le16(status_code);
		td->u.setup_cfm.dialog_token = dialog_token;
		break;

	case WLAN_TDLS_TEARDOWN:
		td->category = WLAN_CATEGORY_TDLS;
		td->action_code = WLAN_TDLS_TEARDOWN;

		skb_put(skb, sizeof(td->u.teardown));
		td->u.teardown.reason_code = cpu_to_le16(status_code);
		break;

	case WLAN_TDLS_DISCOVERY_REQUEST:
		td->category = WLAN_CATEGORY_TDLS;
		td->action_code = WLAN_TDLS_DISCOVERY_REQUEST;

		skb_put(skb, sizeof(td->u.discover_req));
		td->u.discover_req.dialog_token = dialog_token;
		break;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
	case WLAN_TDLS_CHANNEL_SWITCH_REQUEST:
		td->category = WLAN_CATEGORY_TDLS;
		td->action_code = WLAN_TDLS_CHANNEL_SWITCH_REQUEST;

		skb_put(skb, sizeof(td->u.chan_switch_req));
		break;

	case WLAN_TDLS_CHANNEL_SWITCH_RESPONSE:
		td->category = WLAN_CATEGORY_TDLS;
		td->action_code = WLAN_TDLS_CHANNEL_SWITCH_RESPONSE;

		skb_put(skb, sizeof(td->u.chan_switch_resp));
		td->u.chan_switch_resp.status_code = cpu_to_le16(status_code);
		break;
#endif

	default:
		return -EINVAL;
	}

	skw_tdls_add_ies(ndev, skb, peer, action_code, status_code, peer_cap,
		initiator, ies, ies_len);

	return dev_queue_xmit(skb);
}

static int
skw_tdls_build_send_direct(struct net_device *dev,
		const u8 *peer, u8 action_code, u8 dialog_token,
		u16 status_code, struct sk_buff *skb, bool initiator,
		const u8 *ies, size_t ies_len)
{
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_core *skw = iface->skw;
	struct wiphy *wiphy = priv_to_wiphy(skw);
	struct ieee80211_mgmt *mgmt;
	int ret, total_len;
	struct skw_mgmt_tx_param *param;

	skw_dbg("Enter\n");
	mgmt = skw_put_skb_zero(skb, 24);
	memcpy(mgmt->da, peer, ETH_ALEN);
	skw_ether_copy(mgmt->sa, iface->addr);
	skw_ether_copy(mgmt->bssid, iface->sta.core.bss.bssid);
	mgmt->frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT |
					IEEE80211_STYPE_ACTION);

	switch (action_code) {
	case WLAN_PUB_ACTION_TDLS_DISCOVER_RES:
		skb_put(skb, 1 + sizeof(mgmt->u.action.u.tdls_discover_resp));
		mgmt->u.action.category = WLAN_CATEGORY_PUBLIC;
		mgmt->u.action.u.tdls_discover_resp.action_code =
			WLAN_PUB_ACTION_TDLS_DISCOVER_RES;
		mgmt->u.action.u.tdls_discover_resp.dialog_token =
			dialog_token;
		mgmt->u.action.u.tdls_discover_resp.capability =
			status_code ? 0 : (WLAN_CAPABILITY_SHORT_SLOT_TIME |
			 WLAN_CAPABILITY_SHORT_PREAMBLE);
		break;

	default:
		return -EINVAL;
	}

	skw_tdls_add_ies(dev, skb, peer, action_code, status_code, 0,
		initiator, ies, ies_len);

	skw_dbg("sending tdls discover response\n");

	total_len = sizeof(*param) + skb->len;
	param = SKW_ZALLOC(total_len, GFP_KERNEL);
	if (IS_ERR_OR_NULL(param))
		return -ENOMEM;

	param->channel = 0xFF;
	param->wait = 0;
	param->dont_wait_for_ack = 0;
	param->cookie = 0;

	memcpy(param->mgmt, skb->data, skb->len);
	param->mgmt_frame_len = skb->len;

	skw_hex_dump("mgmt tx", skb->data, skb->len, false);

	ret = skw_msg_xmit(wiphy, iface->id, SKW_CMD_TX_MGMT,
			param, total_len, NULL, 0);

	SKW_KFREE(param);
	return ret;
}

int skw_tdls_build_send_mgmt(struct skw_core *skw, struct net_device *ndev,
			const u8 *peer, u8 action_code, u8 dialog_token,
			u16 status_code, u32 peer_cap, bool initiator,
			const u8 *ies, size_t ies_len)
{
	struct sk_buff *skb;
	unsigned int skb_len;
	int ret;

	skb_len = skw->skb_headroom +
		  max(sizeof(struct ieee80211_mgmt),
		      sizeof(struct ieee80211_tdls_data)) +
		  50 + /* supported rates */
		  10 + /* ext capab */
		  26 + /* WMM */
		  2 + max(sizeof(struct ieee80211_ht_cap),
			  sizeof(struct ieee80211_ht_operation)) +
		  2 + max(sizeof(struct ieee80211_vht_cap),
			  sizeof(struct ieee80211_vht_operation)) +
		  50 + /* supported channels */
		  3 + /* 40/20 BSS coex */
		  4 + /* AID */
		  4 + /* oper classes */
		  ies_len +
		  sizeof(struct ieee80211_tdls_lnkie);

	skw_dbg("skb_headroom: %u skb_len: %u ies_len: %lu\n",
		skw->skb_headroom, skb_len, (long)ies_len);

	skb = netdev_alloc_skb(ndev, skb_len);
	if (!skb)
		return -ENOMEM;

	skb_reserve(skb, skw->skb_headroom);

	switch (action_code) {
	case WLAN_TDLS_SETUP_REQUEST:
	case WLAN_TDLS_SETUP_RESPONSE:
	case WLAN_TDLS_SETUP_CONFIRM:
	case WLAN_TDLS_TEARDOWN:
	case WLAN_TDLS_DISCOVERY_REQUEST:
	case WLAN_TDLS_CHANNEL_SWITCH_REQUEST:
	case WLAN_TDLS_CHANNEL_SWITCH_RESPONSE:
		ret = skw_tdls_build_send_encap_data(ndev, peer,
				action_code, dialog_token, status_code,
				peer_cap, skb, initiator, ies, ies_len);
		break;

	case WLAN_PUB_ACTION_TDLS_DISCOVER_RES:
		ret = skw_tdls_build_send_direct(ndev, peer, action_code,
				dialog_token, status_code, skb, initiator,
				ies, ies_len);
		break;

	default:
		ret = -EOPNOTSUPP;
		break;
	}

	return ret;
}
===== ./drivers/skwifi/skw_iface.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include "skw_core.h"
#include "skw_iface.h"
#include "skw_rx.h"
#include "skw_mlme.h"
#include "skw_cfg80211.h"
#include "skw_timer.h"
#include "skw_dfs.h"
#include "trace.h"

static int skw_iface_show(struct seq_file *seq, void *data)
{
	u32 peer_idx_map, idx;
	struct skw_peer_ctx *ctx;
	struct skw_bss_cfg *bss = NULL;
	struct net_device *ndev = seq->private;
	struct skw_iface *iface = netdev_priv(ndev);
	int i;

	seq_puts(seq, "\n");
	seq_printf(seq, "Iface: \t%s (id: %d)\n"
			"    addr:  \t%pM\n"
			"    mode:  \t%s\n"
			"    cpu_id:  \t%d\n",
			netdev_name(iface->ndev),
			iface->id,
			iface->addr,
			skw_iftype_name(iface->wdev.iftype),
			iface->cpu_id);

	switch (iface->wdev.iftype) {
	case NL80211_IFTYPE_STATION:
		if (iface->flags & SKW_IFACE_FLAG_LEGACY_P2P_DEV)
			break;

		skw_fallthrough;

	case NL80211_IFTYPE_P2P_CLIENT:
		bss = &iface->sta.core.bss;
		seq_printf(seq, "    state: \t%s\n",
			   skw_state_name(iface->sta.core.sm.state));
		break;

	case NL80211_IFTYPE_AP:
	case NL80211_IFTYPE_P2P_GO:
		bss = &iface->sap.cfg;
		seq_printf(seq, "    max sta: \t%d\n",
				iface->sap.max_sta_allowed);
		break;

	default:
		break;
	}

	seq_printf(seq, "\nBSS Info: %s\n", bss ? "" : "null");
	if (bss) {
		seq_printf(seq, "    SSID:  \t%s\n"
				"    BSSID: \t%pM\n"
				"    channel:\t%d\n"
				"    width: \t%s\n",
				bss->ssid,
				bss->bssid,
				bss->channel ? bss->channel->hw_value : -1,
				skw_width_name(bss->width));
	}

	peer_idx_map = atomic_read(&iface->peer_map);

	seq_printf(seq, "\nPEER Info: %s\n", peer_idx_map ? "" : "null");
	while (peer_idx_map) {
		idx = ffs(peer_idx_map) - 1;
		SKW_CLEAR(peer_idx_map, BIT(idx));

		ctx = &iface->skw->peer_ctx[idx];

		mutex_lock(&ctx->lock);

		if (ctx->peer) {
			s16 rssi = ctx->peer->seek.rssi >> 3;

			if (ctx->peer->seek.rssi & BIT(10))
				rssi |= 0xff00;

			seq_printf(seq, "    %pM (%d) %s\n",
					ctx->peer->addr,
					ctx->peer->idx,
					skw_state_name(ctx->peer->sm.state));
			seq_printf(seq, "        TX: tidmap: 0x%x, %s: %d, nss:%d, psr: %d, tx_failed: %d\n"
					"        RX: tidmap: 0x%x, %s: %d, nss:%d\n"
					"        rssi: beacon: %d, data: %d\n"
					"        filter stats :\n",
					ctx->peer->txba.bitmap,
					ctx->peer->tx.rate.flags ?
					 "mcs" : "legacy_rate",
					ctx->peer->tx.rate.flags ?
					 ctx->peer->tx.rate.mcs_idx :
					 ctx->peer->tx.rate.legacy_rate,
					 ctx->peer->tx.rate.nss,
					ctx->peer->refer.tx_psr,
					ctx->peer->refer.tx_failed,
					ctx->peer->rx_tid_map,
					ctx->peer->rx.rate.flags ?
					 "mcs" : "legacy_rate",
					ctx->peer->rx.rate.flags ?
					 ctx->peer->rx.rate.mcs_idx :
					 ctx->peer->rx.rate.legacy_rate,
					 ctx->peer->rx.rate.nss,
					ctx->peer->refer.rssi,
					rssi);
			seq_puts(seq, "            fliter:");

			for (i = 0; i < 35; i++)
				seq_printf(seq, "%d ", ctx->peer->refer.filter_cnt[i]);

			seq_puts(seq, "\n            filter drop:");

			for (i = 0; i < 35; i++)
				seq_printf(seq, "%d ", ctx->peer->refer.filter_drop_offload_cnt[i]);

			seq_printf(seq, "\n        Channnel occupancy: tx: %d, rx_idle: %d\n",
				 ctx->peer->refer.percent, ctx->peer->refer.percent);

			seq_puts(seq, "\n");
		}

		mutex_unlock(&ctx->lock);
	}

	seq_puts(seq, "\nTXQ Info:\n");
	seq_printf(seq, "    [VO]: stoped: %d, qlen: %d tx_cache:%d\n"
			"    [VI]: stoped: %d, qlen: %d tx_cache:%d\n"
			"    [BE]: stoped: %d, qlen: %d tx_cache:%d\n"
			"    [BK]: stoped: %d, qlen: %d tx_cache:%d\n",
			SKW_TXQ_STOPED(ndev, SKW_WMM_AC_VO),
			skb_queue_len(&iface->txq[SKW_WMM_AC_VO]),
			skb_queue_len(&iface->tx_cache[SKW_WMM_AC_VO]),
			SKW_TXQ_STOPED(ndev, SKW_WMM_AC_VI),
			skb_queue_len(&iface->txq[SKW_WMM_AC_VI]),
			skb_queue_len(&iface->tx_cache[SKW_WMM_AC_VI]),
			SKW_TXQ_STOPED(ndev, SKW_WMM_AC_BE),
			skb_queue_len(&iface->txq[SKW_WMM_AC_BE]),
			skb_queue_len(&iface->tx_cache[SKW_WMM_AC_BE]),
			SKW_TXQ_STOPED(ndev, SKW_WMM_AC_BK),
			skb_queue_len(&iface->txq[SKW_WMM_AC_BK]),
			skb_queue_len(&iface->tx_cache[SKW_WMM_AC_BK]));

	seq_puts(seq, "\n");

	return 0;
}

static int skw_iface_open(struct inode *inode, struct file *file)
{
	// return single_open(file, skw_iface_show, inode->i_private);
	return single_open(file, skw_iface_show, skw_pde_data(inode));
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
static const struct proc_ops skw_iface_fops = {
	.proc_open = skw_iface_open,
	.proc_read = seq_read,
	.proc_lseek = seq_lseek,
	.proc_release = single_release,
};
#else
static const struct file_operations skw_iface_fops = {
	.owner = THIS_MODULE,
	.open = skw_iface_open,
	.read = seq_read,
	.llseek = seq_lseek,
	.release = single_release,
};
#endif

/*
 * skw_acl_allowed: check if sta is in acl list
 * return: true - allowd to access
 *         false - denied to access
 */
bool skw_acl_allowed(struct skw_iface *iface, u8 *addr)
{
	int i;
	bool match = false;

	if (!iface->sap.acl)
		return true;

	for (i = 0; i < iface->sap.acl->n_acl_entries; i++) {
		u8 *mac = iface->sap.acl->mac_addrs[i].addr;

		if (ether_addr_equal(addr, mac)) {
			match = true;
			break;
		}
	}

	/* white list */
	if (iface->sap.acl->acl_policy == NL80211_ACL_POLICY_DENY_UNLESS_LISTED)
		return match;

	return !match;
}

int skw_cmd_open_dev(struct wiphy *wiphy, int inst, const u8 *mac_addr,
		enum nl80211_iftype type, u16 flags)
{
	int mode, ret;
	struct skw_open_dev_param open_param;

	skw_dbg("%s, inst: %d, mac: %pM, flags: 0x%x\n",
		skw_iftype_name(type), inst, mac_addr, flags);

	BUG_ON(!is_valid_ether_addr(mac_addr));

	switch (type) {
	case NL80211_IFTYPE_ADHOC:
		mode = SKW_IBSS_MODE;
		break;
	case NL80211_IFTYPE_STATION:
		mode = SKW_STA_MODE;
		break;
	case NL80211_IFTYPE_AP:
		mode = SKW_AP_MODE;
		break;
	case NL80211_IFTYPE_P2P_CLIENT:
		mode = SKW_GC_MODE;
		break;
	case NL80211_IFTYPE_P2P_GO:
		mode = SKW_GO_MODE;
		break;
	case NL80211_IFTYPE_P2P_DEVICE:
		mode = SKW_P2P_DEV_MODE;
		break;
	case NL80211_IFTYPE_MONITOR:
		mode = SKW_MONITOR_MODE;
		break;
	default:
		skw_err("iftype: %d not support\n", type);
		return -EINVAL;
	}

	skw_ether_copy(open_param.mac_addr, mac_addr);
	open_param.mode = mode;
	open_param.flags = flags;

#ifdef CONFIG_SKW_OFFCHAN_TX
	open_param.flags |= SKW_OPEN_FLAG_OFFCHAN_TX;
#endif

	ret = skw_msg_xmit(wiphy, inst, SKW_CMD_OPEN_DEV, &open_param,
			   sizeof(open_param), NULL, 0);

	return ret;
}

static int skw_cmd_close_dev(struct wiphy *wiphy, int dev_id)
{
	skw_dbg("dev id: %d\n", dev_id);

	return skw_msg_xmit(wiphy, dev_id, SKW_CMD_CLOSE_DEV, NULL, 0, NULL, 0);
}

void skw_purge_survey_data(struct skw_iface *iface)
{
	struct skw_survey_info *sinfo = NULL;
	LIST_HEAD(flush_list);

	list_replace_init(&iface->survey_list, &flush_list);

	while (!list_empty(&flush_list)) {
		sinfo = list_first_entry(&flush_list,
				 struct skw_survey_info, list);

		list_del(&sinfo->list);
		SKW_KFREE(sinfo);
	}
}

void skw_iface_event_work(struct work_struct *work)
{
	struct sk_buff *skb;
	struct skw_msg *msg_hdr;
	struct skw_iface *iface;

	iface = container_of(work, struct skw_iface, event_work.work);

	while ((skb = skb_dequeue(&iface->event_work.qlist))) {
		msg_hdr = (struct skw_msg *)skb->data;
		skb_pull(skb, sizeof(*msg_hdr));

		skw_event_handler(iface->skw, iface, msg_hdr,
				  skb->data, skb->len);

		kfree_skb(skb);
	}
}

static int skw_add_vif(struct wiphy *wiphy, struct skw_iface *iface)
{
	struct skw_core *skw = wiphy_priv(wiphy);

	skw_dbg("iface: 0x%x, bitmap: 0x%x\n", iface->id, skw->vif.bitmap);

	if (iface->id == SKW_INVALID_ID)
		return 0;

	BUG_ON(skw->vif.iface[iface->id]);

	spin_lock_bh(&skw->vif.lock);

	skw->vif.iface[iface->id] = iface;

	spin_unlock_bh(&skw->vif.lock);

	return 0;
}

static void skw_del_vif(struct wiphy *wiphy, struct skw_iface *iface)
{
	struct skw_core *skw = wiphy_priv(wiphy);

	if (!iface)
		return;

	skw_dbg("iface id: %d\n", iface->id);

	BUG_ON(iface->id >= SKW_NR_IFACE);

	spin_lock_bh(&skw->vif.lock);

	skw->vif.iface[iface->id] = NULL;

	spin_unlock_bh(&skw->vif.lock);
}

static int skw_alloc_inst(struct wiphy *wiphy, u8 id)
{
	int inst = SKW_INVALID_ID;
	struct skw_core *skw = wiphy_priv(wiphy);

	spin_lock_bh(&skw->vif.lock);

	if (id == SKW_INVALID_ID) {
		for (id = 0; id < SKW_NR_IFACE; id++) {
			if (!(skw->vif.bitmap & BIT(id))) {
				inst = id;
				break;
			}
		}
	} else if ((id != (id & 0xf)) || (skw->vif.bitmap & BIT(id))) {
		inst = SKW_INVALID_ID;
	} else {
		inst = id;
	}

	if (inst != SKW_INVALID_ID)
		SKW_SET(skw->vif.bitmap, BIT(id));

	spin_unlock_bh(&skw->vif.lock);

	return inst;
}

static void skw_release_inst(struct wiphy *wiphy, int id)
{
	struct skw_core *skw = wiphy_priv(wiphy);

	if (id != (id & 0xf))
		return;

	spin_lock_bh(&skw->vif.lock);

	SKW_CLEAR(skw->vif.bitmap, BIT(id));

	spin_unlock_bh(&skw->vif.lock);
}

static void skw_sta_work(struct work_struct *wk)
{
	bool run_again = false;
	bool connect_failed = false;
	struct skw_iface *iface = container_of(wk, struct skw_iface, sta.work);
	struct net_device *ndev = iface->ndev;
	struct skw_sta_core *core = &iface->sta.core;
	struct wiphy *wiphy = priv_to_wiphy(iface->skw);

	skw_wdev_lock(&iface->wdev);

	if (time_after(jiffies, core->auth_start + SKW_CONNECT_TIMEOUT))
		connect_failed = true;

	switch (core->sm.state) {
	case SKW_STATE_AUTHED:
		if (time_after(jiffies, core->pending.start + SKW_STEP_TIMEOUT)) {
			iface->sta.report_deauth = false;

			skw_sta_leave(wiphy, ndev, core->bss.bssid, 3, false);

			if (iface->sta.sme_external)
				skw_compat_auth_timeout(ndev, core->bss.bssid);
			else
				skw_disconnected(ndev, 3, true, GFP_KERNEL);
		} else {
			run_again = true;
		}

		break;

	case SKW_STATE_AUTHING:
		if (time_after(jiffies, core->pending.start + SKW_STEP_TIMEOUT)) {
			if (++core->pending.retry >= SKW_MAX_AUTH_ASSOC_RETRY_NUM) {
				connect_failed = true;
			} else {
				skw_set_state(&core->sm, SKW_STATE_AUTHING);

				if (skw_msg_xmit_timeout(wiphy,
							 SKW_NDEV_ID(ndev),
							 SKW_CMD_AUTH,
							 core->pending.cmd,
							 core->pending.cmd_len,
							 NULL, 0, "SKW_CMD_AUTH",
							 msecs_to_jiffies(300), 0))
					connect_failed = true;
			}
		}

		if (connect_failed) {
			iface->sta.report_deauth = false;
			skw_sta_leave(wiphy, ndev, core->bss.bssid, 3, false);

			if (iface->sta.sme_external)
				skw_compat_auth_timeout(ndev, core->bss.bssid);
			else
				skw_disconnected(ndev, 3, true, GFP_KERNEL);
		} else {
			run_again = true;
		}

		break;

	case SKW_STATE_ASSOCING:
		if (time_after(jiffies, core->pending.start + SKW_STEP_TIMEOUT)) {
			if (++core->pending.retry >= SKW_MAX_AUTH_ASSOC_RETRY_NUM) {
				connect_failed = true;
			} else {
				skw_set_state(&core->sm, SKW_STATE_ASSOCING);

				if (skw_msg_xmit_timeout(wiphy,
							 SKW_NDEV_ID(ndev),
							 SKW_CMD_ASSOC,
							 core->pending.cmd,
							 core->pending.cmd_len,
							 NULL, 0, "SKW_CMD_ASSOC",
							 msecs_to_jiffies(300), 0))
					connect_failed = true;
			}
		}

		if (connect_failed) {
			iface->sta.report_deauth = false;
			skw_sta_leave(wiphy, ndev, core->bss.bssid, 3, false);

			if (iface->sta.sme_external)
				skw_compat_assoc_timeout(ndev, core->cbss);
			else
				skw_disconnected(ndev, 3, true, GFP_KERNEL);
		} else {
			run_again = true;
		}

		break;

	default:
		break;
	}

	skw_dbg("inst: %d, state: %s, connect failed: %d, run again: %d\n",
		core->sm.inst, skw_state_name(core->sm.state),
		connect_failed, run_again);

	if (run_again)
		skw_set_sta_timer(core, SKW_STEP_TIMEOUT);

	skw_wdev_unlock(&iface->wdev);
}

static void skw_sta_timer(struct timer_list *t)
{
	struct skw_iface *iface = skw_from_timer(iface, t, sta.core.timer);

	queue_work(iface->skw->event_wq, &iface->sta.work);
}

void skw_set_sta_timer(struct skw_sta_core *core, unsigned long timeout)
{
	if (!timer_pending(&core->timer))
		mod_timer(&core->timer, jiffies + timeout);
}

static int skw_mode_init(struct wiphy *wiphy, struct skw_iface *iface,
			enum nl80211_iftype type, int id)
{
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_sta_core *core = &iface->sta.core;

	switch (type) {
	case NL80211_IFTYPE_STATION:
	case NL80211_IFTYPE_P2P_CLIENT:
		memset(&iface->sta, 0x0, sizeof(iface->sta));

		iface->sta.sme_external = true;
		core->bss.ctx_idx = SKW_INVALID_ID;

		mutex_init(&core->lock);
		core->pending.cmd = SKW_ZALLOC(SKW_2K_SIZE, GFP_KERNEL);
		if (!core->pending.cmd)
			return -ENOMEM;

		core->assoc_req_ie = SKW_ZALLOC(SKW_2K_SIZE, GFP_KERNEL);
		if (!core->assoc_req_ie) {
			SKW_KFREE(core->pending.cmd);
			return -ENOMEM;
		}

		core->sm.inst = id;
		core->sm.iface_iftype = type;
		core->sm.state = SKW_STATE_NONE;
		core->sm.addr = core->bss.bssid;

		INIT_WORK(&iface->sta.work, skw_sta_work);
		skw_compat_setup_timer(&core->timer, skw_sta_timer);

		iface->sta.conn = NULL;
		spin_lock_init(&iface->sta.roam_data.lock);

		if (!(test_bit(SKW_FLAG_STA_SME_EXTERNAL, &skw->flags))) {
			iface->sta.sme_external = false;

			iface->sta.conn = SKW_ZALLOC(sizeof(*iface->sta.conn),
						  GFP_KERNEL);
			if (!iface->sta.conn) {
				iface->sta.conn = NULL;
				SKW_KFREE(core->pending.cmd);
				SKW_KFREE(core->assoc_req_ie);

				return -ENOMEM;
			}

			mutex_init(&iface->sta.conn->lock);
			iface->sta.conn->channel = NULL;

			iface->sta.conn->assoc_ie = SKW_ZALLOC(SKW_2K_SIZE,
							GFP_KERNEL);
			if (!iface->sta.conn->assoc_ie) {
				SKW_KFREE(core->pending.cmd);
				SKW_KFREE(core->assoc_req_ie);
				SKW_KFREE(iface->sta.conn);

				return -ENOMEM;
			}
		}

		break;

	case NL80211_IFTYPE_AP:
	case NL80211_IFTYPE_P2P_GO:
		memset(&iface->sap, 0x0, sizeof(iface->sap));

		skw_list_init(&iface->sap.mlme_client_list);
		iface->sap.max_sta_allowed = skw->fw.max_num_sta;

		skw_dfs_init(wiphy, iface->ndev);

		if (test_bit(SKW_FLAG_SAP_SME_EXTERNAL, &skw->flags))
			iface->sap.sme_external = true;

		iface->sap.probe_resp = SKW_ZALLOC(SKW_2K_SIZE, GFP_KERNEL);
		if (!iface->sap.probe_resp)
			return -ENOMEM;

		break;

	default:
		break;
	}

	return 0;
}

static void skw_mode_deinit(struct wiphy *wiphy, struct skw_iface *iface,
			enum nl80211_iftype iftype)
{
	struct skw_core *skw = iface->skw;
	struct skw_peer_ctx *ctx;

	switch (iftype) {
	case NL80211_IFTYPE_AP:
	case NL80211_IFTYPE_P2P_GO:
		skw_dfs_deinit(wiphy, iface->ndev);

		SKW_KFREE(iface->sap.acl);
		SKW_KFREE(iface->sap.cfg.ht_cap);
		SKW_KFREE(iface->sap.cfg.vht_cap);
		SKW_KFREE(iface->sap.probe_resp);

		break;

	case NL80211_IFTYPE_STATION:
	case NL80211_IFTYPE_P2P_CLIENT:
		if (iface->flags & SKW_IFACE_FLAG_LEGACY_P2P_DEV)
			break;

		if (iface->sta.conn) {
			SKW_KFREE(iface->sta.conn->assoc_ie);
			SKW_KFREE(iface->sta.conn);
		}

		del_timer_sync(&iface->sta.core.timer);
		cancel_work_sync(&iface->sta.work);

		skw_set_state(&iface->sta.core.sm, SKW_STATE_NONE);
		SKW_KFREE(iface->sta.core.pending.cmd);
		SKW_KFREE(iface->sta.core.assoc_req_ie);
		ctx = skw_get_ctx(skw, iface->sta.core.bss.ctx_idx);
		skw_peer_ctx_bind(iface, ctx, NULL);
		memset(&iface->sta.core.bss, 0, sizeof(struct skw_bss_cfg));
		iface->sta.core.bss.ctx_idx = SKW_INVALID_ID;

		break;

	default:
		break;
	}
}

int skw_iface_setup(struct wiphy *wiphy, struct net_device *dev,
		    struct skw_iface *iface, const u8 *addr,
		    enum nl80211_iftype iftype, int id)
{
	int i, ret;
	struct skw_core *skw = wiphy_priv(wiphy);

	skw_dbg("%s, addr: %pM\n", skw_iftype_name(iftype), addr);

	BUG_ON(!addr || !is_valid_ether_addr(addr));

	iface->ndev = dev;
	iface->wdev.wiphy = wiphy;
	iface->skw = wiphy_priv(wiphy);
	iface->default_multicast = -1;

	mutex_init(&iface->lock);
	atomic_set(&iface->peer_map, 0);
	atomic_set(&iface->actived_ctx, 0);

	INIT_LIST_HEAD(&iface->survey_list);

	mutex_init(&iface->key_conf.lock);
	for (i = 0; i < SKW_NUM_MAX_KEY; i++) {
		iface->key_conf.installed_bitmap = 0;
		RCU_INIT_POINTER(iface->key_conf.key[i], NULL);
	}

	skw_event_work_init(&iface->event_work, skw_iface_event_work);

	for (i = 0; i < SKW_MAX_DEFRAG_ENTRY; i++) {
		iface->frag[i].id = i;
		iface->frag[i].tid = SKW_INVALID_ID;
		skb_queue_head_init(&iface->frag[i].skb_list);
	}

	for (i = 0; i < SKW_WMM_AC_MAX + 1; i++) {
		skb_queue_head_init(&iface->txq[i]);
		skb_queue_head_init(&iface->tx_cache[i]);
	}

	ret = skw_mode_init(wiphy, iface, iftype, id);
	if (ret) {
		skw_err("init failed, iface: %d, iftype: %d, ret: %d\n",
			id, iftype, ret);

		return ret;
	}

	ret = skw_cmd_open_dev(wiphy, id, addr, iftype, 0);
	if (ret) {
		skw_err("open failed, iface: %d, iftype: %d, ret:%d\n",
			id, iftype, ret);
		goto iface_deinit;
	}

	spin_lock_bh(&skw->vif.lock);
	skw->vif.opened_dev++;
	spin_unlock_bh(&skw->vif.lock);

	iface->id = id;
	iface->wdev.iftype = iftype;
	skw_ether_copy(iface->addr, addr);
	iface->cpu_id = -1;

	return 0;

iface_deinit:
	skw_mode_deinit(wiphy, iface, iftype);

	return ret;
}

void skw_purge_key_conf(struct skw_key_conf *conf)
{
	int idx;
	struct skw_key *key;

	if (!conf)
		return;

	mutex_lock(&conf->lock);

	for (idx = 0; idx < SKW_NUM_MAX_KEY; idx++) {
		key = rcu_dereference_protected(conf->key[idx],
				lockdep_is_held(&conf->lock));

		RCU_INIT_POINTER(conf->key[idx], NULL);
		if (key)
			kfree_rcu(key, rcu);
	}

	conf->flags = 0;
	conf->installed_bitmap = 0;
	conf->skw_cipher = 0;

	mutex_unlock(&conf->lock);
}

int skw_iface_teardown(struct wiphy *wiphy, struct skw_iface *iface)
{
	int i, ret;
	struct skw_core *skw = wiphy_priv(wiphy);

	skw_dbg("iface id: %d\n", iface->id);

	skw_scan_done(skw, iface, true);
	skw_purge_survey_data(iface);

	for (i = SKW_WMM_AC_VO; i < SKW_WMM_AC_MAX + 1; i++) {
		skb_queue_purge(&iface->txq[i]);
		skb_queue_purge(&iface->tx_cache[i]);
	}

	skw_event_work_deinit(&iface->event_work);

	skw_mode_deinit(wiphy, iface, iface->wdev.iftype);

	skw_purge_key_conf(&iface->key_conf);

	ret = skw_cmd_close_dev(wiphy, iface->id);
	if (ret < 0)
		return ret;

	spin_lock_bh(&skw->vif.lock);

	skw->vif.opened_dev--;
	if (!skw->vif.opened_dev) {
		for (i = 0; i < skw->hw.nr_lmac; i++) {
			atomic_set(&skw->hw.lmac[i].fw_credit, 0);
			skw->rx_packets = 0;
			skw->tx_packets = 0;
		}
	}

	spin_unlock_bh(&skw->vif.lock);

	return 0;
}

struct skw_iface *skw_add_iface(struct wiphy *wiphy, const char *name,
				enum nl80211_iftype iftype, u8 *mac,
				u8 id, bool need_ndev)
{
	u8 *addr;
	int priv_size, ret;
	struct skw_iface *iface;
	struct net_device *ndev = NULL;
	struct skw_core *skw = wiphy_priv(wiphy);
	int inst = skw_alloc_inst(wiphy, id);

	skw_info("%s, inst: %d, mac: %pM, bitmap: 0x%x\n",
		 skw_iftype_name(iftype), inst, mac, skw->vif.bitmap);

	if (inst == SKW_INVALID_ID) {
		skw_err("invalid inst: %d, bitmap: 0x%x\n",
			inst, skw->vif.bitmap);

		return ERR_PTR(-EINVAL);
	}

	priv_size = sizeof(struct skw_iface);
	if (need_ndev) {
		ndev = alloc_netdev_mqs(priv_size, name,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
					NET_NAME_ENUM,
#endif
					ether_setup, SKW_WMM_AC_MAX, 1);

		if (!ndev) {
			skw_err("alloc netdev failed, iftype: %d\n", iftype);
			skw_release_inst(wiphy, inst);

			return ERR_PTR(-ENOMEM);
		}

		iface = netdev_priv(ndev);
	} else {
		iface = SKW_ZALLOC(priv_size, GFP_KERNEL);
		if (!iface) {
			skw_release_inst(wiphy, inst);
			return ERR_PTR(-ENOMEM);
		}
	}

	if (mac && is_valid_ether_addr(mac))
		addr = mac;
	else
		addr = wiphy->addresses[inst].addr;

	ret = skw_iface_setup(wiphy, ndev, iface, addr, iftype, inst);
	if (ret) {
		skw_err("iface setup failed, iftype: %d, ret: %d\n",
			iftype, ret);

		goto free_iface;
	}

	skw_add_vif(wiphy, iface);

	if (ndev) {
		skw_netdev_init(wiphy, ndev, addr);
		ret = skw_register_netdevice(ndev);
		if (ret) {
			skw_err("register netdev failed\n");
			// free_percpu(ndev->tstats);
			goto iface_teardown;
		}

		iface->procfs = skw_procfs_file(SKW_WIPHY_PENTRY(wiphy),
						netdev_name(ndev), 0444,
						&skw_iface_fops, ndev);
	} else {
		skw_ether_copy(iface->wdev.address, addr);
	}

	return iface;

iface_teardown:
	skw_del_vif(wiphy, iface);
	skw_iface_teardown(wiphy, iface);

free_iface:
	if (ndev)
		free_netdev(ndev);
	else
		SKW_KFREE(iface);

	skw_release_inst(wiphy, inst);

	return ERR_PTR(-EBUSY);
}

int skw_del_iface(struct wiphy *wiphy, struct skw_iface *iface)
{
	if (!iface)
		return 0;

	ASSERT_RTNL();

	skw_dbg("iftype = %d, iface id: %d\n", iface->wdev.iftype, iface->id);

	skw_del_vif(wiphy, iface);
	skw_iface_teardown(wiphy, iface);
	skw_release_inst(wiphy, iface->id);

	if (iface->ndev) {
		proc_remove(iface->procfs);
		skw_unregister_netdevice(iface->ndev);
	} else if (iface->wdev.iftype == NL80211_IFTYPE_P2P_DEVICE) {
		cfg80211_unregister_wdev(&iface->wdev);
		SKW_KFREE(iface);
	}

	return 0;
}

struct skw_peer *skw_peer_alloc(void)
{
	int len;

	len = ALIGN(sizeof(struct skw_peer), SKW_PEER_ALIGN);
	len += sizeof(struct skw_ctx_entry);

	return SKW_ZALLOC(len, GFP_KERNEL);
}

static void skw_peer_release(struct rcu_head *head)
{
	struct skw_ctx_entry *entry;

	entry = container_of(head, struct skw_ctx_entry, rcu);

	// NOTE: DO NOT USE SKW_FREE HERE
	kfree(entry->peer);
}

void skw_peer_free(struct skw_peer *peer)
{
	int i;
	struct skw_ctx_entry *entry;

	if (!peer)
		return;

	for (i = 0; i < SKW_NR_TID; i++)
		skw_del_tid_rx(peer, i);

	skw_purge_key_conf(&peer->ptk_conf);
	skw_purge_key_conf(&peer->gtk_conf);

	entry = skw_ctx_entry(peer);

#ifdef CONFIG_SKW_GKI_DRV
	skw_call_rcu(peer->iface->skw, &entry->rcu, skw_peer_release);
#else
	call_rcu(&entry->rcu, skw_peer_release);
#endif
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 15, 0)
static void skw_reorder_timeout(struct timer_list *timer)
#else
static void skw_reorder_timeout(unsigned long timer)
#endif
{
	struct skw_reorder_rx *reorder;

	reorder = container_of((void *)timer, struct skw_reorder_rx, timer);

	skw_dbg("tid: %d, expired sn: %d\n", reorder->tid, reorder->expired.sn);

	if (atomic_read(&reorder->ref_cnt) != reorder->expired.ref_cnt)
		return;

	trace_skw_rx_reorder_timeout(reorder->inst, reorder->peer_idx,
				reorder->tid, reorder->expired.sn);

	spin_lock_bh(&reorder->todo.lock);

	if (!reorder->todo.actived) {
		reorder->todo.actived = true;
		reorder->todo.seq = reorder->expired.sn;
		reorder->todo.reason = SKW_RELEASE_EXPIRED;
		INIT_LIST_HEAD(&reorder->todo.list);

		skw_list_add(&reorder->skw->rx_todo_list, &reorder->todo.list);
	}

	spin_unlock_bh(&reorder->todo.lock);

	skw_wakeup_rx(reorder->skw);
}

void skw_peer_init(struct skw_peer *peer, const u8 *addr, int idx)
{
	int i;
	struct skw_ctx_entry *entry;

	if (WARN_ON(!peer))
		return;

	if (idx >= SKW_MAX_PEER_SUPPORT)
		peer->flags |= SKW_PEER_FLAG_BAD_ID;

	if (!addr)
		peer->flags |= SKW_PEER_FLAG_BAD_ADDR;

	atomic_set(&peer->rx_filter, 0);
	mutex_init(&peer->ptk_conf.lock);
	mutex_init(&peer->gtk_conf.lock);

	for (i = 0; i < SKW_NR_TID; i++) {
		atomic_set(&peer->reorder[i].ref_cnt, 0);
		skw_compat_setup_timer(&peer->reorder[i].timer, skw_reorder_timeout);
		INIT_LIST_HEAD(&peer->reorder[i].todo.list);
		spin_lock_init(&peer->reorder[i].todo.lock);
		spin_lock_init(&peer->reorder[i].lock);
	}

	peer->idx = idx;
	peer->iface = NULL;
	peer->sm.addr = peer->addr;
	peer->sm.state = SKW_STATE_NONE;

	entry = skw_ctx_entry(peer);
	entry->peer = peer;
	entry->idx = idx;

	if (addr) {
		skw_ether_copy(entry->addr, addr);
		skw_ether_copy(peer->addr, addr);
	}
}

void __skw_peer_ctx_transmit(struct skw_peer_ctx *ctx, bool enable)
{
	struct skw_ctx_entry *entry;

	if (WARN_ON(!ctx))
		return;

	lockdep_assert_held(&ctx->lock);

	if (enable) {
		if (WARN_ON(!ctx->peer || ctx->peer->flags))
			return;

		entry = skw_ctx_entry(ctx->peer);
		rcu_assign_pointer(ctx->entry, entry);
		atomic_inc(&ctx->peer->iface->actived_ctx);
		SKW_SET(ctx->peer->flags, SKW_PEER_FLAG_ACTIVE);

	} else {
		entry = rcu_dereference_protected(ctx->entry,
				lockdep_is_held(&ctx->lock));
		if (entry) {
			atomic_dec(&entry->peer->iface->actived_ctx);
			SKW_CLEAR(entry->peer->flags, SKW_PEER_FLAG_ACTIVE);
		}

		RCU_INIT_POINTER(ctx->entry, NULL);
	}
}

void skw_peer_ctx_transmit(struct skw_peer_ctx *ctx, bool enable)
{
	if (!ctx)
		return;

	skw_peer_ctx_lock(ctx);
	__skw_peer_ctx_transmit(ctx, enable);
	skw_peer_ctx_unlock(ctx);
}

int __skw_peer_ctx_bind(struct skw_iface *iface, struct skw_peer_ctx *ctx,
			struct skw_peer *peer)
{
	if (WARN_ON(!iface || !ctx))
		return -EINVAL;

	lockdep_assert_held(&ctx->lock);

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 18, 0)
	atomic_and(~BIT(ctx->idx), &iface->peer_map);
#else
	atomic_set(&iface->peer_map, atomic_read(&iface->peer_map) & (~BIT(ctx->idx)));
#endif

	skw_peer_free(ctx->peer);
	ctx->peer = NULL;

	if (peer) {
		peer->iface = iface;
		peer->sm.inst = iface->id;
		peer->sm.addr = peer->addr;
		peer->sm.iface_iftype = iface->wdev.iftype;
		ctx->peer = peer;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 18, 0)
		atomic_or(BIT(ctx->idx), &iface->peer_map);
#else
		atomic_set(&iface->peer_map, atomic_read(&iface->peer_map) | BIT(ctx->idx));
#endif
	}

	return 0;
}

int skw_peer_ctx_bind(struct skw_iface *iface, struct skw_peer_ctx *ctx,
			struct skw_peer *peer)
{
	int ret;

	if (!iface || !ctx)
		return -EINVAL;

	skw_dbg("ctx: %d, %s\n", ctx->idx, peer ? "bind" : "unbind");

	mutex_lock(&ctx->lock);
	ret = __skw_peer_ctx_bind(iface, ctx, peer);
	mutex_unlock(&ctx->lock);

	return ret;
}

struct skw_peer_ctx *skw_peer_ctx(struct skw_iface *iface, const u8 *mac)
{
	int idx;
	u32 peer_idx_map;
	struct skw_peer_ctx *ctx;
	struct skw_core *skw = iface->skw;

	peer_idx_map = atomic_read(&iface->peer_map);

	if (!peer_idx_map || !mac)
		return NULL;

	while (peer_idx_map) {
		idx = ffs(peer_idx_map) - 1;
		SKW_CLEAR(peer_idx_map, BIT(idx));

		ctx = &skw->peer_ctx[idx];

		mutex_lock(&ctx->lock);

		if (ctx->peer && ether_addr_equal(mac, ctx->peer->addr)) {
			mutex_unlock(&ctx->lock);
			return ctx;
		}

		mutex_unlock(&ctx->lock);
	}

	return NULL;
}

void skw_iface_set_wmm_capa(struct skw_iface *iface, const u8 *ies, size_t len)
{
	int i, j, tmp;
	struct skw_wmm *wmm;
	int ac[4] = {-1, -1, -1, -1};
	unsigned int oui = SKW_OUI(0x00, 0x50, 0xF2);

#define SKW_WMM_SUBTYPE     2
#define SKW_WMM_ACM         BIT(4)

	wmm = (void *)cfg80211_find_vendor_ie(oui, SKW_WMM_SUBTYPE, ies, len);
	if (!wmm)
		goto default_wmm;

	if (wmm->version != 1)
		goto default_wmm;

	iface->wmm.qos_enabled = true;

	for (i = 3; i >= 0; i--) {
		for (tmp = i, j = 0; j < 4; j++) {
			int id = ac[j];

			if (id < 0)
				break;

			if (wmm->ac[id].aifsn > wmm->ac[tmp].aifsn) {
				tmp = id;
				ac[j] = i;
			}
		}

		if (j < 4)
			ac[j] = tmp;
	}

	for (i = 0; i < 4; i++) {
		int aci = ac[i];

		switch (aci) {
		case 0:
			iface->wmm.ac[i].aci = SKW_WMM_AC_BE;
			if (wmm->ac[aci].acm)
				iface->wmm.acm |= BIT(SKW_WMM_AC_BE);

			iface->wmm.factor[SKW_WMM_AC_BE] = SKW_WMM_AC_BE - i;
			break;
		case 1:
			iface->wmm.ac[i].aci = SKW_WMM_AC_BK;
			if (wmm->ac[aci].acm)
				iface->wmm.acm |= BIT(SKW_WMM_AC_BK);

			iface->wmm.factor[SKW_WMM_AC_BK] = SKW_WMM_AC_BK - i;
			break;
		case 2:
			iface->wmm.ac[i].aci = SKW_WMM_AC_VI;
			if (wmm->ac[aci].acm)
				iface->wmm.acm |= BIT(SKW_WMM_AC_VI);

			iface->wmm.factor[SKW_WMM_AC_VI] = (SKW_WMM_AC_VI - i) << 2;
			break;
		case 3:
			iface->wmm.ac[i].aci = SKW_WMM_AC_VO;
			if (wmm->ac[aci].acm)
				iface->wmm.acm |= BIT(SKW_WMM_AC_VI);

			iface->wmm.factor[SKW_WMM_AC_VO] = (SKW_WMM_AC_VO - i) << 1;
			break;
		default:
			break;
		}

		iface->wmm.ac[i].aifsn = wmm->ac[aci].aifsn;
		iface->wmm.ac[i].txop_limit = le16_to_cpu(wmm->ac[aci].txop_limit);

		skw_dbg("aci: %d, aifsn: %d, txop_limit: %d, factor: %d\n",
			iface->wmm.ac[i].aci, iface->wmm.ac[i].aifsn,
			iface->wmm.ac[i].txop_limit, iface->wmm.factor[i]);
	}

	skw_dbg("wmm_acm: 0x%x\n", iface->wmm.acm);
	return;

default_wmm:
	iface->wmm.acm = 0;

	iface->wmm.ac[0].aci = 0;
	iface->wmm.ac[0].aifsn = 2;
	iface->wmm.ac[0].txop_limit = 47;

	iface->wmm.ac[1].aci = 1;
	iface->wmm.ac[1].aifsn = 2;
	iface->wmm.ac[1].txop_limit = 94;

	iface->wmm.ac[2].aci = 2;
	iface->wmm.ac[2].aifsn = 3;
	iface->wmm.ac[2].txop_limit = 0;

	iface->wmm.ac[3].aci = 3;
	iface->wmm.ac[3].aifsn = 7;
	iface->wmm.ac[3].txop_limit = 0;
}
===== ./drivers/skwifi/skw_mbssid.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/kernel.h>
#include <linux/ieee80211.h>
#include <net/cfg80211.h>

#include "skw_core.h"
#include "skw_log.h"
#include "skw_mbssid.h"
#include "skw_cfg80211.h"
#include "skw_compat.h"

#define SKW_GENMASK_ULL(h, l)   (((~0ULL) - (1ULL << (l)) + 1) & \
				(~0ULL >> (BITS_PER_LONG_LONG - 1 - (h))))

static __always_inline u16 skw_get_unaligned_le16(const void *p)
{
	return le16_to_cpup((__le16 *)p);
}

static struct skw_element *skw_find_elem(u8 eid, const u8 *ies,
					int len, const u8 *match,
					unsigned int match_len,
					unsigned int match_offset)
{
	struct skw_element *elem;

	skw_foreach_element_id(elem, eid, ies, len) {
		if (elem->datalen >= match_offset - 2 + match_len &&
		    !memcmp(elem->data + match_offset - 2, match, match_len))
			return (void *)elem;
	}

	return NULL;
}

static const struct skw_element *
skw_get_profile_continuation(const u8 *ie, size_t ie_len,
			const struct skw_element *mbssid_elem,
			const struct skw_element *sub_elem)
{
	const u8 *mbssid_end = mbssid_elem->data + mbssid_elem->datalen;
	const struct skw_element *next_mbssid;
	const struct skw_element *sub;

	next_mbssid = skw_find_elem(WLAN_EID_MULTIPLE_BSSID,
			mbssid_end, ie_len - (mbssid_end - ie),
			NULL, 0, 0);

	if (!next_mbssid ||
	    (sub_elem->data + sub_elem->datalen < mbssid_end - 1))
		return NULL;

	if (next_mbssid->datalen < 4)
		return NULL;

	sub = (void *)&next_mbssid->data[1];

	if (next_mbssid->data + next_mbssid->datalen < sub->data + sub->datalen)
		return NULL;

	if (sub->id != 0 || sub->datalen < 2)
		return NULL;

	return sub->data[0] == WLAN_EID_NON_TX_BSSID_CAP ?  NULL : next_mbssid;
}

static size_t skw_merge_profile(const u8 *ie, size_t ie_len,
				const struct skw_element *mbssid_elem,
				const struct skw_element *sub_elem,
				u8 *merged_ie, size_t max_copy_len)
{
	size_t copied_len = sub_elem->datalen;
	const struct skw_element *next_mbssid;

	if (sub_elem->datalen > max_copy_len)
		return 0;

	memcpy(merged_ie, sub_elem->data, sub_elem->datalen);

	while ((next_mbssid = skw_get_profile_continuation(ie, ie_len,
					mbssid_elem, sub_elem))) {
		const struct skw_element *next = (void *)&next_mbssid->data[1];

		if (copied_len + next->datalen > max_copy_len)
			break;

		memcpy(merged_ie + copied_len, next->data, next->datalen);

		copied_len += next->datalen;
	}

	return copied_len;
}

static inline void skw_gen_new_bssid(const u8 *bssid, u8 max_bssid,
				u8 mbssid_index, u8 *new_bssid)
{
	u64 bssid_u64 = skw_mac_to_u64(bssid);
	u64 mask = SKW_GENMASK_ULL(max_bssid - 1, 0);
	u64 new_bssid_u64;

	new_bssid_u64 = bssid_u64 & ~mask;

	new_bssid_u64 |= ((bssid_u64 & mask) + mbssid_index) & mask;

	skw_u64_to_mac(new_bssid_u64, new_bssid);
}

static bool is_skw_element_inherited(const struct skw_element *elem,
		const struct skw_element *non_inherit_elem)
{
	u8 id_len, ext_id_len, i, loop_len, id;
	const u8 *list;

	if (elem->id == WLAN_EID_MULTIPLE_BSSID)
		return false;

	if (!non_inherit_elem || non_inherit_elem->datalen < 2)
		return true;

	id_len = non_inherit_elem->data[1];
	if (non_inherit_elem->datalen < 3 + id_len)
		return true;

	ext_id_len = non_inherit_elem->data[2 + id_len];
	if (non_inherit_elem->datalen < 3 + id_len + ext_id_len)
		return true;

	if (elem->id == SKW_WLAN_EID_EXTENSION) {
		if (!ext_id_len)
			return true;

		loop_len = ext_id_len;
		list = &non_inherit_elem->data[3 + id_len];
		id = elem->data[0];
	} else {
		if (!id_len)
			return true;

		loop_len = id_len;
		list = &non_inherit_elem->data[2];
		id = elem->id;
	}

	for (i = 0; i < loop_len; i++) {
		if (list[i] == id)
			return false;
	}

	return true;
}

static size_t skw_gen_new_ie(const u8 *ie, size_t ielen,
		const u8 *subelement, size_t subie_len,
		u8 *new_ie, gfp_t gfp)
{
	u8 eid;
	u8 *pos, *tmp;
	const u8 *tmp_old, *tmp_new;
	const struct skw_element *non_inherit;
	u8 *sub_copy;

	sub_copy = SKW_KMEMDUP(subelement, subie_len, gfp);
	if (!sub_copy)
		return 0;

	pos = &new_ie[0];

	/* set new ssid */
	tmp_new = cfg80211_find_ie(WLAN_EID_SSID, sub_copy, subie_len);
	if (tmp_new) {
		memcpy(pos, tmp_new, tmp_new[1] + 2);
		pos += (tmp_new[1] + 2);
	}

	/* get non inheritance list if exists */
	eid = SKW_EID_EXT_NON_INHERITANCE;
	non_inherit = skw_find_elem(SKW_WLAN_EID_EXTENSION, sub_copy,
					subie_len, &eid, 1, 0);

	tmp_old = cfg80211_find_ie(WLAN_EID_SSID, ie, ielen);
	tmp_old = (tmp_old) ? tmp_old + tmp_old[1] + 2 : ie;

	while (tmp_old + tmp_old[1] + 2 - ie <= ielen) {
		if (tmp_old[0] == 0) {
			tmp_old++;
			continue;
		}

		if (tmp_old[0] == SKW_WLAN_EID_EXTENSION) {
			tmp = (u8 *)skw_find_elem(SKW_WLAN_EID_EXTENSION,
					sub_copy, subie_len, &tmp_old[2], 1, 2);
		} else {
			tmp = (u8 *)cfg80211_find_ie(tmp_old[0], sub_copy,
					subie_len);
		}

		if (!tmp) {
			const struct skw_element *old_elem = (void *)tmp_old;

			if (is_skw_element_inherited(old_elem, non_inherit)) {
				memcpy(pos, tmp_old, tmp_old[1] + 2);
				pos += tmp_old[1] + 2;
			}
		} else {
			if (tmp_old[0] == WLAN_EID_VENDOR_SPECIFIC) {
				if (!memcmp(tmp_old + 2, tmp + 2, 5)) {
					memcpy(pos, tmp, tmp[1] + 2);
					pos += tmp[1] + 2;
					tmp[0] = WLAN_EID_SSID;
				} else {
					memcpy(pos, tmp_old, tmp_old[1] + 2);
					pos += tmp_old[1] + 2;
				}
			} else {
				memcpy(pos, tmp, tmp[1] + 2);
				pos += tmp[1] + 2;
				tmp[0] = WLAN_EID_SSID;
			}
		}

		if (tmp_old + tmp_old[1] + 2 - ie == ielen)
			break;

		tmp_old += tmp_old[1] + 2;
	}

	tmp_new = sub_copy;
	while (tmp_new + tmp_new[1] + 2 - sub_copy <= subie_len) {
		if (!(tmp_new[0] == WLAN_EID_NON_TX_BSSID_CAP ||
		    tmp_new[0] == WLAN_EID_SSID)) {
			memcpy(pos, tmp_new, tmp_new[1] + 2);
			pos += tmp_new[1] + 2;
		}

		if (tmp_new + tmp_new[1] + 2 - sub_copy == subie_len)
			break;

		tmp_new += tmp_new[1] + 2;
	}

	SKW_KFREE(sub_copy);

	return pos - new_ie;
}

static void skw_parse_mbssid_data(struct wiphy *wiphy,
				struct ieee80211_channel *rx_channel,
				s32 signal,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 18, 0)
				enum cfg80211_bss_frame_type ftype,
#endif
				const u8 *bssid, u64 tsf,
				u16 beacon_interval, const u8 *ie,
				size_t ie_len, gfp_t gfp)
{
	const u8 *idx_ie;
	const struct skw_element *elem, *sub;
	size_t new_ie_len;
	u8 bssid_index;
	u8 max_indicator;
	u8 new_bssid[ETH_ALEN];
	u8 *new_ie, *profile;
	u64 seen_indices = 0;
	u16 capability;
	struct cfg80211_bss *bss;

	new_ie = SKW_ZALLOC(IEEE80211_MAX_DATA_LEN, gfp);
	if (!new_ie)
		return;

	profile = SKW_ZALLOC(ie_len, gfp);
	if (!profile)
		goto out;

	skw_foreach_element_id(elem, WLAN_EID_MULTIPLE_BSSID, ie, ie_len) {
		if (elem->datalen < 4)
			continue;

		skw_foreach_element(sub, elem->data + 1, elem->datalen - 1) {
			u8 profile_len;

			if (sub->id != 0 || sub->datalen < 4)
				continue;

			if (sub->data[0] != WLAN_EID_NON_TX_BSSID_CAP ||
			    sub->data[1] != 2) {
				continue;
			}

			memset(profile, 0, ie_len);

			profile_len = skw_merge_profile(ie, ie_len,
					elem, sub, profile, ie_len);
			idx_ie = cfg80211_find_ie(SKW_WLAN_EID_MULTI_BSSID_IDX,
						  profile, profile_len);

			if (!idx_ie || idx_ie[1] < 1 ||
			    idx_ie[2] == 0 || idx_ie[2] > 46) {
				/* No valid Multiple BSSID-Index element */
				continue;
			}

			if (seen_indices & (1ULL << (idx_ie[2])))
				net_dbg_ratelimited("Partial info for BSSID index %d\n",
						idx_ie[2]);

			seen_indices |= (1ULL << (idx_ie[2]));

			bssid_index = idx_ie[2];
			max_indicator = elem->data[0];

			skw_gen_new_bssid(bssid, max_indicator,
					bssid_index, new_bssid);

			memset(new_ie, 0, IEEE80211_MAX_DATA_LEN);
			new_ie_len = skw_gen_new_ie(ie, ie_len, profile,
						profile_len, new_ie,
						GFP_KERNEL);
			if (!new_ie_len)
				continue;

			capability = skw_get_unaligned_le16(profile + 2);
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 18, 0)
			bss = cfg80211_inform_bss(wiphy, rx_channel, ftype,
						new_bssid, tsf, capability,
						beacon_interval, new_ie,
						new_ie_len, signal, gfp);
#else
			bss = cfg80211_inform_bss(wiphy, rx_channel,
						new_bssid, tsf, capability,
						beacon_interval, new_ie,
						new_ie_len, signal, gfp);
#endif

			if (!bss)
				break;

			skw_bss_priv(bss)->bssid_index = bssid_index;
			skw_bss_priv(bss)->max_bssid_indicator = max_indicator;

			cfg80211_put_bss(wiphy, bss);
		}
	}

	SKW_KFREE(profile);
out:
	SKW_KFREE(new_ie);
}

void skw_mbssid_data_parser(struct wiphy *wiphy, bool beacon,
		struct ieee80211_channel *chan, s32 signal,
		struct ieee80211_mgmt *mgmt, int mgmt_len)
{
	const u8 *ie = mgmt->u.probe_resp.variable;
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 18, 0)
	enum cfg80211_bss_frame_type ftype = CFG80211_BSS_FTYPE_PRESP;
#endif
	size_t len = offsetof(struct ieee80211_mgmt, u.probe_resp.variable);

	if (!cfg80211_find_ie(WLAN_EID_MULTIPLE_BSSID, ie, mgmt_len - len))
		return;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 18, 0)
	if (beacon)
		ftype = CFG80211_BSS_FTYPE_BEACON;
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 18, 0)
	skw_parse_mbssid_data(wiphy, chan, signal,  ftype, mgmt->bssid,
			le64_to_cpu(mgmt->u.probe_resp.timestamp),
			le16_to_cpu(mgmt->u.probe_resp.beacon_int),
			ie, mgmt_len - len, GFP_KERNEL);
#else
	skw_parse_mbssid_data(wiphy, chan, signal, mgmt->bssid,
			le64_to_cpu(mgmt->u.probe_resp.timestamp),
			le16_to_cpu(mgmt->u.probe_resp.beacon_int),
			ie, mgmt_len - len, GFP_KERNEL);
#endif
}
===== ./drivers/skwifi/skw_recovery.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/skbuff.h>

#include "skw_core.h"
#include "skw_cfg80211.h"
#include "skw_iface.h"
#include "skw_msg.h"
#include "skw_iw.h"
#include "skw_calib.h"
#include "skw_recovery.h"
#include "skw_mlme.h"
#include "skw_rx.h"
#include "skw_tx.h"

static inline void
skw_recovery_sta_disconnect(struct net_device *ndev, u8 *addr)
{
	struct skw_iface *iface = netdev_priv(ndev);

	if (iface->sta.sme_external)
		skw_tx_mlme_mgmt(ndev, IEEE80211_STYPE_DEAUTH, addr, addr, 3);
	else
		skw_disconnected(ndev, 3, true, GFP_KERNEL);
}

static int skw_recovery_sta(struct wiphy *wiphy, struct skw_recovery_data *rd,
				struct skw_iface *iface)
{
	int ret;
	u32 peer_map = rd->iface[iface->id].peer_map;
	struct skw_sta_core *core = &iface->sta.core;
	struct net_device *dev = iface->ndev;

#ifdef SKW_STATE_RECOVERY
	// TODO:
	// recovery peer state

	struct cfg80211_bss *cbss;

	cbss = cfg80211_get_bss(wiphy, core->bss.channel, core->bss.bssid,
				core->bss.ssid, core->bss.ssid_len,
				IEEE80211_BSS_TYPE_ANY, IEEE80211_PRIVACY_ANY);
	if (!cbss) {
		if (!skw_cmd_unjoin(wiphy, dev, peer->addr, 3, true))
			peer->flags |= SKW_PEER_FLAG_DEAUTHED;

		skw_recovery_sta_disconnect(dev, core->bss.bssid);
		return 0;
	}

	ret = skw_join(wiphy, dev, cbss, false);
	if (ret) {
		if (!skw_cmd_unjoin(wiphy, dev, peer->addr, 3, true))
			peer->flags |= SKW_PEER_FLAG_DEAUTHED;

		skw_recovery_sta_disconnect(dev, core->bss.bssid);
		return 0;
	}

	// set key
	// set ip

	cfg80211_put_bss(wiphy, cbss);
#else
	while (peer_map) {
		u8 idx = ffs(peer_map) - 1;
		struct skw_peer *peer = rd->peer[idx];

		SKW_CLEAR(peer_map, BIT(idx));

		if (!peer || peer->flags & SKW_PEER_FLAG_DEAUTHED)
			continue;

		if (ether_addr_equal(peer->addr, core->bss.bssid)) {
			del_timer_sync(&core->timer);
			cancel_work_sync(&iface->sta.work);

			ret = skw_cmd_unjoin(wiphy, dev, peer->addr,
					SKW_LEAVE, true);
			if (ret)
				skw_warn("failed, sta: %pM, ret: %d\n",
					 peer->addr, ret);

			skw_set_state(&core->sm, SKW_STATE_NONE);
			memset(&core->bss, 0, sizeof(struct skw_bss_cfg));
			core->bss.ctx_idx = SKW_INVALID_ID;

			skw_recovery_sta_disconnect(dev, peer->addr);
			peer->flags |= SKW_PEER_FLAG_DEAUTHED;

		} else {
			/* TDLS */
			cfg80211_tdls_oper_request(dev, peer->addr,
					NL80211_TDLS_TEARDOWN,
					SKW_WLAN_REASON_TDLS_TEARDOWN_UNREACHABLE,
					GFP_KERNEL);

			peer->flags |= SKW_PEER_FLAG_DEAUTHED;
		}
	}

	atomic_set(&iface->actived_ctx, 0);
#endif

	return 0;
}

static void
skw_recovery_sap_flush_sta(struct wiphy *wiphy, struct skw_recovery_data *rd,
			struct skw_iface *iface, u8 subtype, u16 reason)
{
	int idx, ret;
	u8 addr[ETH_ALEN];
	struct skw_peer *peer;
	struct skw_core *skw = wiphy_priv(wiphy);
	u32 peer_map = rd->iface[iface->id].peer_map;

	while (peer_map) {
		if (test_bit(SKW_FLAG_FW_ASSERT, &skw->flags))
			break;

		idx = ffs(peer_map) - 1;
		SKW_CLEAR(peer_map, BIT(idx));

		peer = rd->peer[idx];
		if (!peer || peer->flags & SKW_PEER_FLAG_DEAUTHED)
			continue;

		peer->flags |= SKW_PEER_FLAG_DEAUTHED;
		skw_mlme_ap_remove_client(iface, peer->addr);
		skw_del_sta_event(iface, peer->addr, SKW_LEAVE);
	}

	memset(addr, 0xff, ETH_ALEN);
	ret = skw_cmd_del_sta(wiphy, iface->ndev, addr, subtype, reason, true);
	if (ret)
		skw_warn("failed, sta: %pM, ret: %d\n", addr, ret);
}

static int skw_recovery_sap(struct wiphy *wiphy, struct skw_recovery_data *rd,
			struct skw_iface *iface)
{
	int ret, size;
	struct skw_startap_param *param;
	struct net_device *ndev = iface->ndev;

	ret = skw_set_mib(wiphy, iface->ndev);
	if (ret) {
		skw_err("set tlv failed, ret: %d\n", ret);
		return ret;
	}

	param = rd->iface[iface->id].param;
	if (!param) {
		skw_err("invalid param\n");
		return -EINVAL;
	}

	size = rd->iface[iface->id].size;

	ret = skw_send_msg(wiphy, ndev, SKW_CMD_START_AP, param, size, NULL, 0);
	if (ret) {
		skw_err("failed, ret: %d\n", ret);
		return ret;
	}

	// TODO:
	// bind lmac
	skw_lmac_bind_iface(iface->skw, iface, 0);

	skw_dpd_set_coeff_params(wiphy, ndev, param->chan, param->center_chn1,
				 param->center_chn2, param->chan_width);

	skw_recovery_sap_flush_sta(wiphy, rd, iface, 12, SKW_LEAVE);

	return 0;
}

static int skw_recovery_ibss(struct wiphy *wiphy, struct skw_iface *iface)
{
	return 0;
}

static int skw_recovery_p2p_dev(struct wiphy *wiphy, struct skw_iface *iface)
{
	skw_dbg("done\n");

	return 0;
}

static void
skw_recovery_prepare(struct skw_core *skw, struct skw_recovery_data *rd)
{
	int i, j;
	struct skw_peer_ctx *ctx;
	struct skw_iface *iface;

	skw->cmd.seq = 0;
	skw->skw_event_sn = 0;

	if (test_and_set_bit(SKW_FLAG_FW_CHIP_RECOVERY, &skw->flags)) {
		skw_info("received recovery event during recovery");
		return;
	}

	mutex_lock(&rd->lock);

	for (i = 0; i < SKW_MAX_PEER_SUPPORT; i++) {
		ctx = &skw->peer_ctx[i];

		skw_peer_ctx_lock(ctx);

		rcu_assign_pointer(ctx->entry, NULL);
		rd->peer[i] = ctx->peer;
		ctx->peer = NULL;

		skw_peer_ctx_unlock(ctx);
	}

	spin_lock_bh(&skw->vif.lock);

	for (i = 0; i < SKW_NR_IFACE; i++) {
		iface = skw->vif.iface[i];
		if (!iface)
			continue;

		for (j = 0; j <= SKW_WMM_AC_MAX; j++) {
			skb_queue_purge(&iface->txq[j]);
			skb_queue_purge(&iface->tx_cache[j]);
		}

		rd->iface[i].peer_map = atomic_read(&iface->peer_map);
		atomic_set(&iface->peer_map, 0);
	}

	spin_unlock_bh(&skw->vif.lock);

	mutex_unlock(&rd->lock);
}

static void skw_recovery_work(struct work_struct *wk)
{
	int i, ret;
	struct skw_chip_info chip;
	struct skw_core *skw = container_of(wk, struct skw_core, recovery_work);
	struct wiphy *wiphy = priv_to_wiphy(skw);
	struct skw_recovery_data *rd = &skw->recovery_data;

	skw_dbg("start\n");

	skw_recovery_prepare(skw, rd);

	skw_wifi_enable();

	ret = skw_register_rx_callback(skw, skw_rx_cb, skw, skw_rx_cb, skw);
	if (ret < 0)
		skw_err("register rx callback failed, ret: %d\n", ret);

	skw_hw_xmit_init(skw, skw->hw.dma);

	clear_bit(SKW_FLAG_FW_ASSERT, &skw->flags);
	clear_bit(SKW_FLAG_BLOCK_TX, &skw->flags);
	clear_bit(SKW_FLAG_FW_MAC_RECOVERY, &skw->flags);
	clear_bit(SKW_FLAG_FW_THERMAL, &skw->flags);

	skw_sync_cmd_event_version(wiphy);

	ret = skw_sync_chip_info(wiphy, &chip);
	if (ret)
		skw_err("sync chip info failed, ret: %d\n", ret);

	ret = skw_calib_download(wiphy, skw->fw.calib_file);
	if (ret)
		skw_err("calib download failed, ret: %d\n", ret);

	for (i = 0; i < SKW_NR_IFACE; i++) {
		struct skw_iface *iface = skw->vif.iface[i];

		if (!iface)
			continue;

		if (test_bit(SKW_FLAG_FW_ASSERT, &skw->flags))
			break;

		skw_info("%s: inst: %d\n",
			 skw_iftype_name(iface->wdev.iftype), i);

		ret = skw_cmd_open_dev(wiphy, iface->id, iface->addr,
				iface->wdev.iftype, 0);
		if (ret) {
			skw_err("open %s failed, inst: %d, ret: %d\n",
				skw_iftype_name(iface->wdev.iftype),
				iface->id, ret);

			skw_hw_assert(skw, false);

			break;
		}

		mutex_lock(&rd->lock);

		switch (iface->wdev.iftype) {
		case NL80211_IFTYPE_STATION:
			if (iface->flags & SKW_IFACE_FLAG_LEGACY_P2P_DEV) {
				skw_recovery_p2p_dev(wiphy, iface);
				break;
			}

			skw_fallthrough;

		case NL80211_IFTYPE_P2P_CLIENT:
			skw_recovery_sta(wiphy, rd, iface);
			break;

		case NL80211_IFTYPE_AP:
		case NL80211_IFTYPE_P2P_GO:
			skw_recovery_sap(wiphy, rd, iface);
			break;

		case NL80211_IFTYPE_ADHOC:
			skw_recovery_ibss(wiphy, iface);
			break;

		case NL80211_IFTYPE_P2P_DEVICE:
			skw_recovery_p2p_dev(wiphy, iface);
			break;

		default:
			break;
		}

		mutex_unlock(&rd->lock);
	}

	if (!ret) {
		for (i = 0; i < SKW_MAX_PEER_SUPPORT; i++) {
			skw_peer_free(rd->peer[i]);
			rd->peer[i] = NULL;
		}

		clear_bit(SKW_FLAG_FW_CHIP_RECOVERY, &skw->flags);
	}
}

void skw_recovery_del_peer(struct skw_iface *iface, u8 peer_idx)
{
	struct skw_recovery_data *rd = &iface->skw->recovery_data;

	if (!test_bit(SKW_FLAG_FW_CHIP_RECOVERY, &iface->skw->flags))
		return;

	mutex_lock(&rd->lock);

	if (rd->peer[peer_idx])
		rd->peer[peer_idx]->flags |= SKW_PEER_FLAG_DEAUTHED;

	mutex_unlock(&rd->lock);
}

int skw_recovery_data_update(struct skw_iface *iface, void *param, int len)
{
	void *data;
	struct skw_recovery_data *rd = &iface->skw->recovery_data;

	if (!param)
		return 0;

	data = SKW_ZALLOC(SKW_2K_SIZE, GFP_KERNEL);
	if (!data)
		return -ENOMEM;

	memcpy(data, param, len);

	mutex_lock(&rd->lock);

	SKW_KFREE(rd->iface[iface->id].param);

	rd->iface[iface->id].param = data;
	rd->iface[iface->id].size = len;

	mutex_unlock(&rd->lock);

	return 0;
}

void skw_recovery_data_clear(struct skw_iface *iface)
{
	struct skw_recovery_data *rd = &iface->skw->recovery_data;

	mutex_lock(&rd->lock);

	rd->iface[iface->id].size = 0;
	rd->iface[iface->id].peer_map = 0;
	SKW_KFREE(rd->iface[iface->id].param);

	mutex_unlock(&rd->lock);
}

int skw_recovery_init(struct skw_core *skw)
{
	mutex_init(&skw->recovery_data.lock);
	INIT_WORK(&skw->recovery_work, skw_recovery_work);

	return 0;
}

void skw_recovery_deinit(struct skw_core *skw)
{
	int i;
	struct skw_recovery_data *rd = &skw->recovery_data;

	mutex_lock(&rd->lock);

	cancel_work_sync(&skw->recovery_work);

	for (i = 0; i < SKW_NR_IFACE; i++)
		SKW_KFREE(rd->iface[i].param);

	for (i = 0; i < SKW_MAX_PEER_SUPPORT; i++) {
		skw_peer_free(rd->peer[i]);
		rd->peer[i] = NULL;
	}

	mutex_unlock(&rd->lock);
}
===== ./drivers/skwifi/skw_dentry.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <generated/utsrelease.h>
#include "skw_core.h"
#include "skw_dentry.h"
#include "skw_compat.h"
#include "version.h"

static struct dentry *skw_debugfs_root;
static struct proc_dir_entry *skw_proc_root;

static int skw_proc_show(struct seq_file *seq, void *v)
{
#define SKW_CONFIG_INT(conf)                                          \
	do {                                                          \
		seq_printf(seq, "%s=%d\n", #conf, conf);              \
	} while (0)

#define SKW_CONFIG_BOOL(conf)                                         \
	do {                                                          \
		if (IS_ENABLED(conf))                                 \
			seq_printf(seq, "%s=y\n", #conf);             \
		else                                                  \
			seq_printf(seq, "# %s is not set\n", #conf);  \
	} while (0)

#define SKW_CONFIG_STRING(conf)                                       \
	do {                                                          \
		seq_printf(seq, "%s=\"%s\"\n", #conf, conf);          \
	} while (0)

	seq_puts(seq, "\n");
	seq_printf(seq, "Kernel Version:  \t%s\n"
			"Wi-Fi Driver:    \t%s\n"
			"Wi-Fi Branch:    \t%s\n",
			UTS_RELEASE,
			SKW_VERSION,
			SKW_BRANCH);

	seq_puts(seq, "\n");

	SKW_CONFIG_BOOL(CONFIG_SKW_STA_SME_EXT);
	SKW_CONFIG_BOOL(CONFIG_SKW_SAP_SME_EXT);
	SKW_CONFIG_BOOL(CONFIG_SKW_SCAN_RANDOM_MAC);
	SKW_CONFIG_BOOL(CONFIG_SKW_LEGACY_P2P);
	SKW_CONFIG_BOOL(CONFIG_SKW_TX_WORKQUEUE);
	SKW_CONFIG_BOOL(CONFIG_SKW_REPEATER_MODE);
	SKW_CONFIG_BOOL(CONFIG_SKW_HIGH_PRIORITY);
	SKW_CONFIG_BOOL(CONFIG_SKW_VENDOR);
	SKW_CONFIG_BOOL(CONFIG_SKW_REGD_SELF_MANAGED);
	SKW_CONFIG_BOOL(CONFIG_SKW_TDLS);
	SKW_CONFIG_BOOL(CONFIG_SKW_DFS_MASTER);
	SKW_CONFIG_BOOL(CONFIG_SKW_EDMA);
	SKW_CONFIG_BOOL(CONFIG_SKW_OFFCHAN_TX);
	SKW_CONFIG_BOOL(CONFIG_SKW_CALIB_DPD);
	SKW_CONFIG_BOOL(CONFIG_SKW_CALIB_APPEND_BUS_ID);
	SKW_CONFIG_BOOL(CONFIG_SKW_LOG_ERROR);
	SKW_CONFIG_BOOL(CONFIG_SKW_LOG_WARN);
	SKW_CONFIG_BOOL(CONFIG_SKW_LOG_INFO);
	SKW_CONFIG_BOOL(CONFIG_SKW_LOG_DEBUG);
	SKW_CONFIG_BOOL(CONFIG_SKW_LOG_DETAIL);
	SKW_CONFIG_BOOL(CONFIG_SKW_SKB_RECYCLE);
	SKW_CONFIG_INT(CONFIG_SKW_RX_REORDER_TIMEOUT);

	SKW_CONFIG_STRING(CONFIG_SKW_PROJECT_NAME);
	SKW_CONFIG_STRING(CONFIG_SKW_DEFAULT_COUNTRY);
	SKW_CONFIG_STRING(CONFIG_SKW_CHIP_ID);

	seq_puts(seq, "\n");

	return 0;
}

static int skw_proc_open(struct inode *inode, struct file *file)
{
	return single_open(file, skw_proc_show, NULL);
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
static const struct proc_ops skw_proc_fops = {
	.proc_open = skw_proc_open,
	.proc_read = seq_read,
	.proc_lseek = seq_lseek,
	.proc_release = single_release,
};
#else
static const struct file_operations skw_proc_fops = {
	.open = skw_proc_open,
	.read = seq_read,
	.llseek = seq_lseek,
	.release = single_release,
};
#endif

struct dentry *skw_debugfs_subdir(const char *name, struct dentry *parent)
{
	struct dentry *de, *pentry;

	pentry = parent ? parent : skw_debugfs_root;
	if (!pentry)
		return NULL;

	de = debugfs_create_dir(name, pentry);

	return IS_ERR(de) ? NULL : de;
}

struct dentry *skw_debugfs_file(struct dentry *parent,
				const char *name, umode_t mode,
				const struct file_operations *fops, void *data)
{
	struct dentry *de, *pentry;

	pentry = parent ? parent : skw_debugfs_root;
	if (!pentry)
		return NULL;

	de = debugfs_create_file(name, mode, pentry, data, fops);

	return IS_ERR(de) ? NULL : de;
}

struct proc_dir_entry *skw_procfs_subdir(const char *name,
				struct proc_dir_entry *parent)
{
	struct proc_dir_entry *dentry = parent ? parent : skw_proc_root;

	if (!dentry)
		return NULL;

	return proc_mkdir_data(name, 0, dentry, NULL);
}

struct proc_dir_entry *skw_procfs_file(struct proc_dir_entry *parent,
				       const char *name, umode_t mode,
				       const void *fops, void *data)
{
	struct proc_dir_entry *dentry = parent ? parent : skw_proc_root;

	if (!dentry)
		return NULL;

	return proc_create_data(name, mode, dentry, fops, data);
}

int skw_dentry_init(void)
{
	skw_proc_root = proc_mkdir("skwifi", NULL);
	if (!skw_proc_root)
		pr_err("creat proc skwifi failed\n");

	skw_procfs_file(skw_proc_root, "profile", 0, &skw_proc_fops, NULL);

	skw_debugfs_root = debugfs_create_dir("skwifi", NULL);
	if (IS_ERR(skw_debugfs_root))
		skw_debugfs_root = NULL;

	return 0;
}

void skw_dentry_deinit(void)
{
	debugfs_remove_recursive(skw_debugfs_root);
	proc_remove(skw_proc_root);
}
===== ./drivers/skwifi/trace.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/module.h>

#ifndef __CHECKER__
#include <linux/ieee80211.h>
#include <linux/nl80211.h>
#include <net/cfg80211.h>

#define CREATE_TRACE_POINTS
#include "trace.h"

#endif
===== ./drivers/skwifi/skw_cfg80211.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/ieee80211.h>
#include <net/cfg80211.h>
#include <linux/inetdevice.h>
#include <net/addrconf.h>
#include <linux/if_tunnel.h>

#include "skw_core.h"
#include "skw_iface.h"
#include "skw_msg.h"
#include "skw_cfg80211.h"
#include "skw_regd.h"
#include "skw_mlme.h"
#include "skw_timer.h"
#include "skw_work.h"
#include "skw_tdls.h"
#include "skw_calib.h"
#include "skw_recovery.h"
#include "skw_dfs.h"

#define SKW_BIT_ULL(nr)        (1ULL << (nr))

int to_skw_bw(enum nl80211_chan_width bw)
{
	switch (bw) {
	case NL80211_CHAN_WIDTH_20:
	case NL80211_CHAN_WIDTH_20_NOHT:
		return SKW_CHAN_WIDTH_20;

	case NL80211_CHAN_WIDTH_40:
		return SKW_CHAN_WIDTH_40;

	case NL80211_CHAN_WIDTH_80:
		return SKW_CHAN_WIDTH_80;

	case NL80211_CHAN_WIDTH_80P80:
		return SKW_CHAN_WIDTH_80P80;

	case NL80211_CHAN_WIDTH_160:
		return SKW_CHAN_WIDTH_160;

	default:
		break;
	}

	return SKW_CHAN_WIDTH_MAX;
}

static int to_skw_gtk(u8 key_index)
{
	switch (key_index) {
	case 0 ... 3:
		return SKW_KEY_TYPE_GTK;
	case 4 ... 5:
		return SKW_KEY_TYPE_IGTK;
	case 6:
		return SKW_KEY_TYPE_BIGTK;
	default:
		break;
	}

	return SKW_KEY_TYPE_GTK;
}

static int to_skw_cipher_type(u32 cipher)
{
#define SKW_CASE_CIPHER_TYPE(c)                        \
	{                                              \
		case SKW_CIPHER_SUITE_##c:             \
			return SKW_CIPHER_TYPE_##c;    \
	}

	switch (cipher) {
	SKW_CASE_CIPHER_TYPE(WEP40);
	SKW_CASE_CIPHER_TYPE(WEP104);
	SKW_CASE_CIPHER_TYPE(SMS4);
	SKW_CASE_CIPHER_TYPE(TKIP);
	SKW_CASE_CIPHER_TYPE(CCMP);
	SKW_CASE_CIPHER_TYPE(CCMP_256);
	SKW_CASE_CIPHER_TYPE(AES_CMAC);
	SKW_CASE_CIPHER_TYPE(BIP_CMAC_256);
	SKW_CASE_CIPHER_TYPE(BIP_GMAC_128);
	SKW_CASE_CIPHER_TYPE(BIP_GMAC_256);
	SKW_CASE_CIPHER_TYPE(GCMP);
	SKW_CASE_CIPHER_TYPE(GCMP_256);

	default:
		break;
	}
#undef SKW_CASE_CIPHER_TYPE

	return SKW_CIPHER_TYPE_INVALID;
}

static const struct ieee80211_iface_limit skw_iface_limits[] = {
	{
		.max = 1,
		.types = BIT(NL80211_IFTYPE_STATION),
	},
	{
		.max = 1,
		.types = BIT(NL80211_IFTYPE_AP),
	},
	{
		.max = 1,
		.types = BIT(NL80211_IFTYPE_P2P_GO) |
			 BIT(NL80211_IFTYPE_P2P_CLIENT),
	},
};

static const struct ieee80211_iface_limit skw_iface_limits_change[] = {
	{
		.max = 3,
		.types = BIT(NL80211_IFTYPE_STATION),
	},
	{
		.max = 1,
		.types = BIT(NL80211_IFTYPE_AP)     |
			 BIT(NL80211_IFTYPE_P2P_GO) |
			 BIT(NL80211_IFTYPE_P2P_CLIENT),
	},
};

static const struct ieee80211_iface_limit skw_iface_limits_aps[] = {
	{
		.max = 1,
		.types = BIT(NL80211_IFTYPE_STATION) |
			 BIT(NL80211_IFTYPE_P2P_CLIENT),
	},
	{
		.max = 2,
		.types = BIT(NL80211_IFTYPE_AP),
	},
};

static const struct ieee80211_iface_limit skw_iface_limits_monitor[] = {
	{
		.max = 2,
		.types = BIT(NL80211_IFTYPE_MONITOR),
	},
};

#ifdef CONFIG_SKW_DFS_MASTER
static const struct ieee80211_iface_limit skw_iface_limits_dfs[] = {
	{
		.max = 1,
		.types = BIT(NL80211_IFTYPE_STATION),
	},
	{
		.max = 1,
		.types = BIT(NL80211_IFTYPE_AP),
	},
};

static const struct ieee80211_iface_limit skw_iface_limits_dfs_change[] = {
	{
		.max = 2,
		.types = BIT(NL80211_IFTYPE_STATION),
	},
};
#endif

static const struct ieee80211_iface_combination skw_iface_combos[] = {
	{
		.max_interfaces = 3,
		.num_different_channels = 2,
		.limits = skw_iface_limits,
		.n_limits = ARRAY_SIZE(skw_iface_limits),
	},
	{
		.max_interfaces = 3,
		.num_different_channels = 2,
		.limits = skw_iface_limits_change,
		.n_limits = ARRAY_SIZE(skw_iface_limits_change),
	},
	{
		.max_interfaces = 3,
		.num_different_channels = 1,
		.limits = skw_iface_limits_aps,
		.n_limits = ARRAY_SIZE(skw_iface_limits_aps),
	},
	{
		.max_interfaces = 2,
		.num_different_channels = 1,
		.limits = skw_iface_limits_monitor,
		.n_limits = ARRAY_SIZE(skw_iface_limits_monitor),
	},
#ifdef CONFIG_SKW_DFS_MASTER
	{
		.max_interfaces = 2,
		.num_different_channels = 1,
		.limits = skw_iface_limits_dfs,
		.n_limits = ARRAY_SIZE(skw_iface_limits_dfs),
		.radar_detect_widths = BIT(NL80211_CHAN_WIDTH_20_NOHT) |
				       BIT(NL80211_CHAN_WIDTH_20) |
				       BIT(NL80211_CHAN_WIDTH_40) |
				       BIT(NL80211_CHAN_WIDTH_80),
	},
	{
		.max_interfaces = 2,
		.num_different_channels = 1,
		.limits = skw_iface_limits_dfs_change,
		.n_limits = ARRAY_SIZE(skw_iface_limits_dfs_change),
		.radar_detect_widths = BIT(NL80211_CHAN_WIDTH_20_NOHT) |
				       BIT(NL80211_CHAN_WIDTH_20) |
				       BIT(NL80211_CHAN_WIDTH_40) |
				       BIT(NL80211_CHAN_WIDTH_80),
	},
#endif
};

static const struct
ieee80211_txrx_stypes skw_mgmt_stypes[NUM_NL80211_IFTYPES] = {
	[NL80211_IFTYPE_ADHOC] = {
		.tx = 0xffff,
		.rx = BIT(IEEE80211_STYPE_ACTION >> 4) |
			BIT(IEEE80211_STYPE_AUTH >> 4) |
			BIT(IEEE80211_STYPE_DEAUTH >> 4) |
			BIT(IEEE80211_STYPE_PROBE_REQ >> 4),
	},
	[NL80211_IFTYPE_STATION] = {
		.tx = 0xffff,
		.rx = BIT(IEEE80211_STYPE_ACTION >> 4) |
			BIT(IEEE80211_STYPE_PROBE_REQ >> 4) |
			BIT(IEEE80211_STYPE_AUTH >> 4),
	},
	[NL80211_IFTYPE_AP] = {
		.tx = 0xffff,
		.rx = BIT(IEEE80211_STYPE_ASSOC_REQ >> 4) |
			BIT(IEEE80211_STYPE_REASSOC_REQ >> 4) |
			BIT(IEEE80211_STYPE_PROBE_REQ >> 4) |
			BIT(IEEE80211_STYPE_DISASSOC >> 4) |
			BIT(IEEE80211_STYPE_AUTH >> 4) |
			BIT(IEEE80211_STYPE_DEAUTH >> 4) |
			BIT(IEEE80211_STYPE_ACTION >> 4),
	},
	[NL80211_IFTYPE_P2P_CLIENT] = {
		.tx = 0xffff,
		.rx = BIT(IEEE80211_STYPE_ACTION >> 4) |
			BIT(IEEE80211_STYPE_PROBE_REQ >> 4),
	},
	[NL80211_IFTYPE_P2P_GO] = {
		.tx = 0xffff,
		.rx = BIT(IEEE80211_STYPE_ASSOC_REQ >> 4) |
			BIT(IEEE80211_STYPE_REASSOC_REQ >> 4) |
			BIT(IEEE80211_STYPE_PROBE_REQ >> 4) |
			BIT(IEEE80211_STYPE_DISASSOC >> 4) |
			BIT(IEEE80211_STYPE_AUTH >> 4) |
			BIT(IEEE80211_STYPE_DEAUTH >> 4) |
			BIT(IEEE80211_STYPE_ACTION >> 4),
	},
	[NL80211_IFTYPE_P2P_DEVICE] = {
		.tx = 0xffff,
		.rx = BIT(IEEE80211_STYPE_ACTION >> 4) |
			BIT(IEEE80211_STYPE_PROBE_REQ >> 4),
	},
};

#define SKW_CHAN2G(_channel, _freq, _flags) {		\
	.band			= NL80211_BAND_2GHZ,	\
	.center_freq		= (_freq),		\
	.hw_value		= (_channel),		\
	.flags			= (_flags),		\
	.max_antenna_gain	= 0,			\
	.max_power		= 30,			\
}

static struct ieee80211_channel skw_2ghz_chan[] = {
	SKW_CHAN2G(1, 2412, 0),
	SKW_CHAN2G(2, 2417, 0),
	SKW_CHAN2G(3, 2422, 0),
	SKW_CHAN2G(4, 2427, 0),
	SKW_CHAN2G(5, 2432, 0),
	SKW_CHAN2G(6, 2437, 0),
	SKW_CHAN2G(7, 2442, 0),
	SKW_CHAN2G(8, 2447, 0),
	SKW_CHAN2G(9, 2452, 0),
	SKW_CHAN2G(10, 2457, 0),
	SKW_CHAN2G(11, 2462, 0),
	SKW_CHAN2G(12, 2467, 0),
	SKW_CHAN2G(13, 2472, 0),
	SKW_CHAN2G(14, 2484, 0),
};

#undef SKW_CHAN2G

#define SKW_CHAN5G(_channel, _flags) {			    \
	.band			= NL80211_BAND_5GHZ,	    \
	.center_freq		= 5000 + (5 * (_channel)),  \
	.hw_value		= (_channel),		    \
	.flags			= (_flags),		    \
	.max_antenna_gain	= 0,			    \
	.max_power		= 30,			    \
}

static struct ieee80211_channel skw_5ghz_chan[] = {
	SKW_CHAN5G(36, 0),
	SKW_CHAN5G(40, 0),
	SKW_CHAN5G(44, 0),
	SKW_CHAN5G(48, 0),
	SKW_CHAN5G(52, 0),
	SKW_CHAN5G(56, 0),
	SKW_CHAN5G(60, 0),
	SKW_CHAN5G(64, 0),
	SKW_CHAN5G(100, 0),
	SKW_CHAN5G(104, 0),
	SKW_CHAN5G(108, 0),
	SKW_CHAN5G(112, 0),
	SKW_CHAN5G(116, 0),
	SKW_CHAN5G(120, 0),
	SKW_CHAN5G(124, 0),
	SKW_CHAN5G(128, 0),
	SKW_CHAN5G(132, 0),
	SKW_CHAN5G(136, 0),
	SKW_CHAN5G(140, 0),
	SKW_CHAN5G(144, 0),
	SKW_CHAN5G(149, 0),
	SKW_CHAN5G(153, 0),
	SKW_CHAN5G(157, 0),
	SKW_CHAN5G(161, 0),
	SKW_CHAN5G(165, 0),
};

#undef SKW_CHAN5G

#define SKW_RATETAB_ENT(_rate, _rateid, _flags)     \
{                                                   \
	.bitrate        = (_rate),                  \
	.hw_value       = (_rateid),                \
	.flags          = (_flags),                 \
}

static struct ieee80211_rate skw_rates[] = {
	SKW_RATETAB_ENT(10, 0x1, 0),
	SKW_RATETAB_ENT(20, 0x2, 0),
	SKW_RATETAB_ENT(55, 0x5, 0),
	SKW_RATETAB_ENT(110, 0xb, 0),
	SKW_RATETAB_ENT(60, 0x6, 0),
	SKW_RATETAB_ENT(90, 0x9, 0),
	SKW_RATETAB_ENT(120, 0xc, 0),
	SKW_RATETAB_ENT(180, 0x12, 0),
	SKW_RATETAB_ENT(240, 0x18, 0),
	SKW_RATETAB_ENT(360, 0x24, 0),
	SKW_RATETAB_ENT(480, 0x30, 0),
	SKW_RATETAB_ENT(540, 0x36, 0),
};

#undef SKW_RATETAB_ENT

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 19, 0)
static const struct ieee80211_sband_iftype_data skw_he_capa_2ghz = {
	.types_mask = BIT(NL80211_IFTYPE_STATION) | BIT(NL80211_IFTYPE_AP),
	.he_cap = {
		.has_he = true,
		.he_cap_elem = {
			.mac_cap_info[0] = SKW_HE_MAC_CAP0_HTC_HE,
			.mac_cap_info[1] = SKW_HE_MAC_CAP1_TF_MAC_PAD_DUR_16US |
				SKW_HE_MAC_CAP1_MULTI_TID_AGG_RX_QOS_8,
			.mac_cap_info[2] = SKW_HE_MAC_CAP2_BSR |
				SKW_HE_MAC_CAP2_MU_CASCADING |
				SKW_HE_MAC_CAP2_ACK_EN,
			.mac_cap_info[3] = SKW_HE_MAC_CAP3_OMI_CONTROL |
				SKW_HE_MAC_CAP3_GRP_ADDR_MULTI_STA_BA_DL_MU |
				SKW_HE_MAC_CAP3_MAX_AMPDU_LEN_EXP_VHT_2,
			.mac_cap_info[4] = SKW_HE_MAC_CAP4_AMDSU_IN_AMPDU,
			.phy_cap_info[0] = SKW_HE_PHY_CAP0_DUAL_BAND |
				SKW_HE_PHY_CAP0_CHANNEL_WIDTH_SET_40MHZ_IN_2G,
			.phy_cap_info[1] = SKW_HE_PHY_CAP1_DEVICE_CLASS_A |
				SKW_HE_PHY_CAP1_PREAMBLE_PUNC_RX_MASK |
				SKW_HE_PHY_CAP1_LDPC_CODING_IN_PAYLOAD |
				SKW_HE_PHY_CAP1_MIDAMBLE_RX_TX_MAX_NSTS,
			.phy_cap_info[2] = SKW_HE_PHY_CAP2_UL_MU_FULL_MU_MIMO |
				SKW_HE_PHY_CAP2_NDP_4x_LTF_AND_3_2US |
				SKW_HE_PHY_CAP2_STBC_TX_UNDER_80MHZ |
				SKW_HE_PHY_CAP2_STBC_RX_UNDER_80MHZ |
				SKW_HE_PHY_CAP2_UL_MU_PARTIAL_MU_MIMO,
		},
		.he_mcs_nss_supp = {
			.rx_mcs_80 = cpu_to_le16(0xfffa),
			.tx_mcs_80 = cpu_to_le16(0xfffa),
			.rx_mcs_160 = cpu_to_le16(0xffff),
			.tx_mcs_160 = cpu_to_le16(0xffff),
			.rx_mcs_80p80 = cpu_to_le16(0xffff),
			.tx_mcs_80p80 = cpu_to_le16(0xffff),
		},
	},
};

static const struct ieee80211_sband_iftype_data skw_he_capa_5ghz = {
	.types_mask = BIT(NL80211_IFTYPE_STATION) | BIT(NL80211_IFTYPE_AP),
	.he_cap = {
		.has_he = true,
		.he_cap_elem = {
			.mac_cap_info[0] = SKW_HE_MAC_CAP0_HTC_HE,
			.mac_cap_info[1] = SKW_HE_MAC_CAP1_TF_MAC_PAD_DUR_16US |
				SKW_HE_MAC_CAP1_MULTI_TID_AGG_RX_QOS_8,
			.mac_cap_info[2] = SKW_HE_MAC_CAP2_BSR |
				SKW_HE_MAC_CAP2_MU_CASCADING |
				SKW_HE_MAC_CAP2_ACK_EN,
			.mac_cap_info[3] = SKW_HE_MAC_CAP3_OMI_CONTROL |
				SKW_HE_MAC_CAP3_GRP_ADDR_MULTI_STA_BA_DL_MU |
				SKW_HE_MAC_CAP3_MAX_AMPDU_LEN_EXP_VHT_2,
			.mac_cap_info[4] = SKW_HE_MAC_CAP4_AMDSU_IN_AMPDU,

			.phy_cap_info[0] = SKW_HE_PHY_CAP0_DUAL_BAND |
				SKW_HE_PHY_CAP0_CHANNEL_WIDTH_SET_40MHZ_80MHZ_IN_5G |
				SKW_HE_PHY_CAP0_CHANNEL_WIDTH_SET_80PLUS80_MHZ_IN_5G |
				SKW_HE_PHY_CAP0_CHANNEL_WIDTH_SET_160MHZ_IN_5G,
			.phy_cap_info[1] = SKW_HE_PHY_CAP1_DEVICE_CLASS_A |
				SKW_HE_PHY_CAP1_PREAMBLE_PUNC_RX_MASK |
				SKW_HE_PHY_CAP1_LDPC_CODING_IN_PAYLOAD |
				SKW_HE_PHY_CAP1_MIDAMBLE_RX_TX_MAX_NSTS,
			.phy_cap_info[2] = SKW_HE_PHY_CAP2_NDP_4x_LTF_AND_3_2US |
				SKW_HE_PHY_CAP2_STBC_TX_UNDER_80MHZ |
				SKW_HE_PHY_CAP2_STBC_RX_UNDER_80MHZ |
				SKW_HE_PHY_CAP2_UL_MU_FULL_MU_MIMO |
				SKW_HE_PHY_CAP2_UL_MU_PARTIAL_MU_MIMO,
		},
		.he_mcs_nss_supp = {
			.rx_mcs_80 = cpu_to_le16(0xfffa),
			.tx_mcs_80 = cpu_to_le16(0xfffa),
			.rx_mcs_160 = cpu_to_le16(0xfffa),
			.tx_mcs_160 = cpu_to_le16(0xfffa),
			.rx_mcs_80p80 = cpu_to_le16(0xfffa),
			.tx_mcs_80p80 = cpu_to_le16(0xfffa),
		},
	},
};

#endif

#define skw_a_rates       (skw_rates + 4)
#define skw_a_rates_size  8
#define skw_g_rates       (skw_rates + 0)
#define skw_g_rates_size  12

static struct ieee80211_supported_band skw_band_2ghz = {
	.channels = skw_2ghz_chan,
	.n_channels = ARRAY_SIZE(skw_2ghz_chan),
	.bitrates = skw_g_rates,
	.n_bitrates = skw_g_rates_size,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 19, 0)
	.n_iftype_data = 1,
	.iftype_data = &skw_he_capa_2ghz,
#endif
};

static struct ieee80211_supported_band skw_band_5ghz = {
	.channels = skw_5ghz_chan,
	.n_channels = ARRAY_SIZE(skw_5ghz_chan),
	.bitrates = skw_a_rates,
	.n_bitrates = skw_a_rates_size,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 19, 0)
	.n_iftype_data = 1,
	.iftype_data = &skw_he_capa_5ghz,
#endif
};

static const u32 skw_cipher_suites[] = {
	/* keep WEP first, it may be removed below */
	SKW_CIPHER_SUITE_WEP40,
	SKW_CIPHER_SUITE_TKIP,
	SKW_CIPHER_SUITE_CCMP,
	SKW_CIPHER_SUITE_WEP104,
	SKW_CIPHER_SUITE_AES_CMAC,
	SKW_CIPHER_SUITE_GCMP,

	SKW_CIPHER_SUITE_CCMP_256,
	SKW_CIPHER_SUITE_GCMP_256,
	SKW_CIPHER_SUITE_BIP_CMAC_256,
	SKW_CIPHER_SUITE_BIP_GMAC_128,
	SKW_CIPHER_SUITE_BIP_GMAC_256,

	SKW_CIPHER_SUITE_SMS4,
};

static inline void skw_iftype_dump(int iftype_num[NUM_NL80211_IFTYPES])
{
	int i;

	for (i = 0; i < NUM_NL80211_IFTYPES; i++) {
		if (iftype_num[i])
			skw_info("%s: %d\n", skw_iftype_name(i), iftype_num[i]);
	}
}

static void skw_count_iftype(struct wiphy *wiphy, int num[NUM_NL80211_IFTYPES])
{
	int i;
	struct skw_iface *iface;
	struct skw_core *skw = wiphy_priv(wiphy);

	spin_lock_bh(&skw->vif.lock);

	for (i = 0; i < SKW_NR_IFACE; i++) {
		iface = skw->vif.iface[i];
		if (!iface ||
		    (iface->flags & SKW_IFACE_FLAG_LEGACY_P2P_DEV) ||
		    (iface->wdev.iftype == NL80211_IFTYPE_P2P_DEVICE))
			continue;

		num[iface->wdev.iftype]++;
	}

	spin_unlock_bh(&skw->vif.lock);
}

static struct wireless_dev *
skw_add_virtual_intf(struct wiphy *wiphy, const char *name,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 2, 0)
		     unsigned char name_assign_type,
#endif
		     enum nl80211_iftype type,
#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 12, 0)
		     u32 *flags,
#endif
		     struct vif_params *params)
{
	int ret;
	struct skw_iface *iface;
	u8 vif_id = SKW_INVALID_ID;
	int iftype_num[NUM_NL80211_IFTYPES] = {0};

	skw_dbg("%s(%s), mac: %pM\n", name, skw_iftype_name(type),
		params->macaddr);

	skw_count_iftype(wiphy, iftype_num);
	ret = skw_compat_check_combs(wiphy, 0, 0, iftype_num);
	if (ret) {
		skw_err("check combinations failed, %s(%s)\n",
			name, skw_iftype_name(type));

		skw_iftype_dump(iftype_num);

		return ERR_PTR(-EINVAL);
	}

	if (type == NL80211_IFTYPE_P2P_DEVICE)
		vif_id = SKW_LAST_IFACE_ID;

	iface = skw_add_iface(wiphy, name, type, params->macaddr, vif_id,
				type != NL80211_IFTYPE_P2P_DEVICE);
	if (IS_ERR(iface)) {
		skw_err("failed, %ld\n", PTR_ERR(iface));
		return ERR_CAST(iface);
	}

	return &iface->wdev;
}

static int skw_del_virtual_intf(struct wiphy *wiphy, struct wireless_dev *wdev)
{
	struct skw_iface *iface = SKW_WDEV_TO_IFACE(wdev);

	skw_dbg("iftype: %d, iface id: %d\n", wdev->iftype, iface->id);

	return skw_del_iface(wiphy, iface);
}

static int skw_change_intf(struct wiphy *wiphy, struct net_device *dev,
			   enum nl80211_iftype type,
#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 12, 0)
			   u32 *flags,
#endif
			   struct vif_params *params)
{
	u8 *mac;
	int ret;
	int iftype_num[NUM_NL80211_IFTYPES] = {0};
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("%s (inst: %d), %s -> %s, mac: %pM, 4addr: %d, flags: 0x%x\n",
		netdev_name(dev), iface->id,
		skw_iftype_name(dev->ieee80211_ptr->iftype),
		skw_iftype_name(type), params->macaddr,
		params->use_4addr, iface->flags);

	if (iface->flags & SKW_IFACE_FLAG_LEGACY_P2P_DEV)
		iface->wdev.iftype = type;

	if (iface->wdev.iftype == type)
		return 0;

	skw_count_iftype(wiphy, iftype_num);
	iftype_num[type]++;
	iftype_num[iface->wdev.iftype]--;
	ret = skw_compat_check_combs(wiphy, 0, 0, iftype_num);
	if (ret) {
		skw_err("check combinations failed, %s(inst: %d), %s -> %s\n",
			netdev_name(dev), iface->id,
			skw_iftype_name(dev->ieee80211_ptr->iftype),
			skw_iftype_name(type));

		skw_iftype_dump(iftype_num);

		return ret;
	}

	if (iface->ndev)
		netif_tx_stop_all_queues(dev);

	ret = skw_iface_teardown(wiphy, iface);
	if (ret) {
		skw_err("teardown failed, %s (inst: %d), ret: %d\n",
			skw_iftype_name(iface->wdev.iftype), iface->id, ret);

		goto out;
	}

	if (is_valid_ether_addr(params->macaddr))
		mac = params->macaddr;
	else
		mac = (u8 *)wdev_address(dev->ieee80211_ptr);

	ret = skw_iface_setup(wiphy, dev, iface, mac, type, iface->id);
	if (ret) {
		skw_err("open dev failed, %s (inst: %d)\n",
			skw_iftype_name(type), iface->id);

		skw_iface_setup(wiphy, dev, iface, iface->addr,
				iface->wdev.iftype, iface->id);
	}

out:
	if (iface->ndev)
		netif_tx_start_all_queues(dev);

	return ret;
}

static int skw_get_key(struct wiphy *wiphy, struct net_device *netdev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
		int link_id,
#endif
		u8 key_index, bool pairwise, const u8 *mac_addr, void *cookie,
		void (*callback)(void *cookie, struct key_params *params))
{
	skw_dbg("dev: %s, key_index: %d, pairwise: %d, mac: %pM\n",
		netdev_name(netdev), key_index, pairwise, mac_addr);

	return 0;
}

static int skw_cmd_add_key(struct wiphy *wiphy, struct net_device *dev,
			   int cipher, u8 key_idx, int key_type,
			   const u8 *key, int key_len, const u8 *addr)
{
	struct skw_key_params params;
	struct skw_iface *iface = netdev_priv(dev);
	u8 wapi_tx_pn[] = {0x36, 0x5c, 0x36, 0x5c, 0x36, 0x5c};

	memset(&params, 0x0, sizeof(params));

	if (addr)
		skw_ether_copy(params.mac_addr, addr);
	else
		memset(params.mac_addr, 0xff, ETH_ALEN);

	memcpy(params.key, key, key_len);

	params.key_type = key_type;
	params.key_len = key_len;
	params.key_id = key_idx;
	params.cipher_type = cipher;
	params.pn[0] = 1;

	switch (cipher) {
	case SKW_CIPHER_TYPE_SMS4:
		memcpy(params.pn, wapi_tx_pn, SKW_PN_LEN);

		if (is_skw_ap_mode(iface))
			params.pn[0] += 1;

		break;

	case SKW_CIPHER_TYPE_TKIP:
		if (is_skw_ap_mode(iface))
			memcpy(&params.key[0], key, 32);
		else {
			memcpy(&params.key[0], key, 16);
			memcpy(&params.key[16], key + 24, 8);
			memcpy(&params.key[24], key + 16, 8);
		}

		break;

	default:
		break;
	}

	return skw_send_msg(wiphy, dev, SKW_CMD_ADD_KEY, &params,
			sizeof(params), NULL, 0);
}

static int skw_set_key(struct wiphy *wiphy, struct net_device *dev,
			struct skw_key_conf *conf, u8 key_idx, int key_type,
			const u8 *addr, struct key_params *params)
{
	int i, cipher, ret;
	struct skw_key *key, *old_key;

	cipher = to_skw_cipher_type(params->cipher);
	if (cipher == SKW_CIPHER_TYPE_INVALID) {
		skw_warn("cipher 0x%x unsupported\n", params->cipher);
		return -ENOTSUPP;
	}

	key = SKW_ZALLOC(sizeof(struct skw_key), GFP_KERNEL);
	if (!key)
		return -ENOMEM;

	key->key_len = params->key_len;
	memcpy(key->key_data, params->key, params->key_len);

	if (params->seq) {
		skw_hex_dump("seq", params->seq, params->seq_len, false);

		for (i = 1; i < IEEE80211_NUM_TIDS; i++)
			memcpy(key->rx_pn[i], params->seq, SKW_PN_LEN);
	}

	conf->skw_cipher = cipher;

	old_key = rcu_dereference_protected(conf->key[key_idx],
			lockdep_is_held(&conf->lock));

	rcu_assign_pointer(conf->key[key_idx], key);

	SKW_SET(conf->installed_bitmap, BIT(key_idx));

	if (old_key)
		kfree_rcu(old_key, rcu);

	if (cipher == SKW_CIPHER_TYPE_WEP40 ||
	    cipher == SKW_CIPHER_TYPE_WEP104) {
		SKW_SET(conf->flags, SKW_KEY_FLAG_WEP_SHARE);
		return 0;
	}

	ret = skw_cmd_add_key(wiphy, dev, cipher, key_idx, key_type,
			params->key, params->key_len, addr);
	if (ret) {
		RCU_INIT_POINTER(conf->key[key_idx], NULL);
		SKW_CLEAR(conf->installed_bitmap, BIT(key_idx));
		kfree_rcu(key, rcu);
	}

	return ret;
}

static int skw_add_key(struct wiphy *wiphy, struct net_device *dev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
		       int link_id,
#endif
		       u8 key_idx, bool pairwise, const u8 *addr,
		       struct key_params *params)
{
	const u8 *mac;
	int ret, key_type;
	struct skw_key_conf *conf;
	struct skw_peer_ctx *ctx;
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("%s, key_idx: %d, cipher: 0x%x, pairwise: %d, mac: %pM\n",
		netdev_name(dev), key_idx, params->cipher, pairwise, addr);

	key_type = pairwise ? SKW_KEY_TYPE_PTK : to_skw_gtk(key_idx);

	if (addr) {
		ctx = skw_peer_ctx(iface, addr);
		if (!ctx) {
			skw_warn("%pM not linked\n", addr);
			return -ENOLINK;
		}

		skw_peer_ctx_lock(ctx);

		if (!ctx->peer) {
			skw_peer_ctx_unlock(ctx);
			return 0;
		}

		if (pairwise)
			conf = &ctx->peer->ptk_conf;
		else
			conf = &ctx->peer->gtk_conf;

		mutex_lock(&conf->lock);

		ret = skw_set_key(wiphy, dev, conf, key_idx,
				  key_type, addr, params);

		mutex_unlock(&conf->lock);

		skw_peer_ctx_unlock(ctx);

	} else {
		if (is_skw_ap_mode(iface))
			mac = NULL;
		else
			mac = iface->sta.core.bss.bssid;

		conf = &iface->key_conf;

		mutex_lock(&conf->lock);

		ret = skw_set_key(wiphy, dev, conf, key_idx,
				  key_type, mac, params);

		mutex_unlock(&conf->lock);
	}

	if (ret)
		skw_err("failed, cipher: 0x%x, ptk: %d, idx: %d, ret: %d\n",
			params->cipher, pairwise, key_idx, ret);

	return ret;
}

static int __skw_add_key(struct wiphy *wiphy, struct net_device *dev,
			 int link_id, u8 key_idx, bool pairwise,
			 const u8 *addr, struct key_params *params)
{
	return skw_add_key(wiphy, dev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
			link_id,
#endif
			key_idx, pairwise, addr, params);
}

static int skw_cmd_del_key(struct wiphy *wiphy, struct net_device *dev,
			u8 key_idx, int key_type, int cipher, const u8 *addr)
{
	struct skw_key_params params;

	memset(&params, 0x0, sizeof(params));

	if (addr)
		skw_ether_copy(params.mac_addr, addr);
	else
		memset(params.mac_addr, 0xff, ETH_ALEN);

	params.key_type = key_type;
	params.cipher_type = cipher;
	params.key_id = key_idx;

	return skw_send_msg(wiphy, dev, SKW_CMD_DEL_KEY, &params,
			   sizeof(params), NULL, 0);
}

static int skw_remove_key(struct wiphy *wiphy, struct net_device *dev,
			struct skw_key_conf *conf, u8 key_idx,
			int key_type, const u8 *addr)
{
	int ret;
	struct skw_key *key;

	if (SKW_TEST(conf->installed_bitmap, BIT(key_idx))) {
		ret = skw_cmd_del_key(wiphy, dev, key_idx, key_type,
				conf->skw_cipher, addr);
		if (ret)
			skw_err("failed, ret: %d\n", ret);
	}

	key = rcu_dereference_protected(conf->key[key_idx],
			lockdep_is_held(&conf->lock));

	RCU_INIT_POINTER(conf->key[key_idx], NULL);

	SKW_CLEAR(conf->installed_bitmap, BIT(key_idx));

	if (SKW_TEST(conf->flags, SKW_KEY_FLAG_WEP_SHARE))
		SKW_CLEAR(conf->flags, SKW_KEY_FLAG_WEP_SHARE);

	if (key)
		kfree_rcu(key, rcu);

	return 0;
}

static int skw_del_key(struct wiphy *wiphy, struct net_device *dev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
			int link_id,
#endif
			u8 key_idx, bool pairwise, const u8 *addr)
{
	int ret, key_type;
	struct skw_key_conf *conf;
	const u8 *mac = NULL;
	struct skw_peer_ctx *ctx = NULL;
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("key_idx: %d, pairwise: %d, mac: %pM\n",
		key_idx, pairwise, addr);

	if (key_idx >= SKW_NUM_MAX_KEY) {
		skw_err("key index %d out of bounds\n", key_idx);
		return -EINVAL;
	}

	key_type = pairwise ? SKW_KEY_TYPE_PTK : to_skw_gtk(key_idx);

	if (addr) {
		ctx = skw_peer_ctx(iface, addr);
		if (!ctx)
			return 0;

		skw_peer_ctx_lock(ctx);

		if (!ctx->peer) {
			skw_peer_ctx_unlock(ctx);
			return 0;
		}

		if (pairwise)
			conf = &ctx->peer->ptk_conf;
		else
			conf = &ctx->peer->gtk_conf;

		mutex_lock(&conf->lock);

		ret = skw_remove_key(wiphy, dev, conf, key_idx, key_type, addr);

		mutex_unlock(&conf->lock);

		skw_peer_ctx_unlock(ctx);

	} else {
		conf = &iface->key_conf;

		if (is_skw_sta_mode(iface))
			mac = iface->sta.core.bss.bssid;

		mutex_lock(&conf->lock);

		ret = skw_remove_key(wiphy, dev, conf, key_idx, key_type, mac);

		mutex_unlock(&conf->lock);
	}

	return ret;
}

/* for WEP keys */
static int skw_set_default_key(struct wiphy *wiphy, struct net_device *dev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
			       int link_id,
#endif
			       u8 key_idx, bool unicast, bool multicast)
{
	int ret = 0, key_len;
	struct skw_key *key;
	const u8 *mac = NULL;
	u8 key_data[WLAN_MAX_KEY_LEN] = {0};
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_key_conf *conf = &iface->key_conf;

	skw_dbg("dev: %s, key_idx: %d, unicast: %d, multicast: %d\n",
		netdev_name(dev), key_idx, unicast, multicast);

	if (!(conf->installed_bitmap & BIT(key_idx)))
		return 0;

	if (is_skw_sta_mode(iface))
		mac = iface->sta.core.bss.bssid;

	rcu_read_lock();

	key = conf->key[key_idx];
	if (key) {
		memcpy(key_data, key->key_data, key->key_len);
		key_len = key->key_len;
	}

	rcu_read_unlock();

	if (!key)
		return 0;

	if (unicast)
		ret = skw_cmd_add_key(wiphy, dev, conf->skw_cipher,
				      key_idx, SKW_KEY_TYPE_PTK,
				      key_data, key_len, mac);

	if (!ret && multicast)
		ret = skw_cmd_add_key(wiphy, dev, conf->skw_cipher,
				      key_idx, SKW_KEY_TYPE_GTK,
				      key_data, key_len, mac);
	return ret;
}

static int __skw_set_default_key(struct wiphy *wiphy, struct net_device *dev,
			       int link_id, u8 key_idx, bool unicast,
			       bool multicast)
{
	return skw_set_default_key(wiphy, dev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
				link_id,
#endif
				key_idx, unicast, multicast);
}

/* for 11w */
static int skw_set_default_mgmt_key(struct wiphy *wiphy, struct net_device *netdev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
			int link_id,
#endif
			u8 key_index)
{
	skw_dbg("%s, key index: %d\n", netdev_name(netdev), key_index);
	return 0;
}

static int skw_set_mac_acl(struct wiphy *wiphy, struct net_device *dev,
			const struct cfg80211_acl_data *acl)
{
	int size;
	struct skw_iface *iface = netdev_priv(dev);

	if (!acl)
		return 0;

	skw_dbg("dev: %s, nr_entries: %d\n",
		netdev_name(dev), acl->n_acl_entries);

	if (!acl->n_acl_entries) {
		SKW_KFREE(iface->sap.acl);
		return 0;
	}

	size = acl->n_acl_entries * sizeof(struct mac_address);
	size += sizeof(struct cfg80211_acl_data);

	SKW_KFREE(iface->sap.acl);

	iface->sap.acl = SKW_ZALLOC(size, GFP_KERNEL);
	if (!iface->sap.acl)
		return -ENOMEM;

	memcpy(iface->sap.acl, acl, size);

	skw_queue_work(wiphy, netdev_priv(dev), SKW_WORK_ACL_CHECK, NULL, 0);

	return 0;
}

static bool skw_channel_allowed(struct wiphy *wiphy, u16 channel)
{
#define BITMAP_SIZE ((164 + BITS_PER_LONG) / BITS_PER_LONG)
	int i, nr_channel;
	struct skw_iface *iface;
	bool extra_chn = false;
	struct skw_core *skw = wiphy_priv(wiphy);
	int iftype_num[NUM_NL80211_IFTYPES] = {0};
	long channel_map[BITMAP_SIZE] = {0};

	spin_lock_bh(&skw->vif.lock);

	for (nr_channel = 0, i = 0; i < SKW_NR_IFACE; i++) {
		struct ieee80211_channel *chan = NULL;

		iface = skw->vif.iface[i];
		if (!iface)
			continue;

		switch (iface->wdev.iftype) {
		case NL80211_IFTYPE_AP:
		case NL80211_IFTYPE_P2P_GO:
			chan = iface->sap.cfg.channel;
			break;

		case NL80211_IFTYPE_STATION:
			if (atomic_read(&iface->actived_ctx) > 1)
				extra_chn = true;

			/* fall through */
			skw_fallthrough;
		case NL80211_IFTYPE_P2P_CLIENT:
			chan = iface->sta.core.bss.channel;
			break;

		default:
			break;
		}

		if (chan && !test_and_set_bit(chan->hw_value, channel_map))
			nr_channel++;
	}

	spin_unlock_bh(&skw->vif.lock);

	for (i = 0; extra_chn && (i < SKW_MAX_PEER_SUPPORT); i++) {
		struct skw_peer_ctx *ctx = &skw->peer_ctx[i];

		skw_peer_ctx_lock(ctx);

		if (ctx->peer && ctx->peer->channel &&
		    !test_and_set_bit(ctx->peer->channel, channel_map))
			nr_channel++;

		skw_peer_ctx_unlock(ctx);
	}

	if (!test_bit(channel, channel_map))
		nr_channel++;

	if (!skw_compat_check_combs(wiphy, nr_channel, 0, iftype_num))
		return true;

	skw_err("channel %d not allowed, total:%d\n", channel, nr_channel);
	skw_hex_dump("channels", channel_map, sizeof(channel_map), true);

	return false;
}

int skw_set_mib(struct wiphy *wiphy, struct net_device *dev)
{
	int ret = 0;
	u16 *plen;
	struct skw_tlv_conf conf;
	struct skw_iface *iface = netdev_priv(dev);
	u32 val_zero = 0;
	u32 val_one = 1;

	if (!iface->extend.wireless_mode)
		return 0;

	ret = skw_tlv_alloc(&conf, 512, GFP_KERNEL);
	if (ret)
		return ret;

	plen = skw_tlv_reserve(&conf, 2);

	switch (iface->extend.wireless_mode) {
	case SKW_WIRELESS_11G_ONLY:
		if (skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_HE, &val_zero, 4) ||
		    skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_VHT, &val_zero, 4) ||
		    skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_HT, &val_zero, 4) ||
		    skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_B, &val_zero, 4) ||
		    skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_A, &val_zero, 4) ||
		    skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_G, &val_one, 4)) {
			skw_err("set 11G mode failed\n");
			skw_tlv_free(&conf);
		}

		break;

	case SKW_WIRELESS_11N_ONLY:
		if (skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_HE, &val_zero, 4) ||
		    skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_VHT, &val_zero, 4) ||
		    skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_HT, &val_one, 4) ||
		    skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_B, &val_zero, 4) ||
		    skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_A, &val_zero, 4) ||
		    skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_G, &val_zero, 4)) {
			skw_err("set 11N mode failed\n");
			skw_tlv_free(&conf);
		}

		break;

	default:
		break;
	}

	if (conf.total_len) {
		*plen = conf.total_len;
		ret = skw_msg_xmit(wiphy, 0, SKW_CMD_SET_MIB, conf.buff,
				  conf.total_len, NULL, 0);
		if (ret)
			skw_err("failed, ret: %d\n", ret);
	}

	skw_tlv_free(&conf);

	return ret;
}

static int skw_start_ap(struct wiphy *wiphy, struct net_device *dev,
			struct cfg80211_ap_settings *settings)
{
	int ret, bw;
	int total, fixed, offset = 0;
	struct skw_startap_resp resp = {};
	struct skw_startap_param *param = NULL;
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_core *skw = wiphy_priv(wiphy);
	struct cfg80211_beacon_data *bcn = &settings->beacon;
	struct cfg80211_chan_def *chandef = &settings->chandef;

	skw_info("ndev: %s\n", netdev_name(dev));
	skw_dbg("       * ssid: %s\n", settings->ssid);
	skw_dbg("       * bssid: %pM\n", iface->addr);
	skw_dbg("       * channel: %d (BW: %d)\n", chandef->chan->hw_value, chandef->width);
	skw_dbg("       * auth type: %d\n", settings->auth_type);
	skw_dbg("       * akm_suites: %d\n", settings->crypto.n_akm_suites);

	if (!skw_channel_allowed(wiphy, chandef->chan->hw_value))
		return -ENOTSUPP;

	bw = to_skw_bw(settings->chandef.width);
	if (bw == SKW_CHAN_WIDTH_MAX) {
		skw_err("BW %d not support\n", settings->chandef.width);
		return -ENOTSUPP;
	}

	skw_set_mib(wiphy, dev);

	fixed = sizeof(struct skw_startap_param);
	total = fixed +
		bcn->head_len +
		bcn->tail_len +
		bcn->probe_resp_len;

	param = SKW_ZALLOC(total, GFP_KERNEL);
	if (!param) {
		skw_err("malloc failed, size: %d\n", total);
		return -ENOMEM;
	}

	param->chan_width = bw;
	param->chan = chandef->chan->hw_value;
	param->center_chn1 = skw_freq_to_chn(chandef->center_freq1);
	param->center_chn2 = skw_freq_to_chn(chandef->center_freq2);

	param->beacon_int = settings->beacon_interval;
	param->dtim_period = settings->dtim_period;
	param->ssid_len = settings->ssid_len;
	memcpy(param->ssid, settings->ssid, settings->ssid_len);

	if (settings->hidden_ssid)
		param->flags |= settings->hidden_ssid;

	if (bcn->head) {
		skw_hex_dump("beacon_head", bcn->head, bcn->head_len, false);

		param->beacon_head_len = bcn->head_len;
		param->beacon_head_offset = offset + fixed;

		memcpy(param->ies + offset, bcn->head, bcn->head_len);
		offset += bcn->head_len;
	}

	if (bcn->tail) {
		skw_hex_dump("beacon_tail", bcn->tail, bcn->tail_len, false);

		param->beacon_tail_offset = offset + fixed;
		param->beacon_tail_len = bcn->tail_len;

		memcpy(param->ies + offset, bcn->tail, bcn->tail_len);
		offset += bcn->tail_len;

		skw_iface_set_wmm_capa(iface, bcn->tail, bcn->tail_len);
	}

	if (bcn->probe_resp) {
		skw_hex_dump("probe_resp", bcn->probe_resp,
				bcn->probe_resp_len, false);

		param->probe_rsp_ies_offset = offset + fixed;
		param->probe_rsp_ies_len = bcn->probe_resp_len;

		memcpy(param->ies + offset, bcn->probe_resp,
			bcn->probe_resp_len);

		offset += bcn->probe_resp_len;

		if (iface->sap.probe_resp) {
			memcpy(iface->sap.probe_resp, bcn->probe_resp,
					bcn->probe_resp_len);
			iface->sap.probe_resp_len = bcn->probe_resp_len;
		}
	}

	if (skw_recovery_data_update(iface, param, total)) {
		skw_err("build recovery failed\n");

		SKW_KFREE(param);
		return -ENOMEM;
	}

	ret = skw_send_msg(wiphy, dev, SKW_CMD_START_AP, param, total,
			   &resp, sizeof(resp));
	if (ret) {
		skw_err("failed, ret: %d\n", ret);

		skw_recovery_data_clear(iface);
		SKW_KFREE(param);

		return ret;
	}

	if (cfg80211_chandef_dfs_required(wiphy, chandef, iface->wdev.iftype)) {
		ret = skw_dfs_chan_init(wiphy, dev, chandef, 0);
		if (ret) {
			skw_err("dfs channel init failed, ret: %d\n", ret);
			SKW_KFREE(param);

			return ret;
		}

		ret = skw_dfs_start_monitor(wiphy, dev);
		if (ret) {
			skw_dbg("start dfs monitor failed, ret: %d\n", ret);
			SKW_KFREE(param);

			return ret;
		}
	}

	skw_startap_resp_handler(skw, iface, &resp);

	skw_dpd_set_coeff_params(wiphy, dev, param->chan,
		param->center_chn1, param->center_chn2, param->chan_width);

	skw_set_mac_acl(wiphy, dev, settings->acl);

	memcpy(iface->sap.cfg.ssid, settings->ssid, settings->ssid_len);
	iface->sap.cfg.ssid_len = settings->ssid_len;

	iface->sap.cfg.auth_type = settings->auth_type;
	iface->sap.cfg.channel = chandef->chan;
	iface->sap.cfg.width = bw;

	skw_ether_copy(iface->sap.cfg.bssid, iface->addr);
	memcpy(&iface->sap.cfg.crypto, &settings->crypto,
		sizeof(settings->crypto));

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 11, 0)
	iface->sap.cfg.ht_cap = SKW_KMEMDUP(settings->ht_cap,
				sizeof(*settings->ht_cap), GFP_KERNEL);
	iface->sap.cfg.vht_cap = SKW_KMEMDUP(settings->vht_cap,
				sizeof(*settings->vht_cap), GFP_KERNEL);

	iface->sap.ht_required = settings->ht_required;
	iface->sap.vht_required = settings->vht_required;

	iface->sap.cfg.crypto.wep_keys = NULL;
	iface->sap.cfg.crypto.psk = NULL;
#else
	iface->sap.cfg.ht_cap = NULL;
	iface->sap.cfg.vht_cap = NULL;

	iface->sap.ht_required = false;
	iface->sap.vht_required = false;
#endif

	SKW_CLEAR(iface->flags, SKW_IFACE_FLAG_DEAUTH);
	netif_carrier_on(dev);

	SKW_KFREE(param);

	return 0;
}

static int skw_sap_del_sta(struct wiphy *wiphy, struct net_device *dev,
			struct skw_peer_ctx *ctx, u8 subtype, u16 reason)
{
	int ret;
	bool tx = true;
	const u8 *mac = NULL;
	struct skw_iface *iface = netdev_priv(dev);

	if (!ctx)
		return 0;

	skw_peer_ctx_lock(ctx);

	if (ctx->peer) {
		mac = ctx->peer->addr;
		__skw_peer_ctx_transmit(ctx, false);
		skw_set_state(&ctx->peer->sm, SKW_STATE_NONE);

		tx = !(ctx->peer->flags & SKW_PEER_FLAG_DEAUTHED);
		SKW_SET(ctx->peer->flags, SKW_PEER_FLAG_DEAUTHED);
	}

	skw_peer_ctx_unlock(ctx);

	if (!mac)
		return 0;

	skw_mlme_ap_remove_client(iface, mac);

	ret = skw_cmd_del_sta(wiphy, dev, mac, subtype, reason, tx);
	if (!ret)
		skw_peer_ctx_bind(iface, ctx, NULL);

	return ret;
}

static void skw_sap_flush_sta(struct wiphy *wiphy, struct skw_iface *iface,
		u8 subtype, u16 reason)
{
	int idx;
	struct skw_peer_ctx *ctx;
	struct skw_core *skw = wiphy_priv(wiphy);
	u32 peer_map = atomic_read(&iface->peer_map);

	while (peer_map) {
		idx = ffs(peer_map) - 1;
		SKW_CLEAR(peer_map, BIT(idx));

		ctx = &skw->peer_ctx[idx];
		if (!ctx)
			continue;

		skw_sap_del_sta(wiphy, iface->ndev, ctx, subtype, reason);
	}
}

static int skw_stop_ap(struct wiphy *wiphy,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
		struct net_device *dev, unsigned int link_id
#else
		struct net_device *dev
#endif
		SKW_NULL)
{
	int ret = 0;
	struct skw_iface *iface = netdev_priv(dev);

	skw_info("ndev: %s\n", netdev_name(dev));

	netif_carrier_off(dev);

	skw_sap_flush_sta(wiphy, iface, 12, SKW_LEAVE);

	// set flag for tx thread to filter out skb in tx cache
	// mutex_lock(&skw->txrx.lock);
	// SKW_CLEAR(skw->txrx.tx_map, BIT(iface->id));
	// mutex_unlock(&skw->txrx.lock);

	// WARN_ON(iface->sta_list.count);
	skw_purge_key_conf(&iface->key_conf);
	skw_recovery_data_clear(iface);

	SKW_SET(iface->flags, SKW_IFACE_FLAG_DEAUTH);

	skw_dfs_deinit(wiphy, dev);

	ret = skw_send_msg(wiphy, dev, SKW_CMD_STOP_AP, NULL, 0, NULL, 0);
	if (ret) {
		SKW_CLEAR(iface->flags, SKW_IFACE_FLAG_DEAUTH);
		skw_err("failed, ret = %d\n", ret);
		return ret;
	}

	SKW_KFREE(iface->sap.acl);
	SKW_KFREE(iface->sap.cfg.ht_cap);
	SKW_KFREE(iface->sap.cfg.vht_cap);

	return 0;
}

static int skw_change_beacon(struct wiphy *wiphy, struct net_device *dev,
				struct cfg80211_beacon_data *bcn)
{
	int ret = -1;
	int total, fixed, offset = 0;
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_beacon_params *param = NULL;

	skw_dbg("dev: %s\n", netdev_name(dev));

	fixed = sizeof(struct skw_beacon_params);
	total = fixed +
		bcn->head_len +
		bcn->tail_len +
		bcn->probe_resp_len;

	param = SKW_ZALLOC(total, GFP_KERNEL);
	if (IS_ERR_OR_NULL(param)) {
		skw_err("malloc failed, size: %d\n", total);
		return -ENOMEM;
	}

	if (bcn->head) {
		skw_hex_dump("beacon_head", bcn->head, bcn->head_len, false);

		param->beacon_head_len = bcn->head_len;
		param->beacon_head_offset = fixed + offset;
		memcpy(param->ies + offset, bcn->head, bcn->head_len);
		offset += bcn->head_len;
	}

	if (bcn->tail) {
		skw_hex_dump("beacon_tail", bcn->tail, bcn->tail_len, false);

		param->beacon_tail_offset = fixed + offset;
		param->beacon_tail_len = bcn->tail_len;
		memcpy(param->ies + offset, bcn->tail, bcn->tail_len);
		offset += bcn->tail_len;
	}

	if (bcn->probe_resp) {
		skw_hex_dump("probe_resp", bcn->probe_resp, bcn->probe_resp_len, false);

		param->probe_rsp_offset = fixed + offset;
		param->probe_rsp_len = bcn->probe_resp_len;
		memcpy(param->ies + offset, bcn->probe_resp,
				bcn->probe_resp_len);
		offset += bcn->probe_resp_len;

		if (iface->sap.probe_resp) {
			memcpy(iface->sap.probe_resp, bcn->probe_resp,
				bcn->probe_resp_len);

			iface->sap.probe_resp_len = bcn->probe_resp_len;
		}
	}

	ret = skw_send_msg(wiphy, dev, SKW_CMD_CHANGE_BEACON,
			param, total, NULL, 0);
	if (ret)
		skw_err("failed, ret: %d\n", ret);

	SKW_KFREE(param);

	return ret;
}

void skw_set_state(struct skw_sm *sm, enum SKW_STATES state)
{
	skw_log(SKW_STATE, "[%s] inst: %d, %s -> %pM, state: %s -> %s\n",
		SKW_TAG_STATE, sm->inst, skw_iftype_name(sm->iface_iftype),
		sm->addr, skw_state_name(sm->state), skw_state_name(state));

	sm->state = state;
}

int skw_change_station(struct wiphy *wiphy, struct net_device *dev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
			const u8 *mac,
#else
			u8 *mac,
#endif
			struct station_parameters *params)
{
	struct skw_iface *iface = netdev_priv(dev);
	u32 flags_set = params->sta_flags_set;
	struct skw_peer_ctx *ctx = NULL;

	skw_dbg("%s(%s), mac: %pM, flags_set: 0x%x\n",
		netdev_name(dev), skw_iftype_name(dev->ieee80211_ptr->iftype),
		mac, params->sta_flags_set);

	ctx = skw_peer_ctx(iface, mac);
	if (!ctx)
		return -EINVAL;

	skw_peer_ctx_lock(ctx);

	switch (dev->ieee80211_ptr->iftype) {
	case NL80211_IFTYPE_AP:
	case NL80211_IFTYPE_P2P_GO:
	case NL80211_IFTYPE_ADHOC:

		if (flags_set & BIT(NL80211_STA_FLAG_ASSOCIATED)) {
			__skw_peer_ctx_transmit(ctx, true);
			skw_set_state(&ctx->peer->sm, SKW_STATE_ASSOCED);

			if (iface->sap.cfg.crypto.n_akm_suites == 0)
				flags_set |= BIT(NL80211_STA_FLAG_AUTHORIZED);
		}

		if (flags_set & BIT(NL80211_STA_FLAG_AUTHORIZED)) {
			skw_set_state(&ctx->peer->sm, SKW_STATE_COMPLETED);
			atomic_set(&ctx->peer->rx_filter, SKW_RX_FILTER_NONE);
		}

		break;

	case NL80211_IFTYPE_STATION:
	case NL80211_IFTYPE_P2P_CLIENT:
		if (flags_set & BIT(NL80211_STA_FLAG_AUTHORIZED)) {
			skw_set_state(&iface->sta.core.sm, SKW_STATE_COMPLETED);
			atomic_set(&ctx->peer->rx_filter, SKW_RX_FILTER_NONE);
			skw_set_ip_to_fw(wiphy, dev);
		}

		break;

	default:
		break;
	}

	skw_peer_ctx_unlock(ctx);

	return 0;
}

static int skw_set_sta_wep_key(struct wiphy *wiphy, struct skw_iface *iface,
			const u8 *mac, enum SKW_KEY_TYPE key_type)
{
	int idx;
	struct skw_key_params key_params;
	struct skw_key *key;
	struct skw_key_conf *conf = &iface->key_conf;

	skw_dbg("addr: %pM, key type: %d\n", mac, key_type);

	memset(&key_params, 0x0, sizeof(key_params));

	idx = skw_key_idx(conf->installed_bitmap);
	if (idx == SKW_INVALID_ID)
		return -EINVAL;

	rcu_read_lock();
	key = rcu_dereference(conf->key[idx]);
	rcu_read_unlock();

	key_params.cipher_type = conf->skw_cipher;
	key_params.key_id = idx;
	key_params.key_len = key->key_len;
	key_params.key_type = key_type;

	memcpy(key_params.key, key->key_data, key->key_len);
	skw_ether_copy(key_params.mac_addr, mac);

	return skw_send_msg(wiphy, iface->ndev, SKW_CMD_ADD_KEY,
			&key_params, sizeof(key_params), NULL, 0);
}

int skw_cmd_del_sta(struct wiphy *wiphy, struct net_device *dev,
		const u8 *mac, u8 type, u16 reason, bool tx_frame)
{
	struct skw_del_sta_param params;

	skw_dbg("%s: addr: %pM, reason: %d, tx frame: %d\n",
		netdev_name(dev), mac, reason, tx_frame);

	params.reason_code = reason;
	skw_ether_copy(params.mac, mac);
	params.tx_frame = tx_frame;

	return  skw_send_msg(wiphy, dev, SKW_CMD_DEL_STA, &params,
			    sizeof(params), NULL, 0);
}

int skw_delete_station(struct wiphy *wiphy, struct net_device *dev,
			const u8 *mac, u8 subtype, u16 reason)
{
	struct skw_peer_ctx *ctx;
	struct skw_iface *iface = netdev_priv(dev);

	skw_info("subtype: %d, reason: %d, mac: %pM\n", subtype, reason, mac);

	if (!mac || is_broadcast_ether_addr(mac)) {
		skw_sap_flush_sta(wiphy, iface, subtype, reason);

		return 0;
	}

	ctx = skw_peer_ctx(iface, mac);
	if (!ctx)
		return -ENOENT;

	return skw_sap_del_sta(wiphy, dev, ctx, subtype, reason);
}

int skw_add_station(struct wiphy *wiphy, struct net_device *dev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
		    const u8 *mac,
#else
		    u8 *mac,
#endif
		    struct station_parameters *params)
{
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_peer_ctx *ctx;
	struct skw_peer *peer;
	int ret;
	u8 idx;

	skw_dbg("ndev: %s, mac: %pM, flags: 0x%x\n",
		netdev_name(dev), mac, params->sta_flags_set);

	ctx = skw_peer_ctx(iface, mac);
	if (!ctx) {
		peer = skw_peer_alloc();
		if (!peer) {
			skw_err("failed, addr: %pM\n", mac);
			return -ENOMEM;
		}

		ret = skw_send_msg(wiphy, dev, SKW_CMD_ADD_STA, (void *)mac,
				   ETH_ALEN, &idx, sizeof(idx));
		if (ret) {
			skw_err("command failed, addr: %pM, ret: %d\n",
				mac, ret);

			SKW_KFREE(peer);
			return ret;
		}

		skw_peer_init(peer, mac, idx);
		ctx = skw_get_ctx(iface->skw, idx);
		ret = skw_peer_ctx_bind(iface, ctx, peer);
		if (ret) {
			skw_cmd_del_sta(wiphy, dev, mac, 12, SKW_LEAVE, false);
			SKW_KFREE(peer);
			return -EINVAL;
		}
	}

	skw_peer_ctx_lock(ctx);

	__skw_peer_ctx_transmit(ctx, false);
	skw_set_state(&ctx->peer->sm, SKW_STATE_AUTHED);

	skw_peer_ctx_unlock(ctx);

	if (iface->key_conf.flags & SKW_KEY_FLAG_WEP_SHARE)
		skw_set_sta_wep_key(wiphy, iface, mac, SKW_KEY_TYPE_PTK);

	return 0;
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
static int skw_del_station(struct wiphy *wiphy, struct net_device *dev,
			   struct station_del_parameters *params)
{
	return skw_delete_station(wiphy, dev, params->mac,
			params->subtype, params->reason_code);
}
#else
static int skw_del_station(struct wiphy *wiphy, struct net_device *dev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
			   const
#endif
			   u8 *mac)
{
	return skw_delete_station(wiphy, dev, mac,
				12,  /* Deauth */
				WLAN_REASON_DEAUTH_LEAVING);
}
#endif

static void skw_set_rate_info(struct skw_rate *rate, struct rate_info *rinfo)
{
#if 0
	skw_dbg("flags: %d, mcs: %d, bw: %d, gi: %d, nss: %d, he_ru: %d\n",
		rate->flags, rate->mcs_idx, rate->bw,
		rate->gi, rate->nss, rate->he_ru);
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 0, 0)
	switch (rate->bw) {
	case SKW_RATE_INFO_BW_40:
		rinfo->bw = RATE_INFO_BW_40;
		break;

	case SKW_RATE_INFO_BW_80:
		rinfo->bw = RATE_INFO_BW_80;
		break;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 19, 0)
	case SKW_RATE_INFO_BW_HE_RU:
		rinfo->bw = RATE_INFO_BW_HE_RU;
		rinfo->he_ru_alloc = rate->he_ru;
		break;
#endif
	default:
		rinfo->bw = RATE_INFO_BW_20;
		break;
	}
#endif

	rinfo->flags = 0;
	switch (rate->flags) {
	case SKW_RATE_INFO_FLAGS_HT:
		rinfo->mcs = rate->mcs_idx;

		rinfo->flags |= RATE_INFO_FLAGS_MCS;
		if (rate->gi)
			rinfo->flags |= RATE_INFO_FLAGS_SHORT_GI;

		break;

	case SKW_RATE_INFO_FLAGS_VHT:
		rinfo->mcs = rate->mcs_idx;
		rinfo->nss = rate->nss;

		rinfo->flags |= RATE_INFO_FLAGS_VHT_MCS;
		if (rate->gi)
			rinfo->flags |= RATE_INFO_FLAGS_SHORT_GI;

		break;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 19, 0)
	case SKW_RATE_INFO_FLAGS_HE:
		rate->gi = skw_gi_to_nl80211_info_gi(rate->gi);
		rinfo->mcs = rate->mcs_idx;
		rinfo->nss = rate->nss;
		rinfo->he_gi = rate->gi;
		rinfo->he_dcm = rate->he_dcm;
		rinfo->flags |= RATE_INFO_FLAGS_HE_MCS;
		break;
#endif
	default:
		rinfo->legacy = rate->legacy_rate;
		break;
	}
}

static int skw_get_station(struct wiphy *wiphy, struct net_device *dev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
			   const u8 *mac,
#else
			   u8 *mac,
#endif
			   struct station_info *sinfo)
{
	u64 ts;
	int ret = -1;
	struct skw_peer_ctx *ctx;
	struct skw_station_params params;
	struct skw_get_sta_resp get_sta_resp;
	struct skw_iface *iface = netdev_priv(dev);
#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 14, 0)
	struct pcpu_tstats *tstats;
#else
	struct pcpu_sw_netstats *tstats;
#endif
	s16 data_rssi;

	// skw_dbg("dev: %s, mac: %pM\n", netdev_name(dev), mac);

	if (!mac)
		return 0;

	ctx = skw_peer_ctx(iface, mac);
	if (!ctx)
		return -ENOENT;

	memset(&get_sta_resp, 0, sizeof(get_sta_resp));

	ts = local_clock();
	do_div(ts, 1000000);
	params.timestamp = ts;
	skw_ether_copy(params.mac, mac);

	ret = skw_send_msg(wiphy, dev, SKW_CMD_GET_STA, &params,
			   sizeof(params), &get_sta_resp,
			   sizeof(struct skw_get_sta_resp));
	if (ret) {
		skw_warn("failed, ret: %d\n", ret);
		return ret;
	}

	sinfo->tx_failed = get_sta_resp.tx_failed;
	sinfo->filled |= SKW_BIT_ULL(NL80211_STA_INFO_TX_FAILED);

	sinfo->signal = get_sta_resp.signal;
	sinfo->filled |= SKW_BIT_ULL(NL80211_STA_INFO_SIGNAL);

	if (is_skw_sta_mode(iface)) {
		preempt_disable();
		tstats = this_cpu_ptr(dev->tstats);
		preempt_enable();

		u64_stats_update_begin(&tstats->syncp);
	#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 5, 0)
		sinfo->tx_packets = tstats->tx_packets;
	#else
		sinfo->tx_packets = u64_stats_read((const u64_stats_t *)&tstats->tx_packets);
	#endif
		sinfo->filled |= SKW_BIT_ULL(NL80211_STA_INFO_TX_PACKETS);

	#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 5, 0)
		sinfo->tx_bytes = tstats->tx_bytes;
	#else
		sinfo->tx_bytes = u64_stats_read((const u64_stats_t *)&tstats->tx_bytes);
	#endif
		sinfo->filled |= SKW_BIT_ULL(NL80211_STA_INFO_TX_BYTES);

	#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 5, 0)
		sinfo->rx_packets = tstats->rx_packets;
	#else
		sinfo->rx_packets = u64_stats_read((const u64_stats_t *)&tstats->rx_packets);
	#endif
		sinfo->filled |= SKW_BIT_ULL(NL80211_STA_INFO_RX_PACKETS);

	#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 5, 0)
		sinfo->rx_bytes = tstats->rx_bytes;
	#else
		sinfo->rx_bytes = u64_stats_read((const u64_stats_t *)&tstats->rx_bytes);
	#endif
		sinfo->filled |= SKW_BIT_ULL(NL80211_STA_INFO_RX_BYTES);

		u64_stats_update_end(&tstats->syncp);
	}

	skw_set_rate_info(&get_sta_resp.tx_rate, &sinfo->txrate);
	sinfo->filled |= SKW_BIT_ULL(NL80211_STA_INFO_TX_BITRATE);

	skw_peer_ctx_lock(ctx);

	if (ctx->peer) {
		ctx->peer->refer.rssi = sinfo->signal;
		skw_set_rate_info(&ctx->peer->rx.rate, &sinfo->rxrate);

		sinfo->filled |= SKW_BIT_ULL(NL80211_STA_INFO_RX_BITRATE);

		memcpy(&ctx->peer->tx.rate, &get_sta_resp.tx_rate,
			 sizeof(struct skw_rate));
		ctx->peer->refer.tx_psr = get_sta_resp.tx_psr;
		ctx->peer->refer.tx_failed = get_sta_resp.tx_failed;

		memcpy(ctx->peer->refer.filter_cnt,
			get_sta_resp.filter_cnt, sizeof(get_sta_resp.filter_cnt));
		memcpy(ctx->peer->refer.filter_drop_offload_cnt,
			get_sta_resp.filter_drop_offload_cnt,
			sizeof(get_sta_resp.filter_drop_offload_cnt));

		//ctx->peer->refer.percent = get_sta_resp.tx_percent; useless?
		ctx->peer->refer.percent = get_sta_resp.rx_percent;

		if (is_skw_ap_mode(iface)) {
			data_rssi = ctx->peer->seek.rssi >> 3;

			if (ctx->peer->seek.rssi & BIT(10))
				data_rssi |= 0xff00;

			sinfo->signal = data_rssi;

			sinfo->tx_packets = ctx->peer->tx.pkts;
			sinfo->tx_bytes = ctx->peer->tx.bytes;
			sinfo->rx_packets = ctx->peer->rx.pkts;
			sinfo->rx_bytes = ctx->peer->rx.bytes;
			sinfo->filled |= SKW_BIT_ULL(NL80211_STA_INFO_TX_PACKETS) |
					SKW_BIT_ULL(NL80211_STA_INFO_TX_BYTES) |
					SKW_BIT_ULL(NL80211_STA_INFO_RX_PACKETS) |
					SKW_BIT_ULL(NL80211_STA_INFO_RX_BYTES);
		}
	}

	skw_peer_ctx_unlock(ctx);

//	skw_dbg("tx packets:%u tx_bytes:%llu rx_packets:%u rx_bytes:%llu\n",
//		sinfo->tx_packets, sinfo->tx_bytes,
//		sinfo->rx_packets, sinfo->rx_bytes);

	return ret;
}

static void skw_scan_timeout(void *data)
{
	struct skw_iface *iface = data;

	if (unlikely(!iface)) {
		skw_warn("iface is NULL\n");
		return;
	}

	skw_queue_work(priv_to_wiphy(iface->skw), iface,
			SKW_WORK_SCAN_TIMEOUT, NULL, 0);
}

static bool
skw_cqm_bg_scan(struct skw_iface *iface, struct cfg80211_scan_request *req,
				u8 *target_chn)
{
	bool ret;

	if (iface->wdev.iftype != NL80211_IFTYPE_STATION)
		return false;

	spin_lock_bh(&iface->sta.roam_data.lock);
	if (iface->sta.roam_data.flags & SKW_IFACE_STA_ROAM_FLAG_CQM_LOW &&
		iface->sta.core.sm.state == SKW_STATE_COMPLETED &&
		req->n_channels > 10 && req->n_ssids == 1 &&
		req->ssids && req->ssids->ssid_len != 0 &&
		req->ssids->ssid_len == iface->sta.core.bss.ssid_len &&
		memcmp(req->ssids->ssid, iface->sta.core.bss.ssid,
			req->ssids->ssid_len) == 0) {
		skw_dbg("only %d", iface->sta.roam_data.target_chn);
		*target_chn = iface->sta.roam_data.target_chn;
		iface->sta.roam_data.flags &= ~SKW_IFACE_STA_ROAM_FLAG_CQM_LOW;
		skw_del_timer_work(iface->skw, skw_cqm_scan_timeout);
		ret = true;
	} else
		ret = false;
	spin_unlock_bh(&iface->sta.roam_data.lock);

	return ret;
}

static int skw_scan(struct wiphy *wiphy, struct cfg80211_scan_request *req)
{
	int i, ret;
	bool is_cqm_scan;
	u16 *chan;
	int size, nssids_size, offset;
	u8 target_chn;
	u16 scan_chn_num = 0;
	u32 n_channels = req->n_channels;
	char *buff = NULL;
	struct skw_scan_param *param = NULL;
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_iface *iface = SKW_WDEV_TO_IFACE(req->wdev);

	skw_dbg("%s: chip: %d, nr_chan: %d, n_ssids: %d, ie_len: %zd\n",
		skw_iftype_name(req->wdev->iftype), skw->idx,
		req->n_channels, req->n_ssids, req->ie_len);

	//TODO: return busy when STA is associating
	is_cqm_scan = skw_cqm_bg_scan(iface, req, &target_chn);
	if (is_cqm_scan)
		n_channels = 1;

	size = sizeof(struct skw_scan_param) +
	       n_channels * sizeof(u16) +
	       req->n_ssids * sizeof(struct cfg80211_ssid) +
	       req->ie_len;

	buff = SKW_ZALLOC(size, GFP_KERNEL);
	if (IS_ERR_OR_NULL(buff)) {
		skw_err("malloc failed, size: %d\n", size);
		return -ENOMEM;
	}

	offset = 0;

	param = (struct skw_scan_param *)buff;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
	if (req->flags & NL80211_SCAN_FLAG_RANDOM_ADDR &&
	    iface->wdev.iftype == NL80211_IFTYPE_STATION) {
		param->flags |= SKW_SCAN_FLAG_RND_MAC;

		get_random_mask_addr(param->rand_mac,
				     req->mac_addr,
				     req->mac_addr_mask);
	}
#endif

	if (iface->wdev.iftype == NL80211_IFTYPE_AP) {
		param->flags |= SKW_SCAN_FLAG_ACS;
		skw_purge_survey_data(iface);
	}

	offset += sizeof(struct skw_scan_param);
	param->chan_offset = offset;
	param->nr_chan = n_channels;

	chan = (u16 *)(buff + offset);
	if (is_cqm_scan) {
		chan[0] = target_chn;
		scan_chn_num++;
	} else {
		for (i = 0; i < param->nr_chan; i++) {
			if (unlikely(iface->extend.scan_band_filter)) {
				if (!(iface->extend.scan_band_filter & BIT(req->channels[i]->band)))
					continue;
			}

			chan[scan_chn_num] = req->channels[i]->hw_value;

			if ((req->channels[i]->flags & SKW_PASSIVE_SCAN) ||
			    (!req->n_ssids && is_skw_sta_mode(iface)))
				chan[scan_chn_num] |= SKW_SCAN_FLAG_PASSIVE;

			scan_chn_num++;
		}
	}

	skw_dbg("scan_chn_num:%d", scan_chn_num);

	param->nr_chan = scan_chn_num;
	offset += param->nr_chan * sizeof(*chan);

	param->n_ssid = req->n_ssids;
	if (req->n_ssids) {
		nssids_size = req->n_ssids * sizeof(struct cfg80211_ssid);
		memcpy(buff + offset, req->ssids, nssids_size);
		param->ssid_offset = offset;
		offset += nssids_size;
	}

	if (req->ie_len) {
		memcpy(buff + offset, req->ie, req->ie_len);
		param->ie_offset = offset;
		param->ie_len = req->ie_len;
	}

	skw->scan_req = req;
	skw->nr_scan_results = 0;

	skw_add_timer_work(skw, "scan_timeout", skw_scan_timeout, iface,
			SKW_SCAN_TIMEOUT, req, GFP_KERNEL);

	ret = skw_msg_xmit(wiphy, iface->id, SKW_CMD_START_SCAN,
			   buff, size, NULL, 0);
	if (ret) {
		skw->scan_req = NULL;
		skw_del_timer_work(skw, req);
		skw_dbg("failed, ret: %d\n", ret);
	}

	SKW_KFREE(buff);

	return ret;
}

void skw_scan_done(struct skw_core *skw, struct skw_iface *iface, bool aborted)
{
	struct cfg80211_scan_request *scan_req;

	mutex_lock(&skw->lock);

	if (!skw->scan_req)
		goto ret;

	if (&iface->wdev != skw->scan_req->wdev)
		goto ret;

	skw_dbg("inst: %d, aborted: %d, scan result: %d\n",
		iface->id, aborted, skw->nr_scan_results);

	scan_req = skw->scan_req;
	skw->scan_req = NULL;

	skw_del_timer_work(skw, scan_req);

	if (aborted) {
		skw_msg_xmit(priv_to_wiphy(skw), iface->id,
			     SKW_CMD_STOP_SCAN, NULL, 0, NULL, 0);
	}

	skw_compat_scan_done(scan_req, aborted);

ret:
	mutex_unlock(&skw->lock);
}

static void skw_abort_scan(struct wiphy *wiphy, struct wireless_dev *wdev)
{
	struct skw_iface *iface = SKW_WDEV_TO_IFACE(wdev);
	struct skw_core *skw = wiphy_priv(wiphy);

	skw_dbg("inst: %d, scaning: %d\n", iface->id, !!skw->scan_req);

	if (!skw->scan_req)
		return;

	skw_msg_xmit(wiphy, iface->id, SKW_CMD_STOP_SCAN, NULL, 0, NULL, 0);

	skw_scan_done(skw, iface, false);
}

static int skw_mbssid_index(struct skw_core *skw, struct cfg80211_bss *bss)
{
#if (KERNEL_VERSION(5, 1, 0) > LINUX_VERSION_CODE)
	return skw_bss_priv(bss)->bssid_index;
#else
	return bss->bssid_index;
#endif
}

static int skw_mbssid_max_indicator(struct skw_core *skw,
				struct cfg80211_bss *bss)
{
#if (KERNEL_VERSION(5, 1, 0) > LINUX_VERSION_CODE)
	return skw_bss_priv(bss)->max_bssid_indicator;
#else
	return bss->max_bssid_indicator;
#endif
}

const u8 *skw_bss_get_ext_ie(struct cfg80211_bss *bss, u8 ext_eid)
{
	const struct cfg80211_bss_ies *ies;

	ies = rcu_dereference(bss->ies);
	if (!ies)
		return NULL;

	return skw_find_ie_match(SKW_WLAN_EID_EXTENSION, ies->data,
				 ies->len, &ext_eid, 1, 2);
}

static int skw_set_he_mib(struct wiphy *wiphy, int he_enable)
{
	int ret;
	u16 *plen;
	struct skw_tlv_conf conf;

	skw_dbg("he_enable: %d\n", he_enable);

	ret = skw_tlv_alloc(&conf, 128, GFP_KERNEL);
	if (ret) {
		skw_err("alloc failed\n");
		return ret;
	}

	plen = skw_tlv_reserve(&conf, 2);
	if (!plen) {
		skw_err("reserve failed\n");
		skw_tlv_free(&conf);
		return -ENOMEM;
	}

	if (skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_HE, &he_enable, 4)) {
		skw_err("set HE mode [%d] failed\n", he_enable);
		skw_tlv_free(&conf);

		return -EINVAL;
	}

	*plen = conf.total_len;
	ret = skw_msg_xmit(wiphy, 0, SKW_CMD_SET_MIB, conf.buff,
			   conf.total_len, NULL, 0);
	if (ret)
		skw_warn("failed, ret: %d\n", ret);

	skw_tlv_free(&conf);

	return ret;
}

static int skw_set_vht_mib(struct wiphy *wiphy, int vht_enable)
{
	int ret;
	u16 *plen;
	struct skw_tlv_conf conf;

	skw_dbg("vht_enable: %d\n", vht_enable);

	ret = skw_tlv_alloc(&conf, 128, GFP_KERNEL);
	if (ret) {
		skw_err("alloc failed\n");
		return ret;
	}

	plen = skw_tlv_reserve(&conf, 2);
	if (!plen) {
		skw_err("reserve failed\n");
		skw_tlv_free(&conf);
		return -ENOMEM;
	}

	if (skw_tlv_add(&conf, SKW_MIB_DOT11_MODE_VHT, &vht_enable, 4)) {
		skw_err("set vht mode [%d] failed\n", vht_enable);
		skw_tlv_free(&conf);

		return -EINVAL;
	}

	*plen = conf.total_len;
	ret = skw_msg_xmit(wiphy, 0, SKW_CMD_SET_MIB, conf.buff,
			   conf.total_len, NULL, 0);
	if (ret)
		skw_warn("failed, ret: %d\n", ret);

	skw_tlv_free(&conf);

	return ret;
}

static void skw_parse_center_chn(struct cfg80211_bss *bss, int *he_enable,
				 struct skw_center_chn *cc)
{
	unsigned int diff;
	const u8 *ht_ie, *vht_ie;
	u8 vht_seg0_idx, vht_seg1_idx;
	struct ieee80211_ht_operation *ht_oper;
	struct ieee80211_vht_operation *vht_oper;
	const u8 *he_ie;
	struct skw_he_cap_elem *he_cap;

	if (WARN_ON(!bss))
		return;	

	cc->bw = SKW_CHAN_WIDTH_20;
	cc->center_chn1 = bss->channel->hw_value;
	cc->center_chn2 = 0;

	*he_enable = 1;

	rcu_read_lock();

	ht_ie = ieee80211_bss_get_ie(bss, WLAN_EID_HT_OPERATION);
	if (ht_ie && ht_ie[1]) {
		ht_oper = (struct ieee80211_ht_operation *)(ht_ie + 2);

		cc->center_chn2 = 0;

		switch (ht_oper->ht_param & 0x3) {
		case IEEE80211_HT_PARAM_CHA_SEC_NONE:
			cc->bw = SKW_CHAN_WIDTH_20;
			cc->center_chn1 = ht_oper->primary_chan;

			break;

		case IEEE80211_HT_PARAM_CHA_SEC_ABOVE:
			cc->bw = SKW_CHAN_WIDTH_40;
			cc->center_chn1 = ht_oper->primary_chan + 2;
			break;

		case IEEE80211_HT_PARAM_CHA_SEC_BELOW:
			cc->bw = SKW_CHAN_WIDTH_40;
			cc->center_chn1 = ht_oper->primary_chan - 2;
			break;

		default:
			break;
		}
	}

	vht_ie = ieee80211_bss_get_ie(bss, WLAN_EID_VHT_OPERATION);
	if (vht_ie && vht_ie[1]) {
		vht_oper = (struct ieee80211_vht_operation *)(vht_ie + 2);
		cc->center_chn2 = 0;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 12, 0)
		vht_seg0_idx = vht_oper->center_freq_seg0_idx;
		vht_seg1_idx = vht_oper->center_freq_seg1_idx;
#else
		vht_seg0_idx = vht_oper->center_freq_seg1_idx;
		vht_seg1_idx = vht_oper->center_freq_seg2_idx;
#endif
		switch (vht_oper->chan_width) {
		case IEEE80211_VHT_CHANWIDTH_80MHZ:
			cc->bw = SKW_CHAN_WIDTH_80;
			cc->center_chn1 = vht_seg0_idx;

			if (vht_seg1_idx) {
				diff = abs(vht_seg1_idx - vht_seg0_idx);
				if (diff == 8) {
					cc->bw = SKW_CHAN_WIDTH_160;
					cc->center_chn1 = vht_seg1_idx;
				} else if (diff > 8) {
					cc->bw = SKW_CHAN_WIDTH_80P80;
					cc->center_chn2 = vht_seg1_idx;
				}
			}

			break;

		case IEEE80211_VHT_CHANWIDTH_160MHZ:
			cc->bw = SKW_CHAN_WIDTH_160;
			cc->center_chn1 = vht_seg0_idx;
			break;

		case IEEE80211_VHT_CHANWIDTH_80P80MHZ:
			cc->bw = SKW_CHAN_WIDTH_80P80;
			cc->center_chn1 = vht_seg0_idx;
			cc->center_chn2 = vht_seg1_idx;
			break;

		default:
			break;
		}
	}

	he_ie = skw_bss_get_ext_ie(bss, SKW_WLAN_EID_EXT_HE_CAPABILITY);
	if (he_ie && he_ie[1]) {
		skw_hex_dump("he capa", he_ie, he_ie[1] + 2, false);

		/* 802.11ax D3.0 */
		he_cap = (struct skw_he_cap_elem *)(he_ie + 3); // ID: 1 + len: 1 + Num: 1

		skw_dbg("band: %d, ppe: 0x%x, phy_cap_info[0]: 0x%x\n",
			bss->channel->band, he_cap->ppe, he_cap->phy_cap_info[0]);

		if ((he_cap->phy_cap_info[6] & 0x80) == 0x80 &&
		    (he_cap->ppe & 0x78) == 0x60) { // check BIT[3:6]
			switch (bss->channel->band) {
			case NL80211_BAND_2GHZ:
				*he_enable = 0;
				break;

			case NL80211_BAND_5GHZ:
				if (!(he_cap->phy_cap_info[0] &
				    SKW_HE_PHY_CAP0_CHANNEL_WIDTH_SET_160MHZ_IN_5G))
					*he_enable = 0;
				break;

			default:
				break;
			}
		}
	}

	rcu_read_unlock();
}

static int skw_cmd_join(struct wiphy *wiphy, struct net_device *ndev,
			struct cfg80211_bss *bss, u32 bw,
			u16 center_chn1, u16 center_chn2,
			bool roaming, struct skw_join_resp *resp)
{
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_join_param *params;
	int ret = 0, size = 0;

	skw_dbg("bssid: %pM(idx: %d, ind: %d), chn: %d(%d, %d), bw: %d\n",
		bss->bssid, skw_mbssid_index(skw, bss),
		skw_mbssid_max_indicator(skw, bss),
		bss->channel->hw_value,
		center_chn1, center_chn2, bw);

	size = sizeof(struct skw_join_param) + bss->ies->len;
	params = SKW_ZALLOC(size, GFP_KERNEL);
	if (!params)
		return -ENOMEM;

	params->bandwidth = bw;
	params->center_chn1 = center_chn1;
	params->center_chn2 = center_chn2;
	params->chan_num = bss->channel->hw_value;

	params->reserved = 0;
	params->roaming = !!roaming;
	params->capability = bss->capability;
	params->beacon_interval = bss->beacon_interval;
	params->bssid_index = skw_mbssid_index(skw, bss);
	params->max_bssid_indicator = skw_mbssid_max_indicator(skw, bss);
	memcpy(params->bssid, bss->bssid, ETH_ALEN);

	if (bss->ies->len) {
		memcpy(params->bss_ie, bss->ies->data, bss->ies->len);
		params->bss_ie_offset = sizeof(struct skw_join_param);
		params->bss_ie_len = bss->ies->len;
	}

	ret = skw_send_msg(wiphy, ndev, SKW_CMD_JOIN, params,
			   size, resp, sizeof(*resp));
	if (ret)
		skw_err("failed, ret: %d\n", ret);

	SKW_KFREE(params);

	return ret;
}

int skw_cmd_unjoin(struct wiphy *wiphy, struct net_device *ndev,
		   const u8 *addr, u16 reason, bool tx_frame)
{
	int ret;
	struct skw_disconnect_param params;

	skw_dbg("%s, bssid: %pM, reason: %d\n",
		netdev_name(ndev), addr, reason);

	memset(&params, 0x0, sizeof(params));

	params.type = SKW_DISCONNECT_ONLY;
	params.reason_code = reason;
	params.local_state_change = !tx_frame;

	if (tx_frame)
		params.type = SKW_DISCONNECT_SEND_DEAUTH;

	ret = skw_send_msg(wiphy, ndev, SKW_CMD_DISCONNECT, &params,
			   sizeof(params), NULL, 0);
	if (ret)
		skw_err("failed, ret: %d\n", ret);

	return ret;
}

int skw_cmd_monitor(struct wiphy *wiphy, struct cfg80211_chan_def *chandef, u8 mode)
{
	int ret = 0;
	struct skw_set_monitor_param param = {0};

	param.mode = mode;
	switch (param.mode) {
	case SKW_MONITOR_CLOSE:
		break;
	case SKW_MONITOR_COMMON:
	case SKW_MONITOR_MAC_CAP:
	case SKW_MONITOR_PHY_CAP:
		if (!chandef || !chandef->chan)
			return -EINVAL;
		param.chan_num = chandef->chan->hw_value;
		param.center_chn1 = skw_freq_to_chn(chandef->center_freq1);
		param.center_chn2 = skw_freq_to_chn(chandef->center_freq2);

		param.bandwidth = to_skw_bw(chandef->width);

		break;

	default:
		return -EINVAL;
	}

	ret = skw_msg_xmit(wiphy, 0, SKW_CMD_SET_MONITOR_PARAM,
		&param, sizeof(struct skw_set_monitor_param), NULL, 0);

	return ret;
}

static int skw_cmd_auth(struct wiphy *wiphy, struct net_device *dev,
			struct cfg80211_auth_request *req)
{
	int ret = 0;
	u16 auth_alg;
	int size, offset;
	struct skw_auth_param *params = NULL;
	struct skw_iface *iface = netdev_priv(dev);
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 10, 0)
	const u8 *auth_data = req->auth_data;
	size_t auth_data_len = req->auth_data_len;
#else
	const u8 *auth_data = req->sae_data;
	size_t auth_data_len = req->sae_data_len;
#endif

	switch (req->auth_type) {
	case NL80211_AUTHTYPE_OPEN_SYSTEM:
		auth_alg = WLAN_AUTH_OPEN;
		break;
	case NL80211_AUTHTYPE_SHARED_KEY:
		auth_alg = WLAN_AUTH_SHARED_KEY;
		break;
	case NL80211_AUTHTYPE_FT:
		auth_alg = WLAN_AUTH_FT;
		break;
	case NL80211_AUTHTYPE_NETWORK_EAP:
		auth_alg = WLAN_AUTH_LEAP;
		break;
	case NL80211_AUTHTYPE_SAE:
		auth_alg = WLAN_AUTH_SAE;
		break;
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 10, 0)
	case NL80211_AUTHTYPE_FILS_SK:
		auth_alg = WLAN_AUTH_FILS_SK;
		break;
	case NL80211_AUTHTYPE_FILS_SK_PFS:
		auth_alg = WLAN_AUTH_FILS_SK_PFS;
		break;
	case NL80211_AUTHTYPE_FILS_PK:
		auth_alg = WLAN_AUTH_FILS_PK;
		break;
#endif
	case NL80211_AUTHTYPE_AUTOMATIC:
		/*
		 * Fixme: try open wep first, then set share key after using
		 * open wep failed.
		 */
		auth_alg = WLAN_AUTH_OPEN;
		break;
	default:
		return -EOPNOTSUPP;
	}

	size = sizeof(struct skw_auth_param) +
	       req->ie_len +
	       auth_data_len;

	params = SKW_ZALLOC(size, GFP_KERNEL);
	if (IS_ERR_OR_NULL(params)) {
		skw_err("malloc failed, size: %d\n", size);
		return -ENOMEM;
	}

	offset = sizeof(struct skw_auth_param);
	params->auth_algorithm = auth_alg;

	if (auth_data_len) {
		params->auth_data_offset = offset;
		params->auth_data_len = auth_data_len;

		memcpy((u8 *)params + offset, auth_data,
		       auth_data_len);

		offset += auth_data_len;
	}

	if (req->ie && req->ie_len) {
		params->auth_ie_offset = offset;
		params->auth_ie_len = req->ie_len;
		memcpy((u8 *)params + offset, req->ie, req->ie_len);

		offset += req->ie_len;
	}

	memcpy(iface->sta.core.pending.cmd, params, size);
	iface->sta.core.pending.cmd_len = size;

	ret = skw_msg_xmit_timeout(wiphy, SKW_NDEV_ID(dev), SKW_CMD_AUTH,
				params, size, NULL, 0, "SKW_CMD_AUTH",
				msecs_to_jiffies(300), 0);

	SKW_KFREE(params);

	return ret;
}

static inline void skw_oper_and_ht_capa(struct ieee80211_ht_cap *ht_capa,
		const struct ieee80211_ht_cap *ht_capa_mask)
{
	int i;
	u8 *p1, *p2;

	if (!ht_capa_mask) {
		memset(ht_capa, 0, sizeof(*ht_capa));
		return;
	}

	p1 = (u8 *)(ht_capa);
	p2 = (u8 *)(ht_capa_mask);
	for (i = 0; i < sizeof(*ht_capa); i++)
		p1[i] &= p2[i];
}

 /*  Do a logical ht_capa &= ht_capa_mask.  */
static inline void skw_oper_and_vht_capa(struct ieee80211_vht_cap *vht_capa,
				const struct ieee80211_vht_cap *vht_capa_mask)
{
	int i;
	u8 *p1, *p2;

	if (!vht_capa_mask) {
		memset(vht_capa, 0, sizeof(*vht_capa));
		return;
	}

	p1 = (u8 *)(vht_capa);
	p2 = (u8 *)(vht_capa_mask);
	for (i = 0; i < sizeof(*vht_capa); i++)
		p1[i] &= p2[i];
}

static int skw_cmd_assoc(struct wiphy *wiphy, struct net_device *dev,
			 struct cfg80211_assoc_request *req)
{
	int ret = 0;
	int size, offset;
	char *buff = NULL;
	struct skw_assoc_req_param *param = NULL;
	struct skw_iface *iface = netdev_priv(dev);

	size = sizeof(struct skw_assoc_req_param) + req->ie_len;
	buff = SKW_ZALLOC(size, GFP_KERNEL);
	if (IS_ERR_OR_NULL(buff)) {
		skw_err("malloc failed, size: %d\n", size);
		return -ENOMEM;
	}

	offset = 0;
	param = (struct skw_assoc_req_param *)buff;
	memcpy(&param->ht_capa, &req->ht_capa, sizeof(req->ht_capa));

	skw_oper_and_ht_capa(&param->ht_capa, &req->ht_capa_mask);
	memcpy(&param->vht_capa, &req->vht_capa, sizeof(req->vht_capa));

	skw_oper_and_vht_capa(&param->vht_capa, &req->vht_capa_mask);
	memcpy(param->bssid, req->bss->bssid, ETH_ALEN);

	if (req->prev_bssid)
		memcpy(param->pre_bssid, req->prev_bssid, ETH_ALEN);

	param->req_ie_len = req->ie_len;

	offset += sizeof(struct skw_assoc_req_param);
	param->req_ie_offset = offset;

	if (req->ie_len)
		memcpy(param->req_ie, req->ie, req->ie_len);

	memcpy(iface->sta.core.pending.cmd, buff, size);
	iface->sta.core.pending.cmd_len = size;

	ret = skw_msg_xmit_timeout(wiphy, SKW_NDEV_ID(dev), SKW_CMD_ASSOC,
				buff, size, NULL, 0, "SKW_CMD_ASSOC",
				msecs_to_jiffies(300), 0);

	SKW_KFREE(buff);

	return ret;
}

void skw_tx_mlme_mgmt(struct net_device *dev, u16 stype,
		      const u8 *bssid, const u8 *da, u16 reason)
{
	struct ieee80211_mgmt mgmt;
	struct skw_iface *iface = netdev_priv(dev);

	mgmt.duration = 0;
	mgmt.seq_ctrl = 0;
	memcpy(mgmt.da, da, ETH_ALEN);
	memcpy(mgmt.sa, iface->addr, ETH_ALEN);
	memcpy(mgmt.bssid, bssid, ETH_ALEN);
	mgmt.u.deauth.reason_code = cpu_to_le16(reason);
	mgmt.frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT | stype);

	skw_cfg80211_tx_mlme_mgmt(dev, (void *)&mgmt, SKW_DEAUTH_FRAME_LEN);
}

static void skw_fix_compatibility_issues(struct wiphy *wiphy,
		struct skw_iface *iface, struct cfg80211_bss *bss,
		int he_enable, struct skw_center_chn *cc)
{
	const u8 *he_oper_ie;
	struct skw_he_oper_elem *he_oper;
	struct skw_core *skw = iface->skw;
	struct net_device *ndev = iface->ndev;
	const u8 oui[3] = {0x00, 0x0c, 0xe7};

	if (ndev->ieee80211_ptr->iftype != NL80211_IFTYPE_STATION &&
		ndev->ieee80211_ptr->iftype != NL80211_IFTYPE_P2P_CLIENT)
		return;

	skw_set_he_mib(wiphy, he_enable);

	rcu_read_lock();

	he_oper_ie = skw_bss_get_ext_ie(bss, SKW_WLAN_EID_EXT_HE_OPERATION);
	if (he_oper_ie) {
		he_oper = (struct skw_he_oper_elem *)(he_oper_ie + 3);

		if (he_oper->bss_color == 0 &&
		    (int)bss->channel->band == (int)NL80211_BAND_5GHZ &&
		    !(skw->fw.fw_bw_capa & (SKW_BW_5GHZ_80M | SKW_BW_5GHZ_160M | SKW_BW_5GHZ_8080M))) {
			if (he_oper->bss_color_disabled == 0) {
				skw_set_vht_mib(wiphy, 0);
				skw_info("Disable VHT");
			} else {
				if (cc->bw >= SKW_CHAN_WIDTH_80 &&
				    skw_bss_check_vendor_name(bss, oui)) {
					skw_set_he_mib(wiphy, 0);
					skw_info("Disable HE");
				}
			}
		}
	}

	rcu_read_unlock();
}

static int skw_join(struct wiphy *wiphy, struct net_device *ndev,
		    struct cfg80211_bss *bss, bool roaming)
{
	int ret = 0, he_enable;
	struct skw_peer *peer;
	struct skw_peer_ctx *ctx;
	struct skw_center_chn cc = {};
	struct skw_join_resp resp = {};
	struct skw_iface *iface = netdev_priv(ndev);
	struct skw_sta_core *core = &iface->sta.core;

	skw_wdev_assert_lock(iface);

	peer = skw_peer_alloc();
	if (!peer) {
		skw_err("alloc peer failed\n");
		return -ENOMEM;
	}

	skw_parse_center_chn(bss, &he_enable, &cc);
	skw_fix_compatibility_issues(wiphy, iface, bss, he_enable, &cc);

	SKW_CLEAR(iface->flags, SKW_IFACE_FLAG_DEAUTH);
	ret = skw_cmd_join(wiphy, ndev, bss, cc.bw, cc.center_chn1,
			   cc.center_chn2, roaming, &resp);
	if (ret < 0) {
		skw_err("command join failed, ret: %d\n", ret);
		SKW_KFREE(peer);

		return ret;
	}

	skw_peer_init(peer, bss->bssid, resp.peer_idx);
	ctx = skw_get_ctx(iface->skw, resp.peer_idx);
	ret = skw_peer_ctx_bind(iface, ctx, peer);
	if (ret) {
		skw_cmd_unjoin(wiphy, ndev, bss->bssid, SKW_LEAVE, false);
		SKW_KFREE(peer);
		return -EFAULT;
	}

	skw_join_resp_handler(wiphy_priv(wiphy), iface, &resp);

	skw_ether_copy(core->bss.bssid, bss->bssid);
	core->bss.channel = bss->channel;
	core->bss.ctx_idx = resp.peer_idx;
	core->bss.width = cc.bw;

	skw_dpd_set_coeff_params(wiphy, ndev, bss->channel->hw_value,
				 cc.center_chn1, cc.center_chn2, cc.bw);

	if (!iface->sta.sme_external) {
		if (!is_valid_ether_addr(iface->sta.conn->prev_bssid))
			core->bss.auth_type = iface->sta.conn->auth_type;
	}

	return 0;
}

static int skw_unjoin(struct wiphy *wiphy, struct net_device *ndev,
		      const u8 *bssid, u16 reason, bool tx_frame)
{
	int ret = 0;
	struct skw_peer_ctx *ctx;
	struct skw_iface *iface = netdev_priv(ndev);

	skw_dbg("bssid: %pM, reason: %d\n", bssid, reason);

	if (ndev->ieee80211_ptr->iftype == NL80211_IFTYPE_STATION) {
		skw_set_he_mib(wiphy, 1);
		skw_set_vht_mib(wiphy, 1);
	}

	ctx = skw_peer_ctx(iface, bssid);
	if (!ctx) {
		skw_warn("bssid: %pM not exist\n", bssid);
		return 0;
	}

	skw_peer_ctx_transmit(ctx, false);

	SKW_SET(iface->flags, SKW_IFACE_FLAG_DEAUTH);
	ret = skw_cmd_unjoin(wiphy, ndev, bssid, reason, tx_frame);
	if (!ret) {
		memset(&iface->sta.core.bss, 0x0, sizeof(iface->sta.core.bss));
		iface->sta.core.bss.ctx_idx = SKW_INVALID_ID;

		SKW_CLEAR(iface->flags, SKW_IFACE_FLAG_DEAUTH);
		skw_lmac_unbind_iface(wiphy_priv(wiphy), 0, iface->id);

		skw_peer_ctx_bind(iface, ctx, NULL);
	} else {
		skw_warn("command unjoin failed, ret: %d\n", ret);
		SKW_CLEAR(iface->flags, SKW_IFACE_FLAG_DEAUTH);
	}

	return ret;
}

int skw_sta_leave(struct wiphy *wiphy, struct net_device *dev,
		const u8 *bssid, u16 reason, bool tx_frame)
{
	int i;
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("bssid: %pM, reason: %d\n", bssid, reason);

	skw_wdev_assert_lock(iface);

	netif_carrier_off(dev);

	memset(&iface->wmm, 0x0, sizeof(iface->wmm));

	del_timer_sync(&iface->sta.core.timer);

	skw_set_state(&iface->sta.core.sm, SKW_STATE_NONE);
	iface->sta.core.sm.flags = 0;

	skw_unjoin(wiphy, dev, bssid, reason, tx_frame);
	skw_purge_key_conf(&iface->key_conf);

	memset(iface->sta.core.bss.ssid, 0x0, IEEE80211_MAX_SSID_LEN);
	iface->sta.core.bss.ssid_len = 0;

	for (i = 0; i < SKW_MAX_DEFRAG_ENTRY; i++) {
		skb_queue_purge(&iface->frag[i].skb_list);
		iface->frag[i].tid = SKW_INVALID_ID;
	}

	return 0;
}

static int skw_auth(struct wiphy *wiphy, struct net_device *ndev,
		    struct cfg80211_auth_request *req)
{
	int ret;
	struct key_params key;
	bool roaming = false;
	struct skw_iface *iface = netdev_priv(ndev);
	struct skw_bss_cfg *bss = &iface->sta.core.bss;
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 10, 0)
	const u8 *auth_data = req->auth_data;
#else
	const u8 *auth_data = req->sae_data;
#endif

	skw_info("%s, bssid: %pM, auth type: %d, state: %s\n",
		 netdev_name(ndev), req->bss->bssid,
		 req->auth_type, skw_state_name(iface->sta.core.sm.state));

	skw_wdev_assert_lock(iface);

	skw_abort_scan(wiphy, ndev->ieee80211_ptr);

	// skw_scan_done(iface->skw, iface, true);
	// skw_sched_scan_stop(wiphy, ndev, iface->skw->sched_scan_req->reqid);

	switch (iface->sta.core.sm.state) {
	case SKW_STATE_AUTHING:
	case SKW_STATE_ASSOCING:
		return -EBUSY;

	case SKW_STATE_ASSOCED:
	case SKW_STATE_COMPLETED:
		if (ether_addr_equal(bss->bssid, req->bss->bssid))
			return 0;

		roaming = true;

		if (iface->sta.sme_external)
			skw_tx_mlme_mgmt(iface->ndev, IEEE80211_STYPE_DEAUTH,
				iface->sta.core.bss.bssid,
				iface->sta.core.bss.bssid, SKW_LEAVE);

		skw_set_state(&iface->sta.core.sm, SKW_STATE_NONE);

		ret = skw_unjoin(wiphy, ndev, bss->bssid, SKW_LEAVE, false);
		if (ret)
			return ret;

		/* fall through */
		skw_fallthrough;
	case SKW_STATE_NONE:
		if (is_valid_ether_addr(bss->bssid)) {
			skw_warn("unexpected bssid: %pM\n", bss->bssid);
			ret = skw_unjoin(wiphy, ndev, bss->bssid, 3, false);
			if (ret)
				return ret;
		}

		if (!skw_channel_allowed(wiphy, req->bss->channel->hw_value))
			return -EBUSY;

		ret = skw_join(wiphy, ndev, req->bss, roaming);
		if (ret < 0)
			return ret;

		break;

	default:
		break;
	}

	if (req->key && req->key_len) {
		key.seq = NULL;
		key.seq_len = 0;
		key.key = (u8 *)req->key;
		key.key_len = req->key_len;
		key.cipher = SKW_CIPHER_SUITE_WEP40;

		if (req->key_len != 5)
			key.cipher = SKW_CIPHER_SUITE_WEP104;

		ret = __skw_add_key(wiphy, ndev, 0, req->key_idx, false, NULL, &key);
		if (ret < 0) {
			skw_err("add share key failed, ret: %d\n", ret);
			goto unjoin;
		}

		__skw_set_default_key(wiphy, ndev, 0, req->key_idx, true, true);
	}

	iface->sta.core.auth_start = jiffies;
	iface->sta.core.pending.retry = 0;
	iface->sta.core.pending.start = jiffies;
	skw_set_state(&iface->sta.core.sm, SKW_STATE_AUTHING);

	skw_set_sta_timer(&iface->sta.core, SKW_STEP_TIMEOUT);

	ret = skw_cmd_auth(wiphy, ndev, req);
	if (ret) {
		skw_dbg("command auth failed, ret: %d\n", ret);

		del_timer_sync(&iface->sta.core.timer);
		goto unjoin;
	}

	/* SAE confirm */
	if (auth_data && le16_to_cpu(*((u16 *)auth_data) == 2) &&
	    iface->sta.core.sm.flags & SKW_SM_FLAG_SAE_RX_CONFIRM)
		skw_set_state(&iface->sta.core.sm, SKW_STATE_AUTHED);

	iface->sta.report_deauth = true;
	return 0;

unjoin:
	skw_unjoin(wiphy, ndev, req->bss->bssid, SKW_LEAVE, false);

	skw_set_state(&iface->sta.core.sm, SKW_STATE_NONE);

	return ret;
}

static int skw_cfg80211_auth(struct wiphy *wiphy, struct net_device *dev,
			     struct cfg80211_auth_request *req)
{
	struct skw_iface *iface = netdev_priv(dev);

	iface->sta.report_deauth = false;

	return skw_auth(wiphy, dev, req);
}

static int skw_assoc(struct wiphy *wiphy, struct net_device *dev,
		struct cfg80211_assoc_request *req)
{
	int ret;
	const u8 *ssid_ie;
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_sta_core *core = &iface->sta.core;

	skw_dbg("%s, bssid: %pM\n", netdev_name(dev), req->bss->bssid);

	skw_wdev_assert_lock(iface);

	switch (core->sm.state) {
	case SKW_STATE_AUTHING:
	case SKW_STATE_ASSOCING:
		return -EBUSY;

	case SKW_STATE_ASSOCED:
	case SKW_STATE_COMPLETED:
		if (ether_addr_equal(core->bss.bssid, req->bss->bssid))
			return 0;

		skw_set_state(&core->sm, SKW_STATE_NONE);

		ret = skw_unjoin(wiphy, dev, core->bss.bssid, SKW_LEAVE, false);
		if (ret)
			return ret;

		ret = skw_join(wiphy, dev, req->bss, true);
		if (ret)
			return ret;

		skw_set_state(&core->sm, SKW_STATE_AUTHED);

		break;

		/* continue */
	case SKW_STATE_AUTHED:
		break;

	default:
		return -EINVAL;
	}

	rcu_read_lock();

	ssid_ie = ieee80211_bss_get_ie(req->bss, WLAN_EID_SSID);
	if (ssid_ie) {
		memcpy(core->bss.ssid, ssid_ie + 2, ssid_ie[1]);
		core->bss.ssid_len = ssid_ie[1];
	}

	rcu_read_unlock();

	core->cbss = req->bss;
	core->pending.retry = 0;
	core->assoc_req_ie_len = 0;
	memset(core->assoc_req_ie, 0x0, SKW_2K_SIZE);

	skw_set_state(&core->sm, SKW_STATE_ASSOCING);

	skw_set_sta_timer(core, SKW_STEP_TIMEOUT);

	ret = skw_cmd_assoc(wiphy, dev, req);
	if (ret) {
		skw_err("command assoc failed, ret: %d\n", ret);

		core->cbss = NULL;

		del_timer_sync(&core->timer);

		skw_unjoin(wiphy, dev, req->bss->bssid, SKW_LEAVE, false);
		skw_set_state(&core->sm, SKW_STATE_NONE);

		memset(core->bss.ssid, 0x0, IEEE80211_MAX_SSID_LEN);
		core->bss.ssid_len = 0;
	}

	return ret;
}

static int skw_cfg80211_assoc(struct wiphy *wiphy, struct net_device *dev,
			      struct cfg80211_assoc_request *req)
{
	return skw_assoc(wiphy, dev, req);
}

static int skw_cfg80211_deauth(struct wiphy *wiphy, struct net_device *dev,
			struct cfg80211_deauth_request *req)
{
	int ret;
	struct skw_iface *iface = netdev_priv(dev);
	bool tx_frame = !req->local_state_change && iface->sta.report_deauth;

	skw_info("%s: bssid: %pM, reason: %d, tx frame: %d\n",
		 netdev_name(dev), req->bssid, req->reason_code, tx_frame);

	ret = skw_sta_leave(wiphy, dev, req->bssid, req->reason_code, tx_frame);
	if (!ret && iface->sta.report_deauth) {
		skw_tx_mlme_mgmt(dev, IEEE80211_STYPE_DEAUTH,
				 req->bssid, req->bssid,
				 req->reason_code);
	} else {
		skw_err("failed, ret: %d\n", ret);
	}

	return ret;
}

static int skw_cfg80211_disassoc(struct wiphy *wiphy, struct net_device *dev,
			struct cfg80211_disassoc_request *req)
{
	int ret;
	u8 *bssid;
	bool tx_frame = !req->local_state_change;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
	bssid = (u8 *)req->ap_addr;
#else
	bssid = req->bss->bssid;
#endif

	skw_info("%s, bssid: %pM, reason: %d, tx frame: %d\n",
		 netdev_name(dev), bssid, req->reason_code, tx_frame);

	ret = skw_sta_leave(wiphy, dev, bssid, req->reason_code, tx_frame);
	if (!ret) {
		skw_tx_mlme_mgmt(dev, IEEE80211_STYPE_DISASSOC,
				 bssid, bssid, req->reason_code);
	} else {
		skw_err("failed, ret: %d\n", ret);
	}

	return ret;
}

void skw_connected(struct net_device *dev, struct skw_connect_param *conn,
		   const u8 *req_ie, int req_ie_len, const u8 *resp_ie,
		   int resp_ie_len, u16 status, gfp_t gfp)
{
	if (conn->flags & SKW_CONN_FLAG_ASSOCED) {
		skw_compat_cfg80211_roamed(dev, conn->bssid, req_ie,
				req_ie_len, resp_ie, resp_ie_len, gfp);
	} else {
		cfg80211_connect_result(dev, conn->bssid, req_ie, req_ie_len,
				resp_ie, resp_ie_len, status, gfp);
	}

	SKW_SET(conn->flags, SKW_CONN_FLAG_ASSOCED);
}

void skw_disconnected(struct net_device *dev, u16 reason,
		bool local_gen, gfp_t gfp)
{
	struct skw_iface *iface = netdev_priv(dev);

	skw_compat_disconnected(dev, reason, NULL, 0, local_gen, gfp);

	SKW_CLEAR(iface->sta.conn->flags, SKW_CONN_FLAG_ASSOCED);
}

int skw_connect_sae_auth(struct wiphy *wiphy, struct net_device *dev,
			 struct cfg80211_bss *bss)
{
	int ret = 0;
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 17, 0)
	bool roaming = false;
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_connect_param *conn = iface->sta.conn;
	struct cfg80211_external_auth_params params;

	if (!bss) {
		cfg80211_connect_result(dev, conn->bssid, NULL, 0, NULL, 0,
				WLAN_STATUS_UNSPECIFIED_FAILURE,
				GFP_KERNEL);

		return -EINVAL;
	}

	// TODO:
	// unjoin prev bssid for roaming connection

	roaming = is_valid_ether_addr(conn->prev_bssid);
	ret = skw_join(wiphy, dev, bss, roaming);
	if (ret < 0) {
		skw_err("join %pM failed\n", conn->bssid);
		return ret;
	}

	skw_set_state(&iface->sta.core.sm, SKW_STATE_AUTHING);

	params.action = NL80211_EXTERNAL_AUTH_START;
	memcpy(params.bssid, conn->bssid, ETH_ALEN);

	params.ssid.ssid_len = conn->ssid_len;
	memcpy(params.ssid.ssid, conn->ssid, conn->ssid_len);

	params.key_mgmt_suite = cpu_to_be32(WLAN_AKM_SUITE_SAE);
	params.status = WLAN_STATUS_SUCCESS;

	ret = cfg80211_external_auth_request(dev, &params, GFP_KERNEL);
	if (ret) {
		skw_err("failed, ret: %d\n", ret);

		skw_unjoin(wiphy, dev, conn->bssid, SKW_LEAVE, false);
		skw_set_state(&iface->sta.core.sm, SKW_STATE_NONE);

		cfg80211_connect_result(dev, conn->bssid, NULL, 0, NULL, 0,
				WLAN_STATUS_UNSPECIFIED_FAILURE,
				GFP_KERNEL);
	}
#endif

	return ret;
}

int skw_connect_auth(struct wiphy *wiphy, struct net_device *dev,
		struct skw_connect_param *conn, struct cfg80211_bss *bss)
{
	struct cfg80211_auth_request req;

	if (!bss) {
		skw_warn("Invalid bss\n");
		return -EINVAL;
	}

	memset(&req, 0x0, sizeof(req));

	req.bss = bss;
	req.key = conn->key_len ? conn->key : NULL;
	req.key_len = conn->key_len;
	req.key_idx = conn->key_idx;
	req.auth_type = conn->auth_type;

	return skw_auth(wiphy, dev, &req);
}

int skw_connect_assoc(struct wiphy *wiphy, struct net_device *ndev,
		struct skw_connect_param *conn)
{
	int ret = 0;
	struct cfg80211_assoc_request req = {};

	req.bss = cfg80211_get_bss(wiphy, conn->channel, conn->bssid,
				   conn->ssid, conn->ssid_len,
				   SKW_BSS_TYPE_ESS, SKW_PRIVACY_ESS_ANY);
	if (!req.bss) {
		skw_info("cfg80211_get_bss null\n");
		return -ENOENT;
	}

	req.ie = conn->assoc_ie;
	req.ie_len = conn->assoc_ie_len;
	req.prev_bssid = conn->prev_bssid;
	req.use_mfp = conn->flags & SKW_CONN_FLAG_USE_MFP;
	req.flags = conn->flags;
	req.ht_capa = conn->ht_capa;
	req.ht_capa_mask = conn->ht_capa_mask;
	req.vht_capa = conn->vht_capa;
	req.vht_capa_mask = conn->vht_capa_mask;

	ret = skw_assoc(wiphy, ndev, &req);

	cfg80211_put_bss(wiphy, req.bss);

	return ret;
}

int skw_roam_connect(struct skw_iface *iface, const u8 *bssid, u8 chn)
{
	struct ieee80211_channel *req_channel = NULL;
	struct wiphy *wiphy = iface->wdev.wiphy;
	struct skw_connect_param *conn = iface->sta.conn;

	if (!is_valid_ether_addr(bssid))
		return -EINVAL;

	skw_dbg("roam from %pM to %pM auth_type: %d, chn: %d\n",
		conn->bssid, bssid, conn->auth_type, chn);

	req_channel = ieee80211_get_channel(wiphy, skw_to_freq(chn));
	if (!req_channel) {
		skw_err("invalid channel: %d\n", chn);
		return -EINVAL;
	}
#if 0
	iface->sta.backup = SKW_KMEMDUP(&iface->sta.core.bss,
					sizeof(iface->sta.core.bss),
					GFP_KERNEL);
	if (!iface->sta.backup)
		return -EINVAL;

	// skw_peer_transmit();
	memset(&iface->sta.core.bss, 0x0, sizeof(iface->sta.core.bss));
#endif
	conn->channel = req_channel;
	skw_ether_copy(conn->bssid, bssid);
	skw_ether_copy(conn->prev_bssid, iface->sta.core.bss.bssid);

	conn->auth_type = iface->sta.conn->auth_type;

	skw_queue_local_event(priv_to_wiphy(iface->skw), iface,
			      SKW_EVENT_LOCAL_STA_CONNECT, NULL, 0);

	return 0;
}

static int skw_set_cqm_rssi_config(struct wiphy *wiphy, struct net_device *dev,
				s32 rssi_thold, u32 rssi_hyst)
{
	struct skw_set_cqm_rssi_param cqm_param;

	skw_dbg("dev: %s, thold: %d, hyst: %d\n",
		netdev_name(dev), rssi_thold, rssi_hyst);

	//TBD: whether to store the config at host driver

	cqm_param.rssi_thold = rssi_thold;
	cqm_param.rssi_hyst = (u8)rssi_hyst;

	return skw_send_msg(wiphy, dev, SKW_CMD_SET_CQM_RSSI, &cqm_param,
			    sizeof(cqm_param), NULL, 0);
}

static int skw_cfg80211_connect(struct wiphy *wiphy, struct net_device *ndev,
			struct cfg80211_connect_params *req)
{
	struct skw_iface *iface = netdev_priv(ndev);
	struct skw_connect_param *conn = iface->sta.conn;
	const u8 *bssid = skw_compat_bssid(req);
	struct ieee80211_channel *channel = skw_compat_channel(req);

	skw_dbg("%s, ssid: %s, bssid: %pM, auth: %d, chn: %d key_len: %d\n",
		netdev_name(ndev), req->ssid, bssid, req->auth_type,
		channel->hw_value, req->key_len);

	if (!conn) {
		skw_dbg("conn is NULL\n");
		return -ENOMEM;
	}

	if (unlikely(req->ssid_len > IEEE80211_MAX_SSID_LEN)) {
		skw_err("Invalid SSID: %s, len: %zd\n",
			req->ssid, req->ssid_len);

		return -EINVAL;
	}

	mutex_lock(&conn->lock);

	skw_ether_copy(conn->bssid, bssid);
	eth_zero_addr(conn->prev_bssid);

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 7, 0)
	if (req->prev_bssid)
		skw_ether_copy(conn->prev_bssid, req->prev_bssid);
#endif

	if (req->ie && req->ie_len)
		memcpy(conn->assoc_ie, req->ie, req->ie_len);

	conn->assoc_ie_len = req->ie_len;

	if (req->auth_type == NL80211_AUTHTYPE_AUTOMATIC) {
		conn->auth_type = NL80211_AUTHTYPE_OPEN_SYSTEM;
		SKW_SET(conn->flags, SKW_CONN_FLAG_AUTH_AUTO);
	}

	if (req->key && req->key_len) {
		memcpy(conn->key, req->key, req->key_len);
		conn->key_len = req->key_len;
		conn->key_idx = req->key_idx;
		SKW_SET(conn->flags, SKW_CONN_FLAG_KEY_VALID);
	}

	conn->ssid_len = req->ssid_len;
	memcpy(conn->ssid, req->ssid, req->ssid_len);

	conn->auth_type = req->auth_type;
	conn->ht_capa = req->ht_capa;
	conn->vht_capa = req->vht_capa;

	conn->ht_capa_mask = req->ht_capa_mask;
	conn->vht_capa_mask = req->vht_capa_mask;

	mutex_unlock(&conn->lock);

	if (iface->wdev.iftype == NL80211_IFTYPE_STATION) {
		skw_set_cqm_rssi_config(wiphy, ndev, SKW_CQM_DEFAUT_RSSI_THOLD,
					SKW_CQM_DEFAUT_RSSI_HYST);
	}

	return skw_queue_local_event(wiphy, iface,
			SKW_EVENT_LOCAL_STA_CONNECT, NULL, 0);
}

static int skw_cfg80211_disconnect(struct wiphy *wiphy,
			struct net_device *dev, u16 reason)
{
	int ret;
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_sta_core *core = &iface->sta.core;

	skw_info("%s, reason: %d\n", netdev_name(dev), reason);

	ret = skw_sta_leave(wiphy, dev, core->bss.bssid, reason, true);
	if (!ret)
		skw_disconnected(dev, reason, true, GFP_KERNEL);

	return ret;
}

static u64 skw_tx_cookie(void)
{
	static u64 skw_cookie;

	if (WARN_ON(++skw_cookie == 0))
		skw_cookie++;

	return skw_cookie;
}

static int skw_remain_on_channel(struct wiphy *wiphy, struct wireless_dev *wdev,
				 struct ieee80211_channel *chan,
				 unsigned int duration, u64 *cookie)
{
	int ret;
	struct skw_roc_param roc;
	u64 tx_cookie = skw_tx_cookie();
	struct skw_iface *iface = SKW_WDEV_TO_IFACE(wdev);

	skw_dbg("iface: %u, chan: %u, duration: %d, cookie: %llu\n",
		iface->id, chan->hw_value, duration, tx_cookie);

	roc.enable = 1;
	roc.channel_num = chan->hw_value;
	roc.duration = duration;
	roc.cookie = *cookie = tx_cookie;
	//TBD: define the referenced value
	if (chan->flags & IEEE80211_CHAN_NO_HT40MINUS)
		roc.channel_type = 2;
	else if (chan->flags & IEEE80211_CHAN_NO_HT40PLUS)
		roc.channel_type = 1;
	else if (chan->flags & SKW_IEEE80211_CHAN_NO_20MHZ)
		roc.channel_type = 0;
	else
		roc.channel_type = 3;

	ret = skw_msg_xmit(wiphy, iface->id, SKW_CMD_REMAIN_ON_CHANNEL,
			   &roc, sizeof(roc), NULL, 0);

	return ret;
}

static int
skw_cancel_roc(struct wiphy *wiphy, struct wireless_dev *wdev, u64 cookie)
{
	struct skw_iface *iface = SKW_WDEV_TO_IFACE(wdev);
	struct skw_roc_param param;

	skw_dbg("cookie: %lld\n", cookie);

#if 0
	// fixme:
	if (cookie != skw->remain_on_channel_cookie)
		return -ENOENT;
#endif

	memset(&param, 0x0, sizeof(param));

	return skw_msg_xmit(wiphy, iface->id, SKW_CMD_REMAIN_ON_CHANNEL,
			    &param, sizeof(param), NULL, 0);
}

static inline void __skw_set_peer_flags(struct skw_peer_ctx *ctx, u32 flags)
{
	if (ctx) {
		skw_peer_ctx_lock(ctx);

		if (ctx->peer)
			ctx->peer->flags |= flags;

		skw_peer_ctx_unlock(ctx);
	}
}

static void skw_set_peer_flags(struct skw_iface *iface,
			const u8 *addr, u32 flags)
{
	int idx;
	struct skw_peer_ctx *ctx;
	u32 peer_map = atomic_read(&iface->peer_map);

	if (!addr)
		return;

	if (is_unicast_ether_addr(addr)) {
		ctx = skw_peer_ctx(iface, addr);
		__skw_set_peer_flags(ctx, flags);
		return;
	}

	while (peer_map) {
		idx = ffs(peer_map) - 1;
		SKW_CLEAR(peer_map, BIT(idx));

		ctx = &iface->skw->peer_ctx[idx];
		__skw_set_peer_flags(ctx, flags);
	}
}

int skw_mgmt_tx(struct wiphy *wiphy, struct skw_iface *iface,
		struct ieee80211_channel *chan, u32 wait, u64 *cookie,
		bool dont_wait_ack, const void *frame, int frame_len)
{
	int ret, total_len;
	struct skw_mgmt_tx_param *param;
	u64 tx_cookie;
	const struct ieee80211_mgmt *mgmt;
	u16 fc;

	if (!chan || !frame)
		return -EINVAL;
	
	tx_cookie = skw_tx_cookie();
	mgmt = frame;
	fc = SKW_MGMT_SFC(mgmt->frame_control);

	skw_dbg("%s: chan: %d, wait: %d, cookie: %lld, no_ack: %d, len: %d\n",
		skw_mgmt_name(fc), chan->hw_value, wait, tx_cookie,
		dont_wait_ack, frame_len);

	skw_hex_dump("mgmt tx", frame, frame_len, false);

	total_len = sizeof(*param) + frame_len;
	param = SKW_ZALLOC(total_len, GFP_KERNEL);
	if (IS_ERR_OR_NULL(param))
		return -ENOMEM;

	param->wait = wait;
	param->channel = chan->hw_value;
	param->dont_wait_for_ack = dont_wait_ack;
	param->cookie = *cookie = tx_cookie;

	memcpy(param->mgmt, frame, frame_len);
	param->mgmt_frame_len = frame_len;

	ret = skw_msg_xmit(wiphy, iface->id, SKW_CMD_TX_MGMT,
			   param, total_len, NULL, 0);
	if (!ret) {
		if (is_unicast_ether_addr(mgmt->da) &&
		    (fc == IEEE80211_STYPE_DEAUTH ||
		    fc == IEEE80211_STYPE_DISASSOC)) {
			skw_set_peer_flags(iface, mgmt->da,
					   SKW_PEER_FLAG_DEAUTHED);
		}
	} else {
		skw_err("failed, ret: %d\n", ret);
	}

	SKW_KFREE(param);

	return ret;
}

static inline bool is_skw_rrm_report(const void *buf, int buf_len)
{
	const struct ieee80211_mgmt *mgmt = buf;

	if (!ieee80211_is_action(mgmt->frame_control))
		return false;

	if (buf_len < IEEE80211_MIN_ACTION_SIZE +
		      sizeof(mgmt->u.action.u.measurement))
		return false;

	if (mgmt->u.action.category != SKW_WLAN_CATEGORY_RADIO_MEASUREMENT)
		return false;

	if (mgmt->u.action.u.measurement.action_code != WLAN_ACTION_SPCT_MSR_RPRT)
		return false;

	return true;
}

static int __skw_cfg80211_mgmt_tx(struct wiphy *wiphy, struct skw_iface *iface,
				  struct ieee80211_channel *chan, u32 wait,
				  u64 *cookie, bool dont_wait_for_ack,
				  const void *frame, int frame_len)
{
	int limit_len;
	struct ieee80211_channel *tx_chan = chan;
	struct skw_core *skw = wiphy_priv(wiphy);

#define SKW_MGMT_TX_LEN 1500

	limit_len = frame_len + SKW_EXTER_HDR_SIZE + sizeof(struct skw_msg);
	limit_len = round_up(limit_len, skw->hw_pdata->align_value);

	if (!tx_chan) {
		if (is_skw_sta_mode(iface))
			tx_chan = iface->sta.core.bss.channel;
		else
			tx_chan = iface->sap.cfg.channel;
	}

	if (limit_len > SKW_CMD_MAX_LEN) {
		if (is_skw_rrm_report(frame, frame_len)) {
			int head_offset = offsetof(struct ieee80211_mgmt,
					u.action.u.measurement.element_id);

			int ret = -E2BIG;
			int elem_len = 0, next_len = 0;
			int left = frame_len - head_offset;
			char *pos = (u8 *)frame + head_offset, *next = pos;
			char *data = NULL;

			data = SKW_ZALLOC(SKW_MGMT_TX_LEN, GFP_KERNEL);
			if (!data) {
				skw_err("alloc %d failed\n", SKW_MGMT_TX_LEN);
				return -ENOMEM;
			}

			while (left) {
				int tx_len;

				next_len = next[1] + 2;
				tx_len = elem_len + head_offset + next_len;
				if (tx_len < SKW_MGMT_TX_LEN) {
					elem_len += next_len;
					left -= next_len;

					if (left) {
						next += next_len;
						continue;
					}
				}

				memcpy(data, frame, head_offset);
				memcpy(data + head_offset, pos, elem_len);

				ret = skw_mgmt_tx(wiphy, iface, tx_chan, wait,
						cookie, dont_wait_for_ack,
						data, elem_len + head_offset);

				pos = next;
				elem_len = 0;
			}

			SKW_KFREE(data);
			return ret;

		} else {
			skw_warn("failed, frame len: %d\n", frame_len);
			return -E2BIG;
		}
	}

#undef SKW_MGMT_TX_LEN

	return skw_mgmt_tx(wiphy, iface, tx_chan, wait, cookie,
			dont_wait_for_ack, frame, frame_len);
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 14, 0)
static int skw_cfg80211_mgmt_tx(struct wiphy *wiphy, struct wireless_dev *wdev,
				struct cfg80211_mgmt_tx_params *params,
				u64 *cookie)
{
	struct skw_iface *iface = SKW_WDEV_TO_IFACE(wdev);

	return __skw_cfg80211_mgmt_tx(wiphy, iface, params->chan,
				      params->wait, cookie,
				      params->dont_wait_for_ack,
				      params->buf, params->len);
}
#else
static int skw_cfg80211_mgmt_tx(struct wiphy *wiphy, struct wireless_dev *wdev,
			  struct ieee80211_channel *chan, bool offchan,
			  unsigned int wait, const u8 *buf, size_t len,
			  bool no_cck, bool dont_wait_for_ack, u64 *cookie)
{
	struct skw_iface *iface = SKW_WDEV_TO_IFACE(wdev);

	return __skw_cfg80211_mgmt_tx(wiphy, iface, chan, wait, cookie,
			dont_wait_for_ack, buf, len);
}
#endif

static int skw_join_ibss(struct wiphy *wiphy, struct net_device *dev,
			struct cfg80211_ibss_params *params)
{
	int i;
	u8 *pos;
	struct cfg80211_bss *bss;
	struct ieee80211_mgmt *mgmt;
	struct ieee80211_supported_band *sband;
	struct skw_iface *iface = netdev_priv(dev);
	struct cfg80211_chan_def *chandef = &params->chandef;

	skw_dbg("%s, bssid: %pM, ssid: %s, channel: %d, chan_fixed: %d\n",
		netdev_name(dev), params->bssid, params->ssid,
		chandef->chan->hw_value, params->channel_fixed);

	if (params->bssid)
		memcpy(iface->ibss.bssid, params->bssid, ETH_ALEN);
	else
		eth_random_addr(iface->ibss.bssid);

	iface->ibss.bw = to_skw_bw(params->chandef.width);
	if (iface->ibss.bw == SKW_CHAN_WIDTH_MAX)
		return -EINVAL;

	iface->ibss.beacon_int = params->beacon_interval;
	iface->ibss.channel = params->chandef.chan->hw_value;
	iface->ibss.center_freq1 = chandef->center_freq1;
	iface->ibss.center_freq2 = chandef->center_freq2;
	iface->ibss.chandef = params->chandef;

	// start build presp frame
	mgmt = SKW_ZALLOC(SKW_2K_SIZE, GFP_KERNEL);
	if (!mgmt)
		return -ENOMEM;

	mgmt->frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT |
					IEEE80211_STYPE_PROBE_RESP);

	eth_broadcast_addr(mgmt->da);
	memcpy(mgmt->sa, iface->addr, ETH_ALEN);
	memcpy(mgmt->bssid, iface->ibss.bssid, ETH_ALEN);

	mgmt->u.beacon.beacon_int = cpu_to_le16(params->beacon_interval);
	// mgmt->u.beacon.timestamp = cpu_to_le64(0);
	mgmt->u.beacon.capab_info = cpu_to_le16(WLAN_CAPABILITY_IBSS);

	pos = mgmt->u.beacon.variable;

	*pos++ = WLAN_EID_SSID;
	*pos++ = params->ssid_len;
	memcpy(pos, params->ssid, params->ssid_len);
	pos += params->ssid_len;

	*pos++ = WLAN_EID_SUPP_RATES;
	*pos++ = 8;
	sband = wiphy->bands[chandef->chan->band];

	for (i = 0; i < sband->n_bitrates; i++) {
		int rate = DIV_ROUND_UP(sband->bitrates[i].bitrate, 5);
		*pos++ = rate | 0x80;
	}

#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 7, 0)
	if (sband->band == IEEE80211_BAND_2GHZ) {
#else
	if (sband->band == NL80211_BAND_2GHZ) {
#endif
		*pos++ = WLAN_EID_DS_PARAMS;
		*pos++ = 1;
		*pos++ = chandef->chan->hw_value;
	}

	*pos++ = WLAN_EID_IBSS_PARAMS;
	*pos++ = 2;
	*pos++ = 0;
	*pos++ = 0;
#if 0
	*pos++ = WLAN_EID_EXT_SUPP_RATES;
	*pos++ = 0;
#endif
	if (params->ie) {
		memcpy(pos, params->ie, params->ie_len);
		pos += params->ie_len;
	}
	// end build frame

//	skw_set_template_frame();
	bss = cfg80211_get_bss(wiphy, chandef->chan, params->bssid,
				params->ssid, params->ssid_len,
				SKW_BSS_TYPE_IBSS,
				SKW_PRIVACY_IBSS_ANY);
	if (!bss) {
		skw_info("creating new ibss: %pM\n", iface->ibss.bssid);

		bss = cfg80211_inform_bss_frame(wiphy, chandef->chan,
				mgmt, pos - (u8 *)mgmt, DBM_TO_MBM(-30), GFP_KERNEL);
	}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 16, 0)
	// fixme:
	if (params->wep_keys) {
		__skw_add_key(wiphy, dev, 0, params->wep_tx_key, true,
			    iface->ibss.bssid, params->wep_keys);

		__skw_set_default_key(wiphy, dev, 0, params->wep_tx_key, true, true);
	}
#endif

	cfg80211_put_bss(wiphy, bss);

	skw_queue_local_event(wiphy, iface, SKW_EVENT_LOCAL_IBSS_CONNECT,
				NULL, 0);

	return 0;
}

static int skw_leave_ibss(struct wiphy *wiphy, struct net_device *dev)
{
	struct skw_disconnect_param params;
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("%s\n", netdev_name(dev));

	iface->ibss.joined = false;
	iface->ibss.ssid_len = 0;

	params.type = SKW_DISCONNECT_ONLY;
	params.reason_code = 0;

	return skw_send_msg(wiphy, dev, SKW_CMD_DISCONNECT,
			&params, sizeof(params), NULL, 0);
}

static int skw_set_wiphy_params(struct wiphy *wiphy, u32 changed)
{
	int ret = 0;
	u16 *plen;
	struct skw_tlv_conf conf;

	skw_dbg("changed: 0x%x\n", changed);

	ret = skw_tlv_alloc(&conf, 128, GFP_KERNEL);
	if (ret)
		return ret;

	plen = skw_tlv_reserve(&conf, 2);
	if (!plen) {
		skw_tlv_free(&conf);
		return -ENOMEM;
	}

	if (changed & WIPHY_PARAM_RETRY_SHORT) {
		if (skw_tlv_add(&conf, SKW_MIB_RETRY_SHORT,
				&wiphy->retry_short,
				sizeof(wiphy->retry_short)))
			skw_err("add SKW_MIB_RETRY_SHORT failed.\n");
	}

	if (changed & WIPHY_PARAM_RETRY_LONG) {
		if (skw_tlv_add(&conf, SKW_MIB_RETRY_LONG,
				&wiphy->retry_long,
				sizeof(wiphy->retry_long)))
			skw_err("add SKW_MIB_RETRY_LONG failed.\n");
	}

	if (changed & WIPHY_PARAM_FRAG_THRESHOLD) {
		if (skw_tlv_add(&conf, SKW_MIB_FRAG_THRESHOLD,
				&wiphy->frag_threshold,
				sizeof(wiphy->frag_threshold)))
			skw_err("add SKW_MIB_FRAG_THRESHOLD failed.\n");
	}

	if (changed & WIPHY_PARAM_RTS_THRESHOLD) {
		if (skw_tlv_add(&conf, SKW_MIB_RTS_THRESHOLD,
				  &wiphy->rts_threshold,
				  sizeof(wiphy->rts_threshold)))
			skw_err("add SKW_MIB_RTS_THRESHOLD failed.\n");
	}

	if (conf.total_len) {
		*plen = conf.total_len;
		ret = skw_msg_xmit(wiphy, 0, SKW_CMD_SET_MIB, conf.buff,
				conf.total_len, NULL, 0);
	}

	skw_tlv_free(&conf);

	return ret;
}

static int skw_sched_scan_start(struct wiphy *wiphy, struct net_device *dev,
				struct cfg80211_sched_scan_request *req)
{
	int i, ret;
	u16 *chan = NULL;

	u32 delay = 0;
	u64 reqid = 0;
	s8 relative_rssi = 0;
	bool relative_rssi_set = false;
	s32 min_rssi_thold = 0;
	int n_scan_plans = 0, n_plans_len = 0;
	int n_ssids_len, n_match_len;
	int size, fixed, offset = 0;

	struct skw_sched_match_sets *match_sets;
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_sched_scan_param *params;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 12, 0)
	reqid = req->reqid;
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 11, 0)
	relative_rssi_set = req->relative_rssi_set;
	relative_rssi = req->relative_rssi;
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 4, 0)
	n_scan_plans = req->n_scan_plans;
	n_plans_len = n_scan_plans * sizeof(*req->scan_plans);
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 0, 0)
	delay = req->delay;
#endif

#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 15, 0)
	min_rssi_thold = req->rssi_thold;
#else
	min_rssi_thold = req->min_rssi_thold;
#endif

	skw_dbg("%s, n_ssids: %d, n_channels: %d, n_match: %d, n_plans: %d, ie_len: %zd\n",
		netdev_name(dev), req->n_ssids, req->n_channels,
		req->n_match_sets, n_scan_plans, req->ie_len);

	fixed = sizeof(struct skw_sched_scan_param);
	n_ssids_len = req->n_ssids * sizeof(struct cfg80211_ssid);
	n_match_len = req->n_match_sets * sizeof(struct skw_sched_match_sets);

	size = fixed + req->ie_len + n_ssids_len + n_plans_len + n_match_len +
	       req->n_channels * sizeof(u16);

	params = SKW_ZALLOC(size, GFP_KERNEL);
	if (!params) {
		skw_err("malloc failed, size: %d\n", size);

		return -ENOMEM;
	}

	params->req_id = reqid;
	params->flags = req->flags;
	params->delay = delay;
	params->min_rssi_thold = min_rssi_thold;
	params->relative_rssi_set = relative_rssi_set;
	params->relative_rssi = relative_rssi;
	params->scan_width = NL80211_BSS_CHAN_WIDTH_20;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
	skw_ether_copy(params->mac_addr, req->mac_addr);
	skw_ether_copy(params->mac_addr_mask, req->mac_addr_mask);
#endif

	params->n_ssids = req->n_ssids;
	if (req->n_ssids) {
		params->n_ssid_offset = fixed + offset;
		params->n_ssids_len = n_ssids_len;
		memcpy(params->data + offset, req->ssids, n_ssids_len);

		offset += n_ssids_len;
	}

	match_sets = (struct skw_sched_match_sets *)((u8 *)params->data + offset);
	for (i = 0; i < req->n_match_sets; i++) {
		memcpy(match_sets[i].ssid, req->match_sets[i].ssid.ssid, 32);
		match_sets[i].ssid_len = req->match_sets[i].ssid.ssid_len;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 15, 0)
		match_sets[i].rssi_thold = req->match_sets[i].rssi_thold;
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 12, 0)
		skw_ether_copy(match_sets[i].bssid, req->match_sets[i].bssid);
#endif
	}

	params->n_match_sets = req->n_match_sets;
	params->match_sets_offset = fixed + offset;
	params->match_sets_len = n_match_len;
	offset += n_match_len;

	params->n_scan_plans = n_scan_plans;
	if (n_scan_plans) {
		params->scan_plans_offset = fixed + offset;
		params->scan_plans_len = n_plans_len;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 4, 0)
		memcpy(params->data + offset, req->scan_plans, n_plans_len);
#endif

		offset += n_plans_len;
	}

	if (req->ie_len) {
		params->ie_offset = fixed + offset;
		params->ie_len = req->ie_len;
		memcpy(params->data + offset, req->ie, req->ie_len);
		offset += req->ie_len;
	}

	chan = (u16 *)(params->data + offset);
	for (i = 0; i < req->n_channels; i++) {
		chan[i] = req->channels[i]->hw_value;

		/* BIT[15]: set 1 means to run a passive scan on this channel */
		if (req->channels[i]->flags & SKW_PASSIVE_SCAN)
			chan[i] |= SKW_SCAN_FLAG_PASSIVE;
	}

	params->n_channels = req->n_channels;
	params->channels_len = req->n_channels * sizeof(u16);
	params->channels_offset = fixed + offset;

	skw->sched_scan_req = req;
	ret = skw_send_msg(wiphy, dev, SKW_CMD_START_SCHED_SCAN,
			   params, size, NULL, 0);
	if (ret) {
		skw_err("failed, ret: %d\n", ret);
		skw->sched_scan_req = NULL;
	}

	SKW_KFREE(params);

	return ret;
}

static int skw_sched_scan_stop(struct wiphy *wiphy,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 12, 0)
			       struct net_device *dev, u64 reqid
#else
			       struct net_device *dev
#endif
			       SKW_NULL)
{
	u64 scan_id = 0;
	struct skw_core *skw = wiphy_priv(wiphy);

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 12, 0)
	scan_id = reqid;
#endif

	skw_dbg("dev: %s, id: %lld, actived: %d\n",
		netdev_name(dev), scan_id, !!skw->sched_scan_req);

	if (!skw->sched_scan_req)
		return 0;

	skw->sched_scan_req = NULL;
	return skw_send_msg(wiphy, dev, SKW_CMD_STOP_SCHED_SCAN,
			&scan_id, sizeof(scan_id), NULL, 0);
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
static void skw_mgmt_frame_register(struct wiphy *wiphy,
				    struct wireless_dev *wdev,
				    struct mgmt_frame_regs *upd)
{
	u64 ts;
	int ret = 0, idx;
	struct skw_mgmt_register_param param;
	struct skw_iface *iface = SKW_WDEV_TO_IFACE(wdev);
	u16 new_mask = upd->interface_stypes;
	u16 temp_mask = new_mask ^ iface->mgmt_frame_bitmap;
	u16 frame_mtype;
	bool reg;

	if (!temp_mask)
		return;

	while (temp_mask) {
		idx = ffs(temp_mask) - 1;
		SKW_CLEAR(temp_mask, BIT(idx));
		frame_mtype = idx << 4;
		reg = new_mask & BIT(idx);

		skw_dbg("%s %s filter %s\n", skw_iftype_name(wdev->iftype),
			reg ? "add" : "del", skw_mgmt_name(frame_mtype));

		param.frame_type = frame_mtype;
		param.reg = reg;
		ts = local_clock();
		do_div(ts, 1000000);

		param.timestamp = ts;
		ret = skw_msg_xmit(wiphy, iface->id, SKW_CMD_REGISTER_FRAME,
				&param, sizeof(param), NULL, 0);
		if (ret) {
			skw_err("%s %s failed, ret: %d\n",
				reg ? "add" : "del",
				skw_mgmt_name(frame_mtype), ret);
		}
	}

	iface->mgmt_frame_bitmap = new_mask;
}
#else
static void skw_mgmt_frame_register(struct wiphy *wiphy,
				    struct wireless_dev *wdev,
				    u16 frame_type, bool reg)
{
	u64 ts;
	int ret = 0;
	struct skw_mgmt_register_param param;
	int type = (frame_type >> 4) & 0xf;
	struct skw_iface *iface = SKW_WDEV_TO_IFACE(wdev);
	u16 bitmap = iface->mgmt_frame_bitmap;

	if (reg)
		iface->mgmt_frame_bitmap |= BIT(type);
	else
		iface->mgmt_frame_bitmap &= ~BIT(type);

	if (bitmap == iface->mgmt_frame_bitmap)
		return;

	skw_dbg("%s %s filter %s\n", skw_iftype_name(wdev->iftype),
		reg ? "add" : "del", skw_mgmt_name(frame_type));

	param.frame_type = frame_type;
	param.reg = reg;
	ts = local_clock();
	do_div(ts, 1000000);

	param.timestamp = ts;
	ret = skw_msg_xmit(wiphy, iface->id, SKW_CMD_REGISTER_FRAME,
			   &param, sizeof(param), NULL, 0);
	if (ret) {
		skw_err("%s %s failed, ret: %d\n",
			reg ? "add" : "del",
			skw_mgmt_name(frame_type), ret);
	}
}
#endif

static int skw_set_power_mgmt(struct wiphy *wiphy, struct net_device *dev,
				bool enabled, int timeout)
{
	/* firmware trigger legacy ps automatically */
	skw_dbg("%s, enabled: %d, timeout: %d\n",
		netdev_name(dev), enabled, timeout);

	return 0;
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 14, 0)
static int skw_set_qos_map(struct wiphy *wiphy, struct net_device *dev,
			    struct cfg80211_qos_map *qos_map)
{
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("ndev: %s, %s qos_map\n", netdev_name(dev),
		qos_map ? "add" : "del");

	if (!qos_map) {
		SKW_KFREE(iface->qos_map);
		return 0;
	}

	if (!iface->qos_map) {
		iface->qos_map = SKW_ZALLOC(sizeof(*qos_map), GFP_KERNEL);
		if (IS_ERR_OR_NULL(iface->qos_map)) {
			iface->qos_map = NULL;
			return -ENOMEM;
		}
	}

	memcpy(iface->qos_map, qos_map, sizeof(*qos_map));

	return 0;
}
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 18, 0)
static int skw_add_tx_ts(struct wiphy *wiphy, struct net_device *ndev,
			u8 tsid, const u8 *peer, u8 up, u16 admitted_time)
{
	struct skw_ts_info ts;

	skw_dbg("dev: %s, ts id: %d, addr: %pM, up: %d, time: %d\n",
		netdev_name(ndev), tsid, peer, up, admitted_time);
	/* cfg80211 will make a sanity check */
	ts.up = up;
	ts.tsid = tsid;
	skw_ether_copy(ts.peer, peer);
	ts.admitted_time = admitted_time;

	return skw_send_msg(wiphy, ndev, SKW_CMD_ADD_TX_TS,
			    &ts, sizeof(ts), NULL, 0);
}

static int skw_del_tx_ts(struct wiphy *wiphy, struct net_device *ndev,
				u8 tsid, const u8 *peer)
{
	struct skw_ts_info ts;

	skw_dbg("dev: %s, ts id: %d, addr: %pM\n",
		netdev_name(ndev), tsid, peer);

	ts.tsid = tsid;
	skw_ether_copy(ts.peer, peer);
	ts.up = 0xFF;
	ts.admitted_time = 0;

	return skw_send_msg(wiphy, ndev, SKW_CMD_DEL_TX_TS,
			    &ts, sizeof(ts), NULL, 0);
}
#endif

#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 11, 0)
static int skw_tdls_oper(struct wiphy *wiphy, struct net_device *ndev,
			 u8 *peer_addr, enum nl80211_tdls_operation oper)
#else
static int skw_tdls_oper(struct wiphy *wiphy, struct net_device *ndev,
			 const u8 *peer_addr, enum nl80211_tdls_operation oper)
#endif
{
	int ret = 0;
	struct skw_iface *iface = netdev_priv(ndev);
	struct skw_tdls_oper tdls;
	struct skw_peer_ctx *ctx;

	skw_dbg("dev: %s, oper: %d, addr: %pM\n",
		netdev_name(ndev), oper, peer_addr);

	ctx = skw_peer_ctx(iface, peer_addr);
	if (!ctx)
		return -ENOENT;

	switch (oper) {
	case NL80211_TDLS_ENABLE_LINK:
		skw_peer_ctx_transmit(ctx, true);
		break;

	case NL80211_TDLS_DISABLE_LINK:
		skw_peer_ctx_transmit(ctx, false);
		skw_peer_ctx_bind(iface, ctx, NULL);

		break;

	default:
		ret = -ENOTSUPP;
		break;
	}

	if (ret)
		return ret;

	tdls.oper = oper;
	skw_ether_copy(tdls.peer_addr, peer_addr);

	return skw_send_msg(wiphy, ndev, SKW_CMD_TDLS_OPER, &tdls,
			    sizeof(tdls), NULL, 0);
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
static int skw_tdls_chn_switch(struct wiphy *wiphy, struct net_device *ndev,
		const u8 *addr, u8 oper_class, struct cfg80211_chan_def *def)
{
	int ret;
	struct skw_tdls_chan_switch tdls;
	struct skw_peer_ctx *ctx;
	struct skw_iface *iface = netdev_priv(ndev);

	skw_dbg("dev: %s, addr: %pM, def chan: %d\n",
		netdev_name(ndev), addr, def->chan->hw_value);

	ctx = skw_peer_ctx(iface, addr);
	if (!ctx) {
		skw_err("can't find tdls peer: %pM\n", addr);
		return -EINVAL;
	}

	if (!skw_channel_allowed(wiphy, def->chan->hw_value))
		return -EBUSY;

	switch (def->width) {
	case NL80211_CHAN_WIDTH_20:
	case NL80211_CHAN_WIDTH_20_NOHT:
		tdls.chan_width = SKW_CHAN_WIDTH_20;
		break;
	case NL80211_CHAN_WIDTH_40:
		tdls.chan_width = SKW_CHAN_WIDTH_40;
		break;
	case NL80211_CHAN_WIDTH_80:
		tdls.chan_width = SKW_CHAN_WIDTH_80;
		break;
	default:
		skw_err("channel width: %d not support\n", def->width);
		return -ENOTSUPP;
	}

	skw_ether_copy(tdls.addr, addr);
	tdls.chn_switch_enable = 1;
	tdls.oper_class = oper_class;
	tdls.chn = def->chan->hw_value;
	tdls.band = def->chan->band;

	ret = skw_send_msg(wiphy, ndev, SKW_CMD_TDLS_CHANNEL_SWITCH,
			   &tdls, sizeof(tdls), NULL, 0);
	if (!ret) {
		skw_peer_ctx_lock(ctx);

		if (ctx->peer)
			ctx->peer->channel = def->chan->hw_value;

		skw_peer_ctx_unlock(ctx);
	}

	return ret;
}

static void skw_tdls_cancel_chn_switch(struct wiphy *wiphy,
		struct net_device *ndev, const u8 *addr)
{
	struct skw_tdls_chan_switch tdls;
	struct skw_iface *iface = netdev_priv(ndev);

	skw_dbg("dev: %s, addr: %pM\n", netdev_name(ndev), addr);

	if (!skw_peer_ctx(iface, addr)) {
		skw_dbg("can't find tdls peer:%pM\n", addr);
		return;
	}

	memset(&tdls, 0x0, sizeof(tdls));

	tdls.chn_switch_enable = 0;
	skw_ether_copy(tdls.addr, addr);

	if (skw_send_msg(wiphy, ndev, SKW_CMD_TDLS_CHANNEL_SWITCH,
			 &tdls, sizeof(tdls), NULL, 0) < 0)
		skw_err("set command SKW_CMD_TDLS_CANCEL_CHN_SWITCH failed\n");
}
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 11, 0)
//iw phy5 wowlan enable patterns 28+43:34:-:12 16+33:-:11:ee:12:34:-:88:99
static int skw_wow_enable(struct wiphy *wiphy)
{
	int ret = 0;
#ifdef CONFIG_PM
	struct cfg80211_wowlan *wow = wiphy->wowlan_config;
	struct cfg80211_pkt_pattern *patterns = wow->patterns;
	u32 i, j;
	int total;
	struct skw_spd_action_param *spd = NULL;
	struct skw_wow_input_param *wow_param = NULL;
	struct skw_wow_rule *rule;
	struct skw_pkt_pattern *ptn;
	struct skw_pkt_pattern ptn_tmp;
	int vi = 0;
	int y, b, start = 0, gap = 0;
	u8 *rdata;

	total = sizeof(struct skw_spd_action_param) +
			 sizeof(struct skw_wow_input_param);

	if (wow->any) {
		spd = SKW_ZALLOC(total, GFP_KERNEL);
		if (!spd) {
			skw_err("malloc failed, size: %d\n", total);
			return -ENOMEM;
		}

		wow_param = (struct skw_wow_input_param *)((u8 *)spd
			 + sizeof(*spd));
		wow_param->wow_flags = SKW_WOW_ANY_PKT;
		wow_param->rule_num = 0;
		spd->sub_cmd = ACTION_EN_WOW;
		spd->len = sizeof(struct skw_wow_input_param);
		goto cmd_send;
	}

	total += sizeof(struct skw_wow_rule) * wow->n_patterns;

	spd = SKW_ZALLOC(total, GFP_KERNEL);
	if (!spd) {
		skw_err("malloc failed, size: %d\n", total);
		return -ENOMEM;
	}

	wow_param = (struct skw_wow_input_param *)((u8 *)spd
			+ sizeof(*spd));
	wow_param->rule_num = wow->n_patterns;
	spd->sub_cmd = ACTION_EN_WOW;

	if (wow->disconnect)
		wow_param->wow_flags |= SKW_WOW_DISCONNECT;

	if (wow->magic_pkt)
		wow_param->wow_flags |= SKW_WOW_MAGIC_PKT;

	if (wow->gtk_rekey_failure)
		wow_param->wow_flags |= SKW_WOW_GTK_REKEY_FAIL;

	if (wow->eap_identity_req)
		wow_param->wow_flags |= SKW_WOW_EAP_IDENTITY_REQ;

	if (wow->four_way_handshake)
		wow_param->wow_flags |= SKW_WOW_FOUR_WAY_HANDSHAKE;

	if (wow->rfkill_release)
		wow_param->wow_flags |= SKW_WOW_RFKILL_RELEASE;

	for (i = 0; i < wow_param->rule_num; i++) {
		rule = &wow_param->rules[i];
		rdata = rule->rule;
		ptn_tmp.op = PAT_OP_TYPE_SAME;
		ptn_tmp.type_offset = PAT_TYPE_ETH;
		ptn_tmp.offset = patterns[i].pkt_offset;
		ptn_tmp.len = 0;

		vi = 0;
		start = 0;
		gap = 0;
		for (j = 0; j < patterns[i].pattern_len; j++) {
			y = round_up(j + 1, 8) / 8 - 1;
			b = j % 8;
			if (patterns[i].mask[y] & BIT(b)) {
				if (!start) {
					if (vi + sizeof(ptn_tmp)
						>= sizeof(rule->rule)) {
						skw_warn("pat:%d overage\n", i);
						break;
					}

					ptn =
					(struct skw_pkt_pattern *)&rdata[vi];
					memcpy(ptn, &ptn_tmp, sizeof(ptn_tmp));
					ptn->offset += gap;
					vi += sizeof(ptn_tmp);
				}

				rdata[vi++] = patterns[i].pattern[j];
				ptn->len++;
				start = 1;
				gap++;

				if (vi >= sizeof(rule->rule)) {
					skw_warn("pat:%d overage\n", i);
					break;
				}
			} else {
				gap++;
				start = 0;
			}
		}
		rule->len = vi;

		skw_hex_dump("rule", rule, sizeof(*rule), false);
	}

	spd->len = sizeof(struct skw_wow_input_param) +
		sizeof(struct skw_wow_rule) * wow_param->rule_num;

cmd_send:
	skw_dbg("len:%d %d\n", spd->len, total);
	skw_hex_dump("wow", spd, total, false);

	ret = skw_msg_xmit(wiphy, 0, SKW_CMD_SET_SPD_ACTION,
			spd, total, NULL, 0);
	if (ret)
		skw_err("failed, ret: %d\n", ret);

	SKW_KFREE(spd);
#endif
	return ret;
}
#endif

int skw_wow_disable(struct wiphy *wiphy)
{
	struct skw_spd_action_param spd;
	int ret = 0;

	spd.sub_cmd = ACTION_DIS_WOW;
	spd.len = 0;

	ret = skw_msg_xmit(wiphy, 0, SKW_CMD_SET_SPD_ACTION,
			&spd, sizeof(spd), NULL, 0);
	if (ret)
		skw_err("failed, ret: %d\n", ret);

	return ret;
}

static int skw_suspend(struct wiphy *wiphy, struct cfg80211_wowlan *wow)
{
	int ret;
	unsigned long flags;
	struct skw_suspend_t suspend;
	struct skw_core *skw = wiphy_priv(wiphy);

	skw_dbg("WoW: %s, skw flags: 0x%lx\n",
		wow ? "enabled" : "disabled", skw->flags);

	set_bit(SKW_FLAG_BLOCK_TX, &skw->flags);

	memset(&suspend, 0x0, sizeof(suspend));

	flags = BIT(SKW_CMD_FLAG_IGNORE_BLOCK_TX) |
		BIT(SKW_CMD_FLAG_NO_ACK) |
		BIT(SKW_CMD_FLAG_NO_WAKELOCK);

	if (skw->hw.bus == SKW_BUS_SDIO)
		flags |= BIT(SKW_CMD_FLAG_DISABLE_IRQ);

	/* WoW disabled */
	if (!wow) {
		suspend.wow_enable = 0;
		goto send;
	}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
	if (wow->nd_config)
		skw_sched_scan_start(wiphy, NULL, wow->nd_config);
#endif

	suspend.wow_enable = 1;

	if (wow->disconnect)
		suspend.wow_flags |= SKW_WOW_DISCONNECT;

	if (wow->magic_pkt)
		suspend.wow_flags |= SKW_WOW_MAGIC_PKT;

	if (wow->gtk_rekey_failure)
		suspend.wow_flags |= SKW_WOW_GTK_REKEY_FAIL;

	if (wow->eap_identity_req)
		suspend.wow_flags |= SKW_WOW_EAP_IDENTITY_REQ;

	if (wow->four_way_handshake)
		suspend.wow_flags |= SKW_WOW_FOUR_WAY_HANDSHAKE;

	if (wow->rfkill_release)
		suspend.wow_flags |= SKW_WOW_RFKILL_RELEASE;

send:
	ret = skw_msg_xmit_timeout(wiphy, 0, SKW_CMD_SUSPEND, &suspend,
				   sizeof(suspend), NULL, 0, "SKW_CMD_SUSPEND",
				   msecs_to_jiffies(2000), flags);
	if (ret) {
		clear_bit(SKW_FLAG_BLOCK_TX, &skw->flags);

		skw_err("ret: %d, fw flags: 0x%lx\n", ret, skw->flags);
	}

	return  ret;
}

static int skw_resume(struct wiphy *wiphy)
{
	int ret = 0;
	struct skw_core *skw = wiphy_priv(wiphy);

	skw_dbg("skw flags: 0x%lx\n", skw->flags);

	clear_bit(SKW_FLAG_BLOCK_TX, &skw->flags);

	if (skw->hw.bus != SKW_BUS_PCIE)
		return 0;

	ret = skw_msg_xmit(wiphy, 0, SKW_CMD_RESUME, NULL, 0, NULL, 0);
	if (ret)
		skw_warn("ret: %d\n", ret);

	return 0;
}

static void skw_set_wakeup(struct wiphy *wiphy, bool enabled)
{
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 11, 0)
	if (enabled)
		skw_wow_enable(wiphy);
	else
		skw_wow_disable(wiphy);
#endif

	device_set_wakeup_enable(wiphy_dev(wiphy), enabled);
}

static int skw_start_p2p_device(struct wiphy *wiphy, struct wireless_dev *wdev)
{
	skw_dbg("traced\n");

	return 0;
}

static void skw_stop_p2p_device(struct wiphy *wiphy, struct wireless_dev *wdev)
{
	skw_dbg("traced\n");
}

static int skw_probe_client(struct wiphy *wiphy, struct net_device *dev,
			    const u8 *peer, u64 *cookie)
{
	skw_dbg("traced\n");

	return 0;
}

static int skw_change_bss(struct wiphy *wiphy, struct net_device *ndev,
		struct bss_parameters *params)
{
	struct skw_iface *iface = netdev_priv(ndev);

	skw_dbg("%s ap_isolate:%d\n", netdev_name(ndev), params->ap_isolate);
	if (params->ap_isolate >= 0)
		iface->sap.ap_isolate = params->ap_isolate;

	return 0;
}

static int skw_set_monitor_channel(struct wiphy *wiphy,
		struct cfg80211_chan_def *chandef)
{
	return skw_cmd_monitor(wiphy, chandef, SKW_MONITOR_COMMON);
}

static int skw_dump_survey(struct wiphy *wiphy, struct net_device *ndev,
		int idx, struct survey_info *info)
{
	struct skw_iface *iface = netdev_priv(ndev);
	struct skw_survey_info *sinfo = NULL;
	int freq;

	skw_detail("%s, idx: %d\n", netdev_name(ndev), idx);

	sinfo = list_first_entry_or_null(&iface->survey_list,
					 struct skw_survey_info, list);
	if (!sinfo) {
		skw_dbg("last idx: %d\n", idx);
		return -EINVAL;
	}

	list_del(&sinfo->list);

	freq = skw_to_freq(sinfo->data.chan);
	info->noise = sinfo->data.noise;
	info->channel = ieee80211_get_channel(wiphy, freq);

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 0, 0)
	info->time = sinfo->data.time;
	info->time_busy = sinfo->data.time_busy;
	info->time_ext_busy = sinfo->data.time_ext_busy;
	info->filled = SURVEY_INFO_TIME |
		       SURVEY_INFO_TIME_BUSY |
		       SURVEY_INFO_TIME_EXT_BUSY |
		       SURVEY_INFO_NOISE_DBM;
#else
	info->channel_time = sinfo->data.time;
	info->channel_time_busy = sinfo->data.time_busy;
	info->channel_time_ext_busy = sinfo->data.time_ext_busy;
	info->filled = SURVEY_INFO_CHANNEL_TIME |
		       SURVEY_INFO_CHANNEL_TIME_BUSY |
		       SURVEY_INFO_CHANNEL_TIME_EXT_BUSY |
		       SURVEY_INFO_NOISE_DBM;
#endif

	SKW_KFREE(sinfo);

	return 0;
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 17, 0)
static int skw_external_auth(struct wiphy *wiphy, struct net_device *ndev,
		struct cfg80211_external_auth_params *params)
{
	struct skw_iface *iface = netdev_priv(ndev);

	skw_dbg("%s bssid: %pM, action: %u, status: %u\n",
		 netdev_name(ndev), params->bssid,
		 params->action, params->status);

	if (iface->wdev.iftype == NL80211_IFTYPE_AP ||
	    iface->wdev.iftype == NL80211_IFTYPE_P2P_GO) {
		return 0;
	}

	/* Non-AP STA */
	if (!iface->sta.conn) {
		skw_set_state(&iface->sta.core.sm, SKW_STATE_NONE);
		return -EINVAL;
	}

	if (params->status != WLAN_STATUS_SUCCESS) {
		skw_set_state(&iface->sta.core.sm, SKW_STATE_NONE);
		skw_unjoin(wiphy, ndev, params->bssid, SKW_LEAVE, false);
		// release peer and report connect result

		cfg80211_connect_result(iface->ndev, params->bssid,
					NULL, 0, NULL, 0,
					WLAN_STATUS_UNSPECIFIED_FAILURE,
					GFP_KERNEL);
		return 0;
	}

	skw_set_state(&iface->sta.core.sm, SKW_STATE_AUTHED);

	return skw_connect_assoc(wiphy, ndev, iface->sta.conn);
}
#endif

static int skw_update_ft_ies(struct wiphy *wiphy, struct net_device *dev,
			     struct cfg80211_update_ft_ies_params *ftie)
{
#if 0
	struct skw_iface *iface = NULL;
	struct cfg80211_assoc_request req;
	u8 *ie = NULL;
	int ret = 0;

	skw_dbg("md:%u\n", ftie->md);

	if (ftie->ie && ftie->ie_len) {
		iface->sta.ft_ie = SKW_ZALLOC(ftie->ie_len, GFP_KERNEL);
		if (iface->sta.ft_ie)
			memcpy(iface->sta.ft_ie, ftie->ie, ftie->ie_len);
		iface->sta.ft_ie_len = ftie->ie_len;
		skw_dbg("ft ie len:%u\n", iface->sta.ft_ie_len);
	}

	skw_dbg("state:%u\n", iface->sta.core.sm.state);
	if (iface->sta.core.sm.state != SKW_STATE_AUTHING) {
		skw_dbg("received update ft cmd during EAPOL process\n");
		return 0;
	}

	// req.bss = iface->sta.associating_bss;
	req.ie_len = iface->sta.assoc_ie_len + ftie->ie_len;
	ie = SKW_ZALLOC(req.ie_len, GFP_KERNEL);
	if (!ie) {
		skw_err("Mem is not enough\n");
		return -ENOMEM;
	}
	memcpy(ie, ftie->ie, ftie->ie_len);
	memcpy(ie + ftie->ie_len, iface->sta.assoc_ie,
		iface->sta.assoc_ie_len);

	req.ie = ie;
	req.prev_bssid = iface->sta.core.bssid;
	req.use_mfp = iface->sta.use_mfp;
	req.flags = iface->sta.flags;
	req.ht_capa = iface->sta.ht_capa;
	req.ht_capa_mask = iface->sta.ht_capa_mask;
	req.vht_capa = iface->sta.vht_capa;
	req.vht_capa_mask = iface->sta.vht_capa_mask;

	ret = skw_assoc(iface->wdev.wiphy, iface->ndev, &req);

	SKW_KFREE(ie);
	return ret;
#endif
	return 0;
}

static int skw_start_radar_detection(struct wiphy *wiphy, struct net_device *dev,
				struct cfg80211_chan_def *chandef, u32 cac_time_ms)
{
	int ret;
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("dev: %s, channel: %d, cac time: %dms, dfs_region: %d, fw enabled: %d\n",
		netdev_name(dev), chandef->chan->hw_value, cac_time_ms,
		skw->dfs.region, skw->dfs.fw_enabled);

	if (!skw->dfs.fw_enabled)
		return -EINVAL;

	ret = skw_dfs_chan_init(wiphy, dev, chandef, cac_time_ms);
	if (ret)
		return ret;

	ret = skw_dfs_start_cac(wiphy, dev);
	if (!ret) {
		set_bit(SKW_DFS_FLAG_CAC_MODE, &iface->sap.dfs.flags);
		queue_delayed_work(skw->event_wq, &iface->sap.dfs.cac_work,
				msecs_to_jiffies(cac_time_ms));
	}

	return ret;
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 12, 0)
static int skw_channel_switch(struct wiphy *wiphy, struct net_device *dev,
				  struct cfg80211_csa_settings *csa)
{
	int ret;
	char *buff;
	const u8 *ie;
	int ie_len, offset = 0;

	skw_dbg("dev: %s, chan: %d, width: %d\n",
		netdev_name(dev), csa->chandef.chan->hw_value,
		csa->chandef.width);

	buff = SKW_ZALLOC(csa->beacon_csa.tail_len, GFP_KERNEL);
	if (!buff)
		return -ENOMEM;

	ie = cfg80211_find_ie(WLAN_EID_CHANNEL_SWITCH,
				  csa->beacon_csa.tail,
				  csa->beacon_csa.tail_len);
	if (ie) {
		ie_len = ie[1] + 2;

		memcpy(buff, ie, ie_len);
		offset = ie_len;
	}

	ie = cfg80211_find_ie(WLAN_EID_EXT_CHANSWITCH_ANN,
				   csa->beacon_csa.tail,
				   csa->beacon_csa.tail_len);
	if (ie) {
		ie_len = ie[1] + 2;

		memcpy(buff + offset, ie, ie_len);
		offset += ie_len;
	}

	ie = cfg80211_find_ie(WLAN_EID_WIDE_BW_CHANNEL_SWITCH,
				   csa->beacon_csa.tail,
				   csa->beacon_csa.tail_len);
	if (ie) {
		ie_len = ie[1] + 2;

		memcpy(buff + offset, ie, ie_len);
		offset += ie_len;
	}

	ie = cfg80211_find_ie(WLAN_EID_CHANNEL_SWITCH_WRAPPER,
				   csa->beacon_csa.tail,
				   csa->beacon_csa.tail_len);
	if (ie) {
		ie_len = ie[1] + 2;

		memcpy(buff + offset, ie, ie_len);
		offset += ie_len;
	}

	ret = skw_send_msg(wiphy, dev, SKW_CMD_REQ_CHAN_SWITCH,
			buff, offset, NULL, 0);

	SKW_KFREE(buff);

	return ret;
}
#endif

static int skw_tdls_mgmt(struct wiphy *wiphy, struct net_device *dev,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
			 const
#endif
			 u8 *peer, u8 action, u8 token, u16 status,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 15, 0)
			 u32 peer_capability,
#endif
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 17, 0)
			 bool initiator,
#endif
			 const u8 *ies, size_t ies_len)
{
	u32 capa = 0;
	bool tdls_initiator = false;
	struct skw_core *skw = wiphy_priv(wiphy);

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 15, 0)
	capa = peer_capability;
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 17, 0)
	tdls_initiator = initiator;
#endif

	return skw_tdls_build_send_mgmt(skw, dev, peer, action, token, status,
					capa, tdls_initiator, ies, ies_len);
}

static struct cfg80211_ops skw_cfg80211_ops  = {
	.add_virtual_intf = skw_add_virtual_intf,
	.del_virtual_intf = skw_del_virtual_intf,
	.change_virtual_intf = skw_change_intf,
	.scan = skw_scan,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
	.abort_scan = skw_abort_scan,
#endif
	.get_key = skw_get_key,
	.add_key = skw_add_key,
	.del_key = skw_del_key,
	.set_default_key = skw_set_default_key,
	.set_default_mgmt_key = skw_set_default_mgmt_key,
	.change_beacon = skw_change_beacon,
	.start_ap = skw_start_ap,
	.change_station = skw_change_station,
	.stop_ap = skw_stop_ap,
	.add_station = skw_add_station,
	.del_station = skw_del_station,
	.get_station = skw_get_station,
	.auth = skw_cfg80211_auth,
	.assoc = skw_cfg80211_assoc,
	.deauth = skw_cfg80211_deauth,
	.disassoc = skw_cfg80211_disassoc,
	.connect = skw_cfg80211_connect,
	.disconnect = skw_cfg80211_disconnect,
	.join_ibss = skw_join_ibss,
	.leave_ibss = skw_leave_ibss,
	.set_wiphy_params = skw_set_wiphy_params,
	.remain_on_channel = skw_remain_on_channel,
	.cancel_remain_on_channel = skw_cancel_roc,
	.mgmt_tx = skw_cfg80211_mgmt_tx,
	.sched_scan_start = skw_sched_scan_start,
	.sched_scan_stop = skw_sched_scan_stop,
#if (KERNEL_VERSION(5, 8, 0) <= LINUX_VERSION_CODE)
	.update_mgmt_frame_registrations = skw_mgmt_frame_register,
#else
	.mgmt_frame_register = skw_mgmt_frame_register,
#endif
	.set_power_mgmt = skw_set_power_mgmt,
	.set_cqm_rssi_config = skw_set_cqm_rssi_config,
	.start_p2p_device = skw_start_p2p_device,
	.stop_p2p_device = skw_stop_p2p_device,
	.set_mac_acl = skw_set_mac_acl,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 14, 0)
	.set_qos_map = skw_set_qos_map,
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 18, 0)
	.add_tx_ts = skw_add_tx_ts,
	.del_tx_ts = skw_del_tx_ts,
#endif
	.tdls_mgmt = skw_tdls_mgmt,
	.tdls_oper = skw_tdls_oper,
	.suspend = skw_suspend,
	.resume = skw_resume,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
	.tdls_channel_switch = skw_tdls_chn_switch,
	.tdls_cancel_channel_switch = skw_tdls_cancel_chn_switch,
#endif
	.set_wakeup = skw_set_wakeup,
	.probe_client = skw_probe_client,
	.dump_survey = skw_dump_survey,
	.set_monitor_channel = skw_set_monitor_channel,
	.change_bss = skw_change_bss,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 17, 0)
	.external_auth = skw_external_auth,
#endif
	.update_ft_ies = skw_update_ft_ies,
	.start_radar_detection = skw_start_radar_detection,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 12, 0)
	.channel_switch = skw_channel_switch,
#endif
};

static void skw_regd_notifier(struct wiphy *wiphy,
			      struct regulatory_request *req)
{
	struct skw_core *skw = wiphy_priv(wiphy);

	skw_info("regd: %s, initiator = %d, dfs_region: %d\n",
		req->alpha2, req->initiator, req->dfs_region);

	skw->dfs.region = req->dfs_region;

	if (!skw_set_wiphy_regd(wiphy, req->alpha2))
		skw_cmd_set_regdom(wiphy, req->alpha2);
}

struct wiphy *skw_alloc_wiphy(int priv_size)
{
#ifdef CONFIG_SKW_STA_SME_EXT
	skw_cfg80211_ops.connect = NULL;
	skw_cfg80211_ops.disconnect = NULL;
#else
	skw_cfg80211_ops.auth = NULL;
	skw_cfg80211_ops.assoc = NULL;
	skw_cfg80211_ops.deauth = NULL;
	skw_cfg80211_ops.disassoc = NULL;
#endif

	return wiphy_new(&skw_cfg80211_ops, priv_size);
}

#ifdef CONFIG_PM
/* cfg80211 wowlan definitions */
#define SKW_WOWLAN_MAX_PATTERNS              8
#define SKW_WOWLAN_MIN_PATTERN_LEN           1
#define SKW_WOWLAN_MAX_PATTERN_LEN           255
#define SKW_WOWLAN_PKT_FILTER_ID_FIRST       201

static const struct wiphy_wowlan_support skw_wowlan_support = {
	.flags = WIPHY_WOWLAN_ANY |
		 WIPHY_WOWLAN_DISCONNECT |
		 WIPHY_WOWLAN_MAGIC_PKT,
	.n_patterns = SKW_WOWLAN_MAX_PATTERNS,
	.pattern_min_len = SKW_WOWLAN_MIN_PATTERN_LEN,
	.pattern_max_len = SKW_WOWLAN_MAX_PATTERN_LEN,
	.max_pkt_offset = SKW_WOWLAN_MAX_PATTERN_LEN,
};
#endif /* CONFIG_PM */

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 8, 0)
struct skw_iftype_ext_cap iftype_ext_cap[NUM_NL80211_IFTYPES] = {
	{NL80211_IFTYPE_STATION,	{0}, 0},
	{NL80211_IFTYPE_AP,		{0}, 0},
	{NL80211_IFTYPE_P2P_GO,		{0}, 0},
#ifndef CONFIG_SKW_LEGACY_P2P
	{NL80211_IFTYPE_P2P_DEVICE,	{0}, 0},
#endif
};

static struct skw_iftype_ext_cap *skw_get_iftype_ext_cap(u8 iftype)
{
	int i;
	struct skw_iftype_ext_cap *capab = NULL;

	for (i = 0; i < NUM_NL80211_IFTYPES; i++) {
		if (iftype_ext_cap[i].iftype == iftype)
			capab = &iftype_ext_cap[iftype];
	}

	return capab;
}

static void skw_setup_wiphy_iftype_ext_cap(struct wiphy *wiphy)
{
	struct skw_core *skw = wiphy_priv(wiphy);
	struct wiphy_iftype_ext_capab *capab = NULL;
	struct skw_iftype_ext_cap *skw_ext_cap = NULL;

	skw->num_iftype_ext_capab  = 0;

	if (wiphy->interface_modes & (BIT(NL80211_IFTYPE_STATION))) {
		capab = &skw->iftype_ext_cap[NL80211_IFTYPE_STATION];
		capab->iftype = NL80211_IFTYPE_STATION;
		skw_ext_cap = skw_get_iftype_ext_cap(capab->iftype);
		capab->extended_capabilities = skw_ext_cap->ext_cap;
		capab->extended_capabilities_mask = skw_ext_cap->ext_cap;
		capab->extended_capabilities_len = skw_ext_cap->ext_cap_len;
		skw->num_iftype_ext_capab++;
	}

	if (wiphy->interface_modes & (BIT(NL80211_IFTYPE_AP))) {
		capab = &skw->iftype_ext_cap[NL80211_IFTYPE_AP];
		capab->iftype = NL80211_IFTYPE_AP;
		skw_ext_cap = skw_get_iftype_ext_cap(capab->iftype);
		capab->extended_capabilities = skw_ext_cap->ext_cap;
		capab->extended_capabilities_mask = skw_ext_cap->ext_cap;
		capab->extended_capabilities_len = skw_ext_cap->ext_cap_len;
		skw->num_iftype_ext_capab++;
	}

	skw->num_iftype_ext_capab  = 0; //Remove it after set the actual info
	wiphy->num_iftype_ext_capab = skw->num_iftype_ext_capab;
	wiphy->iftype_ext_capab = skw->iftype_ext_cap;
}
#endif

static void skw_sync_band_capa(struct ieee80211_supported_band *band,
				struct skw_chip_info *chip)
{
	u32 flags;
	u16 bit_rate;
	int i, mcs_map;
	int tx_chain = 0, rx_chain = 0;

	band->ht_cap.cap = chip->ht_capa;
	band->ht_cap.ht_supported = true;
	band->ht_cap.ampdu_factor = chip->ht_ampdu_param & 0x3;
	band->ht_cap.ampdu_density = (chip->ht_ampdu_param >> 2) & 0x7;

	for (i = 0; i < 4; i++) {
		mcs_map = (chip->ht_rx_mcs_maps >> (i * 8)) & 0xff;
		if (mcs_map) {
			rx_chain++;
			band->ht_cap.mcs.rx_mask[i] = mcs_map;
		}

		mcs_map = (chip->ht_tx_mcs_maps >> (i * 8)) & 0xff;
		if (mcs_map)
			tx_chain++;
	}

	if (chip->fw_bw_capa & SKW_BW_2GHZ_40M)
		bit_rate = rx_chain * 150; /* Mbps */
	else
		bit_rate = rx_chain * 72;  /* Mbps */

	band->ht_cap.mcs.rx_highest = cpu_to_le16(bit_rate);
	band->ht_cap.mcs.tx_params = IEEE80211_HT_MCS_TX_DEFINED;
	if (tx_chain != rx_chain) {
		band->ht_cap.mcs.tx_params = IEEE80211_HT_MCS_TX_RX_DIFF;
		band->ht_cap.mcs.tx_params |= ((tx_chain - 1) << 2);
	}

	band->vht_cap.cap = chip->vht_capa;
	band->vht_cap.vht_supported = true;
	band->vht_cap.vht_mcs.tx_mcs_map = chip->vht_tx_mcs_maps;
	band->vht_cap.vht_mcs.rx_mcs_map = chip->vht_rx_mcs_maps;

	if (!chip->fw_bw_capa)
		return;

	/* set channel flags */
	for (flags = 0, i = 0; i < 32; i++) {
		if (!(chip->fw_bw_capa & BIT(i))) {
			switch (BIT(i)) {
			case SKW_BW_CAP_2G_20M:
			case SKW_BW_CAP_5G_20M:
				flags |= SKW_IEEE80211_CHAN_NO_20MHZ;
				break;

			case SKW_BW_CAP_2G_40M:
			case SKW_BW_CAP_5G_40M:
				flags |= IEEE80211_CHAN_NO_HT40;
				break;

			case SKW_BW_CAP_5G_80M:
				flags |= IEEE80211_CHAN_NO_80MHZ;
				break;

			case SKW_BW_CAP_5G_160M:
				flags |= IEEE80211_CHAN_NO_160MHZ;
				break;

			default:
				break;
			}
		}
	}

	skw_dbg("BW capa: 0x%x, flags: 0x%x\n", chip->fw_bw_capa, flags);

#ifdef SKW_SYNC_CHANNEL_FLAGS
	for (i = 0; i < band->n_channels; i++)
		band->channels[i].flags = flags;
#endif
}

int skw_setup_wiphy(struct wiphy *wiphy, struct skw_chip_info *chip)
{
	struct skw_core *skw = wiphy_priv(wiphy);

	wiphy->mgmt_stypes = skw_mgmt_stypes;
#if 0
	wiphy->probe_resp_offload = NL80211_PROBE_RESP_OFFLOAD_SUPPORT_WPS |
				NL80211_PROBE_RESP_OFFLOAD_SUPPORT_WPS2 |
				NL80211_PROBE_RESP_OFFLOAD_SUPPORT_P2P;
#endif

	wiphy->flags = WIPHY_FLAG_NETNS_OK |
			WIPHY_FLAG_4ADDR_AP |
			WIPHY_FLAG_4ADDR_STATION |
			WIPHY_FLAG_AP_PROBE_RESP_OFFLOAD |
			WIPHY_FLAG_REPORTS_OBSS;

#ifdef CONFIG_SKW_TDLS
	wiphy->flags |= WIPHY_FLAG_SUPPORTS_TDLS;
	wiphy->flags |= WIPHY_FLAG_TDLS_EXTERNAL_SETUP;
#endif

#ifdef CONFIG_SKW_OFFCHAN_TX
	wiphy->flags |= WIPHY_FLAG_OFFCHAN_TX;
#else
	wiphy->flags |= WIPHY_FLAG_HAS_REMAIN_ON_CHANNEL;
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 12, 0)
	wiphy->flags |= WIPHY_FLAG_HAS_CHANNEL_SWITCH;
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
	wiphy->max_num_csa_counters = 2;
#endif

	/* STA SME EXTERNAL */
	if (!test_bit(SKW_FLAG_STA_SME_EXTERNAL, &skw->flags))
		wiphy->flags |= WIPHY_FLAG_SUPPORTS_FW_ROAM;

	/* AP SME INTERNAL */
	if (!test_bit(SKW_FLAG_SAP_SME_EXTERNAL, &skw->flags)) {
		wiphy->max_acl_mac_addrs = SKW_MAX_ACL_ENTRIES;
		wiphy->flags |= WIPHY_FLAG_HAVE_AP_SME;
		wiphy->ap_sme_capa = 1;
	}

	wiphy->features = NL80211_FEATURE_SK_TX_STATUS |
			  NL80211_FEATURE_SAE |
			  NL80211_FEATURE_HT_IBSS |
			  NL80211_FEATURE_VIF_TXPOWER |
			  NL80211_FEATURE_USERSPACE_MPM |
			  NL80211_FEATURE_FULL_AP_CLIENT_STATE |
			  NL80211_FEATURE_INACTIVITY_TIMER;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
	//wiphy->features |= NL80211_FEATURE_TDLS_CHANNEL_SWITCH;
	wiphy->features |= NL80211_FEATURE_MAC_ON_CREATE;
#endif

#ifdef CONFIG_SKW_SCAN_RANDOM_MAC
	wiphy->features |= SKW_WIPHY_FEATURE_SCAN_RANDOM_MAC;
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 8, 0)
	wiphy_ext_feature_set(wiphy, NL80211_EXT_FEATURE_RRM);
	wiphy_ext_feature_set(wiphy, NL80211_EXT_FEATURE_VHT_IBSS);

	//TODO:Add an function to initialize iftype_ext_cap
	skw_setup_wiphy_iftype_ext_cap(wiphy);
#endif

#if (KERNEL_VERSION(5, 1, 0) <= LINUX_VERSION_CODE)
	wiphy->support_mbssid = true;
#else
	wiphy->bss_priv_size = sizeof(struct skw_bss_priv);
	set_bit(SKW_FLAG_MBSSID_PRIV, &skw->flags);
#endif

	wiphy->interface_modes = BIT(NL80211_IFTYPE_ADHOC) |
				 BIT(NL80211_IFTYPE_STATION) |
				 BIT(NL80211_IFTYPE_AP) |
				 BIT(NL80211_IFTYPE_P2P_GO) |
				 BIT(NL80211_IFTYPE_P2P_CLIENT) |
				 BIT(NL80211_IFTYPE_MONITOR);

#ifndef CONFIG_SKW_LEGACY_P2P
	wiphy->interface_modes |= BIT(NL80211_IFTYPE_P2P_DEVICE);
#endif

	BUILD_BUG_ON_MSG(SKW_EXTENDED_CAPA_LEN > sizeof(skw->ext_capa),
			 "SKW_EXTENDED_CAPA_LEN larger than buffer");
	wiphy->extended_capabilities = skw->ext_capa;
	wiphy->extended_capabilities_mask = skw->ext_capa;
	wiphy->extended_capabilities_len = SKW_EXTENDED_CAPA_LEN;

#if defined(CONFIG_PM)
#if (KERNEL_VERSION(3, 11, 0) <= LINUX_VERSION_CODE)
	wiphy->wowlan = &skw_wowlan_support;
#else
	memcpy(&wiphy->wowlan, &skw_wowlan_support, sizeof(skw_wowlan_support));
#endif
#endif

	skw_sync_band_capa(&skw_band_2ghz, chip);
	wiphy->bands[NL80211_BAND_2GHZ] = &skw_band_2ghz;

	skw_sync_band_capa(&skw_band_5ghz, chip);
	wiphy->bands[NL80211_BAND_5GHZ] = &skw_band_5ghz;

	wiphy->cipher_suites = skw_cipher_suites;
	wiphy->n_cipher_suites = ARRAY_SIZE(skw_cipher_suites);

	wiphy->signal_type = CFG80211_SIGNAL_TYPE_MBM;
	wiphy->max_scan_ssids = chip->max_scan_ssids;
	wiphy->max_scan_ie_len = IEEE80211_MAX_DATA_LEN; /*2304*/
	wiphy->max_remain_on_channel_duration = 500;
	wiphy->max_sched_scan_ie_len = IEEE80211_MAX_DATA_LEN;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 12, 0)
	wiphy->max_sched_scan_reqs = 1;
#endif
	wiphy->max_sched_scan_ssids = 10;
	wiphy->max_match_sets = 16;

	/* MCC support */
	wiphy->iface_combinations = skw_iface_combos;
	wiphy->n_iface_combinations = ARRAY_SIZE(skw_iface_combos);

	wiphy->addresses = skw->address;
	wiphy->n_addresses = ARRAY_SIZE(skw->address);

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 15, 0)
	wiphy->max_ap_assoc_sta = skw->fw.max_num_sta;
#endif

	wiphy->reg_notifier = skw_regd_notifier;

#ifdef CONFIG_SKW_REGD_SELF_MANAGED

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 0, 0)
	wiphy->regulatory_flags |= REGULATORY_WIPHY_SELF_MANAGED;
#elif LINUX_VERSION_CODE >= KERNEL_VERSION(3, 14, 0)
	wiphy->regulatory_flags |= REGULATORY_CUSTOM_REG;
#else
	wiphy->flags |= WIPHY_FLAG_CUSTOM_REGULATORY;
#endif
	set_bit(SKW_FLAG_PRIV_REGD, &skw->flags);

#endif

	return wiphy_register(wiphy);
}
===== ./drivers/skwifi/skw_dfs.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

// #include <linux/kernel.h>
#include <net/cfg80211.h>

#include "skw_dfs.h"
#include "skw_util.h"
#include "skw_cfg80211.h"

#define SKW_MIN_PPB_THRESH            50
#define SKW_PPB_THRESH_RATE(PPB, RATE) ((PPB * RATE + 100 - RATE) / 100)
#define SKW_PPB_THRESH(PPB) SKW_PPB_THRESH_RATE(PPB, SKW_MIN_PPB_THRESH)
#define SKW_PRF2PRI(PRF) ((1000000 + PRF / 2) / PRF)

/* percentage of pulse width tolerance */
#define SKW_WIDTH_TOLERANCE           5
#define SKW_WIDTH_LOWER(W) ((W * (100 - SKW_WIDTH_TOLERANCE) + 50) / 100)
#define SKW_WIDTH_UPPER(W) ((W * (100 + SKW_WIDTH_TOLERANCE) + 50) / 100)

#define SKW_ETSI_PATTERN(ID, WMIN, WMAX, PMIN, PMAX, PRF, PPB, CHIRP)        \
{                                                                            \
	.rule = {                                                            \
		.type_id = ID,                                               \
		.width_min = SKW_WIDTH_LOWER(WMIN),                          \
		.width_max = SKW_WIDTH_UPPER(WMAX),                          \
		.pri_min = (SKW_PRF2PRI(PMAX) - SKW_PRI_TOLERANCE),          \
		.pri_max = (SKW_PRF2PRI(PMIN) * PRF + SKW_PRI_TOLERANCE),    \
		.nr_pri = PRF,                                               \
		.ppb = PPB * PRF,                                            \
		.ppb_thresh = SKW_PPB_THRESH(PPB),                           \
		.max_pri_tolerance = SKW_PRI_TOLERANCE,                      \
		.chirp = CHIRP                                               \
	}                                                                    \
}

/* radar types as defined by ETSI EN-301-893 v1.5.1 */
static struct skw_radar_cfg skw_radar_etsi_cfgs[] = {
	SKW_ETSI_PATTERN(0,  0,  1,  700,  700, 1, 18, false),
	SKW_ETSI_PATTERN(1,  0,  5,  200, 1000, 1, 10, false),
	SKW_ETSI_PATTERN(2,  0, 15,  200, 1600, 1, 15, false),
	SKW_ETSI_PATTERN(3,  0, 15, 2300, 4000, 1, 25, false),
	SKW_ETSI_PATTERN(4, 20, 30, 2000, 4000, 1, 20, false),
	SKW_ETSI_PATTERN(5,  0,  2,  300,  400, 3, 10, false),
	SKW_ETSI_PATTERN(6,  0,  2,  400, 1200, 3, 15, false),
};

#define SKW_FCC_PATTERN(ID, WMIN, WMAX, PMIN, PMAX, PRF, PPB, CHIRP)         \
{                                                                            \
	.rule = {                                                            \
		.type_id = ID,                                               \
		.width_min = SKW_WIDTH_LOWER(WMIN),                          \
		.width_max = SKW_WIDTH_UPPER(WMAX),                          \
		.pri_min = PMIN - SKW_PRI_TOLERANCE,                         \
		.pri_max = PMAX * PRF + SKW_PRI_TOLERANCE,                   \
		.nr_pri = PRF,                                               \
		.ppb = PPB * PRF,                                            \
		.ppb_thresh = SKW_PPB_THRESH(PPB),                           \
		.max_pri_tolerance = SKW_PRI_TOLERANCE,                      \
		.chirp = CHIRP                                               \
	}                                                                    \
}

static struct skw_radar_cfg skw_radar_fcc_cfgs[] = {
	SKW_FCC_PATTERN(0, 0, 1, 1428, 1428, 1, 18, false),
	SKW_FCC_PATTERN(101, 0, 1, 518, 938, 1, 57, false),
	SKW_FCC_PATTERN(102, 0, 1, 938, 2000, 1, 27, false),
	SKW_FCC_PATTERN(103, 0, 1, 2000, 3066, 1, 18, false),
	SKW_FCC_PATTERN(2, 0, 5, 150, 230, 1, 23, false),
	SKW_FCC_PATTERN(3, 6, 10, 200, 500, 1, 16, false),
	SKW_FCC_PATTERN(4, 11, 20, 200, 500, 1, 12, false),
	SKW_FCC_PATTERN(5, 50, 100, 1000, 2000, 1, 1, true),
	SKW_FCC_PATTERN(6, 0, 1, 333, 333, 1, 9, false),
};

#define SKW_JP_PATTERN(ID, WMIN, WMAX, PMIN, PMAX, PRF, PPB, RATE, CHIRP)    \
{                                                                            \
	.rule = {                                                            \
		.type_id = ID,                                               \
		.width_min = SKW_WIDTH_LOWER(WMIN),                          \
		.width_max = SKW_WIDTH_UPPER(WMAX),                          \
		.pri_min = PMIN - SKW_PRI_TOLERANCE,                         \
		.pri_max = PMAX * PRF + SKW_PRI_TOLERANCE,                   \
		.nr_pri = PRF,                                               \
		.ppb = PPB * PRF,                                            \
		.ppb_thresh = SKW_PPB_THRESH_RATE(PPB, RATE),                \
		.max_pri_tolerance = SKW_PRI_TOLERANCE,                      \
		.chirp = CHIRP,                                              \
	}                                                                    \
}

static struct skw_radar_cfg skw_radar_jp_cfgs[] = {
	SKW_JP_PATTERN(0, 0, 1, 1428, 1428, 1, 18, 29, false),
	SKW_JP_PATTERN(1, 2, 3, 3846, 3846, 1, 18, 29, false),
	SKW_JP_PATTERN(2, 0, 1, 1388, 1388, 1, 18, 50, false),
	SKW_JP_PATTERN(3, 0, 4, 4000, 4000, 1, 18, 50, false),
	SKW_JP_PATTERN(4, 0, 5, 150, 230, 1, 23, 50, false),
	SKW_JP_PATTERN(5, 6, 10, 200, 500, 1, 16, 50, false),
	SKW_JP_PATTERN(6, 11, 20, 200, 500, 1, 12, 50, false),
	SKW_JP_PATTERN(7, 50, 100, 1000, 2000, 1, 3, 50, true),
	SKW_JP_PATTERN(5, 0, 1, 333, 333, 1, 9, 50, false),
};

static const struct skw_radar_info skw_radar_infos[] = {
	[NL80211_DFS_UNSET] = {
		.nr_cfg = 0,
		.cfgs = NULL,
	},
	[NL80211_DFS_FCC] = {
		.nr_cfg = ARRAY_SIZE(skw_radar_fcc_cfgs),
		.cfgs = skw_radar_fcc_cfgs,
	},
	[NL80211_DFS_ETSI] = {
		.nr_cfg = ARRAY_SIZE(skw_radar_etsi_cfgs),
		.cfgs = skw_radar_etsi_cfgs,
	},
	[NL80211_DFS_JP] = {
		.nr_cfg = ARRAY_SIZE(skw_radar_jp_cfgs),
		.cfgs = skw_radar_jp_cfgs,
	},
};

static void pool_put_pseq_elem(struct skw_core *skw, struct skw_pri_sequence *pse)
{
	spin_lock_bh(&skw->dfs.skw_pool_lock);

	list_add(&pse->head, &skw->dfs.skw_pseq_pool);

	spin_unlock_bh(&skw->dfs.skw_pool_lock);
}

static void pool_put_pulse_elem(struct skw_core *skw, struct skw_pulse_elem *pe)
{
	spin_lock_bh(&skw->dfs.skw_pool_lock);

	list_add(&pe->head, &skw->dfs.skw_pulse_pool);

	spin_unlock_bh(&skw->dfs.skw_pool_lock);
}

static struct skw_pulse_elem *pool_get_pulse_elem(struct skw_core *skw)
{
	struct skw_pulse_elem *pe = NULL;

	spin_lock_bh(&skw->dfs.skw_pool_lock);

	if (!list_empty(&skw->dfs.skw_pulse_pool)) {
		pe = list_first_entry(&skw->dfs.skw_pulse_pool, struct skw_pulse_elem, head);
		list_del(&pe->head);
	}

	spin_unlock_bh(&skw->dfs.skw_pool_lock);

	return pe;
}

static struct skw_pulse_elem *pulse_queue_get_tail(struct skw_pri_detector *pde)
{
	struct list_head *l = &pde->pulses;

	if (list_empty(l))
		return NULL;

	return list_entry(l->prev, struct skw_pulse_elem, head);
}

static bool pulse_queue_dequeue(struct skw_core *skw, struct skw_pri_detector *pde)
{
	struct skw_pulse_elem *p = pulse_queue_get_tail(pde);

	if (p) {
		list_del_init(&p->head);
		pde->count--;
		/* give it back to pool */
		pool_put_pulse_elem(skw, p);
	}

	return (pde->count > 0);
}

/* remove pulses older than window */
static void pulse_queue_check_window(struct skw_core *skw, struct skw_pri_detector *pde)
{
	u64 min_valid_ts;
	struct skw_pulse_elem *p;

	/* there is no delta time with less than 2 pulses */
	if (pde->count < 2)
		return;

	if (pde->last_ts <= pde->window_size)
		return;

	min_valid_ts = pde->last_ts - pde->window_size;

	while ((p = pulse_queue_get_tail(pde)) != NULL) {
		if (p->ts >= min_valid_ts)
			return;

		pulse_queue_dequeue(skw, pde);
	}
}

static u32 pde_get_multiple(u32 val, u32 fraction, u32 tolerance)
{
	u32 remainder;
	u32 factor;
	u32 delta;

	if (fraction == 0)
		return 0;

	delta = (val < fraction) ? (fraction - val) : (val - fraction);

	if (delta <= tolerance)
		/* val and fraction are within tolerance */
		return 1;

	factor = val / fraction;
	remainder = val % fraction;
	if (remainder > tolerance) {
		/* no exact match */
		if ((fraction - remainder) <= tolerance)
			/* remainder is within tolerance */
			factor++;
		else
			factor = 0;
	}

	return factor;
}

static u32 pseq_handler_add_to_existing_seqs(struct skw_core *skw, struct skw_radar_cfg *cfg, u64 ts)
{
	u32 max_count = 0;
	struct skw_pri_sequence *ps, *ps2;

	list_for_each_entry_safe(ps, ps2, &cfg->pri.sequences, head) {
		u32 delta_ts;
		u32 factor;

		/* first ensure that sequence is within window */
		if (ts > ps->deadline_ts) {
			list_del_init(&ps->head);
			pool_put_pseq_elem(skw, ps);
			continue;
		}

		delta_ts = ts - ps->last_ts;
		factor = pde_get_multiple(delta_ts, ps->pri,
				cfg->rule.max_pri_tolerance);
		if (factor > 0) {
			ps->last_ts = ts;
			ps->count++;

			if (max_count < ps->count)
				max_count = ps->count;
		} else {
			ps->count_falses++;
		}
	}

	return max_count;
}

static struct skw_pri_sequence *pool_get_pseq_elem(struct skw_core *skw)
{
	struct skw_pri_sequence *pse = NULL;

	spin_lock_bh(&skw->dfs.skw_pool_lock);

	if (!list_empty(&skw->dfs.skw_pseq_pool)) {
		pse = list_first_entry(&skw->dfs.skw_pseq_pool, struct skw_pri_sequence, head);
		list_del(&pse->head);
	}

	spin_unlock_bh(&skw->dfs.skw_pool_lock);

	return pse;
}

#define GET_PRI_TO_USE(MIN, MAX, RUNTIME) \
	(MIN + SKW_PRI_TOLERANCE == MAX - SKW_PRI_TOLERANCE ? \
	 MIN + SKW_PRI_TOLERANCE : RUNTIME)
static bool pseq_handler_create_sequences(struct skw_core *skw,
		struct skw_radar_cfg *cfg, u64 ts, u32 min_count)
{
	struct skw_pulse_elem *p;

	list_for_each_entry(p, &cfg->pri.pulses, head) {
		struct skw_pri_sequence ps, *new_ps;
		struct skw_pulse_elem *p2;
		u32 tmp_false_count;
		u64 min_valid_ts;
		u32 delta_ts = ts - p->ts;

		if (delta_ts < cfg->rule.pri_min)
			/* ignore too small pri */
			continue;

		if (delta_ts > cfg->rule.pri_max)
			/* stop on too large pri (sorted list) */
			break;

		/* build a new sequence with new potential pri */
		ps.count = 2;
		ps.count_falses = 0;
		ps.first_ts = p->ts;
		ps.last_ts = ts;
		ps.pri = GET_PRI_TO_USE(cfg->rule.pri_min, cfg->rule.pri_max, ts - p->ts);
		ps.dur = ps.pri * (cfg->rule.ppb - 1) + 2 * cfg->rule.max_pri_tolerance;

		p2 = p;
		tmp_false_count = 0;
		min_valid_ts = ts - ps.dur;
		/* check which past pulses are candidates for new sequence */
		list_for_each_entry_continue(p2, &cfg->pri.pulses, head) {
			u32 factor;

			if (p2->ts < min_valid_ts)
				/* stop on crossing window border */
				break;
			/* check if pulse match (multi)PRI */
			factor = pde_get_multiple(ps.last_ts - p2->ts, ps.pri,
					cfg->rule.max_pri_tolerance);
			if (factor > 0) {
				ps.count++;
				ps.first_ts = p2->ts;
				/*
				 * on match, add the intermediate falses
				 * and reset counter
				 */
				ps.count_falses += tmp_false_count;
				tmp_false_count = 0;
			} else {
				/* this is a potential false one */
				tmp_false_count++;
			}
		}

		if (ps.count <= min_count)
			/* did not reach minimum count, drop sequence */
			continue;

		/* this is a valid one, add it */
		ps.deadline_ts = ps.first_ts + ps.dur;
		new_ps = pool_get_pseq_elem(skw);
		if (!new_ps) {
			new_ps = kmalloc(sizeof(*new_ps), GFP_ATOMIC);
			if (!new_ps) {
				return false;
			}
		}

		memcpy(new_ps, &ps, sizeof(ps));
		INIT_LIST_HEAD(&new_ps->head);
		list_add(&new_ps->head, &cfg->pri.sequences);
	}

	return true;
}

static void pri_detector_reset(struct skw_core *skw, struct skw_pri_detector *pde, u64 ts)
{
	struct skw_pri_sequence *ps, *ps0;
	struct skw_pulse_elem *p, *p0;

	list_for_each_entry_safe(ps, ps0, &pde->sequences, head) {
		list_del_init(&ps->head);
		pool_put_pseq_elem(skw, ps);
	}

	list_for_each_entry_safe(p, p0, &pde->pulses, head) {
		list_del_init(&p->head);
		pool_put_pulse_elem(skw, p);
	}

	pde->count = 0;
	pde->last_ts = ts;
}

static struct skw_pri_sequence *pseq_handler_check_detection(struct skw_radar_cfg *cfg)
{
	struct skw_pri_sequence *ps;

	if (list_empty(&cfg->pri.sequences))
		return NULL;

	list_for_each_entry(ps, &cfg->pri.sequences, head) {
		/*
		 * we assume to have enough matching confidence if we
		 * 1) have enough pulses
		 * 2) have more matching than false pulses
		 */
		if ((ps->count >= cfg->rule.ppb_thresh) &&
		    (ps->count * cfg->rule.nr_pri >= ps->count_falses))
			return ps;
	}

	return NULL;
}

static bool pulse_queue_enqueue(struct skw_core *skw, struct skw_pri_detector *pde, u64 ts)
{
	struct skw_pulse_elem *p = pool_get_pulse_elem(skw);

	if (!p) {
		p = kmalloc(sizeof(*p), GFP_ATOMIC);
		if (!p)
			return false;
	}

	INIT_LIST_HEAD(&p->head);

	p->ts = ts;
	list_add(&p->head, &pde->pulses);

	pde->count++;
	pde->last_ts = ts;
	pulse_queue_check_window(skw, pde);

	if (pde->count >= pde->max_count)
		pulse_queue_dequeue(skw, pde);

	return true;
}

int skw_dfs_add_pulse(struct wiphy *wiphy, struct net_device *dev, struct skw_pulse_info *pulse)
{
	int i;
	bool reset = false;
	u32 max_updated_seq;
	struct skw_pri_sequence *ps;
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_core *skw = wiphy_priv(wiphy);

	if (!iface->sap.dfs.flags)
		return 0;

	if (skw->dfs.last_pulse_ts > pulse->ts)
		reset = true;

	skw->dfs.last_pulse_ts = pulse->ts;

	for (i = 0; i < skw->dfs.info->nr_cfg; i++) {
		struct skw_radar_cfg *cfg = &skw->dfs.info->cfgs[i];
		const struct skw_radar_rule *rule = &cfg->rule;

		if (reset) {
			pri_detector_reset(skw, &cfg->pri, skw->dfs.last_pulse_ts);
			continue;
		}

		if ((rule->width_min > pulse->width) || (rule->width_max < pulse->width)) {
			skw_detail("invalid pulse width, (%d - %d), pulse width: %d\n",
				 rule->width_min, rule->width_max, pulse->width);
			continue;
		}

		if (rule->chirp && rule->chirp != pulse->chirp) {
			skw_detail("invalid chirp\n");
			continue;
		}

		if ((pulse->ts - cfg->pri.last_ts) < rule->max_pri_tolerance) {
			skw_detail("invalid timestap, %lld - %lld = %lld, max: %d\n",
				 pulse->ts, cfg->pri.last_ts, pulse->ts - cfg->pri.last_ts,
				 rule->max_pri_tolerance);
			continue;
		}

		max_updated_seq = pseq_handler_add_to_existing_seqs(skw, cfg, pulse->ts);
		if (!pseq_handler_create_sequences(skw, cfg, pulse->ts, max_updated_seq)) {
			pri_detector_reset(skw, &cfg->pri, pulse->ts);
			continue;
		}

		ps = pseq_handler_check_detection(cfg);
		if (ps) {
			skw_info("radar deteced, iface dfs flags: 0x%lx\n", iface->sap.dfs.flags);

			skw_dfs_deinit(wiphy, dev);

			cfg80211_radar_event(wiphy, &skw->dfs.chan, GFP_KERNEL);

			break;
		} else {
			pulse_queue_enqueue(skw, &cfg->pri, pulse->ts);
		}
	}

	return 0;
}

static void skw_dfs_cac_work(struct work_struct *work)
{
	struct delayed_work *dwk = to_delayed_work(work);
	struct skw_iface *iface = container_of(dwk, struct skw_iface,
						sap.dfs.cac_work);

	skw_dbg("dev: %s finished\n", netdev_name(iface->ndev));

	skw_wdev_lock(&iface->wdev);

	if (iface->wdev.cac_started) {
		skw_dfs_stop_cac(priv_to_wiphy(iface->skw), iface->ndev);

		cfg80211_cac_event(iface->ndev, &iface->skw->dfs.chan,
				NL80211_RADAR_CAC_FINISHED, GFP_KERNEL);
	}

	skw_wdev_unlock(&iface->wdev);
}

int skw_dfs_chan_init(struct wiphy *wiphy, struct net_device *dev,
		      struct cfg80211_chan_def *chandef, u32 cac_time_ms)
{
	int i;
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("chan: %d, dfs region: %d, flags: 0x%lx\n",
		chandef->chan->hw_value, skw->dfs.region,
		skw->dfs.flags);

	if (!skw->dfs.fw_enabled)
		return -ENOTSUPP;

	if (skw->dfs.flags) {
		if (skw->dfs.chan.width != chandef->width ||
		    skw->dfs.chan.chan != chandef->chan) {
			skw_warn("current chan: %d, require chan: %d\n",
				 skw->dfs.chan.chan->hw_value,
				 chandef->chan->hw_value);

			return -EBUSY;
		}
	}

	if (skw->dfs.region >= ARRAY_SIZE(skw_radar_infos)) {
		skw_err("invalid dfs region: %d\n", skw->dfs.region);

		return -EINVAL;
	}

	skw->dfs.info = &skw_radar_infos[skw->dfs.region];
	if (!skw->dfs.info->nr_cfg || !skw->dfs.info->cfgs) {
		skw_err("invalid, region: %d, nr_cfg: %d\n",
			skw->dfs.region, skw->dfs.info->nr_cfg);

		return -EINVAL;
	}

	iface->sap.dfs.cac_time_ms = cac_time_ms;
	skw->dfs.last_pulse_ts = 0;
	skw->dfs.chan = *chandef;

	for (i = 0; i < skw->dfs.info->nr_cfg; i++) {
		struct skw_radar_cfg *cfg = &skw->dfs.info->cfgs[i];
		const struct skw_radar_rule *rule = &cfg->rule;

		INIT_LIST_HEAD(&cfg->pri.sequences);
		INIT_LIST_HEAD(&cfg->pri.pulses);

		cfg->pri.window_size = rule->pri_max * rule->ppb * rule->nr_pri;
		cfg->pri.max_count = rule->ppb * 2;
	}

	return 0;
}

int skw_dfs_start_cac(struct wiphy *wiphy, struct net_device *dev)
{
	int ret;
	struct skw_dfs_cac cac;
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("%s\n", netdev_name(dev));

	if (!skw->dfs.fw_enabled)
		return -ENOTSUPP;

	cac.type = SKW_DFS_START_CAC;
	cac.len = sizeof(struct skw_cac_params);

	cac.params.chn = skw->dfs.chan.chan->hw_value;
	cac.params.center_chn1 = skw_freq_to_chn(skw->dfs.chan.center_freq1);
	cac.params.center_chn2 = skw_freq_to_chn(skw->dfs.chan.center_freq2);
	cac.params.band_width = to_skw_bw(skw->dfs.chan.width);
	cac.params.region = skw->dfs.region;
	cac.params.time_ms = iface->sap.dfs.cac_time_ms;

	ret = skw_send_msg(wiphy, dev, SKW_CMD_DFS, &cac, sizeof(cac), NULL, 0);
	if (!ret) {
		set_bit(SKW_DFS_FLAG_CAC_MODE, &iface->sap.dfs.flags);
		set_bit(SKW_DFS_FLAG_CAC_MODE, &skw->dfs.flags);
	}

	return ret;
}

int skw_dfs_stop_cac(struct wiphy *wiphy, struct net_device *dev)
{
	struct skw_dfs_cac cac;
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("%s\n", netdev_name(dev));

	if (!skw->dfs.fw_enabled)
		return -ENOTSUPP;

	cac.type = SKW_DFS_STOP_CAC;
	cac.len = 0;

	clear_bit(SKW_DFS_FLAG_CAC_MODE, &iface->sap.dfs.flags);
	clear_bit(SKW_DFS_FLAG_CAC_MODE, &skw->dfs.flags);

	return skw_send_msg(wiphy, dev, SKW_CMD_DFS, &cac, sizeof(cac), NULL, 0);
}

int skw_dfs_start_monitor(struct wiphy *wiphy, struct net_device *dev)
{
	int ret;
	struct skw_dfs_cac cac;
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("%s\n", netdev_name(dev));

	if (!skw->dfs.fw_enabled)
		return -ENOTSUPP;

	cac.type = SKW_DFS_START_MONITOR;
	cac.len = 0;

	ret = skw_send_msg(wiphy, dev, SKW_CMD_DFS, &cac, sizeof(cac), NULL, 0);
	if (!ret) {
		set_bit(SKW_DFS_FLAG_MONITOR_MODE, &skw->dfs.flags);
		set_bit(SKW_DFS_FLAG_MONITOR_MODE, &iface->sap.dfs.flags);
	}

	return ret;
}

int skw_dfs_stop_monitor(struct wiphy *wiphy, struct net_device *dev)
{
	struct skw_dfs_cac cac;
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("%s\n", netdev_name(dev));

	if (!skw->dfs.fw_enabled)
		return -ENOTSUPP;

	cac.type = SKW_DFS_STOP_MONITOR;
	cac.len = 0;

	clear_bit(SKW_DFS_FLAG_MONITOR_MODE, &skw->dfs.flags);
	clear_bit(SKW_DFS_FLAG_MONITOR_MODE, &iface->sap.dfs.flags);

	return skw_send_msg(wiphy, dev, SKW_CMD_DFS, &cac, sizeof(cac), NULL, 0);
}

int skw_dfs_init(struct wiphy *wiphy, struct net_device *dev)
{
	int i, j;
	struct skw_iface *iface = netdev_priv(dev);

	BUILD_BUG_ON(IS_ENABLED(CONFIG_SKW_REGD_SELF_MANAGED));

	iface->sap.dfs.flags = 0;
	INIT_DELAYED_WORK(&iface->sap.dfs.cac_work, skw_dfs_cac_work);

	for (i = 0; i < ARRAY_SIZE(skw_radar_infos); i++) {
		const struct skw_radar_info *info = &skw_radar_infos[i];

		for (j = 0; j < info->nr_cfg; j++) {
			INIT_LIST_HEAD(&info->cfgs[j].pri.sequences);
			INIT_LIST_HEAD(&info->cfgs[j].pri.pulses);
		}
	}

	return 0;
}

int skw_dfs_deinit(struct wiphy *wiphy, struct net_device *dev)
{
	int i, j;
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_iface *iface = netdev_priv(dev);

	if (test_bit(SKW_DFS_FLAG_CAC_MODE, &iface->sap.dfs.flags)) {
		cancel_delayed_work_sync(&iface->sap.dfs.cac_work);

		skw_dfs_stop_cac(wiphy, dev);

		cfg80211_cac_event(dev, &skw->dfs.chan,
				NL80211_RADAR_CAC_ABORTED, GFP_KERNEL);
	}

	if (test_bit(SKW_DFS_FLAG_MONITOR_MODE, &iface->sap.dfs.flags))
		skw_dfs_stop_monitor(wiphy, dev);

	for (i = 0; i < ARRAY_SIZE(skw_radar_infos); i++) {
		const struct skw_radar_info *info = &skw_radar_infos[i];

		for (j = 0; j < info->nr_cfg; j++)
			pri_detector_reset(skw, &info->cfgs[j].pri, 0);
	}

	return 0;
}
===== ./drivers/skwifi/skw_mlme.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/kernel.h>
#include <linux/workqueue.h>
#include <linux/skbuff.h>
#include <linux/ieee80211.h>
#include <linux/etherdevice.h>
#include <net/cfg80211.h>

#include "skw_core.h"
#include "skw_cfg80211.h"
#include "skw_iface.h"
#include "skw_timer.h"
#include "skw_msg.h"
#include "skw_mlme.h"
#include "skw_work.h"

#define SKW_AP_AUTH_TIMEOUT     5000
#define SKW_IEEE80211_HDR_LEN   24

static void skw_mlme_ap_del_client(struct skw_iface *iface,
				struct skw_client *client)
{
	if (!client)
		return;

	skw_dbg("client: %pM\n", client->addr);

	skw_del_timer_work(iface->skw, client);

	skw_list_del(&iface->sap.mlme_client_list, &client->list);

	if (client->aid)
		clear_bit(client->aid, iface->sap.aid_map);

	SKW_KFREE(client->assoc_req_ie);
	SKW_KFREE(client->challenge);
	SKW_KFREE(client);
}

static struct skw_client *
skw_mlme_ap_get_client(struct skw_iface *iface, const u8 *addr)
{
	struct skw_client *client = NULL, *tmp;

	spin_lock_bh(&iface->sap.mlme_client_list.lock);

	list_for_each_entry(tmp, &iface->sap.mlme_client_list.list, list) {
		if (tmp && ether_addr_equal(addr, tmp->addr)) {
			client = tmp;
			break;
		}
	}

	spin_unlock_bh(&iface->sap.mlme_client_list.lock);

	return client;
}

static struct skw_client *
skw_mlme_ap_add_client(struct skw_iface *iface, const u8 *addr)
{
	struct skw_client *client = NULL;

	client = SKW_ZALLOC(sizeof(*client), GFP_KERNEL);
	if (client) {
		INIT_LIST_HEAD(&client->list);
		client->iface = iface;
		client->state = SKW_STATE_NONE;
		client->last_seq_ctrl = 0xFFFF;
		client->idle = jiffies;
		client->challenge = NULL;
		client->assoc_req_ie = NULL;
		client->aid = 0;
		skw_ether_copy(client->addr, addr);
		skw_dbg("%pM\n", client->addr);

		skw_list_add(&iface->sap.mlme_client_list, &client->list);
	}

	return client;
}

void skw_mlme_ap_remove_client(struct skw_iface *iface, const u8 *addr)
{
	struct skw_client *client;

	if (!iface->sap.sme_external) {
		client = skw_mlme_ap_get_client(iface, addr);
		skw_mlme_ap_del_client(iface, client);
	}
}

void skw_mlme_ap_del_sta(struct wiphy *wiphy, struct net_device *ndev,
			 const u8 *addr, u8 force)
{
	int ret = -1;

	skw_dbg("sta: %pM\n", addr);

	ret = skw_delete_station(wiphy, ndev, addr, 12, 3);
	if (ret) {
		skw_err("failed, ret: %d\n", ret);
		return;
	}
}

static void skw_mlme_ap_auth_timeout(void *data)
{
	unsigned long timeout;
	struct skw_client *client = data;

	if (!client)
		return;

	skw_dbg("client: %pM\n", client->addr);

	if (client->state == SKW_STATE_ASSOCED)
		return;

	timeout = client->idle + msecs_to_jiffies(SKW_AP_AUTH_TIMEOUT);
	if (time_after(jiffies, timeout)) {
		skw_queue_local_event(priv_to_wiphy(client->iface->skw),
				client->iface, SKW_EVENT_LOCAL_AP_AUTH_TIMEOUT,
				client, sizeof(*client));
		return;
	}
}

#if 0
void skw_flush_sta_info(struct skw_iface *iface)
{
	LIST_HEAD(flush_list);
	struct skw_client *sta;

	spin_lock_bh(&iface->sap.sta_lock);
	list_replace_init(&iface->sap.mlme_client_list, &flush_list);
	spin_unlock_bh(&iface->sap.sta_lock);

	// fixme:
	// deauth all sta
	while (!list_empty(&flush_list)) {
		sta = list_first_entry(&flush_list, struct skw_client, list);
		list_del(&sta->list);
		skw_dbg("sta: %pM, state: %d\n", sta->addr, sta->state);
		// skw_mlle_ap_state_event(sta, SKW_STATE_NONE);
		SKW_KFREE(sta);
	}
}
#endif

int skw_ap_simple_reply(struct skw_iface *iface, struct skw_client *client,
			u16 stype, u16 reason)
{
	struct wiphy *wiphy = priv_to_wiphy(iface->skw);
	struct ieee80211_mgmt reply;

	skw_dbg("stype: %d, reason: %d\n", stype, reason);

	reply.frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT | stype);
	reply.duration = 0;
	reply.seq_ctrl = 0;
	skw_ether_copy(reply.da, client->addr);
	skw_ether_copy(reply.sa, iface->addr);
	skw_ether_copy(reply.sa, iface->sap.cfg.bssid);

	reply.u.deauth.reason_code = cpu_to_le16(reason);

	return skw_mgmt_tx(wiphy, iface, iface->sap.cfg.channel, 0,
			   &client->cookie, false, &reply, SKW_DEAUTH_FRAME_LEN);
}

static void skw_mlme_ap_auth_cb(struct skw_iface *iface,
				struct skw_client *client,
				struct ieee80211_mgmt *mgmt,
				int mgmt_len, bool ack)
{
	u16 status;

	skw_dbg("client: %pM, ack: %d\n", client->addr, ack);
	if (!client)
		return;

	status = le16_to_cpu(mgmt->u.auth.status_code);

	if (ack && status == WLAN_STATUS_SUCCESS) {
		skw_del_timer_work(iface->skw, client);
		skw_add_timer_work(iface->skw, "auth_timeout",
				   skw_mlme_ap_auth_timeout,
				   client, SKW_AP_AUTH_TIMEOUT,
				   client, GFP_KERNEL);
	} else {
		skw_warn("failed\n");
		client->state = SKW_STATE_NONE;
		skw_mlme_ap_del_sta(iface->wdev.wiphy,
				iface->ndev, client->addr, false);
	}
}

static void skw_mlme_ap_assoc_cb(struct skw_iface *iface,
				 struct skw_client *client,
				 struct ieee80211_mgmt *mgmt,
				 int frame_len, bool ack, int reassoc)
{
	u16 status_code;
	struct station_info info;
	struct station_parameters params;

	if (!client)
		return;

	if (reassoc)
		status_code = le16_to_cpu(mgmt->u.reassoc_resp.status_code);
	else
		status_code = le16_to_cpu(mgmt->u.assoc_resp.status_code);

	skw_dbg("client: %pM, ack: %d, status code: %d\n",
		client->addr, ack, status_code);

	if (ack && status_code == WLAN_STATUS_SUCCESS) {
		skw_del_timer_work(iface->skw, client);

		params.sta_flags_set = 0;
		params.sta_flags_set |= BIT(NL80211_STA_FLAG_ASSOCIATED);
		skw_change_station(iface->wdev.wiphy, iface->ndev,
				client->addr, &params);

		memset(&info, 0x0, sizeof(info));
		if (client->assoc_req_ie) {
			info.assoc_req_ies = client->assoc_req_ie;
			info.assoc_req_ies_len = client->assoc_req_ie_len;
#if (KERNEL_VERSION(4, 0, 0) > LINUX_VERSION_CODE)
			info.filled |= STATION_INFO_ASSOC_REQ_IES;
#endif
		}

		cfg80211_new_sta(iface->ndev, client->addr,
				 &info, GFP_KERNEL);
		SKW_KFREE(client->assoc_req_ie);
		client->assoc_req_ie = NULL;
		client->assoc_req_ie_len = 0;

		client->state = SKW_STATE_ASSOCED;
	} else {
		skw_err("failed, ack: %d, status_code: %d\n", ack, status_code);

		client->state = SKW_STATE_NONE;
		skw_mlme_ap_del_sta(iface->wdev.wiphy,
				iface->ndev, client->addr, false);
	}
}

void skw_mlme_ap_tx_status(struct skw_iface *iface, u64 cookie,
			   const u8 *frame, int frame_len, u16 ack)
{
	u16 fc;
	int reassoc = 0;
	struct skw_client *client;
	struct ieee80211_mgmt *mgmt = (struct ieee80211_mgmt *)frame;

	skw_dbg("iface: %d, da: %pM, ack: %d, cookie: %lld\n",
		iface->id, mgmt->da, ack, cookie);

	client = skw_mlme_ap_get_client(iface, mgmt->da);
	if (!client || client->cookie != cookie) {
		skw_dbg("cfg80211 tx status, cookie: %lld\n", cookie);
		goto report;
	}

	fc = SKW_MGMT_SFC(mgmt->frame_control);

	switch (fc) {
	case IEEE80211_STYPE_AUTH:
		skw_mlme_ap_auth_cb(iface, client, mgmt, frame_len, !!ack);
		break;

	case IEEE80211_STYPE_REASSOC_RESP:
		reassoc = 1;
		/* fall through */
		skw_fallthrough;
	case IEEE80211_STYPE_ASSOC_RESP:
		skw_mlme_ap_assoc_cb(iface, client, mgmt, frame_len,
				     !!ack, reassoc);
		break;

	default:
		break;
	}

	return;

report:
	cfg80211_mgmt_tx_status(&iface->wdev, cookie, frame, frame_len,
				ack, GFP_KERNEL);
}

static int skw_mlme_ap_auth_reply(struct skw_iface *iface,
		struct skw_client *client, const u8 *bssid,
		u16 auth_type, u16 transaction, u16 status,
		u8 *ie, int ie_len)
{
	int ret;
	int frame_len;
	struct wiphy *wiphy;
	struct ieee80211_mgmt *reply;

	skw_dbg("da: %pM, bssid: %pM, transaction: %d, status: %d, ie: %d\n",
		client->addr, bssid, transaction, status, ie_len);

	wiphy = priv_to_wiphy(iface->skw);
	frame_len = SKW_IEEE80211_HDR_LEN +
		    sizeof(reply->u.auth) +
		    ie_len;

	reply = SKW_ZALLOC(frame_len, GFP_KERNEL);
	if (IS_ERR(reply))
		return -ENOMEM;

	reply->frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT |
					   IEEE80211_STYPE_AUTH);
	skw_ether_copy(reply->da, client->addr);
	skw_ether_copy(reply->sa, iface->addr);
	skw_ether_copy(reply->bssid, bssid);

	reply->u.auth.auth_alg = cpu_to_le16(auth_type);
	reply->u.auth.auth_transaction = cpu_to_le16(transaction);
	reply->u.auth.status_code = cpu_to_le16(status);

	if (ie && ie_len)
		memcpy(reply->u.auth.variable, ie, ie_len);

	// skw_hex_dump("auth_reply", reply, frame_len, false);
	ret = skw_mgmt_tx(wiphy, iface, iface->sap.cfg.channel,
			  0, &client->cookie, false, reply, frame_len);

	SKW_KFREE(reply);

	return ret;
}

#if 0
static int skw_ap_auth_shared_key(struct skw_client *sta, u16 trans_action)
{
	u16 status;
	u8 *challenge;

	switch (trans_action) {
	case 1:
		sta->challenge = SKW_ZALLOC(WLAN_AUTH_CHALLENGE_LEN,
				GFP_KERNEL);
		if (IS_ERR(sta->challenge)) {
			status = WLAN_STATUS_UNSPECIFIED_FAILURE;
			goto reply;
		}

		/* Generate challenge text */
		get_random_bytes(sta->challenge,
				WLAN_AUTH_CHALLENGE_LEN);

		status = WLAN_STATUS_SUCCESS;
		break;

	case 3:
		challenge = &mgmt->u.auth.variable[2];

		if (memcmp(sta->challenge, challenge,
			   WLAN_AUTH_CHALLENGE_LEN) == 0) {
			status = WLAN_STATUS_SUCCESS;
			SKW_KFREE(sta->challenge);
		} else {
			status = WLAN_STATUS_CHALLENGE_FAIL;
		}

		break;

	default:
		status = WLAN_STATUS_UNKNOWN_AUTH_TRANSACTION;
		break;
	}

	return status;
}
#endif

static int skw_mlme_ap_auth_handler(struct skw_iface *iface, int freq,
				int signal, void *frame, int frame_len)
{
	u8 *ies = NULL, *challenge;
	int ies_len = 0, ret = 0;
	struct skw_client *client = NULL;
	struct station_parameters sta_params;
	u8 challenge_ies[WLAN_AUTH_CHALLENGE_LEN + 2];
	struct wiphy *wiphy = priv_to_wiphy(iface->skw);
	struct ieee80211_mgmt *mgmt = frame;
	u16 auth_alg, status_code, trans_action;
	u16 status = WLAN_STATUS_SUCCESS;
	u16 seq_ctrl;

	auth_alg = le16_to_cpu(mgmt->u.auth.auth_alg);
	trans_action = le16_to_cpu(mgmt->u.auth.auth_transaction);
	status_code = le16_to_cpu(mgmt->u.auth.status_code);
	seq_ctrl = le16_to_cpu(mgmt->seq_ctrl);

	skw_dbg("auth alg: %d, trans action: %d, status: %d, seq: %u\n",
		auth_alg, trans_action, status_code, seq_ctrl);

	client = skw_mlme_ap_get_client(iface, mgmt->sa);
	if (client) {
		skw_dbg("flush peer status\n");
	} else {
		client = skw_mlme_ap_add_client(iface, mgmt->sa);
		if (!client) {
			skw_err("add client: %pM failed\n", mgmt->sa);
			return 0;
		}

		memset(&sta_params, 0x0, sizeof(sta_params));
		skw_add_station(wiphy, iface->ndev, mgmt->sa, &sta_params);
	}

	if (ieee80211_has_retry(mgmt->frame_control) &&
	    client->last_seq_ctrl == seq_ctrl) {
		skw_dbg("drop repeated auth(seq: %d)\n", seq_ctrl);
		return 0;
	}

	client->last_seq_ctrl = seq_ctrl;
	client->state = SKW_STATE_AUTHED;

	if (!ether_addr_equal(mgmt->bssid, iface->sap.cfg.bssid)) {
		skw_warn("failed, ap bssid: %pM, rx bssid: %pM\n",
			 iface->sap.cfg.bssid, mgmt->bssid);
		status = WLAN_STATUS_UNSPECIFIED_FAILURE;
		goto reply;
	}

	// TODO:
	// transation check

#if 0
	if (auth_alg != iface->sap.auth_type) {
		skw_err("auth type not match (client: %d, ap: %d)\n",
			auth_alg, iface->sap.auth_type);
		status = WLAN_STATUS_NOT_SUPPORTED_AUTH_ALG;
		goto reply;
	}

	if (client->state !=  SKW_STATE_NONE) {
		skw_warn("current state: %s\n", sm_str[client->state]);
		return 0;
	}

#endif

	switch (auth_alg) {
	case WLAN_AUTH_OPEN:
		if (trans_action != 1) {
			status = WLAN_STATUS_UNKNOWN_AUTH_TRANSACTION;
			goto reply;
		}

		if (status_code != WLAN_STATUS_SUCCESS)
			return 0;

		status = WLAN_STATUS_SUCCESS;
		client->last_seq_ctrl = seq_ctrl;

		break;

	case WLAN_AUTH_SAE:
		if (!skw_compat_cfg80211_rx_mgmt(&iface->wdev, freq, signal,
				      frame, frame_len, 0, GFP_ATOMIC)) {
			skw_warn("cfg80211_rx_mgmt failed\n");
		}

		return 0;

	case WLAN_AUTH_SHARED_KEY:
		switch (trans_action) {
		case 1:
			client->challenge = SKW_ZALLOC(WLAN_AUTH_CHALLENGE_LEN,
					GFP_KERNEL);
			if (IS_ERR(client->challenge)) {
				status = WLAN_STATUS_UNSPECIFIED_FAILURE;
				goto reply;
			}

			/* Generate challenge text */
			get_random_bytes(client->challenge,
					WLAN_AUTH_CHALLENGE_LEN);

			challenge_ies[0] = WLAN_EID_CHALLENGE;
			challenge_ies[1] = WLAN_AUTH_CHALLENGE_LEN;
			memcpy(challenge_ies + 2, client->challenge,
					WLAN_AUTH_CHALLENGE_LEN);
			ies_len = 2 + WLAN_AUTH_CHALLENGE_LEN;

			ies = challenge_ies;
			status = WLAN_STATUS_SUCCESS;
			break;

		case 3:
			challenge = &mgmt->u.auth.variable[2];

			if (client->challenge &&
				(memcmp(client->challenge, challenge,
				   WLAN_AUTH_CHALLENGE_LEN) == 0))
				status = WLAN_STATUS_SUCCESS;
			else
				status = WLAN_STATUS_CHALLENGE_FAIL;

			break;

		default:
			status = WLAN_STATUS_UNKNOWN_AUTH_TRANSACTION;
			break;
		}

		break;

	default:
		status = WLAN_STATUS_NOT_SUPPORTED_AUTH_ALG;
		skw_warn("unsupport auth alg: %d\n", auth_alg);
		break;
	}

reply:
	ret = skw_mlme_ap_auth_reply(iface, client, mgmt->bssid, auth_alg,
				trans_action + 1, status, ies, ies_len);
	if (ret || status != WLAN_STATUS_SUCCESS) {
		skw_warn("failed, ret = %d, status: %d\n", ret, status);
		client->state = SKW_STATE_NONE;
		skw_mlme_ap_del_sta(wiphy, iface->ndev, mgmt->sa, false);
	}

	return 0;
}

#if 0
static int skw_ap_parse_element(struct skw_80211_element *element,
				const u8 *ies, u32 ie_len)
{
	const struct element *elem;

	return 0;

	for_each_element(elem, ies, ie_len) {
		switch (elem->id) {
		case WLAN_EID_SSID:
			// element->ssid = elem->data;
			// element->ssid_len = elem->data;
			break;

		case WLAN_EID_SUPP_RATES:
			break;
		case WLAN_EID_EXT_SUPP_RATES:
			break;
		case WLAN_EID_RSN:
			break;
		case WLAN_EID_PWR_CAPABILITY:
			break;
		case WLAN_EID_SUPPORTED_CHANNELS:
			break;
		case WLAN_EID_HT_CAPABILITY:
			break;
		case WLAN_EID_HT_OPERATION:
			break;
		case WLAN_EID_VHT_CAPABILITY:
			break;
		case WLAN_EID_VHT_OPERATION:
			break;
		case WLAN_EID_EXT_CAPABILITY:
			break;
		case WLAN_EID_MIC:
			break;
		case WLAN_EID_SUPPORTED_REGULATORY_CLASSES:
			break;
		default:
			break;
		}
	}

	return 0;
}

static u16 skw_ap_check_ssid(struct skw_iface *iface,
			     const u8 *ssid, int ssid_len)
{
	if (!ssid ||
	    ssid_len != iface->sap.ssid_len ||
	    memcmp(ssid, iface->sap.ssid, iface->sap.ssid_len) != 0)
		return WLAN_STATUS_UNSPECIFIED_FAILURE;

	return WLAN_STATUS_SUCCESS;
}

static u16 skw_ap_check_wmm(struct skw_client *sta, const u8 *wmm_ie, int len)
{
#define SKW_WMM_IE_LEN  24
	struct skw_wmm_info {
		u8 oui[3];
		u8 oui_type;
		u8 oui_subtype;
		u8 version;
		u8 qos_info;
	} __packed;

	struct skw_wmm_info *wmm = (struct skw_wmm_info *)wmm_ie;

	if (len != SKW_WMM_IE_LEN ||
	    wmm->oui_subtype != 0 ||
	    wmm->version != 1)
		return WLAN_STATUS_UNSPECIFIED_FAILURE;

	return WLAN_STATUS_SUCCESS;
}
#endif
static u16 skw_mlme_ap_check_assoc_ie(struct skw_iface *iface,
				 struct skw_client *client,
				 const u8 *ie, int ie_len)
{
	// skw_hex_dump("rx assoc ie", ie, ie_len, false);
	// struct skw_80211_element e;

	//memset(&ie, 0x0, sizeof(e));
	// skw_ap_parse_element(&e, ie, ie_len);

#if 0
	/* check ssid */
	if (skw_ap_check_ssid(iface, e.ssid, e.ssid_len))
		return WLAN_STATUS_UNSPECIFIED_FAILURE;

	/* check wmm */
	if (skw_ap_check_wmm(sta, e.wmm, e.wmm_len))
		return WLAN_STATUS_UNSPECIFIED_FAILURE;

	/* check ext capa */
	/* check support rate */
#endif
	return 0;
}

static u16 skw_mlme_ap_new_aid(struct skw_iface *iface)
{
	u16 aid = 0;

	for (aid = 1; aid < 64; aid++)
		if (!test_and_set_bit(aid, iface->sap.aid_map))
			break;

	return aid;
}

/* add basic rate & ext support rate */
static u8 *skw_mlme_ap_add_rate(struct wiphy *wiphy,
			   struct skw_iface *iface, u8 *ies)
{
	int i, nr;
	u8 *pos = ies, *ext_rate_count;
	struct ieee80211_rate *rate;
	struct ieee80211_supported_band *sband;

	/* basic rate */
	sband = wiphy->bands[iface->sap.cfg.channel->band];
	rate = sband->bitrates;
#if 0
	enum ieee80211_rate_flags mandatory;

	if (sband->band == NL80211_BAND_2GHZ) {
		if (scan_width == NL80211_BSS_CHAN_WIDTH_5 ||
		    scan_width == NL80211_BSS_CHAN_WIDTH_10)
			mandatory = IEEE80211_RATE_MANDATORY_G;
		else
			mandatory = IEEE80211_RATE_MANDATORY_B;
	} else {
		mandatory = IEEE80211_RATE_MANDATORY_A;
	}
#endif
	*pos++ = WLAN_EID_SUPP_RATES;
	*pos++ = SKW_BASIC_RATE_COUNT;
	for (i = 0; i < SKW_BASIC_RATE_COUNT; i++)
		*pos++ = rate[i].bitrate / 5;

	/* ext support rate */
	*pos++ = WLAN_EID_EXT_SUPP_RATES;
	ext_rate_count = pos++;

	for (i = SKW_BASIC_RATE_COUNT; i < sband->n_bitrates; i++)
		*pos++ = rate[i].bitrate / 5;

	nr = sband->n_bitrates - SKW_BASIC_RATE_COUNT;
	if (iface->sap.ht_required) {
		*pos++ = 0x80 | SKW_BSS_MEMBERSHIP_SELECTOR_HT_PHY;
		nr++;
	}

	if (iface->sap.vht_required) {
		*pos++ = 0x80 | SKW_BSS_MEMBERSHIP_SELECTOR_VHT_PHY;
		nr++;
	}

	*ext_rate_count = nr;

	return pos;
}

static u8 *skw_mlme_ap_add_ht_cap(struct skw_iface *iface, u8 *ies)
{
	u8 *pos = ies;
	int len = sizeof(struct ieee80211_ht_cap);

	*pos++ = WLAN_EID_HT_CAPABILITY;
	*pos++ = len;
	memcpy(pos, &iface->sap.cfg.ht_cap, len);

	return pos + len;
}

static u8 *skw_mlme_ap_add_ht_oper(struct skw_iface *iface, u8 *ies)
{
	u8 *pos = ies;
	struct ieee80211_ht_operation *oper;

	*pos++ = WLAN_EID_HT_OPERATION;
	*pos++ = sizeof(*oper);

	oper = (struct ieee80211_ht_operation *)pos;
	memset(oper, 0x0, sizeof(*oper));

	oper->primary_chan = iface->sap.cfg.channel->hw_value;

	return pos + sizeof(*oper);
}

static void skw_mlme_ap_parse_ies(const u8 *beacon, int beacon_len,
				 struct skw_element_info *e)
{
	const struct skw_element *element;

	if (!beacon || beacon_len == 0)
		return;

	skw_foreach_element(element, beacon, beacon_len) {
		switch (element->id) {
		case WLAN_EID_SSID:
			e->ssid.len = element->datalen;
			memcpy(e->ssid.data, element->data, element->datalen);
			break;

		case WLAN_EID_SUPP_RATES:
			e->support_rate = element;
			break;

		case WLAN_EID_EXT_SUPP_RATES:
			e->ext_rate = element;
			break;

		case WLAN_EID_HT_CAPABILITY:
			e->ht_capa = element;
			break;

		case WLAN_EID_HT_OPERATION:
			e->ht_oper = element;
			break;

		case WLAN_EID_VHT_CAPABILITY:
			e->vht_capa = element;
			break;

		case WLAN_EID_VHT_OPERATION:
			e->vht_oper = element;
			break;

		case WLAN_EID_EXT_CAPABILITY:
			e->ext_capa = element;
			break;

		case WLAN_EID_VENDOR_SPECIFIC:
			e->vendor_vht = element;
			break;

		default:
			skw_dbg("unused element: %d, len: %d\n",
				element->id, element->datalen);
			break;
		}
	}
}

static int skw_mlme_ap_assoc_reply(struct skw_iface *iface,
		struct skw_client *client, u16 status, bool reassoc)
{
	u16 fc, elen;
	u8 *ies, *pos;
	int ret, frame_len, len;
	struct wiphy *wiphy = priv_to_wiphy(iface->skw);
	struct ieee80211_mgmt *reply;
	struct skw_element_info e;

	skw_dbg("client addr: %pM, reassoc: %d, aid: %d, status code: %d\n",
		client->addr, reassoc, client->aid, status);

	len = sizeof(struct ieee80211_mgmt) + 1024;

	reply = SKW_ZALLOC(len, GFP_KERNEL);
	if (!reply)
		return -ENOMEM;

	memset(&e, 0x0, sizeof(e));

	fc = reassoc ? IEEE80211_STYPE_REASSOC_RESP :
		IEEE80211_STYPE_ASSOC_RESP;

	reply->frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT | fc);
	reply->duration = 0;
	skw_ether_copy(reply->da, client->addr);
	skw_ether_copy(reply->sa, iface->addr);
	skw_ether_copy(reply->bssid, iface->sap.cfg.bssid);
	reply->seq_ctrl = 0;

	reply->u.assoc_resp.capab_info = client->capa;
	reply->u.assoc_resp.status_code = status;
	reply->u.assoc_resp.aid = client->aid;

	frame_len = SKW_IEEE80211_HDR_LEN +
		    sizeof(reply->u.assoc_resp);

	pos = ies = reply->u.assoc_resp.variable;

	len = offsetof(struct ieee80211_mgmt, u.probe_resp.variable);
	skw_mlme_ap_parse_ies(iface->sap.probe_resp + len,
			      iface->sap.probe_resp_len - len, &e);

	/* support rate & ext rate */

	if (e.support_rate) {
		elen = e.support_rate->datalen + 2;
		memcpy(pos, e.support_rate, elen);
		pos += elen;

		if (e.ext_rate) {
			elen = e.ext_rate->datalen + 2;
			memcpy(pos, e.ext_rate, elen);
			pos += elen;
		}
	} else {
		pos = skw_mlme_ap_add_rate(wiphy, iface, pos);
	}

#if 1
	/* 80211n capa & oper */
	if (e.ht_capa && e.ht_oper) {
		elen = e.ht_capa->datalen + 2;
		memcpy(pos, e.ht_capa, elen);
		pos += elen;

		elen = e.ht_oper->datalen + 2;
		memcpy(pos, e.ht_oper, elen);
		pos += elen;
	} else {
		pos = skw_mlme_ap_add_ht_cap(iface, pos);
		pos = skw_mlme_ap_add_ht_oper(iface, pos);
	}

	/* 11ac capa */

	/* vendor vht */
	if (e.vendor_vht) {
		elen = e.vendor_vht->datalen + 2;
		memcpy(pos, e.vendor_vht, elen);
		pos += elen;
	}
#endif

	frame_len += pos - ies;

	ret = skw_mgmt_tx(wiphy, iface, iface->sap.cfg.channel,
			  0, &client->cookie, false, reply, frame_len);

	SKW_KFREE(reply);

	return ret;
}

static int skw_mlme_ap_assoc_handler(struct skw_iface *iface, void *frame,
				int frame_len, int reassoc)
{
	u8 *ie;
	int ie_len = 0, ret;
	u16 capab_info, status;
	struct skw_client *client;
	struct ieee80211_mgmt *mgmt = frame;
	u16 seq_ctrl;

	skw_dbg("iface: %d, sa: %pM, reassoc: %d\n",
		iface->id, mgmt->sa, reassoc);

	seq_ctrl = le16_to_cpu(mgmt->seq_ctrl);

	client = skw_mlme_ap_get_client(iface, mgmt->sa);
	if (!client) {
		skw_warn("client: %pM not exist\n", mgmt->sa);
		return 0;
	}

	if (client->state == SKW_STATE_NONE) {
		status = WLAN_REASON_CLASS2_FRAME_FROM_NONAUTH_STA;
		skw_dbg("client->state: %d\n", client->state);
		skw_ap_send_disassoc(iface, client, status);
		return 0;
	}

	if (ieee80211_has_retry(mgmt->frame_control) &&
	    client->last_seq_ctrl == seq_ctrl) {
		skw_dbg("drop repeated assoc frame(seq: %d)\n", seq_ctrl);
		return 0;
	}

	client->last_seq_ctrl = seq_ctrl;

	ie_len = frame_len - sizeof(struct ieee80211_hdr_3addr);
	if (reassoc) {
		capab_info = le16_to_cpu(mgmt->u.reassoc_req.capab_info);
		ie = mgmt->u.reassoc_req.variable;
		ie_len -= sizeof(mgmt->u.reassoc_req);
	} else {
		capab_info = le16_to_cpu(mgmt->u.assoc_req.capab_info);
		ie = mgmt->u.assoc_req.variable;
		ie_len -= sizeof(mgmt->u.assoc_req);
	}

	client->capa = capab_info;

	// check assoc ies
	status = skw_mlme_ap_check_assoc_ie(iface, client, ie, ie_len);
	if (status != WLAN_STATUS_SUCCESS) {
		skw_ap_send_disassoc(iface, client, status);
		return 0;
	}

	// assign aid
	client->aid = skw_mlme_ap_new_aid(iface);
	if (!client->aid) {
		status = WLAN_STATUS_AP_UNABLE_TO_HANDLE_NEW_STA;
		goto reply;
	}

	// 11W
reply:
	ret = skw_mlme_ap_assoc_reply(iface, client, status, reassoc);
	if (ret || status != WLAN_STATUS_SUCCESS) {
		skw_err("ret: %d, status: %d\n", ret, status);
		return ret;
	}

	if (!client->assoc_req_ie) {
		client->assoc_req_ie = SKW_ZALLOC(ie_len, GFP_KERNEL);
		if (client->assoc_req_ie) {
			memcpy(client->assoc_req_ie, ie, ie_len);
			client->assoc_req_ie_len = ie_len;
		}
	}

	return ret;
}

int skw_mlme_ap_rx_mgmt(struct skw_iface *iface, u16 fc, int freq,
			int signal, void *frame, int frame_len)
{
	int reassoc = 0;
	struct skw_client *client;
	struct ieee80211_mgmt *mgmt = frame;

	// address check
	switch (fc) {
	case IEEE80211_STYPE_AUTH:
		skw_mlme_ap_auth_handler(iface, freq, signal, frame, frame_len);
		break;

	case IEEE80211_STYPE_DEAUTH:
	case IEEE80211_STYPE_DISASSOC:
		client = skw_mlme_ap_get_client(iface, mgmt->sa);
		if (!client) {
			skw_warn("can't find sta:%pM\n", mgmt->sa);
			return 0;
		}

		if (client->state >= SKW_STATE_ASSOCED) {
			//notify hostapd to update state and delete sta
			cfg80211_del_sta(iface->ndev, client->addr, GFP_KERNEL);
		} else if (client->state >= SKW_STATE_AUTHED) {
			//just delete local sta info
			skw_mlme_ap_del_sta(iface->wdev.wiphy,
					    iface->ndev, client->addr, false);
		}
#if 0
		skw_add_timer_work("idle_release", skw_mlme_ap_auth_timeout,
				   client, SKW_AP_IDLE_TIMEOUT,
				   client, GFP_KERNEL);
#endif
		break;

	case IEEE80211_STYPE_REASSOC_REQ:
		reassoc = 1;
		/* fall through */
		skw_fallthrough;
	case IEEE80211_STYPE_ASSOC_REQ:
		skw_mlme_ap_assoc_handler(iface, frame, frame_len, reassoc);
		break;

	case IEEE80211_STYPE_PROBE_REQ:
		skw_fallthrough;
	case IEEE80211_STYPE_PROBE_RESP:
		skw_fallthrough;
	case IEEE80211_STYPE_ACTION:
		if (!skw_compat_cfg80211_rx_mgmt(&iface->wdev, freq, signal,
						frame, frame_len, 0, GFP_ATOMIC)) {
			skw_warn("mlme_ap_rx failed\n");
		}
		break;

	default:
		skw_warn("unsupport fc type: 0x%x\n", fc);
		break;
	}

	return 0;
}

#if 0
int skw_send_deauth_frame(struct wiphy *wiphy, struct net_device *netdev,
			int reason_code)
{
	int ret;
	int size;
	char *buff = NULL;
	struct skw_core *skw;
	struct skw_disconnect_param *deauth_param = NULL;

	skw = wiphy_priv(wiphy);

	size = sizeof(struct skw_disconnect_param);
	buff = SKW_ZALLOC(size, GFP_KERNEL);
	if (IS_ERR_OR_NULL(buff)) {
		skw_err("Malloc disconnect param for deauth failed\n");
		return -ENOMEM;
	}

	deauth_param = (struct skw_disconnect_param *)buff;
	deauth_param->type = SKW_DISCONNECT_SEND_DEAUTH;
	deauth_param->local_state_change = true;
	deauth_param->reason_code = reason_code;
	deauth_param->ie_len = 0;

	ret = skw_send_msg(wiphy, netdev, SKW_CMD_DISCONNECT, buff,
			size, NULL, 0);
	if (ret)
		skw_err("Deauth failed ret:%d\n", ret);

	SKW_KFREE(buff);

	return ret;
}
#endif

static int skw_mlme_sta_ft_event(struct skw_iface *iface, void *buf, int len)
{
	int ie_len;
	struct cfg80211_ft_event_params ft_event;
	struct ieee80211_mgmt *mgmt = buf;

	ie_len = len - offsetof(struct ieee80211_mgmt, u.auth.variable);

	ft_event.ies = mgmt->u.auth.variable;
	ft_event.ies_len = ie_len;
	ft_event.target_ap = mgmt->bssid;
	ft_event.ric_ies = NULL;
	ft_event.ric_ies_len = 0;

	cfg80211_ft_event(iface->ndev, &ft_event);

	return 0;
}

int skw_mlme_sta_rx_auth(struct skw_iface *iface, int freq, int signal,
			 void *buf, int len)
{
	u16 status_code;
	struct ieee80211_mgmt *mgmt = buf;
	struct wiphy *wiphy = iface->wdev.wiphy;
	struct skw_connect_param *conn = iface->sta.conn;

	skw_dbg("auth_type: %d, flags: 0x%x\n",
		conn->auth_type, conn->flags);

	conn->state = SKW_STATE_AUTHED;

	if (conn->auth_type == NL80211_AUTHTYPE_SAE)
		return skw_compat_cfg80211_rx_mgmt(&iface->wdev, freq, signal,
						buf, len, 0, GFP_ATOMIC);

	if (conn->auth_type == NL80211_AUTHTYPE_FT)
		return skw_mlme_sta_ft_event(iface, mgmt, len);

	status_code = le16_to_cpu(mgmt->u.auth.status_code);
	if (status_code == WLAN_STATUS_SUCCESS)
		return skw_connect_assoc(wiphy, iface->ndev, conn);

	if (SKW_TEST(conn->flags, SKW_CONN_FLAG_AUTH_AUTO) &&
	    status_code == WLAN_STATUS_NOT_SUPPORTED_AUTH_ALG) {
		mutex_lock(&iface->sta.conn->lock);

		switch (conn->auth_type) {
		case NL80211_AUTHTYPE_OPEN_SYSTEM:
			if (conn->key_len)
				conn->auth_type = NL80211_AUTHTYPE_SHARED_KEY;
			else
				conn->auth_type = NL80211_AUTHTYPE_FT;
			break;

		case NL80211_AUTHTYPE_SHARED_KEY:
			conn->auth_type = NL80211_AUTHTYPE_FT;
			break;

		default:
			SKW_CLEAR(conn->flags, SKW_CONN_FLAG_AUTH_AUTO);
			break;
		}

		mutex_unlock(&iface->sta.conn->lock);

		if (conn->flags & SKW_CONN_FLAG_AUTH_AUTO) {
			return skw_queue_local_event(wiphy, iface,
					SKW_EVENT_LOCAL_STA_CONNECT,
					NULL, 0);
		}
	}

	/* status code != WLAN_STATUS_SUCCESS */
	conn->state = SKW_STATE_NONE;

	return 0;
}

int skw_mlme_sta_rx_assoc(struct skw_iface *iface, struct cfg80211_bss *bss,
			  void *frame, int len, void *req_ie, int req_ie_len)
{
	u16 status;
	int resp_ie_len;
	struct ieee80211_mgmt *mgmt = frame;
	struct skw_connect_param *conn = iface->sta.conn;

	skw_dbg("bssid: %pM\n", mgmt->bssid);

	mutex_lock(&conn->lock);

	resp_ie_len = offsetof(struct ieee80211_mgmt, u.assoc_resp.variable);
	resp_ie_len = len - resp_ie_len;

	status = le16_to_cpu(mgmt->u.assoc_resp.status_code);
	if (status == WLAN_STATUS_SUCCESS) {
		conn->state = SKW_STATE_ASSOCED;
		skw_connected(iface->ndev, conn, req_ie, req_ie_len,
			      mgmt->u.assoc_resp.variable, resp_ie_len,
			      status, GFP_KERNEL);
	} else {
		conn->state = SKW_STATE_NONE;
		skw_disconnected(iface->ndev, WLAN_REASON_UNSPECIFIED,
				 false, GFP_KERNEL);
	}

	mutex_unlock(&conn->lock);

	return 0;
}
===== ./drivers/skwifi/skw_core.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/kernel.h>
#include <linux/module.h>
#include <linux/device.h>
#include <linux/ip.h>
#include <linux/if_ether.h>
#include <linux/skbuff.h>
#include <linux/inetdevice.h>
#include <net/addrconf.h>
#include <linux/ctype.h>
#include <net/tcp.h>
#include <net/arp.h>
#include <linux/platform_device.h>
#include <linux/if_tunnel.h>
#include <linux/firmware.h>
#include <generated/utsrelease.h>

#include "skw_core.h"
#include "skw_cfg80211.h"
#include "skw_tx.h"
#include "skw_rx.h"
#include "skw_iw.h"
#include "skw_timer.h"
#include "skw_work.h"
#include "version.h"
#include "skw_calib.h"
#include "skw_vendor.h"
#include "skw_regd.h"
#include "skw_recovery.h"
#include "trace.h"

static u8 skw_mac[ETH_ALEN];
static atomic_t skw_chip_idx = ATOMIC_INIT(0);

static const int g_skw_up_to_ac[8] = {
	SKW_WMM_AC_BE,
	SKW_WMM_AC_BK,
	SKW_WMM_AC_BK,
	SKW_WMM_AC_BE,
	SKW_WMM_AC_VI,
	SKW_WMM_AC_VI,
	SKW_WMM_AC_VO,
	SKW_WMM_AC_VO
};

static int skw_repeater_show(struct seq_file *seq, void *data)
{
	struct skw_core *skw = seq->private;

	if (test_bit(SKW_FLAG_REPEATER, &skw->flags))
		seq_puts(seq, "enable\n");
	else
		seq_puts(seq, "disable\n");

	return 0;
}

static int skw_repeater_open(struct inode *inode, struct file *file)
{
	return single_open(file, skw_repeater_show, inode->i_private);
}

static ssize_t skw_repeater_write(struct file *fp, const char __user *buf,
				size_t len, loff_t *offset)
{
	int i;
	char cmd[32] = {0};
	struct skw_core *skw = fp->f_inode->i_private;

	for (i = 0; i < len; i++) {
		char c;

		if (get_user(c, buf))
			return -EFAULT;

		if (c == '\n' || c == '\0')
			break;

		cmd[i] = tolower(c);
		buf++;
	}

	if (strcmp(cmd, "enable") == 0)
		set_bit(SKW_FLAG_REPEATER, &skw->flags);
	else if (strcmp(cmd, "disable") == 0)
		clear_bit(SKW_FLAG_REPEATER, &skw->flags);
	else
		skw_warn("rx_reorder support setting values of \"enable\" or \"disable\"\n");

	return len;
}

static const struct file_operations skw_repeater_fops = {
	.owner = THIS_MODULE,
	.open = skw_repeater_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_repeater_write,
};

static void skw_dbg_print(struct skw_core *skw, struct seq_file *seq)
{
	int i;
	u64 nsecs;
	unsigned long rem_nsec;

	for (i = 0; i < skw->dbg.nr_cmd; i++) {
		struct skw_dbg_cmd *cmd = &skw->dbg.cmd[i];

		seq_printf(seq, "cmd[%d].id: %d, seq: %d, flags: 0x%lx, loop: %d\n",
			i, cmd->id, cmd->seq, cmd->flags, cmd->loop);

		nsecs = cmd->trigger;
		rem_nsec = do_div(nsecs, 1000000000);
		seq_printf(seq, "    cmd.%d.%d.trigger: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		nsecs = cmd->build;
		rem_nsec = do_div(nsecs, 1000000000);
		seq_printf(seq, "    cmd.%d.%d.build: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		nsecs = cmd->xmit;
		rem_nsec = do_div(nsecs, 1000000000);
		seq_printf(seq, "    cmd.%d.%d.xmit: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		nsecs = cmd->done;
		rem_nsec = do_div(nsecs, 1000000000);
		seq_printf(seq, "    cmd.%d.%d.done: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		nsecs = cmd->ack;
		rem_nsec = do_div(nsecs, 1000000000);
		seq_printf(seq, "    cmd.%d.%d.ack: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		nsecs = cmd->assert;
		rem_nsec = do_div(nsecs, 1000000000);
		seq_printf(seq, "    cmd.%d.%d.assert: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		seq_puts(seq, "\n");
	}

	for (i = 0; i < skw->dbg.nr_dat; i++) {
		struct skw_dbg_dat *dat = &skw->dbg.dat[i];

		seq_printf(seq, "dat[%d], tx_qlen: %d\n", i, dat->qlen);

		nsecs = dat->trigger;
		rem_nsec = do_div(nsecs, 1000000000);
		seq_printf(seq, "    dat.%d.%d.trigger: %5lu.%06lu\n",
			i, dat->qlen, (unsigned long)nsecs, rem_nsec / 1000);

		nsecs = dat->done;
		rem_nsec = do_div(nsecs, 1000000000);
		seq_printf(seq, "    dat.%d.%d.done: %5lu.%06lu\n",
			i, dat->qlen, (unsigned long)nsecs, rem_nsec / 1000);

		seq_puts(seq, "\n");
	}
}

static void skw_timestap_print(struct skw_core *skw, struct seq_file *seq)
{
	u64 ts;
	struct rtc_time tm;
	unsigned long rem_nsec;

	ts = skw->fw.host_timestamp;
	rem_nsec = do_div(ts, 1000000000);
	skw_compat_rtc_time_to_tm(skw->fw.host_seconds, &tm);

	seq_printf(seq,
		   "Timestamp: %u - %lu.%06lu (%d-%02d-%02d %02d:%02d:%02d UTC)\n",
		   skw->fw.timestamp, (unsigned long)ts,
		   rem_nsec / 1000, tm.tm_year + 1900,
		   tm.tm_mon + 1, tm.tm_mday, tm.tm_hour,
		   tm.tm_min, tm.tm_sec);
}

static void skw_drv_info_print(struct skw_core *skw, struct seq_file *seq)
{
	int i;

#define FLAG_TEST(n) test_bit(SKW_FLAG_##n, &skw->flags)
	seq_printf(seq,
		   "SKW Flags:\t 0x%lx %s\n"
		   "TX Packets:\t %ld\n"
		   "RX Packets:\t %ld\n"
		   "txqlen_pending:\t %d\n"
		   "nr lmac:\t %d\n"
		   "skb_recycle_qlist:%d\n",
		   skw->flags, FLAG_TEST(FW_ASSERT) ? "(Assert)" : "",
		   skw->tx_packets,
		   skw->rx_packets,
		   atomic_read(&skw->txqlen_pending),
		   skw->hw.nr_lmac,
		   READ_ONCE(skw->skb_recycle_qlist.qlen));

	for (i = 0; i < skw->hw.nr_lmac; i++)
		seq_printf(seq, "    credit[%d]:\t %d (%s)\n",
			   i, skw_get_hw_credit(skw, i),
			   skw_lmac_is_actived(skw, i) ? "active" : "inactive");
#undef FLAG_TEST
}

static void skw_fw_info_print(struct skw_core *skw, struct seq_file *seq)
{
	if (!skw->hw_pdata)
		return;

	/* Firmware & BSP Info */
	seq_printf(seq, "Calib File:\t %s\n"
			"FW Build:\t %s\n"
			"FW Version:\t %s-%s (BSP-MAC)\n"
			"BUS Type:\t 0x%x (%s)\n"
			"Align Size:\t %d\n"
			"TX Limit:\t %d\n",
			skw->fw.calib_file,
			skw->fw.build_time,
			skw->fw.plat_ver,
			skw->fw.wifi_ver,
			skw->hw_pdata->bus_type,
			skw_bus_name(skw->hw.bus),
			skw->hw_pdata->align_value,
			skw->hw.pkt_limit);
}

static int skw_core_show(struct seq_file *seq, void *data)
{
	struct skw_core *skw = seq->private;

	seq_puts(seq, "\n");
	skw_timestap_print(skw, seq);

	seq_puts(seq, "\n");
	skw_drv_info_print(skw, seq);

	seq_puts(seq, "\n");
	skw_fw_info_print(skw, seq);

	seq_puts(seq, "\n");
	skw_dbg_print(skw, seq);

	seq_puts(seq, "\n");

	return 0;
}

static int skw_core_open(struct inode *inode, struct file *file)
{
	// return single_open(file, skw_core_show, inode->i_private);
	return single_open(file, skw_core_show, skw_pde_data(inode));
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
static const struct proc_ops skw_core_fops = {
	.proc_open = skw_core_open,
	.proc_read = seq_read,
	.proc_lseek = seq_lseek,
	.proc_release = single_release,
};
#else
static const struct file_operations skw_core_fops = {
	.owner = THIS_MODULE,
	.open = skw_core_open,
	.read = seq_read,
	.llseek = seq_lseek,
	.release = single_release,
};
#endif

static int skw_assert_show(struct seq_file *seq, void *data)
{
	return 0;
}

static int skw_assert_open(struct inode *inode, struct file *file)
{
	return single_open(file, skw_assert_show, inode->i_private);
}

static ssize_t skw_assert_write(struct file *fp, const char __user *buf,
				size_t len, loff_t *offset)
{
	struct skw_core *skw = fp->f_inode->i_private;

	skw_hw_assert(skw, false);

	return len;
}

static const struct file_operations skw_assert_fops = {
	.owner = THIS_MODULE,
	.open = skw_assert_open,
	.read = seq_read,
	.write = skw_assert_write,
	.release = single_release,
};

static int skw_ndo_open(struct net_device *dev)
{
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_core *skw = iface->skw;

	skw_dbg("dev: %s, type: %s\n", netdev_name(dev),
		skw_iftype_name(dev->ieee80211_ptr->iftype));

	if (test_bit(SKW_FLAG_FW_THERMAL, &skw->flags)) {
		skw_warn("disable TX for thermal warnning");
		netif_tx_stop_all_queues(dev);
	}

	netif_carrier_off(dev);

	if (dev->ieee80211_ptr->iftype == NL80211_IFTYPE_MONITOR) {
		dev->type = ARPHRD_IEEE80211;
		netif_tx_stop_all_queues(dev);
	} else
		dev->type = ARPHRD_ETHER;

	return 0;
}

static int skw_ndo_stop(struct net_device *dev)
{
	struct skw_iface *iface = netdev_priv(dev);
	struct skw_core *skw = iface->skw;

	skw_dbg("dev: %s, type: %s\n", netdev_name(dev),
		skw_iftype_name(dev->ieee80211_ptr->iftype));

	//netif_tx_stop_all_queues(dev);

	// fixme:
	// check if sched scan is going on current netdev
	skw_scan_done(skw, iface, true);

	switch (dev->ieee80211_ptr->iftype) {
	case NL80211_IFTYPE_STATION:
	case NL80211_IFTYPE_P2P_CLIENT:
		// if (iface->sta.sm.state !=  SKW_STATE_NONE)
			//skw_disconnect(iface->wdev.wiphy, iface->ndev,
			//		WLAN_REASON_DEAUTH_LEAVING);
		break;

	case NL80211_IFTYPE_AP:
	case NL80211_IFTYPE_P2P_GO:
		// skw_flush_sta_info(iface);
		break;

	case NL80211_IFTYPE_MONITOR:
		skw_cmd_monitor(priv_to_wiphy(skw), NULL, SKW_MONITOR_CLOSE);
		break;

	default:
		break;
	}

	return 0;
}

static bool skw_udp_filter(struct net_device *ndev, struct sk_buff *skb)
{
	bool ret = false;
	struct udphdr *udp = udp_hdr(skb);

#define DHCP_SERVER_PORT         67
#define DHCP_CLIENT_PORT         68
#define DHCPV6_SERVER_PORT       546
#define DHCPV6_CLIENT_PORT       547

	switch (ntohs(udp->dest)) {
	case DHCP_CLIENT_PORT:
	case DHCP_SERVER_PORT:
		if (ndev->priv_flags & IFF_BRIDGE_PORT) {
			/* set BOOTP flag to broadcast */
			*((u8 *)udp + 18) = 0x80;
			udp->check = 0;
		}

		skw_fallthrough;

	case DHCPV6_CLIENT_PORT:
	case DHCPV6_SERVER_PORT:
		ret = true;
		skw_dbg("DHCP, port: %d\n", ntohs(udp->dest));
		break;

	default:
		ret = false;
		break;
	}

	return ret;
}

static void skw_setup_txba(struct skw_core *skw, struct skw_iface *iface,
			   struct skw_peer *peer, int tid)
{
	int ret;
	struct skw_ba_action tx_ba;

	if (tid >= SKW_NR_TID) {
		skw_warn("tid: %d invalid\n", tid);
		return;
	}

	if ((peer->txba.bitmap | peer->txba.blacklist) & BIT(tid))
		return;

	tx_ba.tid = tid;
	tx_ba.win_size = 64;
	tx_ba.peer_idx = peer->idx;
	tx_ba.action = SKW_ADD_TX_BA;

	ret = skw_queue_work(priv_to_wiphy(skw), iface, SKW_WORK_SETUP_TXBA,
				&tx_ba, sizeof(tx_ba));
	if (!ret)
		peer->txba.bitmap |= BIT(tid);
}

struct skw_ctx_entry *skw_get_ctx_entry(struct skw_core *skw, const u8 *addr)
{
	int i;
	struct skw_ctx_entry *entry;

	for (i = 0; i < SKW_MAX_PEER_SUPPORT; i++) {
		entry = rcu_dereference(skw->peer_ctx[i].entry);
		if (entry && ether_addr_equal(entry->addr, addr))
			return entry;
	}

	return NULL;
}

struct skw_peer_ctx *skw_get_ctx(struct skw_core *skw, u8 idx)
{
	if (idx >= SKW_MAX_PEER_SUPPORT)
		return NULL;

	return &skw->peer_ctx[idx];
}

static int skw_downgrade_ac(struct skw_iface *iface, int aci)
{
#if 1
	while (iface->wmm.acm & BIT(aci)) {
		if (aci == SKW_WMM_AC_BK)
			break;
		aci++;
	}
#else
	if (iface->wmm.acm & BIT(aci)) {
		int i;
		int acm = SKW_WMM_AC_BK;

		for (i = SKW_WMM_AC_BK; i >= 0; i--) {
			if (!(iface->wmm.acm & BIT(i))) {
				acm = i;
				break;
			}
		}

		aci = acm;
	}
#endif

	return aci;
}

static inline bool is_skw_tcp_pure_ack(struct sk_buff *skb)
{
	return tcp_hdr(skb)->ack &&
	       ntohs(ip_hdr(skb)->tot_len) == ip_hdrlen(skb) + tcp_hdrlen(skb);
}

static netdev_tx_t skw_ndo_xmit(struct sk_buff *skb, struct net_device *ndev)
{
	int ret = -1;
	u8 tid;
	u8 fixed_rate = 0;
	u8 fixed_tid = SKW_INVALID_ID;
	u8 peer_index = SKW_INVALID_ID;
	u8 ac_idx = 0, padding = 0;
	u8 prot = 0, tcp_pkt = 0, do_csum = 0;
	bool is_prot_filter = false;
	bool is_udp_filter = false;
	bool is_802_3_frame = false;
	bool pure_tcp_ack = false;
	const u8 tid_map[] = {6, 4, 0, 1};
	int l4_hdr_offset = 0, reset_l4_offset = 0;
	int msdu_len = 0, align_len;
	int nhead, ntail, nroom, txq_len;
	bool is_completed = true;

	struct netdev_queue *txq;
	struct skw_peer_ctx *ctx;
	struct skw_iface *iface = netdev_priv(ndev);
	struct ethhdr *eth = eth_hdr(skb);
	struct skw_ctx_entry *entry = NULL;
	struct sk_buff_head *qlist;
	struct skw_tx_desc_hdr *desc_hdr;
	struct skw_tx_desc_conf *desc_conf;
	struct skw_core *skw = iface->skw;
#ifdef CONFIG_SKW_SKB_RECYCLE
	struct sk_buff *skb_recycle;
#endif
	s16 pkt_limit;

	/* Mini frame size that HW support */
	if (unlikely(skb->len <= 16)) {
		skw_dbg("current: %s\n", current->comm);
		skw_hex_dump("short skb", skb->data, skb->len, true);

		if (skb->len != ETH_HLEN || eth->h_proto != htons(ETH_P_IP))
			SKW_BUG_ON(1);

		goto free;
	}

	if (skb_linearize(skb))
		goto free;

	msdu_len = skb->len;
	SKW_SKB_TXCB(skb)->skb_native_len = skb->len;
	SKW_SKB_TXCB(skb)->ret = 0;
	SKW_SKB_TXCB(skb)->recycle = 0;
	if (skb->ip_summed == CHECKSUM_PARTIAL) {
		l4_hdr_offset = skb_checksum_start_offset(skb);
		do_csum = 1;
	}

	switch (eth->h_proto) {
	case htons(ETH_P_IP):
		prot = ip_hdr(skb)->protocol;
		reset_l4_offset = ETH_HLEN + ip_hdrlen(skb);

		if (prot == IPPROTO_TCP)
			pure_tcp_ack = is_skw_tcp_pure_ack(skb);

		break;

	case htons(ETH_P_IPV6):
		prot = ipv6_hdr(skb)->nexthdr;
		// fixme:
		// get tcp/udp head offset
		reset_l4_offset = ETH_HLEN + sizeof(struct ipv6hdr);
		break;

	case htons(ETH_P_ARP):
		if (test_bit(SKW_FLAG_FW_FILTER_ARP, &skw->flags))
			is_prot_filter = true;
#ifdef CONFIG_SKW_REPEATER_MODE
		if (unlikely(test_bit(SKW_FLAG_REPEATER, &skw->flags)) &&
		    ndev->priv_flags & IFF_BRIDGE_PORT) {
			if (iface->wdev.iftype == NL80211_IFTYPE_STATION) {
				struct sk_buff *arp_skb;
				struct skw_ctx_entry *e;
				struct skw_arphdr *arp = skw_arp_hdr(skb);

				rcu_read_lock();
				e = skw_get_ctx_entry(iface->skw, arp->ar_sha);
				if (e)
					e->peer->ip_addr = arp->ar_sip;

				rcu_read_unlock();

				arp_skb = arp_create(ntohs(arp->ar_op),
						ETH_P_ARP, arp->ar_tip,
						iface->ndev,
						arp->ar_sip, eth->h_dest,
						iface->addr, arp->ar_tha);

				kfree_skb(skb);

				skb = arp_skb;
				if (!skb)
					return NETDEV_TX_OK;

				eth = skw_eth_hdr(skb);
			}
		}
#endif
		//fixed_rate = 1;
		//fixed_tid = 4;
		break;

	case htons(ETH_P_PAE):
	case htons(SKW_ETH_P_WAPI):
	case htons(ETH_P_TDLS):
		is_prot_filter = true;
		break;

	default:
		if (eth->h_proto < ETH_P_802_3_MIN)
			is_802_3_frame = true;

		break;
	}

	if (!do_csum && (prot == IPPROTO_UDP || prot == IPPROTO_TCP))
		skb_set_transport_header(skb, reset_l4_offset);

	// fixme:
	/* enable checksum for TCP & UDP frame, except framgment frame */
	switch (prot) {
	case IPPROTO_UDP:
		is_udp_filter = skw_udp_filter(ndev, skb);
		if (udp_hdr(skb)->check == 0)
			do_csum = 0;

		break;

	case IPPROTO_TCP:
		tcp_pkt = 1;

		break;

	default:
		break;
	}

	ac_idx = skw_downgrade_ac(iface, g_skw_up_to_ac[skb->priority]);
	tid = fixed_tid != SKW_INVALID_ID ? fixed_tid : tid_map[ac_idx];

	rcu_read_lock();

	switch (iface->wdev.iftype) {
	case NL80211_IFTYPE_AP:
	case NL80211_IFTYPE_P2P_GO:
		if (is_unicast_ether_addr(eth->h_dest)) {
			entry = skw_get_ctx_entry(skw, eth->h_dest);
			peer_index = entry ? entry->idx : SKW_INVALID_ID;

			if (entry && entry->peer->sm.state != SKW_STATE_COMPLETED)
				is_completed = false;
		} else {
			fixed_rate = 1;
			peer_index = iface->default_multicast;
		}

		break;

	case NL80211_IFTYPE_STATION:
	case NL80211_IFTYPE_P2P_CLIENT:
	case NL80211_IFTYPE_ADHOC:

		if (atomic_read(&iface->actived_ctx) > 1)
			entry = skw_get_ctx_entry(skw, eth->h_dest);

		if (!entry) {
			ctx = skw_get_ctx(skw, iface->sta.core.bss.ctx_idx);
			if (ctx)
				entry = rcu_dereference(ctx->entry);
		}

		peer_index = entry ? entry->idx : SKW_INVALID_ID;

		if (iface->sta.core.sm.state != SKW_STATE_COMPLETED)
			is_completed = false;

		break;

	default:
		peer_index = SKW_INVALID_ID;
		break;
	}

	if (entry && is_completed)
		skw_setup_txba(skw, iface, entry->peer, tid);

	rcu_read_unlock();

	if (peer_index == SKW_INVALID_ID) {
		skw_dbg("%s drop dst: %pM, proto: 0x%x\n",
			netdev_name(ndev), eth->h_dest, htons(eth->h_proto));

		goto free;
	}

#ifdef CONFIG_SKW_SKB_RECYCLE
	if (!is_prot_filter && !is_udp_filter && !is_802_3_frame && !is_multicast_ether_addr(eth->h_dest)) {
		skb_recycle = skw_recycle_skb_get(skw);
		if (skb_recycle) {
			if (!skw_recycle_skb_copy(skw, skb_recycle, skb)) {
				dev_kfree_skb_any(skb);
				skb = skb_recycle;
				eth = skw_eth_hdr(skb);
				SKW_SKB_TXCB(skb)->recycle = 1;
			} else {
				skw_err("skw_recycle_skb_copy failed\n");
				skw_recycle_skb_free(skw, skb_recycle);
			}
		}
	}
#endif

	padding = (long)(skb->data - skw->skb_headroom) & SKW_DATA_ALIGN_MASK;
	if (padding)
		padding = SKW_DATA_ALIGN_SIZE - padding;

	nroom = skb_headroom(skb);
	nhead = skw->skb_headroom > nroom ? skw->skb_headroom - nroom : 0;

	nroom = skb->len + skw->skb_headroom + padding - SKW_DATA_ALIGN_SIZE;
	align_len = round_up(nroom, skw->hw.align);
	nroom = align_len - nroom;
	ntail = nroom > skb_tailroom(skb) ? nroom - skb_tailroom(skb) : 0;

	if (nhead || ntail || skb_cloned(skb)) {
		if (unlikely(pskb_expand_head(skb, nhead, ntail, GFP_ATOMIC))) {
			skw_dbg("failed, nhead: %d, ntail: %d\n", nhead, ntail);
			goto free;
		}

		eth = skw_eth_hdr(skb);
	}

	desc_conf = (void *)skb_push(skb, sizeof(*desc_conf));
	desc_conf->csum = do_csum;
	desc_conf->ip_prot = tcp_pkt;
	desc_conf->l4_hdr_offset = l4_hdr_offset;

	if (skw->hw.bus == SKW_BUS_PCIE) {
		dma_addr_t pa;

		SKW_SKB_TXCB(skb)->e.eth_type = eth->h_proto;
		SKW_SKB_TXCB(skb)->e.mac_id = iface->id;
		SKW_SKB_TXCB(skb)->e.tid = tid;
		SKW_SKB_TXCB(skb)->e.peer_idx = peer_index;
		SKW_SKB_TXCB(skb)->e.prot = SKW_ETHER_FRAME;
		SKW_SKB_TXCB(skb)->e.encry_dis = 0;
		SKW_SKB_TXCB(skb)->e.rate = fixed_rate;
		SKW_SKB_TXCB(skb)->e.msdu_len = msdu_len;

		SKW_SKB_TXCB(skb)->skb_data_pa = skw_pci_map_single(skw,
			skb->data, skb->len, DMA_TO_DEVICE);
		pa = skw->hw_pdata->virtaddr_to_pcieaddr(skb->data);
		SKW_SKB_TXCB(skb)->e.pa = (pa + 2) & 0xFFFFFFFFFF;
	} else {
		if (padding)
			skb_push(skb, padding);

		desc_hdr = (void *)skb_push(skb, sizeof(*desc_hdr));
		desc_hdr->padding_gap = padding;
		desc_hdr->inst = iface->id & 0x3;

		desc_hdr->tid = tid;
		desc_hdr->peer_lut = peer_index;
		desc_hdr->frame_type = SKW_ETHER_FRAME;
		skw_set_tx_desc_eth_type(desc_hdr, eth->h_proto);

		desc_hdr->encry_dis = 0;
		desc_hdr->msdu_len = msdu_len;
		desc_hdr->rate = fixed_rate;
	}
	__net_timestamp(skb);

	if (unlikely(is_prot_filter || is_udp_filter || is_802_3_frame)) {
		skw_dbg("proto: 0x%x, udp filter: %d, 802.3 frame: %d\n",
			htons(eth->h_proto), is_udp_filter, is_802_3_frame);

		if (skw->hw.bus == SKW_BUS_PCIE) {
			desc_hdr = (void *)skb_push(skb, sizeof(*desc_hdr));
			desc_hdr->padding_gap = padding;
			desc_hdr->inst = iface->id & 0x3;

			desc_hdr->tid = tid;
			desc_hdr->peer_lut = peer_index;
			desc_hdr->frame_type = SKW_ETHER_FRAME;

			desc_hdr->encry_dis = 0;
			desc_hdr->msdu_len = msdu_len;
			desc_hdr->rate = fixed_rate;
			skw_dbg("Add desc hdr for spec data\n");
		}

		ret = skw_msg_try_send(skw, iface->id, SKW_CMD_TX_DATA_FRAME,
				       skb->data, skb->len, NULL, 0,
				       "SKW_CMD_TX_DATA_FRAME");
		if (ret < 0) {
			if (SKW_SKB_TXCB(skb)->tx_retry++ > 3) {
				skw_queue_work(priv_to_wiphy(skw), iface,
					       SKW_WORK_TX_ETHER_DATA,
					       skb->data, skb->len);
			} else {
				skb_pull(skb, skb->len - msdu_len);
				return NETDEV_TX_BUSY;
			}
		}

		goto free;
	}

	SKW_SKB_TXCB(skb)->peer_idx = peer_index;

	if (pure_tcp_ack)
		ac_idx = SKW_ACK_TXQ;

	qlist = &iface->txq[ac_idx];

	skb_queue_tail(qlist, skb);
#ifdef CONFIG_SKW_SKB_RECYCLE
	if (skw->hw.bus == SKW_BUS_PCIE)
		pkt_limit = 32;
	else if (skw->hw.bus == SKW_BUS_SDIO || skw->hw.bus == SKW_BUS_SDIO2)
		pkt_limit = 32;
	else
		pkt_limit = skw->hw.pkt_limit;

	if (prot == IPPROTO_UDP || prot == IPPROTO_TCP) {
		if (skb_queue_len(qlist) < pkt_limit) {
			if (!timer_pending(&skw->tx_worker.timer))
				skw_wakeup_tx(skw, msecs_to_jiffies(1));
		} else
			skw_wakeup_tx(skw, 0);
	} else
		skw_wakeup_tx(skw, 0);
#else
	if (skw->hw.bus == SKW_BUS_PCIE)
		pkt_limit = 32 / 2;
	else
		pkt_limit = skw->hw.pkt_limit;

	pkt_limit = skw->hw.pkt_limit;
	if (prot == IPPROTO_UDP && skb_queue_len(qlist) < pkt_limit) {
		if (!timer_pending(&skw->tx_worker.timer))
			skw_wakeup_tx(skw, msecs_to_jiffies(1));
	} else
		skw_wakeup_tx(skw, 0);

#endif
	trace_skw_tx_xmit(eth->h_dest, peer_index, prot, fixed_rate,
			  do_csum, ac_idx, skb_queue_len(qlist));

	txq_len = skb_queue_len(qlist) + skb_queue_len(&iface->tx_cache[ac_idx]);
	if (txq_len >= SKW_TXQ_HIGH_THRESHOLD) {
		txq = netdev_get_tx_queue(ndev, ac_idx);
		if (!netif_tx_queue_stopped(txq))
			netif_tx_stop_queue(txq);
	}

	return NETDEV_TX_OK;

free:
	if (ret != 0)
		ndev->stats.tx_dropped++;

	dev_kfree_skb_any(skb);

	return NETDEV_TX_OK;
}

static u16 skw_ndo_select(struct net_device *dev, struct sk_buff *skb
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 2, 0)
		, struct net_device *sb_dev
#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4, 19, 0)
		, struct net_device *sb_dev,
		select_queue_fallback_t fallback
#elif LINUX_VERSION_CODE >= KERNEL_VERSION(3, 14, 0)
		, void *accel_priv,
		select_queue_fallback_t fallback
#elif LINUX_VERSION_CODE >= KERNEL_VERSION(3, 13, 0)
		, void *accel_priv
#endif
		SKW_NULL)
{
	struct skw_iface *iface = netdev_priv(dev);

	if (!iface->wmm.qos_enabled) {
		skb->priority = 0;
		return SKW_WMM_AC_BE;
	}

	skb->priority = skw_compat_classify8021d(skb, iface->qos_map);

	return g_skw_up_to_ac[skb->priority];
}

#define SKW_ANDROID_CMD_LEN    128
static int skw_android_cmd(struct net_device *dev, void __user *priv_data)
{
	char command[SKW_ANDROID_CMD_LEN], *data;
	struct android_wifi_priv_cmd priv_cmd;
	bool compat_task = false;

	if (!priv_data)
		return  -EINVAL;

#ifdef CONFIG_COMPAT
	if (SKW_IS_COMPAT_TASK()) {
		struct compat_android_wifi_priv_cmd compat;

		if (copy_from_user(&compat, priv_data, sizeof(compat)))
			return -EFAULT;

		priv_cmd.buf = compat_ptr(compat.buf);
		priv_cmd.used_len = compat.used_len;
		priv_cmd.total_len = compat.total_len;

		compat_task = true;
	}
#endif

	if (!compat_task &&
	    copy_from_user(&priv_cmd, priv_data, sizeof(priv_cmd)))
		return -EFAULT;

	if (copy_from_user(command, priv_cmd.buf, sizeof(command)))
		return -EFAULT;

	command[SKW_ANDROID_CMD_LEN - 1] = 0;

	skw_dbg("%s: %s\n", netdev_name(dev), command);

#define IS_SKW_CMD(c, k)        \
	!strncasecmp(c, SKW_ANDROID_PRIV_##k, strlen(SKW_ANDROID_PRIV_##k))

#define SKW_CMD_DATA(c, k)     \
	(c + strlen(SKW_ANDROID_PRIV_##k) + 1)

#define SKW_CMD_DATA_LEN(c, k) \
	(sizeof(command) - strlen(SKW_ANDROID_PRIV_##k) - 1)

	if (IS_SKW_CMD(command, COUNTRY)) {
		data = SKW_CMD_DATA(command, COUNTRY);
		skw_set_regdom(dev->ieee80211_ptr->wiphy, data);
	} else if (IS_SKW_CMD(command, BTCOEXSCAN_STOP)) {
	} else if (IS_SKW_CMD(command, RXFILTER_START)) {
	} else if (IS_SKW_CMD(command, RXFILTER_STOP)) {
	} else if (IS_SKW_CMD(command, RXFILTER_ADD)) {
	} else if (IS_SKW_CMD(command, RXFILTER_REMOVE)) {
	} else if (IS_SKW_CMD(command, SETSUSPENDMODE)) {
	} else if (IS_SKW_CMD(command, BTCOEXMODE)) {
	} else if (IS_SKW_CMD(command, SET_AP_WPS_P2P_IE)) {
	} else {
		skw_info("Unsupport cmd: %s - ignored\n", command);
	}

#undef IS_SKW_CMD

	return 0;
}

static int skw_ioctl(struct net_device *dev, void __user *user_data)
{
	int ret = -ENOTSUPP;
	char country[4] = {0};
	struct skw_ioctl_cmd cmd;

	if (copy_from_user(&cmd, user_data, sizeof(cmd)))
		return -ENOMEM;

	switch (cmd.id) {
	case SKW_IOCTL_SUBCMD_COUNTRY:

		if (cmd.len > sizeof(country))
			return -EINVAL;

		if (copy_from_user(country, user_data + sizeof(cmd), cmd.len))
			return -EINVAL;

		if (strlen(country) != 2)
			return -EINVAL;

		ret = skw_set_regdom(dev->ieee80211_ptr->wiphy, country);

		break;

	default:
		skw_warn("unsupport cmd: 0x%x, len: %d\n", cmd.id, cmd.len);
		break;
	}

	return ret;
}

static int skw_ndo_ioctl(struct net_device *dev, struct ifreq *ifr,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
			void __user *data,
#endif
			int cmd)
{
	int ret;
	void __user *priv = ifr->ifr_data;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
	priv = data;
#endif

	switch (cmd) {
	case SKW_IOCTL_ANDROID_CMD:
		ret = skw_android_cmd(dev, priv);
		break;

	case SKW_IOCTL_CMD:
		ret = skw_ioctl(dev, priv);
		break;

	default:
		ret = -ENOTSUPP;
		skw_warn("%s, unsupport cmd: 0x%x\n", netdev_name(dev), cmd);

		break;
	}

	return ret;
}

static void skw_ndo_tx_timeout(struct net_device *dev
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
				, unsigned int txqueue
#endif
				SKW_NULL)
{
	struct skw_iface *iface = (struct skw_iface *)netdev_priv(dev);
	struct skw_core *skw;

	if (!iface) {
		skw_err("iface NULL\n");
		return;
	}

	skw = iface->skw;

	skw_warn("ndev:%s,flag:0x%lx\n", netdev_name(dev), skw->flags);
}

static void skw_ndo_set_rx_mode(struct net_device *dev)
{
	int count, total_len;
	struct skw_mc_list *mc;
	struct netdev_hw_addr *ha;

	skw_dbg("%s, mc: %d, uc: %d\n", netdev_name(dev),
		netdev_mc_count(dev), netdev_uc_count(dev));

	count = netdev_mc_count(dev);
	if (!count)
		return;

	total_len = sizeof(*mc) + sizeof(struct mac_address) * count;
	mc = SKW_ZALLOC(total_len, GFP_ATOMIC);
	if (!mc) {
		skw_err("alloc failed, mc count: %d, total_len: %d\n",
			count, total_len);
		return;
	}

	mc->count = count;

	count = 0;
	netdev_for_each_mc_addr(ha, dev)
		skw_ether_copy(mc->mac[count++].addr, ha->addr);

	skw_queue_work(dev->ieee80211_ptr->wiphy, netdev_priv(dev),
		SKW_WORK_SET_MC_ADDR, mc, total_len);

	SKW_KFREE(mc);
}

#if 0
#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 11, 0)
static struct rtnl_link_stats64 *
#else
static void
#endif
skw_ndo_get_stats64(struct net_device *dev,
		    struct rtnl_link_stats64 *stats)
{
	int i;

	for_each_possible_cpu(i) {
		const struct pcpu_sw_netstats *tstats;
		u64 rx_packets, rx_bytes, tx_packets, tx_bytes;
		unsigned int start;

		tstats = per_cpu_ptr(dev->tstats, i);

		do {
			start = u64_stats_fetch_begin_irq(&tstats->syncp);
			rx_packets = tstats->rx_packets;
			tx_packets = tstats->tx_packets;
			rx_bytes = tstats->rx_bytes;
			tx_bytes = tstats->tx_bytes;
		} while (u64_stats_fetch_retry_irq(&tstats->syncp, start));

		stats->rx_packets += rx_packets;
		stats->tx_packets += tx_packets;
		stats->rx_bytes   += rx_bytes;
		stats->tx_bytes   += tx_bytes;
	}

#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 11, 0)
	return stats;
#endif
}
#endif

static int skw_ndo_set_mac_address(struct net_device *dev, void *addr)
{
	struct skw_iface *iface = (struct skw_iface *)netdev_priv(dev);
	struct sockaddr *sa = addr;
	int ret = 0;

	skw_dbg("mac: %pM\n", sa->sa_data);

	ret = eth_mac_addr(dev, sa);
	if (ret) {
		skw_err("failed, addr: %pM, ret: %d\n", sa->sa_data, ret);
		return ret;
	}

	ret = skw_send_msg(iface->wdev.wiphy, dev, SKW_CMD_RANDOM_MAC,
			sa->sa_data, ETH_ALEN, NULL, 0);
	if (ret) {
		skw_err("set mac: %pM failed, ret: %d\n",
			sa->sa_data, ret);

		eth_mac_addr(dev, iface->addr);

		return ret;
	}

	skw_ether_copy(iface->addr, sa->sa_data);

	return 0;
}

#if 0
static void skw_ndo_uninit(struct net_device *ndev)
{
	struct skw_iface *iface = netdev_priv(ndev);
	struct wiphy *wiphy = ndev->ieee80211_ptr->wiphy;

	skw_dbg("%s\n", netdev_name(ndev));

	free_percpu(ndev->tstats);

	skw_del_vif(wiphy, iface);
	skw_iface_teardown(wiphy, iface);
	skw_release_inst(wiphy, iface->id);
}
#endif

static const struct net_device_ops skw_netdev_ops = {
	// .ndo_uninit = skw_ndo_uninit,
	.ndo_open = skw_ndo_open,
	.ndo_stop = skw_ndo_stop,
	.ndo_start_xmit = skw_ndo_xmit,
	.ndo_select_queue = skw_ndo_select,
	.ndo_tx_timeout = skw_ndo_tx_timeout,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 15, 0)
	.ndo_siocdevprivate = skw_ndo_ioctl,
#else
	.ndo_do_ioctl = skw_ndo_ioctl,
#endif
	//.ndo_get_stats64 = skw_ndo_get_stats64,
	.ndo_set_rx_mode = skw_ndo_set_rx_mode,
	.ndo_set_mac_address = skw_ndo_set_mac_address,
};

int skw_netdev_init(struct wiphy *wiphy, struct net_device *ndev, u8 *addr)
{
	struct skw_core *skw;
	struct skw_iface *iface;

	if (!ndev)
		return -EINVAL;

	skw = wiphy_priv(wiphy);
	iface = netdev_priv(ndev);
	SET_NETDEV_DEV(ndev, wiphy_dev(wiphy));

	ndev->features = NETIF_F_GRO |
			 NETIF_F_IP_CSUM |
			 NETIF_F_IPV6_CSUM;

	ndev->ieee80211_ptr = &iface->wdev;
	ndev->netdev_ops = &skw_netdev_ops;
	ndev->watchdog_timeo = 3 * HZ;
	ndev->needed_headroom =	skw->skb_headroom;
	ndev->needed_tailroom = skw->hw_pdata->align_value;
	// ndev->priv_destructor = skw_netdev_deinit;

#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 12, 0)
	ndev->destructor = free_netdev;
#else
	ndev->needs_free_netdev = true;
#endif

#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 0, 0)
	eth_hw_addr_set(ndev, addr);
#else
	skw_ether_copy(ndev->dev_addr, addr);
#endif

#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 14, 0)
	ndev->tstats = netdev_alloc_pcpu_stats(struct pcpu_tstats);
#else
	ndev->tstats = netdev_alloc_pcpu_stats(struct pcpu_sw_netstats);
#endif
	if (!ndev->tstats)
		return -ENOMEM;

#ifdef CONFIG_WIRELESS_EXT
	ndev->wireless_handlers = skw_iw_handlers();
#endif

	return 0;
}

#if 0
void skw_netdev_deinit(struct net_device *dev)
{
	struct skw_iface *iface = netdev_priv(dev);

	skw_dbg("%s\n", netdev_name(dev));

#if 0 //move these actions to ndo_uninit
	free_percpu(dev->tstats);
	skw_cmd_close_dev(iface->wdev.wiphy, iface->id);
	skw_del_vif(iface->skw, iface);
	skw_iface_teardown(iface);
#endif
}
#endif

int skw_sync_cmd_event_version(struct wiphy *wiphy)
{
	int i, ret = 0;
	struct skw_version_info *skw_fw_ver;

#define SKW_CMD_VER(id, ver)   .cmd[id] = ver
#define SKW_EVENT_VER(id, ver) .event[id] = ver
	const struct skw_version_info skw_drv_ver = {
		SKW_CMD_VER(SKW_CMD_DOWNLOAD_INI, V1),
		SKW_CMD_VER(SKW_CMD_GET_INFO, V1),
		SKW_CMD_VER(SKW_CMD_SYN_VERSION, V1),
		SKW_CMD_VER(SKW_CMD_OPEN_DEV, V1),
		SKW_CMD_VER(SKW_CMD_CLOSE_DEV, V1),
		SKW_CMD_VER(SKW_CMD_START_SCAN, V1),
		SKW_CMD_VER(SKW_CMD_STOP_SCAN, V1),
		SKW_CMD_VER(SKW_CMD_START_SCHED_SCAN, V1),
		SKW_CMD_VER(SKW_CMD_STOP_SCHED_SCAN, V1),
		SKW_CMD_VER(SKW_CMD_JOIN, V1),
		SKW_CMD_VER(SKW_CMD_AUTH, V1),
		SKW_CMD_VER(SKW_CMD_ASSOC, V1),
		SKW_CMD_VER(SKW_CMD_ADD_KEY, V1),
		SKW_CMD_VER(SKW_CMD_DEL_KEY, V1),
		SKW_CMD_VER(SKW_CMD_TX_MGMT, V1),
		SKW_CMD_VER(SKW_CMD_TX_DATA_FRAME, V1),
		SKW_CMD_VER(SKW_CMD_SET_IP, V1),
		SKW_CMD_VER(SKW_CMD_DISCONNECT, V1),
		SKW_CMD_VER(SKW_CMD_RPM_REQ, V1),
		SKW_CMD_VER(SKW_CMD_START_AP, V1),
		SKW_CMD_VER(SKW_CMD_STOP_AP, V1),
		SKW_CMD_VER(SKW_CMD_ADD_STA, V1),
		SKW_CMD_VER(SKW_CMD_DEL_STA, V1),
		SKW_CMD_VER(SKW_CMD_GET_STA, V1),
		SKW_CMD_VER(SKW_CMD_RANDOM_MAC, V1),
		SKW_CMD_VER(SKW_CMD_GET_LLSTAT, V1),
		SKW_CMD_VER(SKW_CMD_SET_MC_ADDR, V1),
		SKW_CMD_VER(SKW_CMD_RESUME, V1),
		SKW_CMD_VER(SKW_CMD_SUSPEND, V1),
		SKW_CMD_VER(SKW_CMD_REMAIN_ON_CHANNEL, V1),
		SKW_CMD_VER(SKW_CMD_BA_ACTION, V1),
		SKW_CMD_VER(SKW_CMD_TDLS_MGMT, V1),
		SKW_CMD_VER(SKW_CMD_TDLS_OPER, V1),
		SKW_CMD_VER(SKW_CMD_TDLS_CHANNEL_SWITCH, V1),
		SKW_CMD_VER(SKW_CMD_SET_CQM_RSSI, V1),
		SKW_CMD_VER(SKW_CMD_NPI_MSG, V1),
		SKW_CMD_VER(SKW_CMD_IBSS_JOIN, V1),
		SKW_CMD_VER(SKW_CMD_SET_IBSS_ATTR, V1),
		SKW_CMD_VER(SKW_CMD_RSSI_MONITOR, V1),
		SKW_CMD_VER(SKW_CMD_SET_IE, V1),
		SKW_CMD_VER(SKW_CMD_SET_MIB, V1),
		SKW_CMD_VER(SKW_CMD_REGISTER_FRAME, V1),
		SKW_CMD_VER(SKW_CMD_ADD_TX_TS, V1),
		SKW_CMD_VER(SKW_CMD_DEL_TX_TS, V1),
		SKW_CMD_VER(SKW_CMD_REQ_CHAN_SWITCH, V1),
		SKW_CMD_VER(SKW_CMD_CHANGE_BEACON, V1),
		SKW_CMD_VER(SKW_CMD_DPD_ILC_GEAR_PARAM, V1),
		SKW_CMD_VER(SKW_CMD_DPD_ILC_MARTIX_PARAM, V1),
		SKW_CMD_VER(SKW_CMD_DPD_ILC_COEFF_PARAM, V1),
		SKW_CMD_VER(SKW_CMD_WIFI_RECOVER, V1),
		SKW_CMD_VER(SKW_CMD_PHY_BB_CFG, V1),
		SKW_CMD_VER(SKW_CMD_SET_REGD, V1),
		SKW_CMD_VER(SKW_CMD_SET_EFUSE, V1),
		SKW_CMD_VER(SKW_CMD_SET_PROBEREQ_FILTER, V1),
		SKW_CMD_VER(SKW_CMD_CFG_ANT, V1),
		SKW_CMD_VER(SKW_CMD_RTT, V1),
		SKW_CMD_VER(SKW_CMD_GSCAN, V1),
		SKW_CMD_VER(SKW_CMD_DFS, V1),
		SKW_CMD_VER(SKW_CMD_SET_SPD_ACTION, V2),
		SKW_CMD_VER(SKW_CMD_SET_MONITOR_PARAM, V1),

		/* event */
	};

	skw_fw_ver = SKW_ZALLOC(sizeof(struct skw_version_info), GFP_KERNEL);
	if (!skw_fw_ver)
		return -ENOMEM;

	ret = skw_msg_xmit(wiphy, 0, SKW_CMD_SYN_VERSION,
			   NULL, 0, skw_fw_ver,
			   sizeof(struct skw_version_info));
	if (ret) {
		skw_err("ret: %d\n", ret);
		SKW_KFREE(skw_fw_ver);

		return ret;
	}

	for (i = 0; i < SKW_MAX_MSG_ID; i++) {
		if (skw_fw_ver->cmd[i] == 0 || skw_drv_ver.cmd[i] == 0)
			continue;

		if (skw_drv_ver.cmd[i] != skw_fw_ver->cmd[i]) {
			skw_warn("cmd: %d, drv ver: %d, fw ver: %d\n",
				 i, skw_drv_ver.cmd[i], skw_fw_ver->cmd[i]);

			ret = -EINVAL;
		}
	}

	SKW_KFREE(skw_fw_ver);

	return ret;
}

static int skw_set_capa(struct skw_core *skw, int capa)
{
	int idx, bit;
	int size = sizeof(skw->ext_capa);

	idx = capa / BITS_PER_BYTE;
	bit = capa % BITS_PER_BYTE;

	BUG_ON(idx >= size);

	skw->ext_capa[idx] |= BIT(bit);

	return 0;
}

static int skw_set_ext_capa(struct skw_core *skw, struct skw_chip_info *chip)
{
	skw_set_capa(skw, SKW_EXT_CAPA_BSS_TRANSITION);
	skw_set_capa(skw, SKW_EXT_CAPA_MBSSID);
	skw_set_capa(skw, SKW_EXT_CAPA_TDLS_SUPPORT);
	skw_set_capa(skw, SKW_EXT_CAPA_TWT_REQ_SUPPORT);

	return 0;
}

static const char *skw_get_chip_id(u32 chip_type)
{
	if (strlen(CONFIG_SKW_CHIP_ID))
		return CONFIG_SKW_CHIP_ID;

	switch (chip_type) {
	case 0x100:
		return "EA6621Q";

	case 0x101:
		return "EA6521QF";

	case 0x102:
		return "EA6621QT";

	case 0x103:
		return "EA6521QT";

	default:
		skw_err("Unsupport chip type: 0x%x\n", chip_type);
		break;
	}

	return NULL;
}

int skw_sync_chip_info(struct wiphy *wiphy, struct skw_chip_info *chip)
{
	int ret;
	const char *chipid;
	int vendor, revision;
	u64 ts = local_clock();
	struct skw_core *skw = wiphy_priv(wiphy);

	skw->fw.host_timestamp = ts;
	skw->fw.host_seconds = skw_get_seconds();

	do_div(ts, 1000000);
	ret = skw_msg_xmit(wiphy, 0, SKW_CMD_GET_INFO, &ts, sizeof(ts),
			   chip, sizeof(*chip));
	if (ret) {
		skw_err("ret: %d\n", ret);
		return ret;
	}

	if (chip->priv_filter_arp)
		set_bit(SKW_FLAG_FW_FILTER_ARP, &skw->flags);

	if (chip->priv_ignore_cred)
		set_bit(SKW_FLAG_FW_IGNORE_CRED, &skw->flags);

	if (chip->priv_p2p_common_port)
		set_bit(SKW_FLAG_LEGACY_P2P_COMMON_PORT, &skw->flags);

	if (chip->priv_dfs_master_enabled)
		skw->dfs.fw_enabled = true;

	if (chip->nr_hw_mac)
		skw->hw.nr_lmac = chip->nr_hw_mac;
	else
		skw->hw.nr_lmac = 1;

	BUG_ON(skw->hw.nr_lmac > SKW_MAX_LMAC_SUPPORT);

	memcpy(skw->fw.build_time, chip->fw_build_time,
	       sizeof(skw->fw.build_time));
	memcpy(skw->fw.plat_ver, chip->fw_plat_ver, sizeof(skw->fw.plat_ver));
	memcpy(skw->fw.wifi_ver, chip->fw_wifi_ver, sizeof(skw->fw.wifi_ver));

	skw->fw.timestamp = chip->fw_timestamp;
	skw->fw.max_num_sta = chip->max_sta_allowed;
	skw->fw.fw_bw_capa = chip->fw_bw_capa;

	chipid = skw_get_chip_id(chip->fw_chip_type);
	if (!chipid) {
		skw_err("chip id 0x%x not support\n", chip->fw_chip_type);
		return -ENOTSUPP;
	}

	/* BIT[0:1] Reserved
	 * BIT[2:3] BUS Type
	 * BIT[4:7] Vendor ID
	 */
	vendor = 0;

#ifdef CONFIG_SKW_CALIB_BUS_SENSITIVE
	vendor |= ((skw->hw.bus & 0x3) << 2);
#endif

#ifdef CONFIG_SKW_CALIB_APPEND_MODULE_ID
	if (chip->calib_module_id) {
		int i;
		int vdata = chip->calib_module_id;

		for (i = 0; i < 4; i++) {
			if ((vdata & 0xf) == 0xf)
				vendor |= BIT(4 + i);

			vdata >>= 4;
		}
	}
#endif

	revision = skw->hw_pdata->chipid[15];

	snprintf(skw->fw.calib_file, sizeof(skw->fw.calib_file),
		"%s_%s_R%02x%03x.bin", chipid, CONFIG_SKW_PROJECT_NAME,
		vendor & 0xff, revision);

	skw_set_ext_capa(skw, chip);
	/* HT capa */

	skw_dbg("efuse mac: %pM, %s\n", chip->mac,
		is_valid_ether_addr(chip->mac) ? "valid" : "invalid");

	return 0;
}

#ifdef CONFIG_SKW_RANDOM_MAC_FIXED_TO_EFUSE
static int skw_save_random_mac_to_efuse(struct wiphy *wiphy, u8 *addr)
{
	int ret = 0;
	u16 *plen;
	struct skw_tlv_conf conf;

	skw_dbg("save mac: 0x%pM\n", addr);

	ret = skw_tlv_alloc(&conf, 128, GFP_KERNEL);
	if (ret)
		return ret;

	plen = skw_tlv_reserve(&conf, 2);
	if (!plen) {
		skw_tlv_free(&conf);
		return -ENOMEM;
	}

	if (skw_tlv_add(&conf, SKW_MIB_SET_EFUSE_MAC,
				addr, ETH_ALEN))
		skw_err("add SKW_MIB_SET_EFUSE_MAC failed.\n");

	if (conf.total_len) {
		*plen = conf.total_len;
		ret = skw_msg_xmit(wiphy, 0, SKW_CMD_SET_MIB, conf.buff,
				conf.total_len, NULL, 0);
	}

	skw_tlv_free(&conf);

	return ret;
}
#endif

static void skw_setup_mac_address(struct wiphy *wiphy, u8 *user_mac, u8 *hw_mac)
{
	int i;
	u8 addr[ETH_ALEN] = {0};
	struct skw_core *skw = wiphy_priv(wiphy);

	if (user_mac && is_valid_ether_addr(user_mac)) {
		skw_ether_copy(addr, user_mac);
	} else if (hw_mac && is_valid_ether_addr(hw_mac)) {
		skw_ether_copy(addr, hw_mac);
	} else {
		eth_random_addr(addr);
		addr[0] = 0xFE;
		addr[1] = 0xFD;
		addr[2] = 0xFC;

#ifdef CONFIG_SKW_RANDOM_MAC_FIXED_TO_EFUSE
		skw_save_random_mac_to_efuse(wiphy, addr);
#endif
	}

	for (i = 0; i < SKW_NR_IFACE; i++) {
		skw_ether_copy(skw->address[i].addr, addr);

		if (i != 0) {
			skw->address[i].addr[0] |= BIT(1);
			skw->address[i].addr[3] ^= BIT(i);
		}

		skw_dbg("addr[%d]: %pM\n", i, skw->address[i].addr);
	}
}

static int skw_buffer_init(struct skw_core *skw)
{
	int ret, size;

	if (skw->hw.bus == SKW_BUS_PCIE) {
		ret = skw_edma_init(priv_to_wiphy(skw));
		if (ret < 0) {
			skw_err("edma init failed, ret: %d\n", ret);
			return ret;
		}

		skw->cmd.data = skw->edma_cmd.current_node->buffer;
	} else {
		size = sizeof(struct scatterlist);

		skw->sgl_dat = kcalloc(SKW_NR_SGL_DAT, size, GFP_KERNEL);
		if (!skw->sgl_dat) {
			skw_err("sg list malloc failed, sg length: %d\n",
				SKW_NR_SGL_DAT);

			return -ENOMEM;
		}

		skw->sgl_cmd = kcalloc(SKW_NR_SGL_CMD, size, GFP_KERNEL);
		if (!skw->sgl_cmd) {
			skw_err("sg list malloc failed, sg length: %d\n",
				SKW_NR_SGL_CMD);

			SKW_KFREE(skw->sgl_dat);
			return -ENOMEM;
		}

		skw->cmd.data = SKW_ZALLOC(SKW_MSG_BUFFER_LEN, GFP_KERNEL);
		if (!skw->cmd.data) {
			skw_err("mallc data buffer failed\n");
			SKW_KFREE(skw->sgl_dat);
			SKW_KFREE(skw->sgl_cmd);
			return -ENOMEM;
		}
	}

	return 0;
}

static void skw_buffer_deinit(struct skw_core *skw)
{
	if (skw->hw.bus == SKW_BUS_PCIE) {
		skw_edma_deinit(priv_to_wiphy(skw));
	} else {
		SKW_KFREE(skw->sgl_dat);
		SKW_KFREE(skw->sgl_cmd);
		SKW_KFREE(skw->cmd.data);

		//TODO : recycle txqlen_pending if BSP support API
		if (unlikely(atomic_read(&skw->txqlen_pending)))
			skw_err("txqlen_pending:%d remind\n", atomic_read(&skw->txqlen_pending));
	}
}

static struct wakeup_source *skw_wakeup_source_init(const char *name)
{
	struct wakeup_source *ws;

	ws = wakeup_source_create(name);
	if (ws)
		wakeup_source_add(ws);

	return ws;
}

static void skw_wakeup_source_deinit(struct wakeup_source *ws)
{
	if (ws) {
		wakeup_source_remove(ws);
		wakeup_source_destroy(ws);
	}
}

static void skw_hw_info_init(struct skw_core *skw, struct sv6160_platform_data *pdata)
{
	int i, bus;
	bool extra_v2;
	struct {
		u8 dat_port;
		u8 logic_port;
		u8 flags;
		u8 resv;
	} skw_port[SKW_MAX_LMAC_SUPPORT] = {0};

	atomic_set(&skw->hw.credit, 0);
	skw->hw.align = pdata->align_value;
	skw->hw.cmd_port = pdata->cmd_port;
	skw->hw.pkt_limit = pdata->max_buffer_size / SKW_TX_PACK_SIZE;
	skw->hw.dma = (pdata->bus_type >> 3) & 0x3;

	if (skw->hw.pkt_limit >= SKW_NR_SGL_DAT) {
		WARN_ONCE(1, "pkt limit(%d) larger than buffer", skw->hw.pkt_limit);
		skw->hw.pkt_limit = SKW_NR_SGL_DAT - 1;
	}

	bus = pdata->bus_type & SKW_BUS_TYPE_MASK;
	if (bus == SKW_BUS_SDIO2) {
		bus = SKW_BUS_SDIO;
		extra_v2 = true;
	} else if (bus == SKW_BUS_USB2) {
		bus = SKW_BUS_USB;
		extra_v2 = true;
	} else {
		extra_v2 = false;
	}

	switch (bus) {
	case  SKW_BUS_SDIO:
		skw->hw.bus = SKW_BUS_SDIO;
		skw->hw.bus_dat_xmit = skw_sdio_xmit;
		skw->hw.bus_cmd_xmit = skw_sdio_cmd_xmit;

		skw->hw.extra.hdr_len = SKW_EXTER_HDR_SIZE;
		if (extra_v2)
			skw->hw.extra.len_offset = 0;
		else
			skw->hw.extra.len_offset = 7;

		skw->hw.extra.eof_offset = 23;
		skw->hw.extra.chn_offset = 24;

		skw->hw.rx_desc.hdr_offset = SKW_SDIO_RX_DESC_HDR_OFFSET;
		skw->hw.rx_desc.msdu_offset = SKW_SDIO_RX_DESC_MSDU_OFFSET;

		skw->hw.flags = SKW_HW_FLAG_SDIO_V2 | SKW_HW_FLAG_EXTRA_HDR;

		skw_port[0].dat_port = pdata->data_port & 0xf;
		skw_port[0].logic_port = skw_port[0].dat_port;
		skw_port[0].flags = SKW_LMAC_FLAG_INIT |
				    SKW_LMAC_FLAG_RXCB;

		skw_port[1].dat_port = (pdata->data_port >> 4) & 0xf;
		skw_port[1].logic_port = skw_port[1].dat_port;
		if (skw_port[1].logic_port) {
			skw_port[1].flags = SKW_LMAC_FLAG_INIT |
					    SKW_LMAC_FLAG_RXCB;
		}

		break;

	case SKW_BUS_USB:
		skw->hw.bus = SKW_BUS_USB;
		skw->hw.bus_dat_xmit = skw_usb_xmit;
		skw->hw.bus_cmd_xmit = skw_usb_cmd_xmit;
		skw->hw.flags = SKW_HW_FLAG_EXTRA_HDR;
		skw->hw.extra.hdr_len = SKW_EXTER_HDR_SIZE;
		if (extra_v2)
			skw->hw.extra.len_offset = 0;
		else
			skw->hw.extra.len_offset = 7;

		skw->hw.extra.eof_offset = 23;
		skw->hw.extra.chn_offset = 24;

		skw->hw.rx_desc.hdr_offset = SKW_USB_RX_DESC_HDR_OFFSET;
		skw->hw.rx_desc.msdu_offset = SKW_USB_RX_DESC_MSDU_OFFSET;

		skw_port[0].dat_port = pdata->data_port;
		skw_port[0].logic_port = 0;
		skw_port[0].flags = SKW_LMAC_FLAG_INIT |
				    SKW_LMAC_FLAG_RXCB |
				    SKW_LMAC_FLAG_TXCB;

		skw_port[1].dat_port = pdata->data_port;
		skw_port[1].logic_port = 1;
		skw_port[1].flags = SKW_LMAC_FLAG_INIT;

		break;

	case SKW_BUS_PCIE:
		skw->hw.bus = SKW_BUS_PCIE;
		skw->hw.bus_dat_xmit = skw_pcie_xmit;
		skw->hw.bus_cmd_xmit = skw_pcie_cmd_xmit;
		skw->hw.dma = SKW_ASYNC_EDMA_TX;

		skw->hw.rx_desc.hdr_offset = SKW_PCIE_RX_DESC_HDR_OFFSET;
		skw->hw.rx_desc.msdu_offset = SKW_PCIE_RX_DESC_MSDU_OFFSET;

		skw->hw.cmd_port = -1;

		skw_port[0].dat_port = 0;
		skw_port[0].logic_port = 0;
		skw_port[0].flags = SKW_LMAC_FLAG_INIT;

		skw_port[1].logic_port = 0;
		skw_port[1].dat_port = 0;
		skw_port[1].flags = SKW_LMAC_FLAG_INIT;

		break;

	default:
		break;
	}

	for (i = 0; i < SKW_MAX_LMAC_SUPPORT; i++) {
		skw->hw.lmac[i].id = i;
		skw->hw.lmac[i].lport = skw_port[i].logic_port;
		skw->hw.lmac[i].dport = skw_port[i].dat_port;
		skw->hw.lmac[i].flags = skw_port[i].flags;
		skw->hw.lmac[i].iface_bitmap = 0;

		atomic_set(&skw->hw.lmac[i].fw_credit, 0);
		skb_queue_head_init(&skw->hw.lmac[i].edma_free_list);
	}
}

static int skw_core_init(struct skw_core *skw, struct platform_device *pdev, int idx)
{
	int i, ret;
	char name[32] = {0};

	skw->hw_pdata = dev_get_platdata(&pdev->dev);
	if (!skw->hw_pdata) {
		skw_err("get drv data failed\n");
		return -ENODEV;
	}

	skw->idx = idx;
	skw_hw_info_init(skw, skw->hw_pdata);

	snprintf(name, sizeof(name), "chip%d.%s", idx, skw_bus_name(skw->hw.bus));
	skw->dentry = skw_debugfs_subdir(name, NULL);
	skw->pentry = skw_procfs_subdir(name, NULL);

	mutex_init(&skw->lock);

#ifdef CONFIG_SKW_SAP_SME_EXT
	set_bit(SKW_FLAG_SAP_SME_EXTERNAL, &skw->flags);
#endif

#ifdef CONFIG_SKW_STA_SME_EXT
	set_bit(SKW_FLAG_STA_SME_EXTERNAL, &skw->flags);
#endif

#ifdef CONFIG_SKW_REPEATER_MODE
	set_bit(SKW_FLAG_REPEATER, &skw->flags);
#endif
	skw->regd = NULL;
	skw->country[0] = '0';
	skw->country[1] = '0';

	atomic_set(&skw->exit, 0);
	atomic_set(&skw->tx_wake, 0);
	atomic_set(&skw->rx_wake, 0);

	init_waitqueue_head(&skw->tx_wait_q);
	init_waitqueue_head(&skw->rx_wait_q);

	skb_queue_head_init(&skw->rx_dat_q);
	atomic_set(&skw->txqlen_pending, 0);

	spin_lock_init(&skw->dfs.skw_pool_lock);
	INIT_LIST_HEAD(&skw->dfs.skw_pulse_pool);
	INIT_LIST_HEAD(&skw->dfs.skw_pseq_pool);

	sema_init(&skw->cmd.lock, 1);
	init_waitqueue_head(&skw->cmd.wq);
	skw->cmd.ws = skw_wakeup_source_init("skwifi_cmd");

	spin_lock_init(&skw->vif.lock);

	for (i = 0; i < SKW_MAX_PEER_SUPPORT; i++) {
		skw->peer_ctx[i].idx = i;
		mutex_init(&skw->peer_ctx[i].lock);
	}

	skw_event_work_init(&skw->event_work, skw_default_event_work);
	skw->event_wq = alloc_workqueue("skw_evt_wq.%d", WQ_UNBOUND | WQ_MEM_RECLAIM, 1, idx);
	if (!skw->event_wq) {
		ret = -ENOMEM;
		skw_err("alloc event wq failed, ret: %d\n", ret);

		goto deinit_ws;
	}

	ret = skw_dpd_init(&skw->dpd);
	if (ret < 0)
		goto deinit_wq;

	ret = skw_buffer_init(skw);
	if (ret < 0)
		goto deinit_dpd;

	ret = skw_rx_init(skw);
	if (ret < 0) {
		skw_err("rx init failed, ret: %d\n", ret);
		goto deinit_buff;
	}

	ret = skw_tx_init(skw);
	if (ret < 0) {
		skw_err("tx init failed, ret: %d\n", ret);
		goto deinit_rx;
	}

	skw_debugfs_file(skw->dentry, "repeater", 0666, &skw_repeater_fops, skw);

	skw->dbg.nr_cmd = SKW_DBG_NR_CMD;
	skw->dbg.nr_dat = SKW_DBG_NR_DAT;
	atomic_set(&skw->dbg.loop, 0);

	return 0;

deinit_rx:
	skw_rx_deinit(skw);

deinit_buff:
	skw_buffer_deinit(skw);

deinit_dpd:
	skw_dpd_deinit(&skw->dpd);

deinit_wq:
	destroy_workqueue(skw->event_wq);
	skw_event_work_deinit(&skw->event_work);

deinit_ws:
	skw_wakeup_source_deinit(skw->cmd.ws);

	debugfs_remove_recursive(skw->dentry);
	proc_remove(skw->pentry);

	return ret;
}

static void skw_core_deinit(struct skw_core *skw)
{
	skw_tx_deinit(skw);

	skw_rx_deinit(skw);

	skw_buffer_deinit(skw);

	skw_dpd_deinit(&skw->dpd);

	destroy_workqueue(skw->event_wq);

	skw_event_work_deinit(&skw->event_work);

	skw_wakeup_source_deinit(skw->cmd.ws);

	debugfs_remove_recursive(skw->dentry);
	proc_remove(skw->pentry);
}

int skw_set_ip(struct wiphy *wiphy, struct net_device *ndev,
		struct skw_setip_param *setip_param, int size)
{
	int ret = 0;
	//int size = 0;

	//size = sizeof(struct skw_setip_param);
	ret = skw_queue_work(wiphy, netdev_priv(ndev),
			SKW_WORK_SET_IP, setip_param, size);
	if (ret)
		skw_err("Set IP failed\n");

	return ret;
}

/*
 * Get the IP address for both IPV4 and IPV6, set it
 * to firmware while they are valid.
 */
void skw_set_ip_to_fw(struct wiphy *wiphy, struct net_device *ndev)
{
	struct in_device *in_dev;
	struct in_ifaddr *ifa;

	struct inet6_dev *idev;
	struct inet6_ifaddr *ifp;

	struct skw_setip_param setip_param[SKW_FW_IPV6_COUNT_LIMIT + 1];
	int ip_count = 0, ipv6_count = 0;

	in_dev = __in_dev_get_rtnl(ndev);
	if (!in_dev)
		goto ipv6;

	ifa = in_dev->ifa_list;
	if (!ifa || !ifa->ifa_local)
		goto ipv6;

	skw_info("ip addr: %pI4\n", &ifa->ifa_local);
	setip_param[ip_count].ip_type = SKW_IP_IPV4;
	setip_param[ip_count].ipv4 = ifa->ifa_local;
	ip_count++;

ipv6:
	idev = __in6_dev_get(ndev);
	if (!idev)
		goto ip_apply;

	read_lock_bh(&idev->lock);
	list_for_each_entry_reverse(ifp, &idev->addr_list, if_list) {
		skw_info("ip addr: %pI6\n", &ifp->addr);
		if (++ipv6_count > SKW_FW_IPV6_COUNT_LIMIT) {
			skw_warn("%s set first %d of %d ipv6 address\n",
				ndev->name, SKW_FW_IPV6_COUNT_LIMIT, ipv6_count);

			read_unlock_bh(&idev->lock);
			goto ip_apply;
		}

		setip_param[ip_count].ip_type = SKW_IP_IPV6;
		memcpy(&setip_param[ip_count].ipv6, &ifp->addr, 16);
		ip_count++;
	}
	read_unlock_bh(&idev->lock);

ip_apply:
	if (ip_count)
		skw_set_ip(wiphy, ndev, setip_param, ip_count * sizeof(struct skw_setip_param));
}

#ifdef CONFIG_INET
static int skw_ifa4_notifier(struct notifier_block *nb,
			unsigned long action, void *data)
{
	struct in_ifaddr *ifa = data;
	struct net_device *ndev;
	struct wireless_dev *wdev;
	struct skw_core *skw = container_of(nb, struct skw_core, ifa4_nf);

	skw_dbg("action: %ld\n", action);

	if (!ifa->ifa_dev)
		return NOTIFY_DONE;

	ndev = ifa->ifa_dev->dev;
	wdev = ndev->ieee80211_ptr;

	if (!wdev || wdev->wiphy != priv_to_wiphy(skw))
		return NOTIFY_DONE;

	if (ndev->ieee80211_ptr->iftype != NL80211_IFTYPE_STATION &&
	    ndev->ieee80211_ptr->iftype != NL80211_IFTYPE_P2P_CLIENT)
		return NOTIFY_DONE;

	switch (action) {
	case NETDEV_UP:
//	case NETDEV_DOWN:

		skw_set_ip_to_fw(wdev->wiphy, ndev);

		break;

	default:
		break;
	}

	return NOTIFY_DONE;
}

#endif

#ifdef CONFIG_IPV6
static int skw_ifa6_notifier(struct notifier_block *nb,
			unsigned long action, void *data)
{
	struct inet6_ifaddr *ifa6 = data;
	struct skw_core *skw = container_of(nb, struct skw_core, ifa6_nf);

	struct net_device *ndev;
	struct wireless_dev *wdev;

	skw_dbg("action: %ld\n", action);

	if (!ifa6->idev || !ifa6->idev->dev)
		return NOTIFY_DONE;

	ndev = ifa6->idev->dev;
	wdev = ndev->ieee80211_ptr;

	if (!wdev || wdev->wiphy != priv_to_wiphy(skw))
		return NOTIFY_DONE;

	switch (action) {
	case NETDEV_UP:
	// case NETDEV_DOWN:

		skw_set_ip_to_fw(wdev->wiphy, ndev);

		break;

	default:
		break;
	}

	return NOTIFY_DONE;
}

#endif

static int skw_bsp_notifier(struct notifier_block *nb,
			unsigned long action, void *data)
{
	struct skw_core *skw = container_of(nb, struct skw_core, bsp_nf);

	skw_dbg("action: %ld, skw flags: 0x%lx\n", action, skw->flags);

	switch (action) {
	case SKW_BSP_NF_ASSERT:
	case SKW_BSP_NF_BLOCKED:
		set_bit(SKW_FLAG_FW_ASSERT, &skw->flags);
		skw_abort_cmd(skw);
		cancel_work_sync(&skw->recovery_work);
		skw_wifi_disable();
		break;

	case SKW_BSP_NF_READY:
		schedule_work(&skw->recovery_work);
		break;

	default:
		break;
	}

	return NOTIFY_DONE;
}

static void skw_ifa_notifier_register(struct skw_core *skw)
{
#ifdef CONFIG_INET
	skw->ifa4_nf.notifier_call = skw_ifa4_notifier;
	register_inetaddr_notifier(&skw->ifa4_nf);
#endif

#ifdef CONFIG_IPV6
	skw->ifa6_nf.notifier_call = skw_ifa6_notifier;
	register_inet6addr_notifier(&skw->ifa6_nf);
#endif

	skw->bsp_nf.notifier_call = skw_bsp_notifier;
	skw_register_bsp_notifier(skw, &skw->bsp_nf);
}

static void skw_ifa_notifier_unregister(struct skw_core *skw)
{
#ifdef CONFIG_INET
	unregister_inetaddr_notifier(&skw->ifa4_nf);
#endif

#ifdef CONFIG_IPV6
	unregister_inet6addr_notifier(&skw->ifa6_nf);
#endif

	skw_unregister_bsp_notifier(skw, &skw->bsp_nf);
}

int skw_lmac_bind_iface(struct skw_core *skw, struct skw_iface *iface, int lmac_id)
{
	struct skw_lmac *lmac;

	if (lmac_id >= skw->hw.nr_lmac) {
		skw_err("invalid lmac id: %d\n", skw->hw.nr_lmac);
		return 0;
	}

	iface->lmac_id = lmac_id;
	lmac = &skw->hw.lmac[lmac_id];
	BUG_ON(!(lmac->flags & SKW_LMAC_FLAG_INIT));

	if (skw->hw.bus == SKW_BUS_PCIE) {
		// TODO:
		// register edma channel
		// skw_edma_enable_channel(&lmac->edma_tx_chn, isr);
	}

	SKW_SET(lmac->iface_bitmap, BIT(iface->id));
	SKW_SET(lmac->flags, SKW_LMAC_FLAG_ACTIVED);

	return 0;
}

int skw_lmac_unbind_iface(struct skw_core *skw, int lmac_id, int iface_id)
{
	struct skw_lmac *lmac;

	if (lmac_id >= skw->hw.nr_lmac) {
		skw_err("invalid lmac id: %d\n", skw->hw.nr_lmac);
		return 0;
	}

	lmac = &skw->hw.lmac[lmac_id];

	SKW_CLEAR(lmac->iface_bitmap, BIT(iface_id));

	if (lmac->iface_bitmap)
		return 0;

	// TODO:
	// unregister edma channel

	SKW_CLEAR(lmac->flags, SKW_LMAC_FLAG_ACTIVED);

	return 0;
}

void skw_add_credit(struct skw_core *skw, int lmac_id, int cred)
{
	trace_skw_tx_add_credit(lmac_id, cred);

	atomic_add(cred, &skw->hw.lmac[lmac_id].fw_credit);
	smp_wmb();

	skw_wakeup_tx(skw, 0);
	skw_detail("lmac_id:%d cred:%d", lmac_id, cred);
}

static int skw_add_default_iface(struct wiphy *wiphy)
{
	int ret = 0;
	struct skw_iface *iface = NULL;
#ifdef CONFIG_SKW_LEGACY_P2P
	struct skw_iface *p2p = NULL;
	struct skw_core *skw = wiphy_priv(wiphy);
#endif

	rtnl_lock();

	iface = skw_add_iface(wiphy, "wlan%d", NL80211_IFTYPE_STATION,
				skw_mac, SKW_INVALID_ID, true);
	if (IS_ERR(iface)) {
		ret = PTR_ERR(iface);
		skw_err("add iface failed, ret: %d\n", ret);

		goto unlock;
	}

#ifdef CONFIG_SKW_LEGACY_P2P
	if (test_bit(SKW_FLAG_LEGACY_P2P_COMMON_PORT, &skw->flags))
		p2p = skw_add_iface(wiphy, "p2p%d", NL80211_IFTYPE_STATION,
				NULL, SKW_LAST_IFACE_ID, true);
	else
		p2p = skw_add_iface(wiphy, "p2p%d", NL80211_IFTYPE_P2P_DEVICE,
				NULL, SKW_LAST_IFACE_ID, true);

	if (IS_ERR(p2p)) {
		ret = PTR_ERR(p2p);
		skw_err("add p2p legacy interface failed, ret: %d\n", ret);

		skw_del_iface(wiphy, iface);

		goto unlock;
	}

	if (!test_bit(SKW_FLAG_LEGACY_P2P_COMMON_PORT, &skw->flags))
		p2p->flags |= SKW_IFACE_FLAG_LEGACY_P2P_DEV;

#endif

unlock:
	rtnl_unlock();

	return ret;
}

static int skw_calib_bin_download(struct wiphy *wiphy, const u8 *data, u32 size)
{
	int i = 0, ret = 0;
	int buf_size, remain = size;
	struct skw_calib_param calib;

	skw_dbg("file size: %d\n", size);

	buf_size = sizeof(calib.data);

	while (remain > 0) {
		calib.len = (remain < buf_size) ? remain : buf_size;
		calib.seq = i;
		remain -= calib.len;

		memcpy(calib.data, data, calib.len);

		if (!remain)
			calib.end = 1;
		else
			calib.end = 0;

		skw_dbg("bb_file remain: %d, seq: %d len: %d end: %d\n",
			remain, calib.seq, calib.len, calib.end);

		ret = skw_msg_xmit(wiphy, 0, SKW_CMD_PHY_BB_CFG, &calib,
				sizeof(calib), NULL, 0);
		if (ret) {
			skw_err("failed, ret: %d,  seq: %d\n", ret, i);
			break;
		}

		i++;
		data += calib.len;
	}

	return ret;
}

int skw_calib_download(struct wiphy *wiphy, const char *fname)
{
	int ret = 0;
	const struct firmware *fw;

	skw_dbg("fw file: %s\n", fname);

	ret = request_firmware(&fw, fname, &wiphy->dev);
	if (ret) {
		skw_err("load %s failed, ret: %d\n", fname, ret);
		return ret;
	}

	ret = skw_calib_bin_download(wiphy, fw->data, fw->size);
	if (ret != 0)
		skw_err("bb_file cali msg fail\n");

	release_firmware(fw);

	return ret;
}

void skw_dbg_dump(struct skw_core *skw)
{
	int i;
	u64 nsecs;
	unsigned long rem_nsec;

	for (i = 0; i < skw->dbg.nr_cmd; i++) {
		struct skw_dbg_cmd *cmd = &skw->dbg.cmd[i];

		skw_dbg("cmd[%d].id: %d, seq: %d, flags: 0x%lx, loop: %d\n",
			i, cmd->id, cmd->seq, cmd->flags, cmd->loop);

		nsecs = cmd->trigger;
		rem_nsec = do_div(nsecs, 1000000000);
		skw_dbg("cmd.%d.%d.trigger: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		nsecs = cmd->build;
		rem_nsec = do_div(nsecs, 1000000000);
		skw_dbg("cmd.%d.%d.build: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		nsecs = cmd->xmit;
		rem_nsec = do_div(nsecs, 1000000000);
		skw_dbg("cmd.%d.%d.xmit: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		nsecs = cmd->done;
		rem_nsec = do_div(nsecs, 1000000000);
		skw_dbg("cmd.%d.%d.done: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		nsecs = cmd->ack;
		rem_nsec = do_div(nsecs, 1000000000);
		skw_dbg("cmd.%d.%d.ack: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);

		nsecs = cmd->assert;
		rem_nsec = do_div(nsecs, 1000000000);
		skw_dbg("cmd.%d.%d.assert: %5lu.%06lu\n", cmd->id, cmd->seq,
			(unsigned long)nsecs, rem_nsec / 1000);
	}

	for (i = 0; i < skw->dbg.nr_dat; i++) {
		struct skw_dbg_dat *dat = &skw->dbg.dat[i];

		nsecs = dat->trigger;
		rem_nsec = do_div(nsecs, 1000000000);
		skw_dbg("dat.%d.%d.trigger: %5lu.%06lu\n",
			i, dat->qlen, (unsigned long)nsecs, rem_nsec / 1000);

		nsecs = dat->done;
		rem_nsec = do_div(nsecs, 1000000000);
		skw_dbg("dat.%d.%d.done: %5lu.%06lu\n",
			i, dat->qlen, (unsigned long)nsecs, rem_nsec / 1000);
	}
}

static int skw_drv_probe(struct platform_device *pdev)
{
	int ret = 0;
	struct skw_chip_info chip;
	struct wiphy *wiphy = NULL;
	struct skw_core *skw = NULL;
	int idx = atomic_inc_return(&skw_chip_idx);

	skw_info("chip: %d, MAC: %pM\n", idx, skw_mac);

	wiphy = skw_alloc_wiphy(sizeof(struct skw_core));
	if (!wiphy) {
		ret = -ENOMEM;
		skw_err("malloc wiphy failed\n");

		goto failed;
	}

	set_wiphy_dev(wiphy, pdev->dev.parent);

	skw = wiphy_priv(wiphy);

	ret = skw_core_init(skw, pdev, idx);
	if (ret) {
		skw_err("core init failed, ret: %d\n", ret);
		goto free_wiphy;
	}

	skw_regd_init(wiphy);
	skw_vendor_init(wiphy);
	skw_work_init(wiphy);
	skw_timer_init(skw);
	skw_recovery_init(skw);

	skw_wifi_enable();

	if (skw_sync_cmd_event_version(wiphy) ||
	    skw_sync_chip_info(wiphy, &chip))
		goto core_deinit;

	skw_setup_mac_address(wiphy, skw_mac, chip.mac);

	if (skw_calib_download(wiphy, skw->fw.calib_file) < 0)
		goto core_deinit;

	skw_dpd_download(wiphy, &skw->dpd);

	ret = skw_setup_wiphy(wiphy, &chip);
	if (ret) {
		skw_err("setup wiphy failed, ret: %d\n", ret);
		goto core_deinit;
	}

	rtnl_lock();

	skw_set_wiphy_regd(wiphy, skw->country);

#ifdef CONFIG_SKW_DEFAULT_COUNTRY
	if (strlen(CONFIG_SKW_DEFAULT_COUNTRY) == 2)
		skw_set_regdom(wiphy, CONFIG_SKW_DEFAULT_COUNTRY);
#endif

	rtnl_unlock();

	ret = skw_add_default_iface(wiphy);
	if (ret)
		goto unregister_wiphy;

	skw_ifa_notifier_register(skw);

	platform_set_drvdata(pdev, skw);

	skw_procfs_file(skw->pentry, "core", 0444, &skw_core_fops, skw);

	skw_debugfs_file(SKW_WIPHY_DENTRY(wiphy), "assert", 0444,
			 &skw_assert_fops, skw);

	return 0;

unregister_wiphy:
	wiphy_unregister(wiphy);

core_deinit:
	skw_wifi_disable();
	skw_recovery_deinit(skw);
	skw_timer_deinit(skw);
	skw_work_deinit(wiphy);
	skw_vendor_deinit(wiphy);
	skw_core_deinit(skw);

free_wiphy:
	wiphy_free(wiphy);

failed:
	atomic_dec(&skw_chip_idx);

	return ret;
}

static int skw_drv_remove(struct platform_device *pdev)
{
	int i;
	struct wiphy *wiphy;
	struct skw_core *skw = platform_get_drvdata(pdev);

	skw_info("%s\n", pdev->name);

	if (!skw)
		return 0;

	wiphy = priv_to_wiphy(skw);

	skw_ifa_notifier_unregister(skw);

	rtnl_lock();

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
	cfg80211_shutdown_all_interfaces(wiphy);
#endif

	for (i = 0; i < SKW_NR_IFACE; i++)
		skw_del_iface(wiphy, skw->vif.iface[i]);

	rtnl_unlock();

	wiphy_unregister(wiphy);

	skw_wifi_disable();

	skw_recovery_deinit(skw);

	skw_timer_deinit(skw);

	skw_work_deinit(wiphy);

	skw_vendor_deinit(wiphy);

	skw_core_deinit(skw);

	wiphy_free(wiphy);

	atomic_dec(&skw_chip_idx);

	return 0;
}

static struct platform_driver skw_drv = {
	.probe = skw_drv_probe,
	.remove = skw_drv_remove,
	.driver = {
		.owner = THIS_MODULE,
		.name = "sv6160_wireless1",
	},
};

static int __init skw_module_init(void)
{
	int ret = 0;

	pr_info("[%s] VERSION: %s (%s)\n",
		SKW_TAG_INFO, SKW_VERSION, UTS_RELEASE);

	skw_dentry_init();
	skw_log_level_init();

	skw_power_on_chip();

	// skw_global_config_init(&g_skw_config);

	ret = platform_driver_register(&skw_drv);
	if (ret) {
		skw_err("register %s failed, ret: %d\n",
			skw_drv.driver.name, ret);

		skw_power_off_chip();

		skw_log_level_deinit();
		skw_dentry_deinit();
	}

	return ret;
}

static void __exit skw_module_exit(void)
{
	skw_info("unload\n");

	platform_driver_unregister(&skw_drv);

	skw_power_off_chip();

	skw_log_level_deinit();
	skw_dentry_deinit();
}

module_init(skw_module_init);
module_exit(skw_module_exit);

module_param_array_named(mac, skw_mac, byte, NULL, 0444);
MODULE_PARM_DESC(mac, "config mac address");

MODULE_LICENSE("GPL v2");
MODULE_VERSION("1.0.0");
MODULE_AUTHOR("seekwavetech");
===== ./drivers/skwifi/skw_msg.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/skbuff.h>
#include <net/netlink.h>

#include "skw_core.h"
#include "skw_iface.h"
#include "skw_msg.h"
#include "skw_vendor.h"
#include "skw_mlme.h"
#include "skw_mbssid.h"
#include "skw_cfg80211.h"
#include "skw_timer.h"
#include "skw_rx.h"
#include "skw_tx.h"
#include "skw_work.h"
#include "skw_calib.h"
#include "trace.h"
#include "skw_dfs.h"

static int skw_event_scan_complete(struct skw_core *skw,
			struct skw_iface *iface, void *buf, int len)
{
	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	skw_scan_done(skw, iface, false);

	return 0;
}

static int skw_event_sched_scan_done(struct skw_core *skw,
			struct skw_iface *iface, void *buf, int len)
{
	struct wiphy *wiphy = priv_to_wiphy(skw);

	skw_dbg("actived: %d\n", !!skw->sched_scan_req);

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	if (!skw->sched_scan_req)
		return 0;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 12, 0)
	cfg80211_sched_scan_results(wiphy, skw->sched_scan_req->reqid);
#else
	cfg80211_sched_scan_results(wiphy);
#endif

	return 0;
}

static int skw_event_disconnect(struct skw_core *skw, struct skw_iface *iface,
				void *buf, int len)
{
	int ret = 0;
	struct wiphy *wiphy = priv_to_wiphy(skw);
	struct skw_discon_event_params *param = buf;

	skw_info("bssid: %pM, reason: %u\n", param->bssid, param->reason);

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	skw_sta_leave(wiphy, iface->ndev, param->bssid,
			param->reason, false);

	if (iface->sta.sme_external) {
		if (iface->sta.core.cbss) {
			//cfg80211_abandon_assoc(iface->ndev, iface->sta.core.cbss);

			iface->sta.core.cbss = NULL;
		} else {
			skw_tx_mlme_mgmt(iface->ndev, IEEE80211_STYPE_DEAUTH,
					param->bssid, param->bssid, param->reason);
		}
	} else {
		skw_disconnected(iface->ndev, param->reason, true, GFP_KERNEL);
	}

	return ret;
}

static int skw_sta_rx_deauth(struct wiphy *wiphy, struct skw_iface *iface,
			void *buf, int len)
{
	u16 reason;
	struct ieee80211_mgmt *mgmt = buf;
	struct skw_peer_ctx *ctx;

	skw_wdev_assert_lock(iface);

	if (!ether_addr_equal(mgmt->bssid, mgmt->sa)) {
		cfg80211_tdls_oper_request(iface->ndev, mgmt->sa,
				NL80211_TDLS_TEARDOWN,
				SKW_WLAN_REASON_TDLS_TEARDOWN_UNREACHABLE,
				GFP_KERNEL);
		return 0;
	}

	ctx = skw_peer_ctx(iface, mgmt->bssid);
	if (!ctx) {
		skw_dbg("recv deauth twice\n");
		return -ENOENT;
	}

	reason = le16_to_cpu(mgmt->u.deauth.reason_code);

	skw_sta_leave(wiphy, iface->ndev, mgmt->bssid, reason, false);

	if (iface->sta.sme_external)
		skw_compat_rx_mlme_mgmt(iface->ndev, buf, len);
	else
		skw_disconnected(iface->ndev, reason, true, GFP_KERNEL);

	return 0;
}

static int skw_sta_rx_auth(struct wiphy *wiphy, struct skw_iface *iface,
			   int freq, int signal, void *buf, int len)
{
	u16 status_code;
	struct ieee80211_mgmt *mgmt = buf;
	struct skw_bss_cfg *bss = &iface->sta.core.bss;

	skw_wdev_assert_lock(iface);

	if (!ether_addr_equal(bss->bssid, mgmt->bssid)) {
		skw_warn("bssid unmatch, current: %pM, mgmt: %pM\n",
			 bss->bssid, mgmt->bssid);

		return 0;
	}

	skw_set_state(&iface->sta.core.sm, SKW_STATE_AUTHED);

	iface->sta.core.pending.start = jiffies;
	iface->sta.core.pending.retry = 0;

	status_code = le16_to_cpu(mgmt->u.auth.status_code);
	if (status_code != WLAN_STATUS_SUCCESS) {
		skw_info("auth failed, status code: %d\n", status_code);

		iface->sta.report_deauth = false;
		skw_sta_leave(wiphy, iface->ndev, mgmt->bssid,
				WLAN_REASON_UNSPECIFIED, false);
	}

	/* SAE confirm frame received */
	if (le16_to_cpu(mgmt->u.auth.auth_alg) == 3 &&
	    le16_to_cpu(mgmt->u.auth.auth_transaction) == 2)
		SKW_SET(iface->sta.core.sm.flags, SKW_SM_FLAG_SAE_RX_CONFIRM);

	if (iface->sta.sme_external)
		skw_compat_rx_mlme_mgmt(iface->ndev, buf, len);
	else
		skw_mlme_sta_rx_auth(iface, freq, signal, buf, len);

	return 0;
}

static int skw_sta_rx_assoc(struct skw_iface *iface, int freq,
			int signal, void *buf, int len)
{
	u16 status_code;
	struct skw_peer_ctx *ctx;
	u8 *assoc_req_ie = NULL;
	struct ieee80211_mgmt *mgmt = buf;
	struct skw_sta_core *core = &iface->sta.core;

	skw_wdev_assert_lock(iface);

	ctx = skw_get_ctx(iface->skw, core->bss.ctx_idx);
	if (!ctx) {
		skw_err("invalid pidx: %d\n", core->bss.ctx_idx);
		return 0;
	}

	skw_peer_ctx_lock(ctx);

	if (!ctx->peer ||
	    !ether_addr_equal(ctx->peer->addr, mgmt->bssid)) {
		skw_peer_ctx_unlock(ctx);
		return 0;
	}

	skw_set_state(&core->sm, SKW_STATE_ASSOCED);

	status_code = le16_to_cpu(mgmt->u.assoc_resp.status_code);
	if (status_code == WLAN_STATUS_SUCCESS) {
		u8 *ies = mgmt->u.assoc_resp.variable;
		int ies_len = len - (ies - (u8 *)mgmt);

		skw_iface_set_wmm_capa(iface, ies, ies_len);

		atomic_set(&ctx->peer->rx_filter, SKW_RX_FILTER_SET);
		__skw_peer_ctx_transmit(ctx, true);

		netif_carrier_on(iface->ndev);

	} else {
		skw_info("failed, status code: %d\n", status_code);

		iface->sta.report_deauth = false;
		skw_set_state(&core->sm, SKW_STATE_NONE);
	}

	skw_peer_ctx_unlock(ctx);

	if (core->assoc_req_ie_len)
		assoc_req_ie = core->assoc_req_ie;

	if (iface->sta.sme_external)
		skw_compat_rx_assoc_resp(iface->ndev, core->cbss, buf, len, 0,
				assoc_req_ie, core->assoc_req_ie_len);
	else
		skw_mlme_sta_rx_assoc(iface, NULL, buf, len, assoc_req_ie,
				core->assoc_req_ie_len);

	core->cbss = NULL;

	return 0;
}

static int skw_sta_rx_mgmt(struct skw_core *skw, struct skw_iface *iface,
		u16 fc, int freq, int signal, void *buf, int len)
{
	u16 seq_ctrl;
	int ret = 0;
	struct ieee80211_mgmt *mgmt = buf;
	struct wiphy *wiphy = priv_to_wiphy(skw);

	seq_ctrl = le16_to_cpu(mgmt->seq_ctrl);
	if (ieee80211_has_retry(mgmt->frame_control) &&
	    iface->sta.last_seq_ctrl == seq_ctrl) {
		skw_dbg("drop retry frame (seq: %d)\n", seq_ctrl);

		return 0;
	}

	iface->sta.last_seq_ctrl = seq_ctrl;

	skw_wdev_lock(&iface->wdev);

	switch (fc) {
	case IEEE80211_STYPE_DISASSOC:
		mgmt->frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT |
			  IEEE80211_STYPE_DEAUTH);

		skw_fallthrough;

	case IEEE80211_STYPE_DEAUTH:
		ret = skw_sta_rx_deauth(wiphy, iface, buf, len);
		break;

	case IEEE80211_STYPE_AUTH:
		ret = skw_sta_rx_auth(wiphy, iface, freq, signal, buf, len);
		break;

	case IEEE80211_STYPE_ASSOC_RESP:
	case IEEE80211_STYPE_REASSOC_RESP:
		ret = skw_sta_rx_assoc(iface, freq, signal, buf, len);
		break;

	default:
		skw_compat_cfg80211_rx_mgmt(&iface->wdev, freq, signal, buf,
					len, 0, GFP_ATOMIC);
		break;
	}

	skw_wdev_unlock(&iface->wdev);

	return ret;
}

static void skw_ibss_add_sta(struct skw_iface *iface, void *frame,
					int frame_len)
{
	int ret;
	struct station_parameters params;
	struct ieee80211_mgmt *mgmt = frame;

	if (!ether_addr_equal(mgmt->bssid, iface->ibss.bssid))
		return;

	if (skw_peer_ctx(iface, mgmt->sa))
		return;

	memset(&params, 0x0, sizeof(params));
	ret = skw_add_station(iface->wdev.wiphy, iface->ndev,
			mgmt->sa, &params);
	if (ret < 0)
		return;

	params.sta_flags_set |= BIT(NL80211_STA_FLAG_ASSOCIATED);
	skw_change_station(iface->wdev.wiphy, iface->ndev,
			mgmt->sa, &params);
}

static void skw_ibss_del_sta(struct skw_iface *iface, void *frame,
					int frame_len)
{
	struct skw_peer_ctx *ctx;
	struct ieee80211_mgmt *mgmt = frame;
	u16 reason = le16_to_cpu(mgmt->u.deauth.reason_code);

	skw_dbg("iface: %d, bssid: %pM, sa: %pM, da: %pM, reason: %d\n",
		iface->id, mgmt->bssid, mgmt->sa, mgmt->bssid, reason);

	ctx = skw_peer_ctx(iface, mgmt->sa);
	if (!ctx)
		return;

	skw_peer_ctx_transmit(ctx, false);
	skw_peer_ctx_bind(iface, ctx, NULL);
}

static void skw_ibss_rx_mgmt(struct skw_iface *iface, void *frame,
					int frame_len)
{
	u16 fc;
	struct ieee80211_mgmt *mgmt = frame;

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return;
	}

	fc = SKW_MGMT_SFC(mgmt->frame_control);
	switch (fc) {
	case IEEE80211_STYPE_BEACON:
	case IEEE80211_STYPE_PROBE_RESP:
		skw_ibss_add_sta(iface, frame, frame_len);
		break;

	case IEEE80211_STYPE_DEAUTH:
		skw_ibss_del_sta(iface, frame, frame_len);
		break;

	default:
		break;
	}
}

static bool skw_sta_access_allowed(struct skw_iface *iface, u8 *mac)
{
	int idx;
	struct skw_peer_ctx *ctx;
	int nr_allowed = iface->sap.max_sta_allowed;
	int bitmap = atomic_read(&iface->peer_map);

	while (bitmap && nr_allowed) {
		idx = ffs(bitmap) - 1;
		SKW_CLEAR(bitmap, BIT(idx));

		ctx = &iface->skw->peer_ctx[idx];

		mutex_lock(&ctx->lock);

		if (ctx->peer && ether_addr_equal(ctx->peer->addr, mac)) {
			mutex_unlock(&ctx->lock);
			break;
		}

		mutex_unlock(&ctx->lock);

		nr_allowed--;
	}

	return (nr_allowed && skw_acl_allowed(iface, mac));
}

static int skw_sap_rx_mgmt(struct skw_core *skw, struct skw_iface *iface,
		u16 fc, int freq, int signal, void *buf, int len)
{
	int ret;
	struct skw_peer_ctx *ctx;
	bool force_deauth = false;
	struct ieee80211_mgmt *mgmt = buf;

	if (fc == IEEE80211_STYPE_AUTH) {
		if (!skw_sta_access_allowed(iface, mgmt->sa)) {
			skw_info("deny: sta: %pM\n", mgmt->sa);

			skw_cmd_del_sta(priv_to_wiphy(skw), iface->ndev,
					mgmt->sa,
					12, /* Deauthentication */
					5,  /* WLAN_REASON_DISASSOC_AP_BUSY */
					true);
			return 0;
		}

		ctx = skw_peer_ctx(iface, mgmt->sa);
		if (ctx) {
			skw_peer_ctx_lock(ctx);

			if (ctx->peer && ctx->peer->sm.state >= SKW_STATE_ASSOCED) {
				ctx->peer->flags |= SKW_PEER_FLAG_DEAUTHED;
				force_deauth = true;
			}

			skw_peer_ctx_unlock(ctx);
		}

	} else if (fc == IEEE80211_STYPE_DISASSOC) {
		mgmt->frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT |
						  IEEE80211_STYPE_DEAUTH);
	}

	if (iface->sap.sme_external) {
		if (force_deauth) {
			struct ieee80211_mgmt reply;

			skw_info("force deauth with: %pM\n", mgmt->sa);

			reply.frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT |
							  IEEE80211_STYPE_DEAUTH);
			reply.duration = 0;
			reply.seq_ctrl = 0;
			skw_ether_copy(reply.da, mgmt->da);
			skw_ether_copy(reply.sa, mgmt->sa);
			skw_ether_copy(reply.bssid, mgmt->bssid);

			reply.u.deauth.reason_code = cpu_to_le16(3); // WLAN_REASON_DEAUTH_LEAVING

			ret = !skw_compat_cfg80211_rx_mgmt(&iface->wdev, freq,
						signal, (const u8 *)&reply,
						SKW_DEAUTH_FRAME_LEN, 0, GFP_ATOMIC);
			if (ret)
				skw_warn("deauth with %pM failed\n", mgmt->sa);
		}

		ret = !skw_compat_cfg80211_rx_mgmt(&iface->wdev, freq, signal,
						buf, len, 0, GFP_ATOMIC);
	} else {
		ret = skw_mlme_ap_rx_mgmt(iface, fc, freq, signal, buf, len);
	}

	if (ret)
		skw_warn("frame %s rx failed\n", skw_mgmt_name(fc));

	return ret;
}

static int skw_event_rx_mgmt(struct skw_core *skw, struct skw_iface *iface,
			     void *buf, int len)
{
	u16 fc;
	int freq, signal;
	struct skw_peer_ctx *ctx;
	struct skw_mgmt_hdr *hdr = buf;

	if (!iface || !hdr) {
		skw_err("iface: 0x%p, buf: 0x%p\n", iface, hdr);
		return -EINVAL;
	}

	freq = skw_to_freq(hdr->chan);
	signal = DBM_TO_MBM(hdr->signal);
	fc = SKW_MGMT_SFC(hdr->mgmt->frame_control);

	skw_dbg("%s(inst: %d), sa: %pM, chn: %d, signal: %d\n",
		skw_mgmt_name(fc), iface->id, hdr->mgmt->sa, hdr->chan, signal);

	skw_hex_dump("mgmt rx", buf, len, false);

	if (fc == IEEE80211_STYPE_DEAUTH || fc == IEEE80211_STYPE_DISASSOC) {
		skw_info("iface: %d, sa: %pM, da: %pM, %s(reason: %d)\n",
			 iface->id, hdr->mgmt->sa, hdr->mgmt->da,
			 skw_mgmt_name(fc), hdr->mgmt->u.deauth.reason_code);

		ctx = skw_peer_ctx(iface, hdr->mgmt->sa);
		if (ctx) {
			skw_peer_ctx_lock(ctx);

			if (ctx->peer)
				SKW_SET(ctx->peer->flags,
						SKW_PEER_FLAG_DEAUTHED);

			skw_peer_ctx_unlock(ctx);
		}
	}

	switch (iface->wdev.iftype) {
	case NL80211_IFTYPE_STATION:
		if (iface->flags & SKW_IFACE_FLAG_LEGACY_P2P_DEV) {
			skw_compat_cfg80211_rx_mgmt(&iface->wdev, freq, signal,
					(void *)hdr->mgmt, hdr->mgmt_len,
					0, GFP_ATOMIC);

			break;
		}
		skw_fallthrough;

	case NL80211_IFTYPE_P2P_CLIENT:
		skw_sta_rx_mgmt(skw, iface, fc, freq, signal, hdr->mgmt,
				hdr->mgmt_len);
		break;

	case NL80211_IFTYPE_AP:
	case NL80211_IFTYPE_P2P_GO:
		skw_sap_rx_mgmt(skw, iface, fc, freq, signal, hdr->mgmt,
				hdr->mgmt_len);
		break;

	case NL80211_IFTYPE_ADHOC:
		skw_ibss_rx_mgmt(iface, hdr->mgmt, hdr->mgmt_len);
		break;

	default:
		skw_compat_cfg80211_rx_mgmt(&iface->wdev, freq, signal,
					(void *)hdr->mgmt, hdr->mgmt_len,
					0, GFP_ATOMIC);
		break;
	}

	return 0;
}

static int skw_event_acs_report(struct skw_core *skw, struct skw_iface *iface,
				void *buf, int len)
{
	struct skw_survey_info *sinfo = NULL;

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	sinfo = SKW_ZALLOC(sizeof(*sinfo), GFP_KERNEL);
	if (!sinfo)
		return -ENOMEM;

	INIT_LIST_HEAD(&sinfo->list);
	memcpy(&sinfo->data, buf, sizeof(struct skw_survey_data));

	list_add(&sinfo->list, &iface->survey_list);

	return 0;
}

void skw_del_sta_event(struct skw_iface *iface, const u8 *addr, u16 reason)
{
	struct ieee80211_mgmt mgmt;

	if (iface->wdev.iftype == NL80211_IFTYPE_STATION) {
		cfg80211_tdls_oper_request(iface->ndev, addr,
					   NL80211_TDLS_TEARDOWN,
					   reason, GFP_KERNEL);

		return;
	}

	if (iface->sap.sme_external) {
		mgmt.duration = 0;
		mgmt.seq_ctrl = 0;
		memcpy(mgmt.da, iface->addr, ETH_ALEN);
		memcpy(mgmt.sa, addr, ETH_ALEN);
		memcpy(mgmt.bssid, iface->sap.cfg.bssid, ETH_ALEN);
		mgmt.u.deauth.reason_code = cpu_to_le16(reason);
		mgmt.frame_control = cpu_to_le16(IEEE80211_FTYPE_MGMT |
						 IEEE80211_STYPE_DISASSOC);

		skw_compat_cfg80211_rx_mgmt(&iface->wdev,
				 iface->sap.cfg.channel->center_freq,
				 -5400, (void *)&mgmt,
				 SKW_DEAUTH_FRAME_LEN, 0, GFP_ATOMIC);
	} else {
		cfg80211_del_sta(iface->ndev, addr, GFP_KERNEL);
	}
}

static int skw_event_del_sta(struct skw_core *skw, struct skw_iface *iface,
			     void *buf, int len)
{
	struct skw_del_sta *del_sta = buf;
	struct skw_peer_ctx *ctx = NULL;

	skw_info("mac: %pM, reason: %d\n", del_sta->mac, del_sta->reason_code);

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	ctx = skw_peer_ctx(iface, del_sta->mac);
	if (!ctx) {
		skw_err("sta: %pM not exist\n", del_sta->mac);
		return -EINVAL;
	}

	skw_peer_ctx_lock(ctx);

	skw_del_sta_event(iface, del_sta->mac, del_sta->reason_code);

	skw_peer_ctx_unlock(ctx);

	return 0;
}

static int skw_event_rrm_report(struct skw_core *skw, struct skw_iface *iface,
				void *buf, int len)
{
	return 0;
}

static int skw_get_bss_channel(struct ieee80211_mgmt *mgmt, int len)
{
	const u8 *tmp;
	int chn = -1;
	const u8 *ie = mgmt->u.beacon.variable;
	size_t ielen = len - offsetof(struct ieee80211_mgmt,
				u.probe_resp.variable);

	tmp = cfg80211_find_ie(WLAN_EID_DS_PARAMS, ie, ielen);
	if (tmp && tmp[1] == 1) {
		chn = tmp[2];
	} else {
		tmp = cfg80211_find_ie(WLAN_EID_HT_OPERATION, ie, ielen);
		if (tmp && tmp[1] >= sizeof(struct ieee80211_ht_operation)) {
			struct ieee80211_ht_operation *htop = (void *)(tmp + 2);

			chn = htop->primary_chan;
		}
	}

	return chn;
}

static int skw_event_scan_report(struct skw_core *skw, struct skw_iface *iface,
				 void *buf, int len)
{
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 17, 0)
	struct timespec64 ts;
#endif
	struct cfg80211_bss *bss = NULL;
	struct ieee80211_channel *rx_channel = NULL;
	struct skw_mgmt_hdr *hdr = buf;
	int freq = skw_to_freq(hdr->chan);
	s32 signal = DBM_TO_MBM(hdr->signal);
	bool is_beacon = ieee80211_is_beacon(hdr->mgmt->frame_control);

	skw_log(SKW_SCAN, "[%s] bssid: %pM, chn: %d, signal: %d, %s\n",
		SKW_TAG_SCAN, hdr->mgmt->sa, hdr->chan, hdr->signal,
		is_beacon ? "beacon" : "probe resp");

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	rx_channel = ieee80211_get_channel(iface->wdev.wiphy, freq);
	if (!rx_channel) {
		skw_err("invalid, freq: %d, channel: %d\n", freq, hdr->chan);
		return -EINVAL;
	}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 17, 0)
	ts = ktime_to_timespec64(ktime_get_boottime());
	hdr->mgmt->u.probe_resp.timestamp = ((u64)ts.tv_sec * 1000000)
						+ ts.tv_nsec / 1000;
#else
	hdr->mgmt->u.probe_resp.timestamp = ktime_get_boottime().tv64;
	do_div(hdr->mgmt->u.probe_resp.timestamp,  1000);
#endif

	bss = cfg80211_inform_bss_frame(iface->wdev.wiphy, rx_channel,
					hdr->mgmt, hdr->mgmt_len,
					signal, GFP_KERNEL);
	if (unlikely(!bss)) {
		int bss_chn = skw_get_bss_channel(hdr->mgmt, hdr->mgmt_len);

		skw_dbg("failed, bssid: %pM, chn: %d, rx chn: %d, flags: %d\n",
			hdr->mgmt->bssid, bss_chn, hdr->chan, rx_channel->flags);

		return 0;
	}

	skw->nr_scan_results++;

	if (test_bit(SKW_FLAG_MBSSID_PRIV, &skw->flags) && bss) {
		skw_bss_priv(bss)->bssid_index = 0;
		skw_bss_priv(bss)->max_bssid_indicator = 0;

		skw_mbssid_data_parser(iface->wdev.wiphy, is_beacon,
			rx_channel, signal, hdr->mgmt, hdr->mgmt_len);
	}

	cfg80211_put_bss(iface->wdev.wiphy, bss);

	return 0;
}

static int skw_event_mgmt_tx_status(struct skw_core *skw,
				struct skw_iface *iface, void *buf, int len)
{
	struct skw_tx_mgmt_status *status = buf;

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	// fixme:
	// check this tx status is for driver or for apps
	switch (iface->wdev.iftype) {
	case NL80211_IFTYPE_STATION:
	case NL80211_IFTYPE_P2P_CLIENT:
	case NL80211_IFTYPE_P2P_DEVICE:
		cfg80211_mgmt_tx_status(&iface->wdev, status->cookie,
					&status->mgmt, status->payload_len,
					status->ack, GFP_KERNEL);

		break;

	case NL80211_IFTYPE_AP:
	case NL80211_IFTYPE_P2P_GO:
		skw_mlme_ap_tx_status(iface, status->cookie, &status->mgmt,
					status->payload_len, status->ack);
		break;

	default:
		break;
	}

	return 0;
}

static int skw_event_ba_action(struct skw_core *skw, struct skw_iface *iface,
			       void *data, int len)
{
	struct skw_peer_ctx *ctx;
	int ret;
	struct skw_ba_action *ba = (struct skw_ba_action *)data;
	const u8 *action_str[] = {"ADD_TX_BA", "DEL_TX_BA",
				  "ADD_RX_BA", "DEL_RX_BA",
				  "REQ_RX_BA"};

	skw_dbg("%s, peer: %d, tid: %d, status: %d, win start: %d, win size: %d\n",
		action_str[ba->action], ba->peer_idx, ba->tid, ba->status_code,
		ba->ssn, ba->win_size);

	if (!iface || ba->tid >= SKW_NR_TID ||
	    ba->peer_idx >= SKW_MAX_PEER_SUPPORT) {
		skw_warn("iface: 0x%p, peer idx: %d, tid: %d\n",
			 iface, ba->peer_idx, ba->tid);

		SKW_BUG_ON(1);

		return 0;
	}

	ctx = &skw->peer_ctx[ba->peer_idx];

	skw_peer_ctx_lock(ctx);

	if (!ctx->peer)
		goto unlock;

	switch (ba->action) {
	case SKW_ADD_TX_BA:
		if (ba->status_code) {
			if (++ctx->peer->txba.tx_try[ba->tid] > 5)
				ctx->peer->txba.blacklist |= BIT(ba->tid);

			SKW_CLEAR(ctx->peer->txba.bitmap, BIT(ba->tid));
		}

		break;

	case SKW_DEL_TX_BA:
		if (ba->tid != SKW_INVALID_ID) {
			SKW_CLEAR(ctx->peer->txba.bitmap, BIT(ba->tid));
			ctx->peer->txba.tx_try[ba->tid] = 0;
		} else {
			memset(&ctx->peer->txba, 0x0, sizeof(ctx->peer->txba));
		}

		break;

	case SKW_REQ_RX_BA:
		skw_update_tid_rx(ctx->peer, ba->tid, ba->ssn, ba->win_size);
		break;

	case SKW_ADD_RX_BA:
		ret = skw_add_tid_rx(ctx->peer, ba->tid, ba->ssn, ba->win_size);
		if (ret < 0) {
			skw_warn("add tid rx fail, ret: %d\n", ret);
		} else {
			SKW_SET(ctx->peer->rx_tid_map, BIT(ba->tid));
		}

		break;

	case SKW_DEL_RX_BA:
		skw_del_tid_rx(ctx->peer, ba->tid);
		SKW_CLEAR(ctx->peer->rx_tid_map, BIT(ba->tid));
		break;

	default:
		WARN_ON(1);
		break;
	}

unlock:
	skw_peer_ctx_unlock(ctx);

	return 0;
}

static int skw_event_enter_roc(struct skw_core *skw, struct skw_iface *iface,
				void *buf, int len)
{
	struct skw_enter_roc *roc = buf;
	struct ieee80211_channel *chan = NULL;

	skw_dbg("cookie: %llu chn: %u duration:%u\n",
		roc->cookie, roc->chn, roc->duration);

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	chan = ieee80211_get_channel(iface->wdev.wiphy, skw_to_freq(roc->chn));
	if (unlikely(!chan)) {
		skw_err("can't get channel:%d\n", roc->chn);
		return -EINVAL;
	}

	cfg80211_ready_on_channel(&iface->wdev, roc->cookie, chan,
					  roc->duration, GFP_ATOMIC);

	return 0;
}

static int skw_event_cancel_roc(struct skw_core *skw, struct skw_iface *iface,
				void *buf, int len)
{
	struct skw_cancel_roc *roc = buf;
	struct ieee80211_channel *chan = NULL;

	skw_dbg("cookie: %llu chn: %u\n", roc->cookie, roc->chn);

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	chan = ieee80211_get_channel(iface->wdev.wiphy, skw_to_freq(roc->chn));
	if (unlikely(!chan)) {
		skw_err("can't get channel:%d\n", roc->chn);
		return -EINVAL;
	}

	cfg80211_remain_on_channel_expired(&iface->wdev, roc->cookie,
				chan, GFP_KERNEL);

	return 0;
}

static int skw_event_tdls(struct skw_core *skw, struct skw_iface *iface,
			  void *buf, int len)
{
	unsigned int length = 0;
	struct sk_buff *skb = NULL;
	struct net_device *ndev = NULL;
	int ret = 0;

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	length = (unsigned int)len;
	skb = dev_alloc_skb(length);
	if (!skb)
		return -ENOMEM;

	skb_push(skb, length);
	memcpy(skb->data, buf, length);
	ndev = iface->ndev;

	skb->dev = ndev;
	skb->protocol = eth_type_trans(skb, ndev);

	if (!(ndev->flags & IFF_UP)) {
		dev_kfree_skb(skb);
		return -ENETDOWN;
	}

	ret = netif_receive_skb(skb);
	if (ret == NET_RX_SUCCESS)
		ndev->stats.rx_packets++;
	else
		ndev->stats.rx_dropped++;

	return 0;
}

#if 0
static int skw_event_credit_update(struct skw_core *skw,
			struct skw_iface *iface, void *cred, int len)
{
	if (!cred && len != sizeof(u16))
		return -EINVAL;

	skw_add_credit(skw, 0, *(u16 *)cred);

	return 0;
}
#endif

static int skw_event_mic_failure(struct skw_core *skw, struct skw_iface *iface,
				 void *buf, int len)
{
	struct skw_mic_failure *mic_failure = buf;

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	cfg80211_michael_mic_failure(iface->ndev, mic_failure->mac,
			 (mic_failure->is_mcbc ? NL80211_KEYTYPE_GROUP :
			  NL80211_KEYTYPE_PAIRWISE), mic_failure->key_id,
			NULL, GFP_KERNEL);

	return 0;
}

static int skw_event_thermal_warn(struct skw_core *skw, struct skw_iface *iface,
				  void *buf, int len)
{
#define SKW_FW_THERMAL_TRIP      0

	u8 event = *(u8 *)buf;
	struct skw_iface *tmp_iface = NULL;
	int i;

	/*
	 * 0: stop transmit
	 * 1: resume transmit
	 */

	skw_warn("active: %u\n", !event);

	if (event == SKW_FW_THERMAL_TRIP)
		set_bit(SKW_FLAG_FW_THERMAL, &skw->flags);
	else
		clear_bit(SKW_FLAG_FW_THERMAL, &skw->flags);

	for (i = 0; i < SKW_NR_IFACE; i++) {
		tmp_iface = skw->vif.iface[i];
		if (!tmp_iface)
			continue;

		if (tmp_iface->wdev.iftype == NL80211_IFTYPE_P2P_DEVICE)
			continue;

		if (event == SKW_FW_THERMAL_TRIP)
			netif_tx_stop_all_queues(tmp_iface->ndev);
		else
			netif_tx_start_all_queues(tmp_iface->ndev);
	}

	return 0;
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 14, 0)
static int skw_event_rssi_monitor(struct skw_core *skw, struct skw_iface *iface,
				  void *buf, int len)
{
	struct skw_rssi_mointor *rssi_mointor = buf;
	struct sk_buff *skb = NULL;

	if (!iface || !buf || len != sizeof(struct skw_rssi_mointor))
		return -EINVAL;

	skb = skw_compat_vendor_event_alloc(priv_to_wiphy(skw),
			NULL, EXT_VENDOR_EVENT_BUF_SIZE + NLMSG_HDRLEN,
			SKW_NL80211_VENDOR_SUBCMD_MONITOR_RSSI, GFP_KERNEL);

	if (!skb) {
		skw_err("Alloc skb for rssi monitor event failed\n");
		return -ENOMEM;
	}

	if (nla_put_u32(skb, SKW_WLAN_VENDOR_ATTR_RSSI_MONITORING_REQUEST_ID,
		rssi_mointor->req_id) ||
		nla_put(skb, SKW_WLAN_VENDOR_ATTR_RSSI_MONITORING_CUR_BSSID,
		ETH_ALEN, rssi_mointor->curr_bssid) ||
		nla_put_s8(skb, SKW_WLAN_VENDOR_ATTR_RSSI_MONITORING_CUR_RSSI,
		rssi_mointor->curr_rssi)) {
		skw_err("nla put for rssi monitor event failed\n");
		goto fail;
	}

	cfg80211_vendor_event(skb, GFP_KERNEL);

fail:
	kfree_skb(skb);
	return 0;
}
#endif

void skw_cqm_scan_timeout(void *data)
{
	struct skw_iface *iface = data;

	skw_dbg(" enter\n");
	if (unlikely(!iface)) {
		skw_warn("iface is NULL\n");
		return;
	}

	spin_lock_bh(&iface->sta.roam_data.lock);
	iface->sta.roam_data.flags &= ~SKW_IFACE_STA_ROAM_FLAG_CQM_LOW;
	spin_unlock_bh(&iface->sta.roam_data.lock);
}

static int skw_event_cqm(struct skw_core *skw, struct skw_iface *iface,
			 void *buf, int len)
{
	struct skw_cqm_info *cqm_info = buf;

	skw_dbg("cqm_status:%d cqm_rssi:%d chan:%d %pM\n",
		cqm_info->cqm_status, cqm_info->cqm_rssi,
		cqm_info->chan, cqm_info->bssid);

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	switch (cqm_info->cqm_status) {
	case CQM_STATUS_RSSI_LOW:
		if (iface->sta.sme_external) {
			if (is_valid_ether_addr(cqm_info->bssid)) {
				spin_lock_bh(&iface->sta.roam_data.lock);
				if (!(iface->sta.roam_data.flags & SKW_IFACE_STA_ROAM_FLAG_CQM_LOW)) {
					skw_dbg("recv cqm low event bssid:%pM\n", cqm_info->bssid);
					memcpy(iface->sta.roam_data.target_bssid, cqm_info->bssid, ETH_ALEN);
					iface->sta.roam_data.target_chn = cqm_info->chan;
					skw_add_timer_work(skw, "cqm_scan_timeout", skw_cqm_scan_timeout,
							iface, SKW_CQM_SCAN_TIMEOUT,
							skw_cqm_scan_timeout, GFP_KERNEL);
					iface->sta.roam_data.flags |= SKW_IFACE_STA_ROAM_FLAG_CQM_LOW;
				}
				spin_unlock_bh(&iface->sta.roam_data.lock);
			}

			skw_compat_cqm_rssi_notify(iface->ndev,
					NL80211_CQM_RSSI_THRESHOLD_EVENT_LOW,
					cqm_info->cqm_rssi, GFP_KERNEL);

		} else {
			skw_roam_connect(iface, cqm_info->bssid,
						  cqm_info->chan);
		}

		break;

	case CQM_STATUS_RSSI_HIGH:
		if (iface->sta.sme_external) {
			skw_compat_cqm_rssi_notify(iface->ndev,
					NL80211_CQM_RSSI_THRESHOLD_EVENT_HIGH,
					cqm_info->cqm_rssi, GFP_KERNEL);
		}

		break;

	case CQM_STATUS_BEACON_LOSS:
		if (is_valid_ether_addr(cqm_info->bssid)) {
			// FW use beacon loss event to trigger roaming
			if (iface->sta.sme_external) {
				skw_dbg("beacon loss trigger roaming");
				skw_compat_cqm_rssi_notify(iface->ndev,
					NL80211_CQM_RSSI_THRESHOLD_EVENT_LOW,
					cqm_info->cqm_rssi, GFP_KERNEL);
			} else
				skw_roam_connect(iface, cqm_info->bssid, cqm_info->chan);
		} else {
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 19, 0)
			cfg80211_cqm_beacon_loss_notify(iface->ndev, GFP_KERNEL);
#endif
		}

		break;

	case CQM_STATUS_TDLS_LOSS:
		cfg80211_cqm_pktloss_notify(iface->ndev, cqm_info->bssid,
					    0, GFP_KERNEL);
		break;

	default:
		break;
	}

	return 0;
}

static int skw_trans_80211_to_8023(struct sk_buff *skb, int len)
{
	int ret = 0;
	struct ieee80211_hdr *wh = (struct ieee80211_hdr *)skb->data;
	u32 hdrsize;
	struct llc *llchdr;
	struct ethhdr *eth_hdr;
	u16 ether_type = 0;
	u8 a1[ETH_ALEN];
	u8 a2[ETH_ALEN];
	u8 a3[ETH_ALEN];
	u16 fc;

	wh = (struct ieee80211_hdr *)skb->data;
	memcpy(a1, wh->addr1, ETH_ALEN);
	memcpy(a2, wh->addr2, ETH_ALEN);
	memcpy(a3, wh->addr3, ETH_ALEN);
	fc = wh->frame_control;

	if (ieee80211_is_data_qos(fc))
		hdrsize = sizeof(struct ieee80211_qos_hdr);
	else
		hdrsize = sizeof(struct ieee80211_hdr_3addr);

	llchdr = (struct llc *)(((uint8_t *)skb->data) + hdrsize);
	ether_type = llchdr->llc_un.type_snap.ether_type;

	/*
	 * Now move the data pointer to the beginning of the mac header :
	 * new-header = old-hdr + (wifhdrsize + llchdrsize - ethhdrsize)
	 */
	skb_pull(skb,
		(hdrsize + sizeof(struct llc) - sizeof(struct ethhdr)));
	eth_hdr = (struct ethhdr *)skb->data;

	if (ieee80211_has_a4(fc))
		ret = -EINVAL;
	else if (ieee80211_has_tods(fc)) {
		memcpy(eth_hdr->h_dest, a3, ETH_ALEN);
		memcpy(eth_hdr->h_source, a2, ETH_ALEN);
	} else if (ieee80211_has_fromds(fc)) {
		memcpy(eth_hdr->h_dest, a1, ETH_ALEN);
		memcpy(eth_hdr->h_source, a3, ETH_ALEN);
	} else { //TDLS IEEE80211_FC1_DIR_NODS
		memcpy(eth_hdr->h_dest, a1, ETH_ALEN);
		memcpy(eth_hdr->h_source, a2, ETH_ALEN);
	}

	eth_hdr->h_proto = ether_type;

	return ret;
}

static int skw_event_rx_unprotect_frame(struct skw_core *skw,
				struct skw_iface *iface, void *buf, int len)
{
	struct ieee80211_hdr *hdr = buf;
	struct ieee80211_mgmt *mgmt = buf;
	int ret = 0;
	unsigned long sz;

	skw_dbg("frame control: %02x, len: %d\n",
		SKW_MGMT_SFC(mgmt->frame_control), len);

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	if (ieee80211_is_data(hdr->frame_control)) {
		//Convert it to 802.3 then check the ethernet type,
		//drop it while it is not EAPOL or WAPI data.
		struct sk_buff *skb = container_of(buf, struct sk_buff, data);
		struct ethhdr *eth_hdr = NULL;

		ret = skw_trans_80211_to_8023(skb, len);
		if (ret) {
			skw_err("convert to 802.3 failed ret:%d\n", ret);
			return ret;
		}

		eth_hdr = (struct ethhdr *)skb->data;

		if (htons(ETH_P_PAE) == eth_hdr->h_proto) {
			skb->dev = iface->ndev;
			skb->protocol = eth_type_trans(skb, iface->ndev);
			skb->csum = 0;
			skb->ip_summed = CHECKSUM_NONE;

			sz = skb->len;
			if (netif_receive_skb(skb) == NET_RX_SUCCESS) {
				iface->ndev->stats.rx_packets++;
				iface->ndev->stats.rx_bytes += sz;
			} else {
				iface->ndev->stats.rx_dropped++;
			}

		} else {
			skw_warn("received unprotect frame from:%pM\n",
						eth_hdr->h_source);
		}
	} else if (ieee80211_is_mgmt(hdr->frame_control)) {
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 11, 0)
		cfg80211_rx_unprot_mlme_mgmt(iface->ndev, buf, len);
#else
		if (ieee80211_is_deauth(hdr->frame_control))
			cfg80211_send_unprot_deauth(iface->ndev, buf, len);
		else
			cfg80211_send_unprot_disassoc(iface->ndev, buf, len);
#endif
	} else {
		skw_err("Unsupported frames\n");
		return -EINVAL;
	}

	return 0;
}

static int skw_chbw_to_cfg80211_chan_def(struct wiphy *wiphy,
					 struct cfg80211_chan_def *chdef,
					 struct skw_event_csa_param *csa)
{
	int freq;
	struct ieee80211_channel *chan = NULL;

	skw_dbg("chn: %d, bw: %d, center1: %d, center2: %d, bss type: 0x%x\n",
		csa->chan, csa->band_width, csa->center_chan1,
		csa->center_chan2, csa->bss_type);

	memset(chdef, 0, sizeof(struct cfg80211_chan_def));

	freq = skw_to_freq(csa->chan);
	if (!freq) {
		skw_err("invalid channel: %d\n", csa->chan);
		return -EINVAL;
	}

	chan = ieee80211_get_channel(wiphy, freq);
	if (!chan || chan->flags & IEEE80211_CHAN_DISABLED) {
		skw_err("invalid freq: %d\n", freq);
		return -EINVAL;
	}

	chdef->chan = chan;
	chdef->center_freq1 = skw_to_freq(csa->center_chan1);
	chdef->center_freq2 = 0;

	switch (csa->band_width) {
	case SKW_CHAN_WIDTH_20:
		if (csa->bss_type & SKW_CAPA_HT)
			chdef->width = NL80211_CHAN_WIDTH_20;
		else
			chdef->width = NL80211_CHAN_WIDTH_20_NOHT;
		break;

	case SKW_CHAN_WIDTH_40:
		chdef->width = NL80211_CHAN_WIDTH_40;
		break;

	case SKW_CHAN_WIDTH_80:
		chdef->width = NL80211_CHAN_WIDTH_80;
		break;

	case SKW_CHAN_WIDTH_80P80:
		chdef->width = NL80211_CHAN_WIDTH_80P80;
		chdef->center_freq2 = skw_to_freq(csa->center_chan2);
		break;

	case SKW_CHAN_WIDTH_160:
		chdef->width = NL80211_CHAN_WIDTH_160;
		break;

	default:
		skw_err("invalid band width: %d\n", csa->band_width);
		return -EINVAL;
	}

	if (!cfg80211_chandef_valid(chdef)) {
		skw_err("chandef invalid\n");
		return -EINVAL;
	}

	return 0;
}

static int skw_event_chan_switch(struct skw_core *skw, struct skw_iface *iface,
				 void *buf, int len)
{
	struct skw_event_csa_param *csa_param = buf;
	struct cfg80211_chan_def chan_def;

	skw_dbg("mode: %d\n", csa_param->mode);

	if (unlikely(!iface)) {
		skw_err("iface invalid\n");
		return -EINVAL;
	}

	skw_hex_dump("csa_event", csa_param, sizeof(*csa_param), false);

	if (!skw_chbw_to_cfg80211_chan_def(iface->wdev.wiphy, &chan_def, csa_param))
		skw_dbg("mode:%d, switch to chan: %d\n", csa_param->mode, csa_param->chan);
	else {
		skw_err("failed convert  to cfg80211_chan_def\n");
		return -EINVAL;
	}

	if (csa_param->mode == SKW_CSA_START) {
		netif_carrier_off(iface->ndev);

		skw_ch_switch_started_notify(iface->ndev, &chan_def, 10, true);
	} else {
		netif_carrier_on(iface->ndev);

		cfg80211_ch_switch_notify(iface->ndev, &chan_def, 0, 1);

		if (is_skw_sta_mode(iface)) {
			iface->sta.core.bss.channel = chan_def.chan;
			iface->sta.core.bss.width = csa_param->band_width;
		} else {
			iface->sap.cfg.channel = chan_def.chan;
			iface->sap.cfg.width = csa_param->band_width;
		}
	}

	return 0;
}

static int skw_event_tx_frame(struct skw_core *skw, struct skw_iface *iface,
			      void *buf, int len)
{
	u16 fc;
	u8 *ie;
	int ie_len;
	struct skw_frame_tx_status *tx = buf;
	struct skw_sta_core *core;

	if (unlikely(!iface)) {
		skw_warn("iface invalid\n");
		return -EINVAL;
	}

	if (iface->wdev.iftype != NL80211_IFTYPE_STATION &&
	    iface->wdev.iftype != NL80211_IFTYPE_P2P_CLIENT)
		return 0;

	skw_hex_dump("tx frame", buf, len, false);

	fc = SKW_MGMT_SFC(tx->mgmt->frame_control);

	skw_dbg("iface: %d, fc: 0x%x, len: %d\n", iface->id, fc, len);

	if (fc == IEEE80211_STYPE_ASSOC_REQ ||
	    fc == IEEE80211_STYPE_REASSOC_REQ) {
		if (fc == IEEE80211_STYPE_ASSOC_REQ) {
			ie = tx->mgmt->u.assoc_req.variable;
			ie_len = tx->mgmt_len - offsetof(struct ieee80211_mgmt,
				u.assoc_req.variable);
		} else {
			ie = tx->mgmt->u.reassoc_req.variable;
			ie_len = tx->mgmt_len - offsetof(struct ieee80211_mgmt,
				u.reassoc_req.variable);
		}

		skw_wdev_lock(&iface->wdev);
		core = &iface->sta.core;

		if (ie_len <= SKW_2K_SIZE) {
			memcpy(core->assoc_req_ie, ie, ie_len);
			core->assoc_req_ie_len = ie_len;
		}

		skw_wdev_unlock(&iface->wdev);
	}

	return 0;
}

static int skw_event_dpd_coeff_result(struct skw_core *skw,
			struct skw_iface *iface, void *buf, int len)
{
	skw_dpd_coeff_result_handler(skw, buf, len);

	return 0;
}

static int skw_event_dpd_gear_cmpl(struct skw_core *skw,
			struct skw_iface *iface, void *buf, int len)
{
	skw_dpd_gear_cmpl_handler(skw, buf, len);

	return 0;
}

static int skw_event_fw_recovery(struct skw_core *skw,
			struct skw_iface *iface, void *buf, int len)
{
	u8 done = *(u8 *)buf;

	skw_dbg("done: %d\n", done);

	/* Frimware start recovery */
	if (done)
		clear_bit(SKW_FLAG_FW_MAC_RECOVERY, &skw->flags);
	else
		set_bit(SKW_FLAG_FW_MAC_RECOVERY, &skw->flags);

	return 0;
}

static int skw_event_mp_mode_handler(struct skw_core *skw,
			struct skw_iface *iface, void *buf, int len)
{
	u8 state = *(u8 *)buf;

	skw_dbg("state: %d\n", state);

	if (state) {
		set_bit(SKW_FLAG_MP_MODE, &skw->flags);
		skw_abort_cmd(skw);

	} else {
		clear_bit(SKW_FLAG_MP_MODE, &skw->flags);
	}

	return 0;
}

static int skw_event_dfs_radar_pulse(struct skw_core *skw,
			struct skw_iface *iface, void *buff, int len)
{
	int i;
	struct skw_pulse_info info;
	struct skw_radar_pulse *radar = buff;

#define SKW_RADAR_RSSI(r) ((r) < 0x10 ? (r) - 60 : (r) - 92)
#define SKW_RADAR_TS(t)   ((jiffies_to_usecs(jiffies) & (~0xffffff)) | t)

	if (!skw->dfs.info || !skw->dfs.fw_enabled || !skw->dfs.flags)
		return 0;

	for (i = 0; i < radar->nr_pulse; i++) {
		info.chirp = radar->data[i].chirp;
		info.width = radar->data[i].width >> 1;
		info.rssi = SKW_RADAR_RSSI(radar->data[i].rssi);
		info.ts = SKW_RADAR_TS(radar->data[i].ts);

		skw_log(SKW_DFS, "[SKWIFI DFS] %s: [%d] inst: %d, width: %d, rssi: %d, chirp: %d, ts: 0x%llx\n",
			__func__, i, iface->id, info.width, info.rssi, info.chirp, info.ts);

		if (!info.width)
			continue;

		skw_dfs_add_pulse(priv_to_wiphy(skw), iface->ndev, &info);
	}

	return 0;
}

static int skw_local_ap_auth_timeout(struct skw_core *skw,
			struct skw_iface *iface, void *buf, int len)
{
	struct skw_client *client = buf;

	skw_warn("client: %pM\n", client->addr);

	skw_mlme_ap_del_sta(priv_to_wiphy(skw), iface->ndev,
					client->addr, false);

	return 0;
}

static int skw_local_ibss_connect(struct skw_core *skw,
			struct skw_iface *iface, void *buf, int len)
{
	u16 chn;
	int ret;
	struct skw_ibss_params params;

	memcpy(params.ssid, iface->ibss.ssid, iface->ibss.ssid_len);
	params.ssid_len = iface->ibss.ssid_len;

	memcpy(params.bssid, iface->ibss.bssid, ETH_ALEN);

	params.type = 0;
	params.chan = iface->ibss.channel;
	params.bw = iface->ibss.bw;
	params.beacon_int = iface->ibss.beacon_int;

	chn = skw_freq_to_chn(iface->ibss.center_freq1);
	params.center_chan1 = chn;

	chn = skw_freq_to_chn(iface->ibss.center_freq2);
	params.center_chan2 = chn;

	ret = skw_send_msg(iface->wdev.wiphy, iface->ndev, SKW_CMD_IBSS_JOIN,
			&params, sizeof(params), NULL, 0);
	if (!ret) {
		netif_carrier_on(iface->ndev);

		cfg80211_ibss_joined(iface->ndev, iface->ibss.bssid,
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 15, 0)
				iface->ibss.chandef.chan,
#endif
				GFP_KERNEL);
	} else {
		skw_err("failed, ret: %d, ssid: %s, bssid: %pM\n",
			ret, iface->ibss.ssid, iface->ibss.bssid);
	}

	return ret;
}

static int skw_local_sta_connect(struct skw_core *skw,
			struct skw_iface *iface, void *buf, int len)
{
	int ret = 0;
	struct cfg80211_bss *bss;
	struct wiphy *wiphy = iface->wdev.wiphy;
	struct skw_connect_param *conn = iface->sta.conn;

	if (!iface->sta.conn)
		return 0;

	bss = cfg80211_get_bss(wiphy, conn->channel, conn->bssid,
			conn->ssid, conn->ssid_len,
			SKW_BSS_TYPE_ESS, SKW_PRIVACY_ESS_ANY);

	if (conn->auth_type == NL80211_AUTHTYPE_SAE)
		ret = skw_connect_sae_auth(wiphy, iface->ndev, bss);
	else
		ret = skw_connect_auth(wiphy, iface->ndev, conn, bss);

	cfg80211_put_bss(wiphy, bss);

	return ret;
}

#define FUNC_INIT(e, f)         \
	[e] = {                 \
		.id = e,        \
		.name = #e,     \
		.func = f       \
	}

static const struct skw_event_func g_event_fn[] = {
	FUNC_INIT(SKW_EVENT_NORMAL_SCAN_CMPL, skw_event_scan_complete),
	FUNC_INIT(SKW_EVENT_SCHED_SCAN_CMPL, skw_event_sched_scan_done),
	FUNC_INIT(SKW_EVENT_DISCONNECT, skw_event_disconnect),
	FUNC_INIT(SKW_EVNET_RX_MGMT, skw_event_rx_mgmt),
	FUNC_INIT(SKW_EVENT_ACS_REPORT, skw_event_acs_report),
	FUNC_INIT(SKW_EVENT_DEL_STA, skw_event_del_sta),
	FUNC_INIT(SKW_EVENT_RRM_REPORT, skw_event_rrm_report),
	FUNC_INIT(SKW_EVENT_SCAN_REPORT, skw_event_scan_report),
	FUNC_INIT(SKW_EVENT_MGMT_TX_STATUS, skw_event_mgmt_tx_status),
	FUNC_INIT(SKW_EVENT_BA_ACTION, skw_event_ba_action),
	FUNC_INIT(SKW_EVENT_ENTER_ROC, skw_event_enter_roc),
	FUNC_INIT(SKW_EVENT_CANCEL_ROC, skw_event_cancel_roc),
	FUNC_INIT(SKW_EVENT_TDLS, skw_event_tdls),
	// FUNC_INIT(SKW_EVENT_CREDIT_UPDATE, skw_event_credit_update),
	FUNC_INIT(SKW_EVENT_MIC_FAILURE, skw_event_mic_failure),
	FUNC_INIT(SKW_EVENT_THERMAL_WARN, skw_event_thermal_warn),
#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 14, 0)
	FUNC_INIT(SKW_EVENT_RSSI_MONITOR, skw_event_rssi_monitor),
#endif
	FUNC_INIT(SKW_EVENT_CQM, skw_event_cqm),
	FUNC_INIT(SKW_EVENT_RX_UNPROTECT_FRAME, skw_event_rx_unprotect_frame),
	FUNC_INIT(SKW_EVENT_CHAN_SWITCH, skw_event_chan_switch),
	FUNC_INIT(SKW_EVENT_TX_FRAME, skw_event_tx_frame),
	FUNC_INIT(SKW_EVENT_DPD_ILC_COEFF_REPORT, skw_event_dpd_coeff_result),
	FUNC_INIT(SKW_EVENT_DPD_ILC_GEAR_CMPL, skw_event_dpd_gear_cmpl),
	FUNC_INIT(SKW_EVENT_FW_RECOVERY, skw_event_fw_recovery),
	FUNC_INIT(SKW_EVENT_NPI_MP_MODE, skw_event_mp_mode_handler),
	FUNC_INIT(SKW_EVENT_RADAR_PULSE, skw_event_dfs_radar_pulse),
	FUNC_INIT(SKW_EVENT_MAX, NULL),
};

static const struct skw_event_func g_local_event_fn[] = {
	// FUNC_INIT(SKW_EVENT_LOCAL_STA_AUTH_ASSOC_TIMEOUT, skw_local_sta_auth_assoc_timeout),
	FUNC_INIT(SKW_EVENT_LOCAL_AP_AUTH_TIMEOUT, skw_local_ap_auth_timeout),
	FUNC_INIT(SKW_EVENT_LOCAL_STA_CONNECT, skw_local_sta_connect),
	FUNC_INIT(SKW_EVENT_LOCAL_IBSS_CONNECT, skw_local_ibss_connect),
	FUNC_INIT(SKW_EVENT_LOCAL_MAX, NULL),
};

#undef FUNC_INIT

static inline void skw_cmd_lock(struct skw_core *skw, unsigned long flags)
{
	down(&skw->cmd.lock);

	if (flags & BIT(SKW_CMD_FLAG_NO_WAKELOCK))
		return;

	__pm_stay_awake(skw->cmd.ws);
}

static inline void skw_cmd_unlock(struct skw_core *skw, unsigned long flags)
{
	if (!(flags & BIT(SKW_CMD_FLAG_NO_WAKELOCK)))
		__pm_relax(skw->cmd.ws);

	up(&skw->cmd.lock);
}

static bool skw_cmd_tx_allowed(struct skw_core *skw, int inst, int cmd, unsigned long extra_flags)
{
	struct skw_iface *iface;
	unsigned long flags = READ_ONCE(skw->flags);

	if (inst < 0) {
		skw_warn("invalid inst: %d\n", inst);
		SKW_BUG_ON(1);

		return false;
	}

	if (extra_flags & BIT(SKW_CMD_FLAG_IGNORE_BLOCK_TX))
		flags &= ~BIT(SKW_FLAG_BLOCK_TX);

	if (!skw_tx_allowed(flags)) {
		skw_warn("skw->flags: 0x%lx, extra_flags: 0x%lx\n",
			 skw->flags, extra_flags);

		return false;
	}

	iface = to_skw_iface(skw, inst);
	if (iface && iface->ndev &&
	    iface->ndev->ieee80211_ptr->iftype == NL80211_IFTYPE_MONITOR) {
		if (cmd == SKW_CMD_SET_MONITOR_PARAM ||
		    cmd == SKW_CMD_CLOSE_DEV ||
		    cmd == SKW_CMD_OPEN_DEV)
			return true;

		return false;
	}

	if (likely(skw->vif.opened_dev))
		return true;

	return (cmd == SKW_CMD_GET_INFO ||
		cmd == SKW_CMD_SYN_VERSION ||
		cmd == SKW_CMD_OPEN_DEV ||
		cmd == SKW_CMD_PHY_BB_CFG ||
		cmd == SKW_CMD_SET_REGD ||
		cmd == SKW_CMD_SET_MIB ||
		cmd == SKW_CMD_DPD_ILC_GEAR_PARAM ||
		cmd == SKW_CMD_DPD_ILC_MARTIX_PARAM);
}

static int skw_set_cmd(struct skw_core *skw, int dev_id, int cmd,
		       void *data, int data_len, void *arg,
		       int arg_size, char *name, u64 start,
		       unsigned long extra_flags)
{
	struct skw_msg *msg_hdr;
	int total_len, msg_len;
	u8 *pos;

	// lockdep_assert_held(&skw->cmd.lock.lock);
	pos = skw->cmd.data;
	total_len = msg_len = data_len + sizeof(*msg_hdr);

	if (skw_need_extra_hdr(skw)) {
		total_len = round_up(total_len + skw->hw.extra.hdr_len,
				     skw->hw.align);

		skw_set_extra_hdr(skw, pos, skw->hw.cmd_port, total_len, 0, 0);

		pos += skw->hw.extra.hdr_len;
	}

	if (total_len > SKW_CMD_MAX_LEN) {
		skw_warn("total_len: %d\n", total_len);
		SKW_BUG_ON(1);

		return -E2BIG;
	}

	skw->cmd.id = cmd;
	skw->cmd.name = name;
	skw->cmd.seq++;
	skw->cmd.start_time = jiffies;
	skw->cmd.arg = arg;
	skw->cmd.arg_size = arg_size;
	skw->cmd.status = 0;
	skw->cmd.data_len = total_len;
	WRITE_ONCE(skw->cmd.flags, extra_flags);

	msg_hdr = (struct skw_msg *) pos;
	msg_hdr->inst_id = dev_id;
	msg_hdr->type = SKW_MSG_CMD;
	msg_hdr->id = cmd;
	msg_hdr->total_len = msg_len;
	msg_hdr->seq = skw->cmd.seq;

	pos += sizeof(*msg_hdr);
	if (data_len)
		memcpy(pos, data, data_len);

	skw->dbg.cmd_idx = (skw->dbg.cmd_idx + 1) % skw->dbg.nr_cmd;
	skw->dbg.cmd[skw->dbg.cmd_idx].trigger = start;
	skw->dbg.cmd[skw->dbg.cmd_idx].build = skw_local_clock();
	skw->dbg.cmd[skw->dbg.cmd_idx].id = cmd;
	skw->dbg.cmd[skw->dbg.cmd_idx].seq = skw->cmd.seq;
	skw->dbg.cmd[skw->dbg.cmd_idx].flags = skw->cmd.flags;
	skw->dbg.cmd[skw->dbg.cmd_idx].xmit = 0;
	skw->dbg.cmd[skw->dbg.cmd_idx].ack = 0;
	skw->dbg.cmd[skw->dbg.cmd_idx].assert = 0;
	skw->dbg.cmd[skw->dbg.cmd_idx].loop = 0;
	atomic_set(&skw->dbg.loop, 0);

	skw_log(SKW_CMD, "[%s] TX %s[%d], iface: %d, seq: %d, flags: 0x%lx,len = %d\n",
		SKW_TAG_CMD, name, cmd, dev_id, skw->cmd.seq, skw->cmd.flags, data_len);

	return 0;
}

static void skw_cmd_timeout_fn(void *data)
{
	struct skw_core *skw = data;

	skw_err("<%s> %s[%d], seq: %d, flags: 0x%lx, timeout:%d(ms)\n",
		skw_bus_name(skw->hw.bus), skw->cmd.name, skw->cmd.id,
		skw->cmd.seq, skw->flags, jiffies_to_msecs(SKW_CMD_TIMEOUT));

	set_bit(SKW_FLAG_BLOCK_TX, &skw->flags);
	skw->dbg.cmd[skw->dbg.cmd_idx].assert = skw_local_clock();

	if (!skw->dbg.cmd[skw->dbg.cmd_idx].loop)
		skw->dbg.cmd[skw->dbg.cmd_idx].loop = atomic_read(&skw->dbg.loop);

	skw_cmd_unlock(skw, 0);

	skw_assert_schedule(priv_to_wiphy(skw));
}

static void skw_msg_try_send_cb(struct skw_core *skw)
{
	skw_del_timer_work(skw, skw->cmd.data);
	skw_cmd_unlock(skw, 0);
}

int skw_msg_try_send(struct skw_core *skw, int inst, int cmd, void *data,
		     int data_len, void *arg, int arg_size, char *name)
{
	int ret;

	if (down_trylock(&skw->cmd.lock))
		return -EBUSY;

	__pm_stay_awake(skw->cmd.ws);

	if (!skw_cmd_tx_allowed(skw, inst, cmd, 0)) {
		skw_cmd_unlock(skw, 0);
		return -EIO;
	}

	ret = skw_set_cmd(skw, inst, cmd, data, data_len,
			  arg, arg_size, name,
			  skw_local_clock(), 0);
	if (ret) {
		skw_cmd_unlock(skw, 0);
		return ret;
	}

	skw_add_timer_work(skw, name, skw_cmd_timeout_fn, skw, SKW_CMD_TIMEOUT,
			   skw->cmd.data, GFP_ATOMIC);

	skw->cmd.callback = skw_msg_try_send_cb;

	set_bit(SKW_CMD_FLAG_XMIT, &skw->cmd.flags);
	skw_wakeup_tx(skw, 0);

	return 0;
}

static void skw_msg_xmit_timeout_cb(struct skw_core *skw)
{
	set_bit(SKW_CMD_FLAG_DONE, &skw->cmd.flags);

	smp_mb();

	wake_up(&skw->cmd.wq);
}

/* SDIO BUS
 *             +--------------------- MSG_HDR->total_len ---------------------+
 *             |                                                              |
 * +-----------+----------+------------+------------+-----------+-------------+
 * | EXTRA_HDR |  MSG_HDR | IE_OFFSET  |  PARAM ... |   IE ...  |  OTHERS ... |
 * +-----------+----------+------------+------------+-----------+-------------+
 *                        |                         |
 *                        +-------- IE_OFFSET ------+
 */
static int skw_cmd_xmit_timeout(struct wiphy *wiphy, int dev_id, int cmd,
			 void *buf, int buf_len, void *arg, int arg_size,
			 char *name, unsigned long timeout, u64 start,
			 unsigned long extra_flags)
{
	int ret;
	struct skw_core *skw = wiphy_priv(wiphy);

	ret = skw_set_cmd(skw, dev_id, cmd, buf, buf_len,
			  arg, arg_size, name, start, extra_flags);
	if (ret)
		return ret;

	skw->cmd.callback = skw_msg_xmit_timeout_cb;
	set_bit(SKW_CMD_FLAG_XMIT, &skw->cmd.flags);

	skw_wakeup_tx(skw, 0);

	ret = wait_event_interruptible_timeout(skw->cmd.wq,
			test_bit(SKW_CMD_FLAG_DONE, &skw->cmd.flags),
			msecs_to_jiffies(100));
	if (ret)
		goto out;

	skw_dbg("skw_hw_request_ack, cmd: %s(%d)\n", name, cmd);
	skw_hw_request_ack(skw);

	ret = wait_event_interruptible_timeout(skw->cmd.wq,
			test_bit(SKW_CMD_FLAG_DONE, &skw->cmd.flags), timeout);
	if (unlikely(!ret)) {
		skw_err("<%s> %s[%d], seq: %d, flags: 0x%lx, timeout:%d(ms)\n",
			skw_bus_name(skw->hw.bus), name, cmd, skw->cmd.seq,
			skw->flags, jiffies_to_msecs(timeout));

		skw->dbg.cmd[skw->dbg.cmd_idx].assert = skw_local_clock();

		if (!skw->dbg.cmd[skw->dbg.cmd_idx].loop)
			skw->dbg.cmd[skw->dbg.cmd_idx].loop = atomic_read(&skw->dbg.loop);

		set_bit(SKW_CMD_FLAG_ACKED, &skw->cmd.flags);
		skw_hw_assert(skw, true);

		return -ETIMEDOUT;
	}

out:
	return ret > 0 ? 0 - skw->cmd.status : ret;
}

int skw_msg_xmit_timeout(struct wiphy *wiphy, int dev_id, int cmd,
			 void *buf, int buf_len, void *arg, int arg_size,
			 char *name, unsigned long timeout,
			 unsigned long extra_flags)
{
	int ret;
	struct skw_core *skw = wiphy_priv(wiphy);

	if (!skw_cmd_tx_allowed(skw, dev_id, cmd, extra_flags))
		return -EIO;

	BUG_ON(in_interrupt());

	skw_cmd_lock(skw, extra_flags);

	ret = skw_cmd_xmit_timeout(wiphy, dev_id, cmd, buf, buf_len,
				arg, arg_size, name, timeout,
				skw_local_clock(), extra_flags);

	skw_cmd_unlock(skw, extra_flags);

	return ret;
}

/*
 *        +--------------+-----------------+------------------+
 *        |   msg_hdr    |  status_code    |     payload      |
 *        +--------------+-----------------+------------------+
 * octets:        8               2              variable
 *
 */
int skw_cmd_ack_handler(struct skw_core *skw, void *data, int data_len)
{
	struct skw_msg *msg_ack = data;

	if (msg_ack->id != skw->cmd.id || msg_ack->seq != skw->cmd.seq ||
	    test_and_set_bit(SKW_CMD_FLAG_ACKED, &skw->cmd.flags)) {
		skw_err("ack id: %d, ack seq: %d, cmd id: %d, cmd seq: %d, flags: 0x%lx\n",
			msg_ack->id, msg_ack->seq, skw->cmd.id,
			skw->cmd.seq, skw->cmd.flags);

		return -EINVAL;
	}

	skw->cmd.status = msg_ack->data[0];
	skw->dbg.cmd[skw->dbg.cmd_idx].ack = skw_local_clock();

	skw_log(SKW_CMD, "[%s] RX %s[%d], status = %d, used %d msec\n",
		SKW_TAG_CMD, skw->cmd.name, skw->cmd.id, skw->cmd.status,
		jiffies_to_msecs(jiffies - skw->cmd.start_time));

	if (skw->cmd.arg) {
		u16 hdr_len = sizeof(struct skw_msg) + sizeof(u16);
		u16 len = msg_ack->total_len - hdr_len;

		// WARN_ON(msg_ack->total_len - hdr_len != skw->cmd.arg_size);
		if (len != skw->cmd.arg_size)
			skw_warn("%s expect len: %d, recv len: %d\n",
				 skw->cmd.name, skw->cmd.arg_size, len);

		memcpy(skw->cmd.arg, (u8 *)data + hdr_len,
		       min(data_len - hdr_len, (int)skw->cmd.arg_size));
	}

	skw->cmd.callback(skw);

	return 0;
}

void skw_event_handler(struct skw_core *skw, struct skw_iface *iface,
		       struct skw_msg *msg_hdr, void *data, size_t data_len)
{
	int inst, max_event_id;
	const struct skw_event_func *handler, *func;

	if (msg_hdr->type == SKW_MSG_EVENT_LOCAL) {
		inst = iface->id;
		func = g_local_event_fn;
		max_event_id = SKW_EVENT_LOCAL_MAX;
	} else {
		inst = 0;
		func = g_event_fn;
		max_event_id = SKW_EVENT_MAX;
	}

	if (msg_hdr->id >= max_event_id) {
		skw_err("invalid event id, type: %d, id: %d(max: %d)\n",
			 msg_hdr->type, msg_hdr->id, max_event_id);
		return;
	}

	handler = &func[msg_hdr->id];
	if (!handler->func) {
		skw_err("function not implement, type: %d, id: %d\n",
			 msg_hdr->type, msg_hdr->id);
		return;
	}

	skw_log(SKW_EVENT, "[%s] iface: %d, %s[%d], seq: %d, len: %ld\n",
		msg_hdr->type == SKW_MSG_EVENT_LOCAL ? SKW_TAG_LOCAL : SKW_TAG_EVENT,
		inst, handler->name, msg_hdr->id, msg_hdr->seq, (long)data_len);

	handler->func(skw, iface, data, data_len);
}

void skw_default_event_work(struct work_struct *work)
{
	struct skw_core *skw;
	struct sk_buff *skb;
	struct skw_msg *msg_hdr;

	skw = container_of(work, struct skw_core, event_work.work);

	while ((skb = skb_dequeue(&skw->event_work.qlist))) {
		msg_hdr = (struct skw_msg *)skb->data;
		skb_pull(skb, sizeof(struct skw_msg));

		skw_event_handler(skw, NULL, msg_hdr, skb->data, skb->len);

		kfree_skb(skb);
	}
}

int skw_queue_local_event(struct wiphy *wiphy, struct skw_iface *iface,
			  int event_id, void *data, size_t data_len)
{
	int ret;
	struct skw_msg msg;
	struct sk_buff *skb;
	struct skw_event_work *work;
	static u16 local_event_sn;

	skw_dbg("iface: %d, msg: %s, msg len: %ld\n", iface ? iface->id : 0,
		g_local_event_fn[event_id].name, (long)data_len);

	msg.total_len = data_len + sizeof(msg);

	skb = netdev_alloc_skb(NULL, msg.total_len);
	if (!skb) {
		skw_err("alloc skb failed, len: %d\n", msg.total_len);
		return -ENOMEM;
	}

	msg.inst_id = iface ? iface->id : 0;
	msg.type = SKW_MSG_EVENT_LOCAL;
	msg.id = event_id;
	msg.seq = ++local_event_sn;

	skw_put_skb_data(skb, &msg, sizeof(msg));
	skw_put_skb_data(skb, data, data_len);

	if (iface) {
		work = &iface->event_work;
	} else {
		struct skw_core *skw = wiphy_priv(wiphy);

		work = &skw->event_work;
	}

	ret = skw_queue_event_work(wiphy, work, skb);
	if (ret < 0)
		kfree_skb(skb);

	return ret;
}
===== ./drivers/skwifi/skw_log.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/version.h>
#include <linux/uaccess.h>
#include <linux/ctype.h>

#include "skw_compat.h"
#include "skw_log.h"
#include "skw_dentry.h"

#define SKW_LL_MASK 0xffff

#if defined(CONFIG_SKW_LOG_ERROR)
#define SKW_LOG_LEVEL SKW_ERROR
#elif defined(CONFIG_SKW_LOG_WARN)
#define SKW_LOG_LEVEL SKW_WARN
#elif defined(CONFIG_SKW_LOG_INFO)
#define SKW_LOG_LEVEL SKW_INFO
#elif defined(CONFIG_SKW_LOG_DEBUG)
#define SKW_LOG_LEVEL SKW_DEBUG
#elif defined(CONFIG_SKW_LOG_DETAIL)
#define SKW_LOG_LEVEL SKW_DETAIL
#else
#define SKW_LOG_LEVEL SKW_INFO
#endif

static unsigned long skw_dbg_level;

unsigned long skw_log_level(void)
{
	return skw_dbg_level;
}

static void skw_set_log_level(int level)
{
	unsigned long dbg_level;

	dbg_level = skw_log_level() & (~SKW_LL_MASK);
	dbg_level |= ((level << 1) - 1);

	xchg(&skw_dbg_level, dbg_level);
}

static void skw_enable_func_log(int func, bool enable)
{
	unsigned long dbg_level = skw_log_level();

	if (enable)
		dbg_level |= func;
	else
		dbg_level &= (~func);

	xchg(&skw_dbg_level, dbg_level);
}

static int skw_log_show(struct seq_file *seq, void *data)
{
	int i;
	u32 level = skw_log_level();
	u8 *log_name[] = {"NONE", "ERROR", "WARN", "INFO", "DEBUG", "DETAIL"};

	i = ffs((level & SKW_LL_MASK) + 1) - 1;

	seq_puts(seq, "\n");
	seq_printf(seq, "Log Level: %s    [ERROR|WARN|INFO|DEBUG|DETAIL]\n", log_name[i]);

#define SKW_LOG_STATUS(s) (level & (s) ? "enable" : "disable")
	seq_puts(seq, "\n");
	seq_printf(seq, "command log: %s\n", SKW_LOG_STATUS(SKW_CMD));
	seq_printf(seq, "event   log: %s\n", SKW_LOG_STATUS(SKW_EVENT));
	seq_printf(seq, "dump    log: %s\n", SKW_LOG_STATUS(SKW_DUMP));
	seq_printf(seq, "scan    log: %s\n", SKW_LOG_STATUS(SKW_SCAN));
	seq_printf(seq, "timer   log: %s\n", SKW_LOG_STATUS(SKW_TIMER));
	seq_printf(seq, "state   log: %s\n", SKW_LOG_STATUS(SKW_STATE));
	seq_printf(seq, "work    log: %s\n", SKW_LOG_STATUS(SKW_WORK));
	seq_printf(seq, "DFS     log: %s\n", SKW_LOG_STATUS(SKW_DFS));
#undef SKW_LOG_STATUS

	return 0;
}

static int skw_log_open(struct inode *inode, struct file *file)
{
	// return single_open(file, &skw_log_show, inode->i_private);
	return single_open(file, &skw_log_show, skw_pde_data(inode));
}

static int skw_log_control(const char *cmd, bool enable)
{
	if (!strcmp("command", cmd))
		skw_enable_func_log(SKW_CMD, enable);
	else if (!strcmp("event", cmd))
		skw_enable_func_log(SKW_EVENT, enable);
	else if (!strcmp("dump", cmd))
		skw_enable_func_log(SKW_DUMP, enable);
	else if (!strcmp("scan", cmd))
		skw_enable_func_log(SKW_SCAN, enable);
	else if (!strcmp("timer", cmd))
		skw_enable_func_log(SKW_TIMER, enable);
	else if (!strcmp("state", cmd))
		skw_enable_func_log(SKW_STATE, enable);
	else if (!strcmp("work", cmd))
		skw_enable_func_log(SKW_WORK, enable);
	else if (!strcmp("dfs", cmd))
		skw_enable_func_log(SKW_DFS, enable);
	else if (!strcmp("detail", cmd))
		skw_set_log_level(SKW_DETAIL);
	else if (!strcmp("debug", cmd))
		skw_set_log_level(SKW_DEBUG);
	else if (!strcmp("info", cmd))
		skw_set_log_level(SKW_INFO);
	else if (!strcmp("warn", cmd))
		skw_set_log_level(SKW_WARN);
	else if (!strcmp("error", cmd))
		skw_set_log_level(SKW_ERROR);
	else
		return -EINVAL;

	return 0;
}

static ssize_t skw_log_write(struct file *fp, const char __user *buffer,
				size_t len, loff_t *offset)
{
	int i, idx;
	char cmd[32];
	bool enable = false;

	for (idx = 0, i = 0; i < len; i++) {
		char c;

		if (get_user(c, buffer))
			return -EFAULT;

		switch (c) {
		case ' ':
			break;

		case ':':
			cmd[idx] = 0;
			if (!strcmp("enable", cmd))
				enable = true;
			else
				enable = false;

			idx = 0;
			break;

		case '|':
		case '\0':
		case '\n':
			cmd[idx] = 0;
			skw_log_control(cmd, enable);
			idx = 0;
			break;

		default:
			cmd[idx++] = tolower(c);
			idx %= 32;

			break;
		}

		buffer++;
	}

	return len;
}

#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0)
static const struct proc_ops skw_log_fops = {
	.proc_open = skw_log_open,
	.proc_read = seq_read,
	.proc_release = single_release,
	.proc_write = skw_log_write,
};
#else
static const struct file_operations skw_log_fops = {
	.owner = THIS_MODULE,
	.open = skw_log_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_log_write,
};
#endif

void skw_log_level_init(void)
{
	skw_set_log_level(SKW_LOG_LEVEL);

	skw_enable_func_log(SKW_CMD, false);
	skw_enable_func_log(SKW_EVENT, false);
	skw_enable_func_log(SKW_DUMP, false);
	skw_enable_func_log(SKW_SCAN, false);
	skw_enable_func_log(SKW_TIMER, false);
	skw_enable_func_log(SKW_STATE, true);
	skw_enable_func_log(SKW_WORK, false);
	skw_enable_func_log(SKW_DFS, false);

	skw_procfs_file(NULL, "log_level", 0666, &skw_log_fops, NULL);
}

void skw_log_level_deinit(void)
{
}
===== ./drivers/skwifi/skw_calib.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/crc32c.h>
#include <linux/fs.h>
#include <linux/uaccess.h>
#include <linux/firmware.h>

#include "skw_core.h"
#include "skw_msg.h"
#include "skw_log.h"
#include "skw_cfg80211.h"
#include "skw_util.h"
#include "skw_calib.h"

static int skw_dpd_ilc_download_gear_param(struct wiphy *wiphy,
			int gear, const u8 *data, u32 t_size)
{
	int ret = 0;
	int i;
	struct skw_ilc_cali_param ilc_param;

	for (i = 0; i < 64; i++) {
		ilc_param.gear = gear;
		ilc_param.len = 1 << 10;
		ilc_param.seq = i;

		memcpy(ilc_param.data, data + (i << 10), 1024);

		if ((i + 1) == 64)
			ilc_param.end = 1;
		else
			ilc_param.end = 0;
		skw_dbg("dbg gear: %d, seq: %d len:%d end:%d\n", ilc_param.gear,
			ilc_param.seq, ilc_param.len, ilc_param.end);

		ret = skw_msg_xmit(wiphy, 0, SKW_CMD_DPD_ILC_GEAR_PARAM,
				   &ilc_param, sizeof(ilc_param), NULL, 0);
		if (ret) {
			skw_err("failed, ret: %d, gear: %d, seq: %d\n",
				ret, gear, i);

			break;
		}
	}

	return ret;
}

static int skw_dpd_ilc_download_matrix_param(struct wiphy *wiphy,
					const u8 *data, u32 t_size)
{
	int ret = 0;

	ret = skw_msg_xmit(wiphy, 0, SKW_CMD_DPD_ILC_MARTIX_PARAM,
			   (void *)data, t_size, NULL, 0);

	return ret;
}

static int skw_dpd_cali_download(struct wiphy *wiphy,
	const char *dpd_name, const char *matrix_name, const char *store_file)
{
	const struct firmware *ilc;
	const struct firmware *mtx;
	struct skw_core *skw = NULL;
	int ret = 0;
	struct file *fp;
	int gear, i;
	struct skw_ilc_result_param *para;

	skw = wiphy_priv(wiphy);
	ret = request_firmware(&mtx, matrix_name, &wiphy->dev);
	if (ret) {
		skw_err("matrix req fail\n");
		goto ret;
	}

	if (mtx->size < SKW_DPD_MATRIX_LEN) {
		ret = -EINVAL;
		skw_err("matrix not enough\n");
		goto relese_mtx;
	}

	ret = skw_dpd_ilc_download_matrix_param(wiphy, mtx->data,
						SKW_DPD_MATRIX_LEN);
	if (ret != 0) {
		skw_err("dpd matrix msg fail\n");
		goto relese_mtx;
	}

	ret = request_firmware(&ilc, dpd_name, &wiphy->dev);
	if (ret) {
		skw_err("dpd fw req fail\n");
		goto relese_mtx;
	}

	if (ilc->size < SKW_GEAR_NUM * SKW_DPD_PARAM_LEN) {
		ret = -EINVAL;
		skw_err("ilc not enough\n");
		goto relese_ilc;
	}

	para = skw->dpd.resource;
	for (i = 0; i < SKW_DPD_CHN_CNT; i++)
		para[i].invalid = 1;

	for (gear = 0; gear < SKW_GEAR_NUM; gear++) {
		ret = skw_dpd_ilc_download_gear_param(wiphy, gear + 4,
					ilc->data + gear * SKW_DPD_PARAM_LEN,
					SKW_DPD_PARAM_LEN);
		if (ret != 0) {
			skw_err("dpd cali msg fail\n");
			goto relese_ilc;
		}

		skw_dbg("wait dpd_cmpl\n");
		if (wait_for_completion_timeout(&skw->dpd.cmpl,
					SKW_DPD_ILC_TIMEOUT) == 0) {
			skw_err("dpd cali time out\n");
			ret = -ETIME;
			goto relese_ilc;
		}
	}

	fp = skw_file_open(store_file, O_RDWR | O_CREAT, 0666);
	if (!fp) {
		skw_err("skw_file_open Fail\n");
		ret = -ENOENT;
		goto relese_ilc;
	}

	*(u32 *)((u8 *)skw->dpd.resource + SKW_DPD_RESOURCE_DATA_CNT) =
		crc32c(0, skw->dpd.resource, SKW_DPD_RESOURCE_DATA_CNT);

	ret = skw_file_write(fp, skw->dpd.resource, skw->dpd.size, 0);
	if (ret < 0)
		skw_err("dpd write res fail %d", ret);

	skw_file_close(fp);

relese_ilc:
	release_firmware(ilc);
relese_mtx:
	release_firmware(mtx);
ret:
	return ret;
}

static int skw_dpd_chn_to_index(u16 chn)
{
	int index = 0;

	switch (chn) {
	case 1 ... 14:
		index = chn - 1;
		break;

	case 36 ... 64:
		index = ((chn - 36) >> 2) + 14;
		break;

	case 100 ... 144:
		index = ((chn - 100) >> 2) + 22;
		break;

	case 149 ... 165:
		index = ((chn - 149) >> 2) + 34;
		break;

	default:
		index = -1;
		break;
	}

	return index;
}

static int skw_dpd_load_resource(struct skw_dpd *dpd, const char *path)
{
	int ret;
	struct file *fp;

	fp = skw_file_open(path, O_RDONLY, 0);
	if (!fp)
		return -ENOENT;

	ret = skw_file_read(fp, dpd->resource, dpd->size, 0);
	if (ret < 0)
		goto out;

	if (*(u32 *)((u8 *)dpd->resource + SKW_DPD_RESOURCE_DATA_CNT)
		!= crc32c(0, dpd->resource, SKW_DPD_RESOURCE_DATA_CNT)) {
		ret = -SKW_EDPDVRFY;
		skw_err("resource crc:%d fail", ret);
	}
out:
	skw_file_close(fp);

	return ret;
}

int skw_dpd_coeff_result_handler(struct skw_core *skw,
	void *buf, int len)
{
	int index;
	struct skw_coeff_samples *gear;
	struct skw_ilc_result_param *param;
	struct skw_event_ilc_res_of_smpl *res = buf;

	index = skw_dpd_chn_to_index(res->chidx);
	if (index < 0) {
		skw_err("dpd chn %d not found\n", res->chidx);
		return -EINVAL;
	}

	param = skw->dpd.resource;
	param[index].center_ch = res->chidx;
	param[index].invalid = !res->succ;
	gear = &param[index].r_data[res->gear - 4];
	skw_dbg("coeff idx:%d ch:%d invalid:%d gear:%d smpl:%d cch:%d\n",
		index, res->chidx, param[index].invalid,
		res->gear, res->smpl, param[index].center_ch);

	memcpy(gear->smpl[res->smpl - 1], res->s_data, sizeof(res->s_data));

	return 0;
}

int skw_dpd_gear_cmpl_handler(struct skw_core *skw, void *buf, int len)
{
	struct skw_event_ilc_gear_cmpl *cmpl = buf;

	if (cmpl->c_flag != 1) {
		skw_err("dpd %d not cpml\n", cmpl->c_flag);
		return -EINVAL;
	}

	skw_dbg("com dpd_cmpl\n");
	complete(&skw->dpd.cmpl);

	return 0;
}

static int skw_get_5g_80mhz_center_ch(u8 ch)
{
	int i;
	const int center_ch_5g[] = {42, 58, 106, 122, 138, 155, 171};

	for (i = 0; i < ARRAY_SIZE(center_ch_5g); i++) {
		if (ch >= center_ch_5g[i] - 6 &&
		    ch <= center_ch_5g[i] + 6)
			return center_ch_5g[i];
	}

	return 0;
}

int skw_dpd_set_coeff_params(struct wiphy *wiphy,
	struct net_device *ndev, u8 chn, u8 center_chan,
	u8 center_chan_two, u8 bandwidth)
{
	int ret = 0;
	int index, i;
	struct skw_core *skw = NULL;
	struct skw_ilc_result_param *para;
	u8 cmd_center_ch;
	u8 cmd_band;

	skw_dbg("param: %d %d %d %d", chn, center_chan,
		center_chan_two, bandwidth);

	skw = wiphy_priv(wiphy);
	if (!skw) {
		skw_err("skw->dpd skw null");
		return -EINVAL;
	}
	para = skw->dpd.resource;
	if (!para) {
		skw_err("skw->dpd.resource null");
		return -EINVAL;
	}

	cmd_center_ch = center_chan;

	if (cmd_center_ch > 14) {
		cmd_band = SKW_CHAN_WIDTH_80;
		cmd_center_ch = skw_get_5g_80mhz_center_ch(chn);
	} else {
		cmd_band = SKW_CHAN_WIDTH_20;
	}

	if ((chn > 14) && (cmd_band == SKW_CHAN_WIDTH_80)) {
		index = skw_dpd_chn_to_index(cmd_center_ch);
		if (index < 0)
			return -EINVAL;
	} else {
		index = skw_dpd_chn_to_index(cmd_center_ch);
		if (index < 0)
			return -EINVAL;

		if (index >= SKW_DPD_CHN_CNT)
			return -EINVAL;

		if (para[index].invalid == 1) {
			for (i = 0; i < max(index, (SKW_DPD_CHN_CNT - index));
				i++) {
				if ((index - i >= 0))
					if (para[index - i].invalid == 0) {
						index = index - i;
						break;
					}
				if ((index + i < SKW_DPD_CHN_CNT))
					if (para[index + i].invalid == 0) {
						index = index + i;
						break;
					}
			}
		}
	}

	if (!para[index].center_ch)
		para[index].center_ch = cmd_center_ch;
	para[index].chn = chn;
	para[index].center_two_ch = center_chan_two;
	para[index].band = cmd_band;
	skw_dbg("send chn:%d center:%d center2:%d band:%d",
		para[index].chn, para[index].center_ch,
		para[index].center_two_ch, para[index].band);

	ret = skw_send_msg(wiphy, ndev, SKW_CMD_DPD_ILC_COEFF_PARAM,
		&para[index], sizeof(struct skw_ilc_result_param), NULL, 0);
	if (ret)
		skw_err("Send ilc coeff failed, ret: %d", ret);

	return ret;
}

int skw_dpd_download(struct wiphy *wiphy, struct skw_dpd *dpd)
{
	// TODO:
	// Maybe we should build a new dpd_resource name
	// with chip_id from chip_info struct

	if (skw_dpd_load_resource(dpd, SKW_DPD_RESOURCE_FILE) < 0) {
		if (skw_dpd_cali_download(wiphy, SKW_DPD_SRC_FW,
					SKW_DPD_MATRIX_FW,
					SKW_DPD_RESOURCE_FILE) < 0) {
			skw_err("dpd ilc dowload failed\n");
			return -EFAULT;
		}
	}

	return 0;
}

int skw_dpd_init(struct skw_dpd *dpd)
{
	init_completion(&dpd->cmpl);

	dpd->size = SKW_DPD_RESOURCE_DATA_CNT + SKW_DPD_RESOURCE_CRC_CNT;
	dpd->resource = SKW_ZALLOC(dpd->size, GFP_KERNEL);
	if (!dpd->resource) {
		skw_err("malloc dpd resource failed, size: %d\n",
			dpd->size);
		return -ENOMEM;
	}

	return 0;
}

void skw_dpd_deinit(struct skw_dpd *dpd)
{
	SKW_KFREE(dpd->resource);
}
===== ./drivers/skwifi/skw_timer.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/skbuff.h>
#include <net/cfg80211.h>

#include "skw_core.h"
#include "skw_timer.h"
#include "skw_msg.h"
#include "skw_mlme.h"

static int skw_timer_show(struct seq_file *seq, void *data)
{
	struct skw_timer *timer;
	struct skw_core *skw = seq->private;

	seq_printf(seq, "count: %d\n", skw->timer_data.count);

	if (!skw->timer_data.count)
		return 0;

	spin_lock_bh(&skw->timer_data.lock);
	list_for_each_entry(timer, &skw->timer_data.list, list) {
		seq_puts(seq, "\n");

		seq_printf(seq, "name: %s\n"
				"id: 0x%p\n"
				"time left: %u ms\n",
				timer->name,
				timer->id,
				jiffies_to_msecs(timer->timeout - jiffies));
	}

	spin_unlock_bh(&skw->timer_data.lock);

	return 0;
}

static int skw_timer_open(struct inode *inode, struct file *file)
{
	return single_open(file, skw_timer_show, inode->i_private);
}

static const struct file_operations skw_timer_fops = {
	.owner = THIS_MODULE,
	.open = skw_timer_open,
	.read = seq_read,
	.llseek = seq_lseek,
	.release = single_release,
};

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 15, 0)
static void skw_timer_work(struct timer_list *data)
#else
static void skw_timer_work(unsigned long data)
#endif
{
	struct skw_core *skw;
	struct skw_timer *timer, *next;
	LIST_HEAD(timeout_list);

	skw = container_of((void *)data, struct skw_core, timer_data.timer);

	spin_lock_bh(&skw->timer_data.lock);
	list_for_each_entry_safe(timer, next, &skw->timer_data.list, list) {
		if (time_before(jiffies, timer->timeout))
			break;

		list_move(&timer->list, &timeout_list);
	}

	spin_unlock_bh(&skw->timer_data.lock);

	while (!list_empty(&timeout_list)) {
		timer = list_first_entry(&timeout_list, struct skw_timer, list);
		skw_log(SKW_TIMER, "[%s] %s: %s(id: 0x%p)\n",
			SKW_TAG_TIMER, __func__, timer->name, timer->id);
		list_del(&timer->list);

		timer->cb(timer->data);
		skw->timer_data.count--;

		SKW_KFREE(timer);
	}

	spin_lock_bh(&skw->timer_data.lock);
	timer = list_first_entry_or_null(&skw->timer_data.list, struct skw_timer, list);
	if (timer)
		mod_timer(&skw->timer_data.timer, timer->timeout);

	spin_unlock_bh(&skw->timer_data.lock);
}

static bool skw_timer_id_exist(struct skw_core *skw, void *id)
{
	bool result = false;
	struct skw_timer *timer;

	spin_lock_bh(&skw->timer_data.lock);

	list_for_each_entry(timer, &skw->timer_data.list, list) {
		if (id == timer->id) {
			result = true;
			break;
		}
	}

	spin_unlock_bh(&skw->timer_data.lock);

	return result;
}

int skw_add_timer_work(struct skw_core *skw, const char *name,
		       void (*cb)(void *dat), void *data,
		       unsigned long timeout, void *timer_id, gfp_t flags)
{
	struct skw_timer *timer, *node;
	struct list_head *head;

	if (!timer_id || !cb)
		return -EINVAL;

	skw_log(SKW_TIMER, "[%s] %s: %s(id: 0x%p), time out = %ld\n",
		SKW_TAG_TIMER, __func__, name, timer_id, timeout);

	if (skw_timer_id_exist(skw, timer_id)) {
		skw_warn("id: 0x%p exist\n", timer_id);
		SKW_BUG_ON(1);

		return -EINVAL;
	}

	timer = SKW_ZALLOC(sizeof(*timer), flags);
	if (IS_ERR(timer))
		return -ENOMEM;

	INIT_LIST_HEAD(&timer->list);

	timer->name = name;
	timer->cb = cb;
	timer->data = data;
	timer->id = timer_id;
	timer->timeout = msecs_to_jiffies(timeout) + jiffies + 1;

	spin_lock_bh(&skw->timer_data.lock);
	head = &skw->timer_data.list;

	list_for_each_entry(node, &skw->timer_data.list, list) {
		if (time_before_eq(timer->timeout, node->timeout)) {
			head = &node->list;
			break;
		}
	}

	list_add(&timer->list, head);

	skw->timer_data.count++;
	node = list_first_entry(&skw->timer_data.list, struct skw_timer, list);

	mod_timer(&skw->timer_data.timer, node->timeout);
	spin_unlock_bh(&skw->timer_data.lock);

	return 0;
}

void skw_del_timer_work(struct skw_core *skw, void *timer_id)
{
	struct skw_timer *timer;

	skw_log(SKW_TIMER, "[%s] %s: id: 0x%p\n",
		SKW_TAG_TIMER, __func__, timer_id);

	spin_lock_bh(&skw->timer_data.lock);
	list_for_each_entry(timer, &skw->timer_data.list, list) {
		if (timer->id == timer_id) {
			list_del(&timer->list);
			skw->timer_data.count--;
			SKW_KFREE(timer);
			break;
		}
	}

	timer = list_first_entry_or_null(&skw->timer_data.list, struct skw_timer, list);
	if (timer)
		mod_timer(&skw->timer_data.timer, timer->timeout);

	spin_unlock_bh(&skw->timer_data.lock);
}

void skw_timer_init(struct skw_core *skw)
{
	// skw->timer_work.timeout = LONG_MAX;
	skw->timer_data.count = 0;

	INIT_LIST_HEAD(&skw->timer_data.list);
	spin_lock_init(&skw->timer_data.lock);

	// fixme:
	// timer_setup(&skw->timer_data.timer, skw->timer_data.timer_work, 0);
	skw_compat_setup_timer(&skw->timer_data.timer, skw_timer_work);

	skw_debugfs_file(skw->dentry, "timer", 04444, &skw_timer_fops, skw);
}

void skw_timer_deinit(struct skw_core *skw)
{
	LIST_HEAD(flush_list);

	del_timer(&skw->timer_data.timer);

	spin_lock_bh(&skw->timer_data.lock);
	list_replace_init(&skw->timer_data.list, &flush_list);
	spin_unlock_bh(&skw->timer_data.lock);

	while (!list_empty(&flush_list)) {
		struct skw_timer *timer = list_first_entry(&flush_list,
				struct skw_timer, list);
		list_del(&timer->list);
		skw_log(SKW_TIMER, "[%s] %s: name: %s\n",
			SKW_TAG_TIMER, __func__, timer->name);

		SKW_KFREE(timer);
	}
}
===== ./drivers/skwifi/skw_regd.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/nl80211.h>
#include <net/cfg80211.h>

#include "skw_core.h"
#include "skw_regd.h"
#include "skw_msg.h"
#include "skw_log.h"
#include "skw_db.h"

static int skw_regd_show(struct seq_file *seq, void *data)
{
	struct wiphy *wiphy = seq->private;
	struct skw_core *skw = wiphy_priv(wiphy);

	seq_puts(seq, "\n");

	seq_printf(seq, "country: %c%c\n", skw->country[0], skw->country[1]);

	seq_puts(seq, "\n");

	return 0;
}

static int skw_regd_open(struct inode *inode, struct file *file)
{
	return single_open(file, skw_regd_show, inode->i_private);
}

static ssize_t skw_regd_write(struct file *fp, const char __user *buf,
				size_t size, loff_t *off)
{
	u8 country[3];
	struct wiphy *wiphy = fp->f_inode->i_private;

	if (size != 3) {
		skw_err("invalid len: %zd\n", size);
		return size;
	}

	if (copy_from_user(&country, buf, size)) {
		skw_err("copy failed\n");
		return size;
	}

	skw_set_regdom(wiphy, country);

	return size;
}

static const struct file_operations skw_regd_fops = {
	.owner = THIS_MODULE,
	.open = skw_regd_open,
	.read = seq_read,
	.write = skw_regd_write,
	.llseek = seq_lseek,
	.release = single_release,
};

static inline bool is_skw_valid_reg_code(const char *alpha2)
{
	if (!alpha2)
		return false;

	if (alpha2[0] == '0' && alpha2[1] == '0')
		return true;

	return isalpha(alpha2[0]) && isalpha(alpha2[1]);
}

static bool skw_alpha2_equal(const char *alpha2_x, const char *alpha2_y)
{
	if (!alpha2_x || !alpha2_y)
		return false;

	return alpha2_x[0] == alpha2_y[0] && alpha2_x[1] == alpha2_y[1];
}

static bool skw_freq_in_rule_band(const struct ieee80211_freq_range *freq_range,
			      u32 freq_khz)
{
#define ONE_GHZ_IN_KHZ	1000000
	u32 limit = freq_khz > 45 * ONE_GHZ_IN_KHZ ?
			20 * ONE_GHZ_IN_KHZ : 2 * ONE_GHZ_IN_KHZ;

	if (abs(freq_khz - freq_range->start_freq_khz) <= limit)
		return true;

	if (abs(freq_khz - freq_range->end_freq_khz) <= limit)
		return true;

	return false;

#undef ONE_GHZ_IN_KHZ
}

static bool skw_does_bw_fit_range(const struct ieee80211_freq_range *freq_range,
				u32 center_freq_khz, u32 bw_khz)
{
	u32 start_freq_khz, end_freq_khz;

	start_freq_khz = center_freq_khz - (bw_khz / 2);
	end_freq_khz = center_freq_khz + (bw_khz / 2);

	if (start_freq_khz >= freq_range->start_freq_khz &&
	    end_freq_khz <= freq_range->end_freq_khz)
		return true;

	return false;
}

static const struct ieee80211_regdomain *skw_get_regd(const char *alpha2)
{
	int i;
	const struct ieee80211_regdomain *regdom;

	if (!is_skw_valid_reg_code(alpha2)) {
		skw_err("Invalid alpha\n");
		return NULL;
	}

	for (i = 0; i < skw_regdb_size; i++) {
		regdom = skw_regdb[i];

		if (skw_alpha2_equal(alpha2, regdom->alpha2))
			return regdom;
	}

	skw_warn("country: %c%c not support\n", alpha2[0], alpha2[1]);

	return NULL;
}

static bool is_skw_valid_reg_rule(const struct ieee80211_reg_rule *rule)
{
	u32 freq_diff;
	const struct ieee80211_freq_range *freq_range = &rule->freq_range;

	if (freq_range->start_freq_khz <= 0 || freq_range->end_freq_khz <= 0) {
		skw_dbg("invalid, start: %d, end: %d\n",
			freq_range->start_freq_khz, freq_range->end_freq_khz);

		return false;
	}

	if (freq_range->start_freq_khz > freq_range->end_freq_khz) {
		skw_dbg("invalid, start: %d > end: %d\n",
			freq_range->start_freq_khz, freq_range->end_freq_khz);
		return false;
	}

	freq_diff = freq_range->end_freq_khz - freq_range->start_freq_khz;

	if (freq_range->end_freq_khz <= freq_range->start_freq_khz ||
	    freq_range->max_bandwidth_khz > freq_diff) {
		skw_dbg("invalid, start: %d, end: %d, max band: %d, diff: %d\n",
			freq_range->start_freq_khz, freq_range->end_freq_khz,
			freq_range->max_bandwidth_khz, freq_diff);
		return false;
	}

	return true;
}

static bool is_skw_valid_rd(const struct ieee80211_regdomain *rd)
{
	int i;
	const struct ieee80211_reg_rule *reg_rule = NULL;

	for (i = 0; i < rd->n_reg_rules; i++) {
		reg_rule = &rd->reg_rules[i];

		if (!is_skw_valid_reg_rule(reg_rule))
			return false;
	}

	return true;
}

static const struct ieee80211_reg_rule *
skw_freq_reg_info(const struct ieee80211_regdomain *regd, u32 freq)
{
	int i;
	bool band_rule_found = false;
	bool bw_fits = false;

	if (!regd)
		return ERR_PTR(-EINVAL);

	for (i = 0; i < regd->n_reg_rules; i++) {
		const struct ieee80211_reg_rule *rr;
		const struct ieee80211_freq_range *fr = NULL;

		rr = &regd->reg_rules[i];
		fr = &rr->freq_range;

		if (!band_rule_found)
			band_rule_found = skw_freq_in_rule_band(fr, freq);

		bw_fits = skw_does_bw_fit_range(fr, freq, MHZ_TO_KHZ(20));

		if (band_rule_found && bw_fits)
			return rr;
	}

	if (!band_rule_found)
		return ERR_PTR(-ERANGE);

	return ERR_PTR(-EINVAL);
}

static const struct ieee80211_reg_rule *skw_regd_rule(struct wiphy *wiphy, u32 freq)
{
	u32 freq_khz = MHZ_TO_KHZ(freq);
	struct skw_core *skw = wiphy_priv(wiphy);

	if (skw->regd || skw_regd_self_mamaged(wiphy))
		return skw_freq_reg_info(skw->regd, freq_khz);

	return freq_reg_info(wiphy, freq_khz);
}

int skw_cmd_set_regdom(struct wiphy *wiphy, const char *alpha2)
{
	int ret;
	int i, idx, band;
	struct ieee80211_supported_band *sband;
	struct skw_regdom regd = {};
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_reg_rule *rule = &regd.rules[0];
	const struct ieee80211_reg_rule *rr = NULL, *_rr = NULL;

#define SKW_MAX_POWER(rr)  (MBM_TO_DBM(rr->power_rule.max_eirp))
#define SKW_MAX_GAIN(rr)   (MBI_TO_DBI(rr->power_rule.max_antenna_gain))

	regd.country[0] = alpha2[0];
	regd.country[1] = alpha2[1];
	regd.country[2] = 0;

	for (idx = 0, band = 0; band < NUM_NL80211_BANDS; band++) {
		sband = wiphy->bands[band];
		if (!sband)
			continue;

		for (i = 0; i < sband->n_channels; i++) {
			struct ieee80211_channel *chn = &sband->channels[i];

			rr = skw_regd_rule(wiphy, chn->center_freq);
			if (IS_ERR(rr) || rr->flags & SKW_RRF_NO_IR)
				continue;

			if (rr != _rr) {
				regd.nr_reg_rules++;

				rule = &regd.rules[idx++];

				rule->nr_channel = 0;
				rule->start_channel = chn->hw_value;
				rule->max_power = SKW_MAX_POWER(rr);
				rule->max_gain = SKW_MAX_GAIN(rr);
				rule->flags = rr->flags;

				_rr = rr;
			}

			rule->nr_channel = chn->hw_value - rule->start_channel + 1;
		}
	}

	if (!regd.nr_reg_rules)
		return 0;

	for (i = 0; i < regd.nr_reg_rules; i++) {
		skw_dbg("%d @ %d, power: %d, gain: %d, flags: 0x%x\n",
			regd.rules[i].start_channel, regd.rules[i].nr_channel,
			regd.rules[i].max_power, regd.rules[i].max_gain,
			regd.rules[i].flags);
	}

	ret = skw_msg_xmit(wiphy, 0, SKW_CMD_SET_REGD, &regd,
			   sizeof(regd), NULL, 0);
	if (!ret) {
		skw->country[0] = alpha2[0];
		skw->country[1] = alpha2[1];
	} else {
		skw_warn("failed, country: %c%c, rules: %d, ret: %d\n",
			 alpha2[0], alpha2[1], regd.nr_reg_rules, ret);
	}

	return ret;
}

static int __skw_set_wiphy_regd(struct wiphy *wiphy, struct ieee80211_regdomain *rd)
{
	int ret = 0;
	struct skw_core *skw = wiphy_priv(wiphy);

	skw->regd = rd;
#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 0, 0)
	if (rtnl_is_locked())
		ret = skw_set_wiphy_regd_sync(wiphy, rd);
	else
		ret = regulatory_set_wiphy_regd(wiphy, rd);
#else
	wiphy_apply_custom_regulatory(wiphy, rd);
#endif

	return ret;
}

int skw_set_wiphy_regd(struct wiphy *wiphy, const char *country)
{
	const struct ieee80211_regdomain *regd;

	if (!skw_regd_self_mamaged(wiphy))
		return 0;

	regd = skw_get_regd(country);
	if (!regd)
		return -EINVAL;

	if (!is_skw_valid_rd(regd))
		return -EINVAL;

#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 0, 0)
	if (country[0] == '0' && country[1] == '0')
		wiphy->regulatory_flags &= ~REGULATORY_DISABLE_BEACON_HINTS;
	else
		wiphy->regulatory_flags |= REGULATORY_DISABLE_BEACON_HINTS;
#endif

	return __skw_set_wiphy_regd(wiphy, (void *)regd);
}

int skw_set_regdom(struct wiphy *wiphy, char *country)
{
	int ret;

	skw_dbg("country: %c%c\n", country[0], country[1]);

	if (!is_skw_valid_reg_code(country)) {
		skw_err("Invalid country code: %c%c\n",
			country[0], country[1]);

		return -EINVAL;
	}

	if (skw_regd_self_mamaged(wiphy)) {
		ret = skw_set_wiphy_regd(wiphy, country);
		if (!ret)
			ret = skw_cmd_set_regdom(wiphy, country);

		return ret;
	}

	return regulatory_hint(wiphy, country);
}

void skw_regd_init(struct wiphy *wiphy)
{
	skw_debugfs_file(SKW_WIPHY_DENTRY(wiphy), "regdom", 0666, &skw_regd_fops, wiphy);
}
===== ./drivers/skwifi/skw_work.c =====
// SPDX-License-Identifier: GPL-2.0

/******************************************************************************
 *
 * Copyright (C) 2020 SeekWave Technology Co.,Ltd.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of version 2 of the GNU General Public License as
 * published by the Free Software Foundation;
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 ******************************************************************************/

#include <linux/skbuff.h>

#include "skw_core.h"
#include "skw_cfg80211.h"
#include "skw_iface.h"
#include "skw_mlme.h"
#include "skw_msg.h"
#include "skw_work.h"
#include "skw_timer.h"
#include "skw_recovery.h"
#include "skw_tx.h"
#include "skw_dfs.h"

#define SKW_WORK_FLAG_ASSERT        0
#define SKW_WORK_FLAG_RCU_FREE      1
#define SKW_WORK_FLAG_UNLOCK        2

static void skw_ap_acl_check(struct wiphy *wiphy, struct skw_iface *iface)
{
	int idx;
	struct skw_peer_ctx *ctx;
	u32 peer_idx_map = atomic_read(&iface->peer_map);
	struct skw_core *skw = wiphy_priv(wiphy);

	while (peer_idx_map) {
		idx = ffs(peer_idx_map) - 1;
		SKW_CLEAR(peer_idx_map, BIT(idx));

		ctx = &skw->peer_ctx[idx];

		if (ctx->peer && !skw_acl_allowed(iface, ctx->peer->addr))
			skw_mlme_ap_del_sta(wiphy, iface->ndev,
					ctx->peer->addr, false);
	}
}

static void skw_work_async_adma_tx_free(struct skw_core *skw,
				struct scatterlist *sglist, int nents)
{
	int idx;
	struct scatterlist *sg;
	struct sk_buff *skb;
	unsigned long *skb_addr, *sg_addr;

	for_each_sg(sglist, sg, nents, idx) {
		sg_addr = (unsigned long *)sg_virt(sg);

		skb_addr = sg_addr - 1;
		skb = (struct sk_buff *)*skb_addr;
		if (unlikely(skb < (struct sk_buff *)PAGE_OFFSET)) {
			/* Invalid skb pointer */
			skw_dbg("wrong address p_data:0x%lx from FW\n", (unsigned long)sg_addr);
			continue;
		}

		skb->dev->stats.tx_packets++;
		skb->dev->stats.tx_bytes += SKW_SKB_TXCB(skb)->skb_native_len;
		//kfree_skb(skb);
		skw_skb_kfree(skw, skb);
		atomic_dec(&skw->txqlen_pending);
	}

	SKW_KFREE(sglist);
}

static int skw_work_process(struct wiphy *wiphy, struct skw_iface *iface,
			int work_id, void *data, int data_len, const u8 *name)
{
	int ret = 0;
	struct skw_sg_node *node;
	struct skw_ba_action *ba;
	struct skw_core *skw = wiphy_priv(wiphy);

	skw_log(SKW_WORK, "[%s]: iface: %d, %s (id: %d)\n",
		SKW_TAG_WORK, iface ? iface->id : -1, name, work_id);

	switch (work_id) {
	case SKW_WORK_BA_ACTION:
		ret = skw_send_msg(wiphy, iface->ndev, SKW_CMD_BA_ACTION,
				data, data_len, NULL, 0);
		break;

	case SKW_WORK_SCAN_TIMEOUT:
		skw_scan_done(skw, iface, true);
		break;

	case SKW_WORK_ACL_CHECK:
		skw_ap_acl_check(wiphy, iface);
		break;

	case SKW_WORK_SET_MC_ADDR:
		ret = skw_send_msg(wiphy, iface->ndev, SKW_CMD_SET_MC_ADDR,
				data, data_len, NULL, 0);
		break;

	case SKW_WORK_SET_IP:
		ret = skw_send_msg(wiphy, iface->ndev, SKW_CMD_SET_IP,
				data, data_len, NULL, 0);
		break;

	case SKW_WORK_TX_FREE:
		node = data;
		skw_work_async_adma_tx_free(skw, node->sg, node->nents);

		break;

	case SKW_WORK_SETUP_TXBA:
		ba = data;

		skw_dbg("%s, iface: %d, peer: %d, tid: %d\n",
			name, iface->id, ba->peer_idx, ba->tid);

		ret = skw_send_msg(wiphy, iface->ndev, SKW_CMD_BA_ACTION,
				data, data_len, NULL, 0);
		if (ret) {
			struct skw_peer_ctx *ctx;

			skw_err("setup TXBA failed, ret: %d\n", ret);

			ctx = skw_get_ctx(skw, ba->peer_idx);

			skw_peer_ctx_lock(ctx);

			if (ctx->peer)
				SKW_CLEAR(ctx->peer->txba.bitmap, BIT(ba->tid));

			skw_peer_ctx_unlock(ctx);
		}

		break;

	case SKW_WORK_TX_ETHER_DATA:
		skw_send_msg(wiphy, iface->ndev, SKW_CMD_TX_DATA_FRAME,
				data, data_len, NULL, 0);
		break;
#if 0
	case SKW_WORK_RADAR_PULSE:
		skw_dfs_radar_pulse_event(wiphy, iface, data, data_len);
		break;
#endif

	default:
		skw_info("invalid work: %d\n", work_id);
		break;
	}

	return ret;
}

static void skw_work(struct work_struct *work)
{
	struct sk_buff *skb;
	struct skw_work_cb *cb;
	struct skw_core *skw = container_of(work, struct skw_core, work);
	struct wiphy *wiphy = priv_to_wiphy(skw);

	while (skw->work_data.flags || skb_queue_len(&skw->work_data.work_list)) {
		if (test_bit(SKW_WORK_FLAG_RCU_FREE, &skw->work_data.flags)) {
			struct rcu_head *head;

			spin_lock_bh(&skw->work_data.rcu_lock);

			head = skw->work_data.rcu_hdr;
			if (head)
				skw->work_data.rcu_hdr = head->next;

			spin_unlock_bh(&skw->work_data.rcu_lock);

			if (head) {
				synchronize_rcu();
				head->func(head);
			} else {
				skw->work_data.rcu_tail = &skw->work_data.rcu_hdr;
				clear_bit(SKW_WORK_FLAG_RCU_FREE, &skw->work_data.flags);
			}
		}

		if (test_and_clear_bit(SKW_WORK_FLAG_ASSERT, &skw->work_data.flags))
			skw_hw_assert(skw, false);

		if (!skb_queue_len(&skw->work_data.work_list))
			continue;

		skb = skb_dequeue(&skw->work_data.work_list);
		cb = SKW_WORK_CB(skb);
		skw_work_process(wiphy, cb->iface, cb->id,
				skb->data, skb->len, cb->name);
		kfree_skb(skb);
	}
}

void skw_assert_schedule(struct wiphy *wiphy)
{
	struct skw_core *skw = wiphy_priv(wiphy);

	set_bit(SKW_WORK_FLAG_ASSERT, &skw->work_data.flags);
	schedule_work(&skw->work);
}

#ifdef CONFIG_SKW_GKI_DRV
void skw_call_rcu(void *core, struct rcu_head *head, rcu_callback_t func)
{
	struct skw_core *skw = core;

	spin_lock_bh(&skw->work_data.rcu_lock);

	head->func = func;
	head->next = NULL;

	*skw->work_data.rcu_tail = head;
	skw->work_data.rcu_tail = &head->next;

	spin_unlock_bh(&skw->work_data.rcu_lock);

	set_bit(SKW_WORK_FLAG_RCU_FREE, &skw->work_data.flags);

	schedule_work(&skw->work);
}
#endif

int __skw_queue_work(struct wiphy *wiphy, struct skw_iface *iface,
		     enum SKW_WORK_ID id, void *data,
		     int dat_len, const u8 *name)
{
	struct skw_core *skw = wiphy_priv(wiphy);
	struct skw_work_cb *wcb;
	struct sk_buff *skb;

	skb = dev_alloc_skb(dat_len);
	if (!skb)
		return -ENOMEM;

	if (data)
		skw_put_skb_data(skb, data, dat_len);

	wcb = SKW_WORK_CB(skb);
	wcb->iface = iface;
	wcb->id = id;
	wcb->name = name;

	skb_queue_tail(&skw->work_data.work_list, skb);
	schedule_work(&skw->work);

	return 0;
}

int skw_queue_event_work(struct wiphy *wiphy, struct skw_event_work *work,
			 struct sk_buff *skb)
{
	struct skw_core *skw = wiphy_priv(wiphy);

	if (!atomic_read(&work->enabled))
		return -EINVAL;

	skb_queue_tail(&work->qlist, skb);

	if (!work_pending(&work->work))
		queue_work(skw->event_wq, &work->work);

	return 0;
}

void skw_work_init(struct wiphy *wiphy)
{
	struct skw_core *skw = wiphy_priv(wiphy);

	skw->work_data.rcu_hdr = NULL;
	skw->work_data.rcu_tail = &skw->work_data.rcu_hdr;

	spin_lock_init(&skw->work_data.rcu_lock);
	skb_queue_head_init(&skw->work_data.work_list);
	INIT_WORK(&skw->work, skw_work);
}

void skw_work_deinit(struct wiphy *wiphy)
{
	struct skw_core *skw = wiphy_priv(wiphy);

	flush_work(&skw->work);
	skb_queue_purge(&skw->work_data.work_list);
}
===== ./drivers/seekwaveplatform/sdio/skw_sdio_log.c =====
/**************************************************************************
 * Copyright(c) 2020-2030  Seekwave Corporation.
 * SEEKWAVE TECH LTD..CO
 *
 *Seekwave Platform the sdio log debug fs
 *FILENAME:skw_sdio_log.c
 *DATE:2022-04-11
 *MODIFY:
 *Author:Jones.Jiang
 **************************************************************************/
#include <linux/uaccess.h>
#include <linux/kernel.h>
#include <linux/slab.h>
#include "skw_sdio.h"
#include "skw_sdio_log.h"
#include "skw_sdio_debugfs.h"

extern char firmware_version[];

static unsigned long skw_sdio_dbg_level;

unsigned long skw_sdio_log_level(void)
{
	return skw_sdio_dbg_level;
}

static void skw_sdio_set_log_level(int level)
{
	unsigned long dbg_level;

	dbg_level = skw_sdio_log_level() & 0xffff0000;
	dbg_level |= ((level << 1) - 1);

	xchg(&skw_sdio_dbg_level, dbg_level);
}

static void skw_sdio_enable_func_log(int func, bool enable)
{
	unsigned long dbg_level = skw_sdio_log_level();

	if (enable)
		dbg_level |= func;
	else
		dbg_level &= (~func);

	xchg(&skw_sdio_dbg_level, dbg_level);
}

static int skw_sdio_log_show(struct seq_file *seq, void *data)
{
#define SKW_SDIO_LOG_STATUS(s) (level & (s) ? "enable" : "disable")

	int i;
	u32 level = skw_sdio_log_level();
	u8 *log_name[] = {"NONE", "ERROR", "WARNNING", "INFO", "DEBUG"};

	for (i = 0; i < 5; i++) {
		if (!(level & BIT(i)))
			break;
	}

	seq_printf(seq, "%s\n", log_name[i < 5 ? i : 4]);

	seq_puts(seq, "\n");
	seq_printf(seq, "port0 log: %s\n", SKW_SDIO_LOG_STATUS(SKW_SDIO_PORT0));
	seq_printf(seq, "port1 log: %s\n", SKW_SDIO_LOG_STATUS(SKW_SDIO_PORT1));
	seq_printf(seq, "port2 log: %s\n", SKW_SDIO_LOG_STATUS(SKW_SDIO_PORT2));
	seq_printf(seq, "port3 log: %s\n", SKW_SDIO_LOG_STATUS(SKW_SDIO_PORT3));
	seq_printf(seq, "port4 log: %s\n", SKW_SDIO_LOG_STATUS(SKW_SDIO_PORT4));
	seq_printf(seq, "port5 log: %s\n", SKW_SDIO_LOG_STATUS(SKW_SDIO_PORT5));
	seq_printf(seq, "port6 log: %s\n", SKW_SDIO_LOG_STATUS(SKW_SDIO_PORT6));
	seq_printf(seq, "port7 log: %s\n", SKW_SDIO_LOG_STATUS(SKW_SDIO_PORT7));
	seq_printf(seq, "savelog  : %s\n", SKW_SDIO_LOG_STATUS(SKW_SDIO_SAVELOG));
	seq_printf(seq, "dump  log: %s\n", SKW_SDIO_LOG_STATUS(SKW_SDIO_DUMP));

	return 0;
}

static int skw_sdio_log_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_sdio_log_show, inode->i_private);
}

static int skw_sdio_log_control(const char *cmd, bool enable)
{
	if (!strcmp("dump", cmd))
		skw_sdio_enable_func_log(SKW_SDIO_DUMP, enable);
	else if (!strcmp("port0", cmd))
		skw_sdio_enable_func_log(SKW_SDIO_PORT0, enable);
	else if (!strcmp("port1", cmd))
		skw_sdio_enable_func_log(SKW_SDIO_PORT1, enable);
	else if (!strcmp("port2", cmd))
		skw_sdio_enable_func_log(SKW_SDIO_PORT2, enable);
	else if (!strcmp("port3", cmd))
		skw_sdio_enable_func_log(SKW_SDIO_PORT3, enable);
	else if (!strcmp("port4", cmd))
		skw_sdio_enable_func_log(SKW_SDIO_PORT4, enable);
	else if (!strcmp("port5", cmd))
		skw_sdio_enable_func_log(SKW_SDIO_PORT5, enable);
    else if (!strcmp("port6", cmd))
		skw_sdio_enable_func_log(SKW_SDIO_PORT6, enable);
	else if (!strcmp("port7", cmd))
		skw_sdio_enable_func_log(SKW_SDIO_PORT7, enable);
    else if (!strcmp("savelog", cmd))
		skw_sdio_enable_func_log(SKW_SDIO_SAVELOG, enable);
	else if (!strcmp("debug", cmd))
		skw_sdio_set_log_level(SKW_SDIO_DEBUG);
	else if (!strcmp("info", cmd))
		skw_sdio_set_log_level(SKW_SDIO_INFO);
	else if (!strcmp("warn", cmd))
		skw_sdio_set_log_level(SKW_SDIO_WARNING);
	else if (!strcmp("error", cmd))
		skw_sdio_set_log_level(SKW_SDIO_ERROR);
	else
		return -EINVAL;

	return 0;
}

static ssize_t skw_sdio_log_write(struct file *fp, const char __user *buffer,
				size_t len, loff_t *offset)
{
	int i, idx;
	char cmd[32];
	bool enable = false;

	for (idx = 0, i = 0; i < len; i++) {
		char c;

		if (get_user(c, buffer))
			return -EFAULT;

		switch (c) {
		case ' ':
			break;

		case ':':
			cmd[idx] = 0;
			if (!strcmp("enable", cmd))
				enable = true;
			else
				enable = false;

			idx = 0;
			break;

		case '|':
		case '\0':
		case '\n':
			cmd[idx] = 0;
			skw_sdio_log_control(cmd, enable);
			idx = 0;
			break;

		default:
			cmd[idx++] = c;
			idx %= 32;

			break;
		}

		buffer++;
	}

	return len;
}

static const struct file_operations skw_sdio_log_fops = {
	.owner = THIS_MODULE,
	.open = skw_sdio_log_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_sdio_log_write,
};

static int skw_version_show(struct seq_file *seq, void *data)
{
	seq_printf(seq, "firmware info: %s\n", firmware_version);
	return 0;
}

static int skw_version_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_version_show, inode->i_private);
}

static const struct file_operations skw_version_fops = {
	.owner = THIS_MODULE,
	.open = skw_version_open,
	.read = seq_read,
	.release = single_release,
};

static int skw_port_statistic_show(struct seq_file *seq, void *data)
{
	char *statistic = kzalloc(2048, GFP_KERNEL);

	skw_get_port_statistic(statistic, 2048);
	seq_printf(seq, "Statistic:\n %s\n", statistic);
	skw_get_assert_print_info(statistic, 2048);
	seq_printf(seq, "sdio last irqs information:\n%s", statistic);
	skw_get_sdio_debug_info(statistic, 2048);
	seq_printf(seq, "\nsdio debug information:\n%s", statistic);
	kfree(statistic);
	return 0;
}

static int skw_port_statistic_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_port_statistic_show, inode->i_private);
}

static const struct file_operations skw_port_statistic_fops = {
	.owner = THIS_MODULE,
	.open = skw_port_statistic_open,
	.read = seq_read,
	.release = single_release,
};

static int skw_cp_log_show(struct seq_file *seq, void *data)
{
	if (!skw_sdio_cp_log_status())
		seq_puts(seq, "Enabled");
	else
		seq_puts(seq, "Disabled");
	return 0;
}

static int skw_cp_log_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_cp_log_show, inode->i_private);
}

static ssize_t skw_cp_log_write(struct file *fp, const char __user *buffer,
				size_t len, loff_t *offset)
{
	char cmd[16] = {0};

	if (len >= sizeof(cmd))
		return -EINVAL;
	if (copy_from_user(cmd, buffer, len))
		return -EFAULT;
	if (!strncmp("enable", cmd, 6)) {
		skw_sdio_debug_log_open();
		skw_sdio_cp_log(0);
	} else if (!strncmp("disable", cmd, 7)) {
		skw_sdio_debug_log_close();
		skw_sdio_cp_log(1);
	}

	return len;
}

static const struct file_operations skw_cp_log_fops = {
	.owner = THIS_MODULE,
	.open = skw_cp_log_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_cp_log_write,
};

static int skw_recovery_debug_show(struct seq_file *seq, void *data)
{
	if (skw_sdio_recovery_debug_status())
		seq_puts(seq, "Disabled");
	else
		seq_puts(seq, "Enabled");
	return 0;
}

static int skw_recovery_debug_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_recovery_debug_show, inode->i_private);
}

static ssize_t skw_recovery_debug_write(struct file *fp, const char __user *buffer,
				size_t len, loff_t *offset)
{
	char cmd[16] = {0};

	if (len >= sizeof(cmd))
		return -EINVAL;
	if (copy_from_user(cmd, buffer, len))
		return -EFAULT;
	if (!strncmp("disable", cmd, 7))
		skw_sdio_recovery_debug(1);
	else if (!strncmp("enable", cmd, 6))
		skw_sdio_recovery_debug(0);

	return len;
}

static const struct file_operations skw_recovery_debug_fops = {
	.owner = THIS_MODULE,
	.open = skw_recovery_debug_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_recovery_debug_write,
};

static int skw_dumpmem_show(struct seq_file *seq, void *data)
{
	return 0;
}

static int skw_dumpmem_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_dumpmem_show, inode->i_private);
}

static ssize_t skw_dumpmem_write(struct file *fp, const char __user *buffer,
				size_t len, loff_t *offset)
{
	char cmd[16] = {0};

	if (len >= sizeof(cmd))
		return -EINVAL;
	if (copy_from_user(cmd, buffer, len))
		return -EFAULT;
	if (!strncmp("dump", cmd, 4))
		skw_sdio_dumpmem(1);
	else if (!strncmp("stop", cmd, 4))
		skw_sdio_dumpmem(0);

	return len;
}

static const struct file_operations skw_dumpmem_fops = {
	.owner = THIS_MODULE,
	.open = skw_dumpmem_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_dumpmem_write,
};

static int skw_sdio_wifi_show(struct seq_file *seq, void *data)
{
	if (skw_sdio_wifi_status())
		seq_puts(seq, "PowerOn");
	else
		seq_puts(seq, "PowerOff");
	return 0;
}

static int skw_sdio_wifi_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_sdio_wifi_show, inode->i_private);
}

static ssize_t skw_sdio_wifi_poweron(struct file *fp, const char __user *buffer,
				size_t len, loff_t *offset)
{
	char cmd[16] = {0};

	if (len >= sizeof(cmd))
		return -EINVAL;
	if (copy_from_user(cmd, buffer, len))
		return -EFAULT;
	if (!strncmp("on", cmd, 2))
		skw_sdio_wifi_power_on(1);
	else if (!strncmp("off", cmd, 3))
		skw_sdio_wifi_power_on(0);

	return len;
}

static const struct file_operations skw_sdio_wifi_fops = {
	.owner = THIS_MODULE,
	.open = skw_sdio_wifi_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_sdio_wifi_poweron,
};

void skw_sdio_log_level_init(void)
{
	skw_sdio_set_log_level(SKW_SDIO_INFO);

	skw_sdio_enable_func_log(SKW_SDIO_DUMP, false);
	skw_sdio_enable_func_log(SKW_SDIO_PORT0, false);
	skw_sdio_enable_func_log(SKW_SDIO_PORT1, false);
	skw_sdio_enable_func_log(SKW_SDIO_PORT2, false);
	skw_sdio_enable_func_log(SKW_SDIO_PORT3, false);
	skw_sdio_enable_func_log(SKW_SDIO_PORT4, false);
	skw_sdio_enable_func_log(SKW_SDIO_PORT5, false);
	skw_sdio_enable_func_log(SKW_SDIO_PORT6, false);
	skw_sdio_enable_func_log(SKW_SDIO_SAVELOG, false);
	skw_sdio_enable_func_log(SKW_SDIO_PORT7, false);
	skw_sdio_add_debugfs("log_level", 0666, NULL, &skw_sdio_log_fops);
	skw_sdio_add_debugfs("Version", 0666, NULL, &skw_version_fops);
	skw_sdio_add_debugfs("Statistic", 0666, NULL, &skw_port_statistic_fops);
	skw_sdio_add_debugfs("CPLog", 0666, NULL, &skw_cp_log_fops);
	skw_sdio_add_debugfs("WiFi", 0666, NULL, &skw_sdio_wifi_fops);
	skw_sdio_add_debugfs("recovery", 0666, NULL, &skw_recovery_debug_fops);
	skw_sdio_add_debugfs("dumpmem", 0666, NULL, &skw_dumpmem_fops);
}
===== ./drivers/seekwaveplatform/sdio/skw_sdio_debugfs.c =====
/*****************************************************************************
 * Copyright(c) 2020-2030  Seekwave Corporation.
 * SEEKWAVE TECH LTD..CO
 *Seekwave Platform the sdio log debug fs
 *FILENAME:skw_sdio_debugfs.c
 *DATE:2022-04-11
 *MODIFY:
 *
 **************************************************************************/

#include "skw_sdio_debugfs.h"
#include "skw_sdio_log.h"
#include "skw_sdio.h"

static struct dentry *skw_sdio_root_dir;

static ssize_t skw_sdio_default_read(struct file *fp, char __user *buf, size_t len,
				loff_t *offset)
{
	return 0;
}

static ssize_t skw_sdio_state_write(struct file *fp, const char __user *buffer,
				size_t len, loff_t *offset)
{
	return len;
}

static const struct file_operations skw_sdio_state_fops = {
	.open = skw_sdio_default_open,
	.read = skw_sdio_default_read,
	.write = skw_sdio_state_write,
};

struct dentry *skw_sdio_add_debugfs(const char *name, umode_t mode, void *data,
			       const struct file_operations *fops)
{
	skw_sdio_dbg("%s:name: %s\n", __func__, name);

	return debugfs_create_file(name, mode, skw_sdio_root_dir, data, fops);
}

int skw_sdio_debugfs_init(void)
{
	skw_sdio_root_dir = debugfs_create_dir("skwsdio", NULL);
	if (IS_ERR(skw_sdio_root_dir))
		return PTR_ERR(skw_sdio_root_dir);

	// skw_sdio_add_debugfs("state", 0666, wiphy, &skw_sdio_state_fops);
	// skw_sdio_add_debugfs("log_level", 0444, wiphy, &skw_sdio_log_fops);

	return 0;
}

void skw_sdio_debugfs_deinit(void)
{
	skw_sdio_dbg("%s :traced\n", __func__);

	debugfs_remove_recursive(skw_sdio_root_dir);
}
===== ./drivers/seekwaveplatform/sdio/skw_sdio_rx.c =====
#include <linux/kernel.h>
#include <linux/errno.h>
#include <linux/slab.h>
#include <linux/module.h>
#include <linux/kref.h>
#include <linux/uaccess.h>
#include <linux/usb.h>
#include <linux/mutex.h>
#include <linux/bitops.h>
#include <linux/kthread.h>
#include <linux/notifier.h>
#include <linux/platform_device.h>
#include <linux/scatterlist.h>
#include <linux/dma-mapping.h>
#include <linux/semaphore.h>
#include <linux/module.h>
#include <linux/list.h>
#include <linux/timer.h>
#include <linux/err.h>
#include <linux/gpio.h>
#include <linux/mmc/sdio_func.h>
#include <linux/skbuff.h>
#include "skw_sdio.h"
#include "skw_sdio_log.h"
#include <linux/workqueue.h>
#define MODEM_ASSERT_TIMEOUT_VALUE  2 * HZ
#define MAX_SG_COUNT	100
#define SDIO_BUFFER_SIZE	(16 * 1024)
#define MAX_FIRMWARE_SIZE 256
#define PORT_STATE_IDLE	0
#define PORT_STATE_OPEN	1
#define PORT_STATE_CLSE	2
#define PORT_STATE_ASST	3

#define CRC_16_L_SEED   0x80
#define CRC_16_L_POLYNOMIAL  0x8000
#define CRC_16_POLYNOMIAL  0x1021
int recovery_debug_status;
int cp_detect_sleep_mode;
#define IS_LOG_PORT(portno)  ((skw_cp_ver == SKW_SDIO_V10) ? (portno == 1) : (portno == SDIO2_BSP_LOG_PORT))
struct sdio_port {
	struct platform_device *pdev;
	struct scatterlist *sg_rx;
	int	 sg_index;
	int	 total;
	int	sent_packet;
	unsigned int type;
	unsigned int channel;
	rx_submit_fn rx_submit;
	void *rx_data;
	int	state;
	char *read_buffer;
	int rx_rp;
	int rx_wp;
	char *write_buffer;
	int  length;
	struct completion rx_done;
	struct completion tx_done;
	struct mutex rx_mutex;
	int	rx_packet;
	int	rx_count;
	int	tx_flow_ctrl;
	int	 rx_flow_ctrl;
	u16	next_seqno;
};

/***********************************************************/
char firmware_version[128];
char assert_context[1024];
int  assert_context_size = 0;
static int assert_info_print;
static u8 fifo_ind;
static u64 port_dmamask = DMA_BIT_MASK(32);
struct sdio_port sdio_ports[SDIO2_MAX_CH_NUM];
static u8 cp_fifo_status;
struct debug_vars debug_infos;
static BLOCKING_NOTIFIER_HEAD(modem_notifier_list);
#if KERNEL_VERSION(4, 4, 0) <= LINUX_VERSION_CODE
static DEFINE_PER_CPU(struct page_frag_cache, skw_sdio_alloc_cache);
#endif
unsigned int crc_16_l_calc(char *buf_ptr, unsigned int len);
static int skw_sdio_rx_port_follow_ctl(int portno, int rx_fctl);
//add the crc api the same as cp crc_16 api
extern void kernel_restart(char *cmd);
static int skw_sdio_irq_ops(int irq_enable);
char skw_cp_ver = SKW_SDIO_V10;
int max_ch_num = MAX_CH_NUM;

#ifdef CONFIG_PRINTK_TIME_FROM_ARM_ARCH_TIMER
#include <clocksource/arm_arch_timer.h>
u64 skw_local_clock(void)
{
	u64 ns;

	ns = arch_timer_read_counter() * 1000;
	do_div(ns, 24);

	return ns;
}
#else
#if KERNEL_VERSION(4, 11, 0) <= LINUX_VERSION_CODE
#include <linux/sched/clock.h>
#else
#include <linux/sched.h>
#endif
u64 skw_local_clock(void)
{
	return local_clock();
}
#endif

void skw_get_assert_print_info(char *buffer, int size)
{
	int ret = 0;
	int j = 0;
	u64 ts;
	unsigned long rem_nsec;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	if (!buffer) {
		skw_sdio_info("buffer is null!\n");
		return;
	}
	ret += sprintf(&buffer[ret], "last irq times: [%6d] [%6d] ", debug_infos.rx_inband_irq_cnt, debug_infos.rx_gpio_irq_cnt);
	for (j = 0; j < CHN_IRQ_RECORD_NUM; j++) {
		ts = debug_infos.last_irq_times[j];
		rem_nsec = do_div(ts, 1000000000);
		ret += sprintf(&buffer[ret], "[%5lu.%06lu] ", (unsigned long)ts, rem_nsec / 1000);
	}
	if (skw_sdio->irq_type == SKW_SDIO_INBAND_IRQ) {
		ret += sprintf(&buffer[ret], "\nlast clear irq times:    [%6d] ", debug_infos.rx_inband_irq_cnt);
		for (j = 0; j < CHN_IRQ_RECORD_NUM; j++) {
			ts = debug_infos.last_clear_irq_times[j];
			rem_nsec = do_div(ts, 1000000000);
			ret += sprintf(&buffer[ret], "[%5lu.%06lu] ", (unsigned long)ts, rem_nsec / 1000);
		}
	}
	ret += sprintf(&buffer[ret], "\nlast rx read times:      [%6d] ", debug_infos.rx_read_cnt);
	for (j = 0; j < CHN_IRQ_RECORD_NUM; j++) {
		ts = debug_infos.last_rx_read_times[j];
		rem_nsec = do_div(ts, 1000000000);
		ret += sprintf(&buffer[ret], "[%5lu.%06lu] ", (unsigned long)ts, rem_nsec / 1000);
	}

	if (ret >= size)
		skw_sdio_info("ret bigger than size %d %d\n", ret, size);
}

void skw_get_sdio_debug_info(char *buffer, int size)
{
	int ret = 0;
	int i = 0;
	int j = 0;
	u64 ts;
	unsigned long rem_nsec;

	if (!buffer) {
		skw_sdio_info("buffer is null!\n");
		return;
	}

	ret += sprintf(&buffer[ret], "channel irq times:\n");
	for (i = 0; i < max_ch_num; i++) {
		ret += sprintf(&buffer[ret], "channel[%2d]: [%6d] ", i, debug_infos.chn_irq_cnt[i]);
		for (j = 0; j < CHN_IRQ_RECORD_NUM; j++) {
			ts = debug_infos.chn_last_irq_time[i][j];
			rem_nsec = do_div(ts, 1000000000);
			ret += sprintf(&buffer[ret], "[%5lu.%06lu] ", (unsigned long)ts, rem_nsec / 1000);
		}
		ret += sprintf(&buffer[ret], "\n");
	}
	ret += sprintf(&buffer[ret], "cmd_timeout_cnt: %d\n", debug_infos.cmd_timeout_cnt);
	ret += sprintf(&buffer[ret], "last_sent_wifi_cmd[0]: 0x%x\n", debug_infos.last_sent_wifi_cmd[0]);
	ret += sprintf(&buffer[ret], "last_sent_wifi_cmd[1]: 0x%x\n", debug_infos.last_sent_wifi_cmd[1]);
	ret += sprintf(&buffer[ret], "last_sent_wifi_cmd[2]: 0x%x\n", debug_infos.last_sent_wifi_cmd[2]);
	ts = debug_infos.last_sent_time;
	rem_nsec = do_div(ts, 1000000000);
	ret += sprintf(&buffer[ret], "last_sent_time: [%5lu.%06lu]\n", (unsigned long)ts, rem_nsec / 1000);
	ts = debug_infos.last_rx_submit_time;
	rem_nsec = do_div(ts, 1000000000);
	ret += sprintf(&buffer[ret], "last_rx_submit_time: [%5lu.%06lu]\n", (unsigned long)ts, rem_nsec / 1000);
	if (debug_infos.host_assert_cp_time) {
		ts = debug_infos.host_assert_cp_time;
		rem_nsec = do_div(ts, 1000000000);
		ret += sprintf(&buffer[ret], "host_assert_cp_time: [%5lu.%06lu]\n", (unsigned long)ts, rem_nsec / 1000);
	}
	if (debug_infos.cp_assert_time) {
		ts = debug_infos.cp_assert_time;
		rem_nsec = do_div(ts, 1000000000);
		ret += sprintf(&buffer[ret], "cp_assert_time: [%5lu.%06lu]\n", (unsigned long)ts, rem_nsec / 1000);
	}
	if (debug_infos.host_assert_cp_time > debug_infos.last_sent_time) {
		ts = debug_infos.host_assert_cp_time - debug_infos.last_sent_time;
		rem_nsec = do_div(ts, 1000000000);
		ret += sprintf(&buffer[ret], "timeout: [%5lu.%06lu]\n", (unsigned long)ts, rem_nsec / 1000);
	}

	if (ret >= size)
		skw_sdio_info("ret bigger than size %d %d\n", ret, size);
}

/********************************************************
 * skw_sdio_update img crc checksum
 * For update the CP IMG
 *Author: JUNWEI JIANG
 *Date:2022-08-11
 * *****************************************************/

void skw_get_port_statistic(char *buffer, int size)
{
		int ret = 0;
		int i;

		if (!buffer)
			return;

		for (i = 0; i < SDIO2_MAX_CH_NUM; i++)
		{
			if (ret >= size)
				break;

			if (sdio_ports[i].state)
				ret += sprintf(&buffer[ret], "port%d: rx %d %d, tx %d %d\n",
						i, sdio_ports[i].rx_count, sdio_ports[i].rx_packet,
						sdio_ports[i].total, sdio_ports[i].sent_packet);
		}
}

unsigned int crc_16_l_calc(char *buf_ptr, unsigned int len)
{
	unsigned int i;
	unsigned short crc = 0;

	while (len-- != 0)
	{
		for (i = CRC_16_L_SEED; i != 0; i = i >> 1)
		{
			if ((crc & CRC_16_L_POLYNOMIAL) != 0)
			{
				crc = crc << 1;
				crc = crc ^ CRC_16_POLYNOMIAL;
			} else {
				crc = crc << 1;
			}

			if ((*buf_ptr & i) != 0)
			{
				crc = crc ^ CRC_16_POLYNOMIAL;
			}
		}
		buf_ptr++;
	}
	return (crc);
}

static int skw_sdio_rx_port_follow_ctl(int portno, int rx_fctl)
{
	char ftl_val = 0;
	int ret = 0;

	skw_sdio_info(" portno:%d, rx_fctl:%d\n", portno, rx_fctl);

	if ((portno < 0) || (portno > max_ch_num))
		return -1;

	if (portno < 8) {
		ret = skw_sdio_readb(SKW_SDIO_RX_CHANNEL_FTL0, &ftl_val);
		if (ret)
			return -1;

		if (rx_fctl)
			ftl_val = ftl_val | (1 << portno);
		else
			ftl_val = ftl_val & (~(1 << portno));
		ret = skw_sdio_writeb(SKW_SDIO_RX_CHANNEL_FTL0, ftl_val);
	} else{
		portno = portno - 8;
		ret = skw_sdio_readb(SKW_SDIO_RX_CHANNEL_FTL1, &ftl_val);
		if (ret)
			return -1;

		if (rx_fctl)
			ftl_val = ftl_val | (1 << portno);
		else
			ftl_val = ftl_val & (~(1 << portno));
		ret = skw_sdio_writeb(SKW_SDIO_RX_CHANNEL_FTL1, ftl_val);
	}
	return ret;
}

void modem_register_notify(struct notifier_block *nb)
{
	blocking_notifier_chain_register(&modem_notifier_list, nb);
}

void modem_unregister_notify(struct notifier_block *nb)
{
	blocking_notifier_chain_unregister(&modem_notifier_list, nb);
}

void modem_notify_event(int event)
{
	blocking_notifier_call_chain(&modem_notifier_list, event, NULL);
}

void skw_sdio_exception_work(struct work_struct *work)
{
	int i = 0;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	skw_sdio_info(" entern...\n");
	mutex_lock(&skw_sdio->except_mutex);
	if (skw_sdio->cp_state != 1)
	{
		mutex_unlock(&skw_sdio->except_mutex);
		return;
	}
	skw_sdio->cp_state = DEVICE_BLOCKED_EVENT;
	mutex_unlock(&skw_sdio->except_mutex);
	if (!skw_sdio->host_state)
		modem_notify_event(DEVICE_BLOCKED_EVENT);

	for (i = 0; i < 5; i++)//BT PORT STATE  SETTING
	{
		if (!sdio_ports[i].state || sdio_ports[i].state == PORT_STATE_CLSE)
			continue;

		sdio_ports[i].state = PORT_STATE_ASST;
		complete(&sdio_ports[i].rx_done);

		if (i != 1)
			complete(&sdio_ports[i].tx_done);
		if (i <= 1)
			sdio_ports[i].next_seqno = 1;
	}
	if (!recovery_debug_status) {
		skw_sdio->service_state_map = 0;
		skw_recovery_mode();
	}
}

#if KERNEL_VERSION(4, 10, 0) <= LINUX_VERSION_CODE
static void *skw_sdio_alloc_frag(unsigned int fragsz, gfp_t gfp_mask)
{
	struct page_frag_cache *nc;
	unsigned long flags;
	void *data;

	local_irq_save(flags);
	nc = this_cpu_ptr(&skw_sdio_alloc_cache);
	data = page_frag_alloc(nc, fragsz, gfp_mask);
	local_irq_restore(flags);
	return data;
}
#elif KERNEL_VERSION(4, 5, 0) > LINUX_VERSION_CODE
static void *skw_sdio_alloc_frag(unsigned int fragsz, gfp_t gfp_mask)
{
	void *data;

	data = netdev_alloc_frag(fragsz);
	return data;
}

static void page_frag_free(void *data)
{
	put_page(virt_to_head_page(data));
}

#else
static void *skw_sdio_alloc_frag(unsigned int fragsz, gfp_t gfp_mask)
{
	struct page_frag_cache *nc;
	unsigned long flags;
	void *data;

	local_irq_save(flags);
	nc = this_cpu_ptr(&skw_sdio_alloc_cache);
	data = __alloc_page_frag(nc, fragsz, gfp_mask);
	local_irq_restore(flags);
	return data;
}

#define page_frag_free __free_page_frag
#endif

static void skw_sdio_rx_down(struct skw_sdio_data_t *skw_sdio)
{
	wait_for_completion_interruptible(&skw_sdio->rx_completed);
}

void skw_sdio_rx_up(struct skw_sdio_data_t *skw_sdio)
{
	skw_reinit_completion(skw_sdio->rx_completed);
	complete(&skw_sdio->rx_completed);
}

void skw_sdio_dispatch_packets(struct skw_sdio_data_t *skw_sdio)
{
	int i;
	struct sdio_port *port;

	for (i = 0; i < max_ch_num; i++) {
		port = &sdio_ports[i];
		if (!port->state)
			continue;
		if (port->rx_rp != port->rx_wp)
			skw_sdio_dbg("port[%d] sg_index=%d (%d,%d)\n", i,
				port->sg_index, port->rx_rp, port->rx_wp);
		if (port->rx_submit && port->sg_index) {
			debug_infos.last_rx_submit_time = skw_local_clock();
			port->rx_submit(port->channel, port->sg_rx, port->sg_index, port->rx_data);
			skw_sdio_dbg("port[%d] sg_index=%d (%d,%d)\n", i,
				port->sg_index, port->rx_rp, port->rx_wp);
			port->sg_index = 0;
		}
	}
}

static void skw_sdio_sdma_set_nsize(unsigned int size)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int count;

	if (size == 0) {
		skw_sdio->next_size = MAX_PAC_SIZE;
		return;
	}

	count = (size >> 10) + 9;
	size = SKW_SDIO_ALIGN_BLK(size + (count << 3));
	skw_sdio->next_size = (size > SDIO_BUFFER_SIZE) ? SDIO_BUFFER_SIZE : size;
}

static void skw_sdio_adma_set_packet_num(unsigned int num)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	if (num == 0)
		num = 1;

	if (num >= MAX_SG_COUNT)
		skw_sdio->remain_packet = MAX_SG_COUNT;
	else
		skw_sdio->remain_packet = num;
}

/************************************************************************
 *Decription:release debug recovery auto test
 *Author:junwei.jiang
 *Date:2023-05-30
 *Modfiy:
 *
 ********************************************************************* */
int skw_sdio_dumpmem(int dump)
{
	int dumpmem_status = dump;

	skw_sdio_info("the dump status =%d\n", dumpmem_status);
	if (dumpmem_status == 1) {
		skw_sdio_info("dump mem start\n");
		modem_notify_event(DEVICE_DUMPMEM_EVENT);
	} else if (dumpmem_status == 0) {
		skw_sdio_info("dump mem stop\n");
	}
	return 0;
}

/************************************************************************
 *Decription:dump mem file
 *Author:junwei.jiang
 *Date:2024-05-10
 *Modfiy:
 *
 ********************************************************************* */
int skw_sdio_recovery_debug(int disable)
{
	recovery_debug_status = disable;
	skw_sdio_info("the recovery status =%d\n", recovery_debug_status);
	return 0;
}

int skw_sdio_recovery_debug_status(void)
{
	skw_sdio_info("the recovery val =%d\n", recovery_debug_status);
	return recovery_debug_status;
}

static int skw_sdio_handle_packet(struct skw_sdio_data_t *skw_sdio,
		struct scatterlist *sg, struct skw_packet_header *header, int portno)
{
	struct sdio_port  *port;
	int buf_size, i;
	char *addr;
	u32 *data;

	if (portno >= max_ch_num)
		return -EINVAL;
	port = &sdio_ports[portno];
	port->rx_packet++;
	port->rx_count += header->len;
	if (portno == LOOPCHECK_PORT) {
		char *cmd = (char *)(header + 4);

		cmd[header->len - 12] = 0;
		skw_sdio_info("LOOPCHECK channel received: %s\n", (char *)cmd);
		if (header->len == 19 && !strncmp(cmd, "BTREADY", 7)) {
			skw_sdio->service_state_map |= 2;
			//kernel_restart(0);
			skw_sdio->device_active = 1;
			complete(&skw_sdio->download_done);
		} else if (header->len == 18 && !strncmp(cmd, "BTEXIT", 6)) {
			complete(&skw_sdio->download_done);
		} else if (header->len == 21 && !strncmp(cmd, "WIFIREADY", 9)) {
			skw_sdio->service_state_map |= 1;
			//kernel_restart(0);
			skw_sdio->device_active = 1;
			complete(&skw_sdio->download_done);
		} else if (!strncmp((char *)cmd, "BSPASSERT", 9)) {
			debug_infos.cp_assert_time = skw_local_clock();
			if (!skw_sdio->cp_state)
				schedule_delayed_work(&skw_sdio->skw_except_work, msecs_to_jiffies(12000));

			mutex_lock(&skw_sdio->except_mutex);
			if (skw_sdio->cp_state == DEVICE_BLOCKED_EVENT) {
				if (skw_sdio->adma_rx_enable)
					page_frag_free(header);

				mutex_unlock(&skw_sdio->except_mutex);
				return 0;
			}
			skw_sdio->cp_state = 1;/*cp except set value*/
			mutex_unlock(&skw_sdio->except_mutex);
			skw_sdio->service_state_map = 0;
			memset(assert_context, 0, 1024);
			assert_context_size = 0;
			modem_notify_event(DEVICE_ASSERT_EVENT);
			skw_sdio_err(" bsp assert !!!\n");
		} else if (header->len == 20 && !strncmp(cmd, "DUMPDONE", 8)) {
			mutex_lock(&skw_sdio->except_mutex);
			if (skw_sdio->cp_state == DEVICE_BLOCKED_EVENT) {
				if (skw_sdio->adma_rx_enable)
					page_frag_free(header);

				mutex_unlock(&skw_sdio->except_mutex);
				return 0;
			}
			skw_sdio->cp_state = DEVICE_DUMPDONE_EVENT;/*cp except set value 2*/
			mutex_unlock(&skw_sdio->except_mutex);
			cancel_delayed_work_sync(&skw_sdio->skw_except_work);
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
			modem_notify_event(DEVICE_DUMPDONE_EVENT);
#else
			if (!strncmp((char *)skw_sdio->chip_id, "SV6160", 6) && !recovery_debug_status) {
				modem_notify_event(DEVICE_DUMPDONE_EVENT);
			}
#endif
			skw_sdio_err("The CP DUMPDONE OK :\n %d::%s\n", assert_context_size, assert_context);
			for (i = 0; i < 5; i++) {
				if (!sdio_ports[i].state || sdio_ports[i].state == PORT_STATE_CLSE)
					continue;

				sdio_ports[i].state = PORT_STATE_ASST;
				complete(&sdio_ports[i].rx_done);
				if (i != 1)
					complete(&sdio_ports[i].tx_done);
				if (i <= 1)
					sdio_ports[i].next_seqno = 1;
			}
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
			skw_recovery_mode();//recoverymode open api
#else
			if (!strncmp((char *)skw_sdio->chip_id, "SV6160", 6) && skw_sdio->cp_state != DEVICE_BLOCKED_EVENT) {
				skw_recovery_mode();//recoverymode open api
			}
#endif
		} else if (!strncmp("trunk_W", cmd, 7)) {
			memset(firmware_version, 0, sizeof(firmware_version));
			strncpy(firmware_version, cmd, strlen(cmd));
			cmd = strstr(firmware_version, "slp=");
			if (cmd)
				cp_detect_sleep_mode = cmd[4] - 0x30;
			else
				cp_detect_sleep_mode = 4;

			if (!skw_sdio->sdio_bootdata->first_dl_flag) {
				skw_sdio_gpio_irq_pre_ops();
			}
			if (!skw_sdio->cp_state)
				complete(&skw_sdio->download_done);
			if (skw_sdio->cp_state) {
				assert_info_print = 0;
				if (sdio_ports[0].state == PORT_STATE_ASST)
					sdio_ports[0].state = PORT_STATE_OPEN;
				modem_notify_event(DEVICE_BSPREADY_EVENT);
			}
			skw_sdio->host_state = 0;
			skw_sdio->cp_state = 0;
			wake_up(&skw_sdio->wq);
		} else if (!strncmp(cmd, "BSPREADY", 8)) {
			loopcheck_send_data("RDVERSION", 9);
		}
		skw_sdio_dbg("Line:%d the port=%d\n", __LINE__, port->channel);
		if (skw_sdio->adma_rx_enable)
			page_frag_free(header);
		return 0;
	}
	if (!port->state) {
		if (skw_sdio->adma_rx_enable) {
			if (!IS_LOG_PORT(portno))
				skw_sdio_err("port%d discard data for wrong state\n", portno);
			page_frag_free(header);
			return 0;
		}
	}
	if (port->sg_rx && port->rx_data) {
		if (port->sg_index >= MAX_SG_COUNT) {
			skw_sdio_err(" rx sg_buffer is overflow!\n");
		} else {
			sg_set_buf(&port->sg_rx[port->sg_index++], header, header->len + 4);
		}
	} else {
		mutex_lock(&port->rx_mutex);
		buf_size = (port->length + port->rx_wp - port->rx_rp) % port->length;
		buf_size = port->length - 1 - buf_size;
		addr = (char *)(header + 1);
		data = (u32 *)addr;
		if (((data[2] & 0xffff) != port->next_seqno) && port->channel > 1 &&
			(header->len > 12) && !IS_LOG_PORT(portno)) {
			skw_sdio_err("portno:%d, packet lost recv seqno=%d expected %d\n", port->channel,
					data[2] & 0xffff, port->next_seqno);
			if (skw_sdio->adma_rx_enable)
				page_frag_free(header);
			mutex_unlock(&port->rx_mutex);
			return 0;
		}
		if (header->len > 12) {
			int packet = 0, total = 0;
			port->next_seqno++;
			addr += 12;
			header->len -= 12;
			total = data[1] >> 8;
			packet = data[2] & 0xFFFF;
		} else if (header->len == 12) {
			header->len = 0;
			port->tx_flow_ctrl--;
			complete(&port->tx_done);
			skw_port_log(portno, "%s link msg: 0x%x 0x%x port%d: %d\n", __func__,
					data[0], data[1], portno, port->tx_flow_ctrl);
		}
		if (skw_sdio->cp_state) {
			if (header->len != 245 || buf_size < 2048) {
				if (assert_info_print++ < 28 && strncmp((const char *)addr, "+LOG", 4)) {
					if (assert_context_size + header->len < sizeof(assert_context)) {
						memcpy(assert_context + assert_context_size, addr, header->len);
						assert_context_size += header->len;
					}
				}
			}
			if (buf_size < 2048)
				msleep(10);
		}
		if (port->rx_submit && !port->sg_rx) {
			if (header->len)
				port->rx_submit(portno, port->rx_data, header->len, addr);
		} else if (buf_size < header->len) {
			skw_port_log(portno, "%s port%d overflow:buf_size %d-%d, packet size %d (w,r)=(%d, %d)\n",
					__func__, portno, buf_size, port->length, header->len,
					port->rx_wp,  port->rx_rp);
		} else if (port->state && header->len) {
			if (port->length - port->rx_wp > header->len) {
				memcpy(&port->read_buffer[port->rx_wp], addr, header->len);
				port->rx_wp += header->len;
			} else {
				memcpy(&port->read_buffer[port->rx_wp], addr, port->length - port->rx_wp);
				memcpy(&port->read_buffer[0], &addr[port->length - port->rx_wp],
						header->len - port->length + port->rx_wp);
				port->rx_wp = header->len - port->length + port->rx_wp;
			}

			if (!port->rx_flow_ctrl && buf_size - header->len < (port->length / 3)) {
				port->rx_flow_ctrl = 1;
				skw_sdio_rx_port_follow_ctl(portno, port->rx_flow_ctrl);
			}
			mutex_unlock(&port->rx_mutex);
			complete(&port->rx_done);
			if (skw_sdio->adma_rx_enable)
				page_frag_free(header);
			return 0;
		}
		mutex_unlock(&port->rx_mutex);
		if (skw_sdio->adma_rx_enable)
			page_frag_free(header);
	}
	return 0;
}

static int skw_sdio2_handle_packet(struct skw_sdio_data_t *skw_sdio,
		struct scatterlist *sg, struct skw_packet2_header *header, int portno)
{
	struct sdio_port  *port;
	int buf_size, i;
	char *addr;
	u32 *data;

	if (portno >= max_ch_num)
		return -EINVAL;
	port = &sdio_ports[portno];
	port->rx_packet++;
	port->rx_count += header->len;
	if (portno == SDIO2_LOOPCHECK_PORT) {
		char *cmd = (char *)(header + 4);

		cmd[header->len - 12] = 0;
		skw_sdio_info("LOOPCHECK channel received: %s\n", (char *)cmd);
		if (header->len == 19 && !strncmp(cmd, "BTREADY", 7)) {
			skw_sdio->service_state_map |= 2;
			//kernel_restart(0);
			skw_sdio->device_active = 1;
			complete(&skw_sdio->download_done);
		} else if (header->len == 21 && !strncmp(cmd, "WIFIREADY", 9)) {
			skw_sdio->service_state_map |= 1;
			//kernel_restart(0);
			skw_sdio->device_active = 1;
			complete(&skw_sdio->download_done);
		} else if (header->len == 21 && !strncmp((char *)cmd, "BSPASSERT", 9)) {
			debug_infos.cp_assert_time = skw_local_clock();
			if (!skw_sdio->cp_state)
				schedule_delayed_work(&skw_sdio->skw_except_work, msecs_to_jiffies(12000));

			mutex_lock(&skw_sdio->except_mutex);
			if (skw_sdio->cp_state == DEVICE_BLOCKED_EVENT) {
				if (skw_sdio->adma_rx_enable)
					page_frag_free(header);

				mutex_unlock(&skw_sdio->except_mutex);
				return 0;
			}
			skw_sdio->cp_state = 1;/*cp except set value*/
			mutex_unlock(&skw_sdio->except_mutex);
			skw_sdio->service_state_map = 0;
			memset(assert_context, 0, 1024);
			assert_context_size = 0;
			modem_notify_event(DEVICE_ASSERT_EVENT);
			skw_sdio_err(" bsp assert !!!\n");
		} else if (header->len == 20 && !strncmp(cmd, "DUMPDONE", 8)) {
			mutex_lock(&skw_sdio->except_mutex);
			if (skw_sdio->cp_state == DEVICE_BLOCKED_EVENT) {
				if (skw_sdio->adma_rx_enable)
					page_frag_free(header);

				mutex_unlock(&skw_sdio->except_mutex);
				return 0;
			}
			skw_sdio->cp_state = DEVICE_DUMPDONE_EVENT;/*cp except set value 2*/
			mutex_unlock(&skw_sdio->except_mutex);
			cancel_delayed_work_sync(&skw_sdio->skw_except_work);
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
			modem_notify_event(DEVICE_DUMPDONE_EVENT);
#endif
			skw_sdio_err("The CP DUMPDONE OK :\n %d::%s\n", assert_context_size, assert_context);
			for (i = 0; i < 5; i++) {
				if (!sdio_ports[i].state || sdio_ports[i].state == PORT_STATE_CLSE)
					continue;

				sdio_ports[i].state = PORT_STATE_ASST;
				complete(&sdio_ports[i].rx_done);
				if (i != 1)
					complete(&sdio_ports[i].tx_done);
				if (i == 1)
					sdio_ports[i].next_seqno = 1;
			}
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
			skw_recovery_mode();//recoverymode open api
#endif

		} else if (!strncmp("trunk_W", cmd, 7)) {
			if (skw_sdio->cp_state) {
				if (sdio_ports[0].state == PORT_STATE_ASST)
					sdio_ports[0].state = PORT_STATE_OPEN;
				modem_notify_event(DEVICE_BSPREADY_EVENT);
			}

			skw_sdio->cp_state = 0;
			assert_info_print = 0;
			memset(firmware_version, 0, sizeof(firmware_version));
			strncpy(firmware_version, cmd, strlen(cmd));
			skw_sdio_info("firmware version: %s:%s\n", cmd, firmware_version);
		} else if (!strncmp(cmd, "BSPREADY", 8)) {
			loopcheck_send_data("RDVERSION", 9);
		}
		skw_sdio_info("Line:%d the port=%d\n", __LINE__, port->channel);
		if (skw_sdio->adma_rx_enable)
			page_frag_free(header);
		return 0;
	}
	if (!port->state) {
		if (skw_sdio->adma_rx_enable) {
			if (!IS_LOG_PORT(portno))
				skw_sdio_err("port%d discard data for wrong state\n", portno);
			page_frag_free(header);
			return 0;
		}
	}
	if (port->sg_rx) {
		if (port->sg_index >= MAX_SG_COUNT) {
			skw_sdio_err(" rx sg_buffer is overflow!\n");
		} else {
			sg_set_buf(&port->sg_rx[port->sg_index++], header, header->len + 4);
		}
	} else {
		mutex_lock(&port->rx_mutex);
		buf_size = (port->length + port->rx_wp - port->rx_rp) % port->length;
		buf_size = port->length - 1 - buf_size;
		addr = (char *)(header + 1);
		data = (u32 *)addr;
		if (((data[2] & 0xffff) != port->next_seqno) && header->len > 12) {
			skw_sdio_err("portno:%d, packet lost recv seqno=%d expected %d\n", port->channel,
					data[2] & 0xffff, port->next_seqno);
			if (skw_sdio->adma_rx_enable)
				page_frag_free(header);
			mutex_unlock(&port->rx_mutex);
			return 0;
		}
		if (header->len > 12) {
			int packet = 0, total = 0;
			port->next_seqno++;
			addr += 12;
			header->len -= 12;
			total = data[1] >> 8;
			packet = data[2] & 0xFFFF;
		} else if (header->len == 12) {
			header->len = 0;
			port->tx_flow_ctrl--;
			skw_port_log(portno, "%s link msg: 0x%x 0x%x 0x%x: %d\n", __func__,
					data[0], data[1], data[2], port->tx_flow_ctrl);
			complete(&port->tx_done);
		}
		if (skw_sdio->cp_state) {
			if (header->len != 245 || buf_size < 2048)
			skw_sdio_info("%s(%d.%d) (%d,%d) len=%d : 0x%x\n", __func__,
					   portno, port->next_seqno, port->rx_wp,  port->rx_rp, header->len, data[3]);
			if (buf_size < 2048)
				msleep(10);
		}
		if (buf_size < header->len) {
			skw_port_log(portno, "%s port%d overflow:buf_size %d-%d, packet size %d (w,r)=(%d, %d)\n",
					__func__, portno, buf_size, port->length, header->len,
					port->rx_wp,  port->rx_rp);
		} else if (port->state && header->len) {
			if (port->length - port->rx_wp > header->len) {
				memcpy(&port->read_buffer[port->rx_wp], addr, header->len);
				port->rx_wp += header->len;
			} else {
				memcpy(&port->read_buffer[port->rx_wp], addr, port->length - port->rx_wp);
				memcpy(&port->read_buffer[0], &addr[port->length - port->rx_wp],
						header->len - port->length + port->rx_wp);
				port->rx_wp = header->len - port->length + port->rx_wp;
			}

			if (!port->rx_flow_ctrl && buf_size - header->len < (port->length / 3)) {
				port->rx_flow_ctrl = 1;
				skw_sdio_rx_port_follow_ctl(portno, port->rx_flow_ctrl);
			}
			mutex_unlock(&port->rx_mutex);
			complete(&port->rx_done);
			if (skw_sdio->adma_rx_enable)
				page_frag_free(header);
			return 0;
		}
		mutex_unlock(&port->rx_mutex);
		if (skw_sdio->adma_rx_enable)
			page_frag_free(header);
	}
	return 0;
}

int send_modem_assert_command(void)
{
	int ret = 0;
	u32 *cmd = debug_infos.last_sent_wifi_cmd;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	char *statistic = kzalloc(2048, GFP_KERNEL);

	if (skw_sdio->cp_state)
		return ret;

	skw_sdio->cp_state = 1;/*cp except set value*/
	ret = skw_sdio_writeb(SKW_AP2CP_IRQ_REG, BIT(4));
	if (ret != 0) {
		skw_sdio->host_state = 1;
		skw_sdio_err("the sdio host controller exception err= %d !!\n", ret);
	}
	debug_infos.host_assert_cp_time = skw_local_clock();
	skw_sdio_err("%s ret=%d cmd: 0x%x 0x%x 0x%x :%d-%d %ums-%ums\n", __func__,
			 ret, cmd[0], cmd[1], cmd[2], cp_fifo_status, fifo_ind, jiffies_to_msecs(debug_infos.last_sent_time), jiffies_to_msecs(debug_infos.host_assert_cp_time));
	skw_get_assert_print_info(statistic, 2048);
	skw_sdio_info("sdio last irqs information:\n%s\n", statistic);
	kfree(statistic);
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
	schedule_delayed_work(&skw_sdio->skw_except_work, msecs_to_jiffies(2000));
#else
	schedule_delayed_work(&skw_sdio->skw_except_work, msecs_to_jiffies(12000));
#endif
	return ret;
}

/* for adma */
static int skw_sdio_adma_parser(struct skw_sdio_data_t *skw_sdio, struct scatterlist *sgs,
				int packet_count)
{
	struct skw_packet_header *header = NULL;
	unsigned int i;
	int channel = 0;
	unsigned int parse_len = 0;
	u32 *data;
	struct sdio_port *port;

	port = &sdio_ports[0];
	for (i = 0; i < packet_count; i++) {
		header = (struct skw_packet_header *)sg_virt(sgs + i);
		data = (uint32_t *)header;
		if (atomic_read(&skw_sdio->suspending))
			skw_sdio_info("ch:%d len:%d 0x%x 0x%x\n", header->channel, header->len, data[2], data[3]);
		skw_port_log(header->channel, "%s[%d]:ch:%d len:0x%0x 0x%08X 0x%08X : 0x%08X 0x%08x 0x%08X\n", __func__,
			i,	header->channel, header->len, data[2], data[3], data[5], data[6], data[7]);
		channel = header->channel;

		if (!header->eof && (channel < max_ch_num) && header->len) {
			parse_len += header->len;
			data = (uint32_t *)(header + 1);
			if ((header->len > (MAX_PAC_SIZE - sizeof(struct skw_packet_header))) ||
				(header->len == 0)) {
				skw_sdio_err("%s invalid header[%d]len[%d]: 0x%x 0x%x\n",
						__func__,  header->channel, header->len, data[0], data[1]);
				page_frag_free(header);
				continue;
			}
			skw_sdio->rx_packer_cnt++;
			skw_sdio_handle_packet(skw_sdio, sgs + i, header, channel);
		} else {
#if 0
			skw_sdio_err("%s[%d]:ch:%d len:0x%0x 0x%08X 0x%08X : 0x%08X 0x%08x 0x%08X\n", __func__,
			i,	header->channel, header->len, data[2], data[3], data[5], data[6], data[7]);
			print_hex_dump(KERN_ERR, "PACKET ERR:", 0, 16, 1,
					header, 1792, 1);
			skw_sdio_err("%s PUB HAEAD ERROR: packet[%d/%d] channel=%d,size=%d eof=%d!!!",
					__func__, i, packet_count, channel, header->len, header->eof);
#endif
			page_frag_free(header);
			continue;
		}
	}
	if (debug_infos.last_irq_time && (channel > 0 && channel < max_ch_num)) {
		if (channel > SDIO2_MAX_CH_NUM)
			skw_sdio_err("line: %d channel number error %d %d\n", __LINE__, channel, SDIO2_MAX_CH_NUM);
		debug_infos.chn_last_irq_time[channel][debug_infos.chn_irq_cnt[channel] % CHN_IRQ_RECORD_NUM] = debug_infos.last_irq_time;
		debug_infos.chn_irq_cnt[channel]++;
	}
	atomic_set(&skw_sdio->suspending, 0);
	return 0;
}

static int skw_sdio2_adma_parser(struct skw_sdio_data_t *skw_sdio, struct scatterlist *sgs,
				int packet_count)
{
	struct skw_packet2_header *header = NULL;
	unsigned int i;
	int channel = 0;
	unsigned int parse_len = 0;
	u32 *data;
	struct sdio_port *port;

	port = &sdio_ports[0];
	for (i = 0; i < packet_count; i++) {
		header = (struct skw_packet2_header *)sg_virt(sgs + i);
		data = (uint32_t *)header;
		if (atomic_read(&skw_sdio->suspending))
			skw_sdio_info("ch:%d len:%d 0x%x 0x%x\n", header->channel, header->len, data[2], data[3]);
		skw_port_log(header->channel, "%s[%d]:ch:%d len:0x%0x 0x%08X 0x%08X : 0x%08X 0x%08x 0x%08X\n", __func__,
			i,	header->channel, header->len, data[2], data[3], data[5], data[6], data[7]);
		channel = header->channel;

		if (!header->eof && (channel < max_ch_num) && header->len) {
			parse_len += header->len;
			data = (uint32_t *)(header + 1);
			if ((header->len > (MAX_PAC_SIZE - sizeof(struct skw_packet2_header))) ||
				(header->len == 0)) {
				skw_sdio_err("%s invalid header[%d]len[%d]: 0x%x 0x%x\n",
						__func__,  header->channel, header->len, data[0], data[1]);
				page_frag_free(header);
				continue;
			}
			skw_sdio->rx_packer_cnt++;
			skw_sdio2_handle_packet(skw_sdio, sgs + i, header, channel);
		} else {
			skw_sdio_err("%s[%d]:ch:%d len:0x%0x 0x%08X 0x%08X : 0x%08X 0x%08x 0x%08X\n", __func__,
			i,	header->channel, header->len, data[2], data[3], data[5], data[6], data[7]);
			page_frag_free(header);
			continue;
		}
	}
	if (debug_infos.last_irq_time && (channel > 0 && channel < max_ch_num)) {
		if (channel > SDIO2_MAX_CH_NUM)
			skw_sdio_err("line: %d channel number error %d %d\n", __LINE__, channel, SDIO2_MAX_CH_NUM);
		debug_infos.chn_last_irq_time[channel][debug_infos.chn_irq_cnt[channel] % CHN_IRQ_RECORD_NUM] = debug_infos.last_irq_time;
		debug_infos.chn_irq_cnt[channel]++;
	}
	atomic_set(&skw_sdio->suspending, 0);
	return 0;
}

/* for normal dma */
static int skw_sdio_sdma_parser(char *data_buf, int total)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct skw_packet_header *header = NULL;
	int channel = 0;
	u32 *data;
	unsigned char *p = NULL;
	unsigned int parse_len = 0;
	int current_len = 0;
#if 0
	print_hex_dump(KERN_ERR, "skw_rx_buf:", 0, 16, 1,
			data_buf, total, 1);
#endif
	header = (struct skw_packet_header *)data_buf;
	for (parse_len = 0; parse_len < total;) {
		if (header->eof != 0)
			break;
		p = (unsigned char *)header;
		data = (uint32_t *)header;
		if (atomic_read(&skw_sdio->suspending))
			skw_sdio_info("ch:%d len:%d 0x%x 0x%x\n", header->channel, header->len, data[2], data[3]);
		skw_port_log(header->channel, "%s:ch:%d len:0x%0x 0x%08X 0x%08X : 0x%08X 0x%08x 0x%08X\n", __func__,
				header->channel, header->len, data[1], data[2], data[3], data[4], data[5]);
		channel = header->channel;
		current_len = header->len;
		parse_len += current_len;
		if ((channel >= max_ch_num) || (current_len == 0) ||
			(current_len > (MAX_PAC_SIZE - sizeof(struct skw_packet_header)))) {
			skw_sdio_err("%s skip [%d]len[%d]\n", __func__, header->channel, current_len);
			break;
		}
		skw_sdio->rx_packer_cnt++;
		skw_sdio_handle_packet(skw_sdio, NULL, header, channel);
		skw_port_log(header->channel, "the -header->len----%d\n", current_len);
		/* pointer to next packet header*/
		p += sizeof(struct skw_packet_header) + SKW_SDIO_ALIGN_4BYTE(current_len);
		header = (struct skw_packet_header *)p;
	}
	if (debug_infos.last_irq_time && (channel > 0 && channel < max_ch_num)) {
		if (channel > SDIO2_MAX_CH_NUM)
			skw_sdio_err("line: %d channel number error %d %d\n", __LINE__, channel, SDIO2_MAX_CH_NUM);
		debug_infos.chn_last_irq_time[channel][debug_infos.chn_irq_cnt[channel] % CHN_IRQ_RECORD_NUM] = debug_infos.last_irq_time;
		debug_infos.chn_irq_cnt[channel]++;
	}
	atomic_set(&skw_sdio->suspending, 0);
	return 0;
}

static int skw_sdio2_sdma_parser(char *data_buf, int total)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct skw_packet2_header *header = NULL;
	int channel = 0;
	u32 *data;
	unsigned char *p = NULL;
	unsigned int parse_len = 0;
	int current_len = 0;
#if 0
	print_hex_dump(KERN_ERR, "skw_rx_buf:", 0, 16, 1,
			data_buf, total, 1);
#endif
	header = (struct skw_packet2_header *)data_buf;
	for (parse_len = 0; parse_len < total;) {
		if (header->eof != 0)
			break;
		p = (unsigned char *)header;
		data = (uint32_t *)header;
		if (atomic_read(&skw_sdio->suspending))
			skw_sdio_info("ch:%d len:%d 0x%x 0x%x\n", header->channel, header->len, data[2], data[3]);
		skw_port_log(header->channel, "ch:%d len:0x%0x 0x%08X 0x%08X : 0x%08X 0x%08x 0x%08X\n",
				header->channel, header->len, data[1], data[2], data[3], data[4], data[5]);
		channel = header->channel;
		current_len = header->len;
		parse_len += current_len;
		if ((channel >= max_ch_num) || (current_len == 0) ||
			(current_len > (MAX_PAC_SIZE - sizeof(struct skw_packet2_header)))) {
			skw_sdio_err("%s skip [%d]len[%d]\n", __func__, header->channel, current_len);
			break;
		}
		skw_sdio->rx_packer_cnt++;
		skw_sdio2_handle_packet(skw_sdio, NULL, header, channel);
		skw_port_log(header->channel, "the -header->len----%d\n", current_len);
		/* pointer to next packet header*/
		p += sizeof(struct skw_packet2_header) + SKW_SDIO_ALIGN_4BYTE(current_len);
		header = (struct skw_packet2_header *)p;
	}
	if (debug_infos.last_irq_time && (channel > 0 && channel < max_ch_num)) {
		if (channel > SDIO2_MAX_CH_NUM)
			skw_sdio_err("line: %d channel number error %d %d\n", __LINE__, channel, SDIO2_MAX_CH_NUM);
		debug_infos.chn_last_irq_time[channel][debug_infos.chn_irq_cnt[channel] % CHN_IRQ_RECORD_NUM] = debug_infos.last_irq_time;
		debug_infos.chn_irq_cnt[channel]++;
	}
	atomic_set(&skw_sdio->suspending, 0);
	return 0;
}

struct scatterlist *skw_sdio_prepare_adma_buffer(struct skw_sdio_data_t *skw_sdio, int *sg_count, int *nsize_offset)
{
	struct scatterlist *sgs;
	void   *buffer;
	int	i, j, data_size;
	int	alloc_size = PAGE_SIZE;

	sgs = kzalloc((*sg_count) * sizeof(struct scatterlist), GFP_KERNEL);

	if (!sgs)
		return NULL;

	for (i = 0; i < (*sg_count) - 1; i++) {
		buffer = skw_sdio_alloc_frag(alloc_size, GFP_ATOMIC);
		if (buffer)
			sg_set_buf(&sgs[i], buffer, MAX_PAC_SIZE);
		else {
			*sg_count = i + 1;
			break;
		}
	}

	if (i <= 0)
		goto err;

	sg_mark_end(&sgs[*sg_count - 1]);
	data_size = MAX_PAC_SIZE * ((*sg_count) - 1);
	data_size = data_size % SKW_SDIO_NSIZE_BUF_SIZE;
	*nsize_offset = SKW_SDIO_NSIZE_BUF_SIZE - data_size;
	if (*nsize_offset < 8)
		*nsize_offset = SKW_SDIO_NSIZE_BUF_SIZE + *nsize_offset;
	*nsize_offset = *nsize_offset + SKW_SDIO_NSIZE_BUF_SIZE;
	sg_set_buf(sgs + i, skw_sdio->next_size_buf, *nsize_offset);
	return sgs;
err:
	skw_sdio_err("%s failed\n", __func__);
	for (j = 0; j < i; j++)
		page_frag_free(sg_virt(sgs + j));
	kfree(sgs);
	return NULL;
}

int skw_sdio_rx_thread(void *p)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int read_len, buf_num;
	int ret = 0;
	unsigned int rx_nsize = 0;
	unsigned int valid_len = 0;
	char *rx_buf;
	struct scatterlist *sgs = NULL;
	char fifo_ind_local;
	char reg = 0;

	skw_sdio_sdma_set_nsize(0);
	skw_sdio_adma_set_packet_num(1);
	cp_fifo_status = 0;
	while (1) {
		/* Wait the semaphore */
		skw_sdio_rx_down(skw_sdio);
		if (!debug_infos.cp_assert_time) {
			debug_infos.last_rx_read_times[debug_infos.rx_read_cnt % CHN_IRQ_RECORD_NUM] = skw_local_clock();
			debug_infos.rx_read_cnt++;
		}
		if (skw_sdio->threads_exit) {
			skw_sdio_err("line %d threads exit\n", __LINE__);
			break;
		}
		if (!SKW_CARD_ONLINE(skw_sdio)) {
			skw_sdio_unlock_rx_ws(skw_sdio);
			skw_sdio_err("line %d not have card\n", __LINE__);
			continue;
		}
		skw_resume_check();
		if (skw_sdio->irq_type == SKW_SDIO_EXTERNAL_IRQ) {
			int value = gpio_get_value(skw_sdio->gpio_in);

			if (value == 0) {
				ret = skw_sdio_readb(SKW_SDIO_CP2AP_FIFO_IND, &fifo_ind_local);
				if (ret) {
					skw_sdio_err("line %d sdio cmd52 read fail ret:%d\n", __LINE__, ret);
					skw_sdio_unlock_rx_ws(skw_sdio);
					continue;
				}
			}
			ret = skw_sdio_readb(SKW_SDIO_CP2AP_FIFO_IND, &fifo_ind_local);
			if (ret) {
				skw_sdio_err("line %d sdio cmd52 read fail ret:%d\n", __LINE__, ret);
				skw_sdio_unlock_rx_ws(skw_sdio);
				continue;
			}
			skw_sdio_dbg("line:%d cp fifo status(%d,%d) ret=%d\n",
					__LINE__, fifo_ind_local, cp_fifo_status, ret);
			if (!ret && !fifo_ind_local)
				skw_sdio_dbg("cp fifo ret -- %d\n", ret);
			if (fifo_ind_local == cp_fifo_status) {
				skw_sdio_info("line:%d cp fifo status(%d,%d) ret=%d\n",
						__LINE__, fifo_ind_local, cp_fifo_status, ret);
				skw_sdio_unlock_rx_ws(skw_sdio);
				continue;
			}
		}
		cp_fifo_status = fifo_ind_local;
receive_again:
		if (skw_sdio->adma_rx_enable) {
			int	nsize_offset;

			buf_num = skw_sdio->remain_packet;
			if (buf_num > MAX_PAC_COUNT)
				buf_num = MAX_PAC_COUNT;

			buf_num = buf_num + 1;
			sgs = skw_sdio_prepare_adma_buffer(skw_sdio, &buf_num, &nsize_offset);
			buf_num = buf_num - 1;
			if (!sgs) {
				skw_sdio_err("prepare adma buffer fail\n");
				goto submit_packets;
			}
			if (skw_sdio->power_off) {
				skw_sdio_err("line %d device power off\n", __LINE__);
				rx_nsize = 0;
				ret = -EIO;
			} else {
				ret = skw_sdio_adma_read(skw_sdio, sgs, buf_num + 1,
					buf_num * MAX_PAC_SIZE + nsize_offset);
			}
			if (ret) {
				skw_sdio_err("%d adma read fail ret:%d\n", __LINE__, ret);
				if (ret == -ETIMEDOUT && !skw_sdio->power_off) {
					try_to_wakeup_modem(8);
					ret = skw_sdio_adma_read(skw_sdio, sgs, buf_num + 1,
							buf_num * MAX_PAC_SIZE + nsize_offset);
				}
				if (ret) {
					skw_sdio_err("%d adma read fail ret:%d\n", __LINE__, ret);
					rx_nsize = 0;
					kfree(sgs);
					goto submit_packets;
				}
			}
			rx_nsize =  *((uint32_t *)(skw_sdio->next_size_buf + (nsize_offset - 4)));
			if (SKW_SDIO_INBAND_IRQ == skw_sdio->irq_type && rx_nsize == 0) {
	 ret = skw_sdio_readb(SDIO_INT_EXT, &reg);
	 if (ret < 0) {
	     skw_sdio_err("line %d sdio readb error ret=%d\n", __LINE__, ret);
	 } else {
	     skw_sdio_dbg("line %d SDIO_INT_EXT=0x%x\n", __LINE__, reg);
	     }
			}
			valid_len = *((uint32_t *)(skw_sdio->next_size_buf + (nsize_offset - 8)));
			skw_sdio_dbg("line:%d total:%lld next_pac:%d:, valid len:%d cnt %d\n",
					  __LINE__, skw_sdio->rx_packer_cnt, rx_nsize, valid_len, buf_num);

			if (skw_cp_ver == SKW_SDIO_V10) {
				skw_sdio_adma_parser(skw_sdio, sgs, buf_num);
			} else{
				skw_sdio2_adma_parser(skw_sdio, sgs, buf_num);
			}
			kfree(sgs);
		} else {
			unsigned int alloc_size;

			read_len = skw_sdio->next_size;
			alloc_size = SKW_SDIO_ALIGN_BLK(read_len);
			rx_buf = kzalloc(alloc_size, GFP_KERNEL);
			if (!rx_buf) {
				skw_sdio_err("line %d kzalloc fail\n", __LINE__);
				goto submit_packets;
			}
			ret = skw_sdio_sdma_read(rx_buf, alloc_size);
#if 0
			print_hex_dump(KERN_ERR, "src_sdma_data:", 0, 16, 1,
					rx_buf, alloc_size, 1);
#endif
			if (ret != 0) {
				skw_sdio_err("line %d sdma read fail ret:%d\n", __LINE__, ret);
				rx_nsize = 0;
				goto submit_packets;
			}
			rx_nsize = *((uint32_t *)(rx_buf + (alloc_size - 4)));
	if (SKW_SDIO_INBAND_IRQ == skw_sdio->irq_type && rx_nsize == 0) {
	 ret = skw_sdio_readb(SDIO_INT_EXT, &reg);
	 if (ret < 0) {
	     skw_sdio_err("line %d sdio readb error ret=%d\n", __LINE__, ret);
	 } else {
	     skw_sdio_dbg("line %d SDIO_INT_EXT=0x%x\n", __LINE__, reg);
	     }
			}
			valid_len = *((uint32_t *)(rx_buf + (alloc_size - 8)));

			skw_sdio_dbg("%s the sdma rx thread alloc_size:%d,read_len:%d,rx_nsize:%d,valid_len:%d\n",
					__func__, alloc_size, read_len, rx_nsize, valid_len);
			if (skw_cp_ver == SKW_SDIO_V10) {
				skw_sdio_sdma_parser(rx_buf, valid_len);
			} else{
				skw_sdio2_sdma_parser(rx_buf, valid_len);
			}
			kfree(rx_buf);
		}
submit_packets:
		skw_sdio_dispatch_packets(skw_sdio);
		if (skw_sdio->adma_rx_enable)
			skw_sdio_adma_set_packet_num(rx_nsize);
		else
			skw_sdio_sdma_set_nsize(rx_nsize);
		if (skw_sdio->power_off)
			rx_nsize = 0;
		if (rx_nsize > 0)
			goto receive_again;

		debug_infos.last_irq_time = 0;
		skw_sdio_unlock_rx_ws(skw_sdio);
	}
	return 0;
}

static int open_sdio_port(int id, void *callback, void *data)
{
	struct sdio_port *port;

	if (id >= max_ch_num)
		return -EINVAL;

	port = &sdio_ports[id];
	if ((port->state == PORT_STATE_OPEN) || port->rx_submit)
		return -EBUSY;
	port->rx_submit = callback;
	port->rx_data = data;
	init_completion(&port->rx_done);
	init_completion(&port->tx_done);
	mutex_init(&port->rx_mutex);
	port->state = PORT_STATE_OPEN;
	port->tx_flow_ctrl = 0;
	port->rx_flow_ctrl = 0;
	if (id > 1) {
		port->next_seqno = 1; //cp start seqno default no 1
		port->rx_wp = port->rx_rp = 0;
	}
	skw_sdio_info("%s(%d) %s portno = %d\n", current->comm, current->pid, __func__, id);
	return 0;
}

static int close_sdio_port(int id)
{
	struct sdio_port *port;

	if (id >= max_ch_num)
		return -EINVAL;
	port = &sdio_ports[id];
	skw_sdio_info("%s(state=%d) portno = %d\n", current->comm, port->state, id);
	if (!port->state)
		return -ENODEV;
	port->state = PORT_STATE_CLSE;
	port->rx_submit = NULL;
	complete(&port->rx_done);
	return 0;
}

void send_host_suspend_indication(struct skw_sdio_data_t *skw_sdio)
{
	u32 value = 0;
	u32 timeout = 2000, timeout1 = 20;

	if (skw_sdio->gpio_out >= 0 && skw_sdio->resume_com) {
		skw_sdio_dbg("%s enter gpio=0\n", __func__);
		skw_sdio->host_active = 0;
		if (gpio_get_value(skw_sdio->gpio_in) == 0) {
			udelay(10);
			if (gpio_get_value(skw_sdio->gpio_in) == 0) {
				disable_irq(skw_sdio->irq_num);
				gpio_set_value(skw_sdio->gpio_out, 0);
				do {
					value = gpio_get_value(skw_sdio->gpio_in);
					if (value || timeout1 == 0) {
						skw_sdio_info("%s cp sts:%d in %d ms\n", __func__, value, 20 - timeout1);
						enable_irq(skw_sdio->irq_num);
						goto next;
					}
					mdelay(1);
				} while (timeout1--);
			}
		}
		gpio_set_value(skw_sdio->gpio_out, 0);
next:
		skw_sdio->device_active = 0;
		do {
			value = gpio_get_value(skw_sdio->gpio_in);
			if (value == 0)
				break;
			udelay(10);
		} while (timeout--);
	} else
		skw_sdio_dbg("%s enter\n", __func__);
}

void send_host_resume_indication(struct skw_sdio_data_t *skw_sdio)
{
	if (skw_sdio->gpio_out >= 0) {
		skw_sdio->host_active = 1;
		gpio_set_value(skw_sdio->gpio_out, 1);
		skw_sdio->resume_com = 1;
	}
}

static void send_cp_wakeup_signal(struct skw_sdio_data_t *skw_sdio)
{
	if (skw_sdio->gpio_out < 0)
		return;

	gpio_set_value(skw_sdio->gpio_out, 0);
	udelay(5);
	gpio_set_value(skw_sdio->gpio_out, 1);
}

extern int skw_sdio_enable_async_irq(void);
int try_to_wakeup_modem(int portno)
{
	int ret = 0;
	int val;
	unsigned long flags;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	ktime_t cur_time, last_time;

	if (skw_sdio->gpio_out < 0)
		return 0;
	skw_sdio->device_active = gpio_get_value(skw_sdio->gpio_in);

	if (skw_sdio->device_active)
		return 0;
	skw_reinit_completion(skw_sdio->device_wakeup);
	skw_sdio->tx_req_map |= 1 << portno;
	skw_port_log(portno, "%s enter device_active=%d : %d\n", __func__, skw_sdio->device_active, skw_sdio->resume_com);
	skw_sdio_dbg("%s portno====%d--- enter device_active=%d : %d\n", __func__, portno, skw_sdio->device_active, skw_sdio->resume_com);
	if (skw_sdio->device_active == 0) {
		local_irq_save(flags);
		if (skw_sdio->resume_com == 0)
			gpio_set_value(skw_sdio->gpio_out, 1);
		else
			send_cp_wakeup_signal(skw_sdio);
		local_irq_restore(flags);
		cur_time = ktime_get();
		skw_sdio_info("line %d cur_time =  %llu\n", __LINE__, cur_time);
		ret = wait_for_completion_interruptible_timeout(&skw_sdio->device_wakeup, HZ / 100);
		if (ret < 0) {
			skw_sdio->tx_req_map &= ~(1 << portno);
			return -ETIMEDOUT;
		}
	}
	val = gpio_get_value(skw_sdio->gpio_in);
	if (!val) {
		local_irq_save(flags);
		send_cp_wakeup_signal(skw_sdio);
		local_irq_restore(flags);
		last_time = ktime_get();
		skw_sdio_info(" line %d last_time =  %llu\n", __LINE__, last_time);
		ret = wait_for_completion_interruptible_timeout(&skw_sdio->device_wakeup, HZ / 100);
		if (ret < 0) {
			skw_sdio->tx_req_map &= ~(1 << portno);
			return -ETIMEDOUT;
		}
		val = gpio_get_value(skw_sdio->gpio_in);
	}
	if (val && !skw_sdio->sdio_func[FUNC_1]->irq_handler &&
		!skw_sdio->resume_com && skw_sdio->irq_type == SKW_SDIO_INBAND_IRQ) {
		sdio_claim_host(skw_sdio->sdio_func[FUNC_1]);
		ret = skw_sdio_enable_async_irq();
		if (ret < 0)
			skw_sdio_err("enable sdio async irq fail ret = %d\n", ret);
		sdio_release_host(skw_sdio->sdio_func[FUNC_1]);
		skw_port_log(portno, "%s enable SDIO inband IRQ ret=%d\n", __func__, ret);
	}
	return ret;
}

void host_gpio_in_routine(int value)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int  device_active = skw_sdio->device_active;

	if (skw_sdio->gpio_out < 0)
		return;

	skw_sdio->device_active = value;
	skw_sdio_dbg("%s enter %d-%d, host tx=0x%x:%d\n", __func__, device_active,
			skw_sdio->device_active, skw_sdio->tx_req_map, skw_sdio->host_active);
	if (device_active  && !skw_sdio->device_active &&
	   skw_sdio->tx_req_map && skw_sdio->host_active) {
		send_cp_wakeup_signal(skw_sdio);
	}
	if (skw_sdio->device_active && atomic_read(&skw_sdio->resume_flag))
		complete(&skw_sdio->device_wakeup);
	if (skw_sdio->device_active) {
		if (skw_sdio->host_active == 0)
			skw_sdio->host_active = 1;
		gpio_set_value(skw_sdio->gpio_out, 1);
		skw_sdio->resume_com = 1;
	}
}

static int setup_sdio_packet(void *packet, u8 channel, char *msg, int size)
{
	struct skw_packet_header *header = NULL;
	u32 *data = packet;

	data[0] = 0;
	header = (struct skw_packet_header *)data;
	header->channel = channel;
	header->len = size;
	memcpy(data + 1, msg, size);
	data++;
	data[size >> 2] = 0;
	header = (struct skw_packet_header *)&data[size >> 2];
	header->eof = 1;
	size += 8;
	return size;
}

static int setup_sdio2_packet(void *packet, u8 channel, char *msg, int size)
{
	struct skw_packet2_header *header = NULL;
	u32 *data = packet;

	data[0] = 0;
	header = (struct skw_packet2_header *)data;
	header->channel = channel;
	header->len = size;
	memcpy(data + 1, msg, size);
	data++;
	data[size >> 2] = 0;
	header = (struct skw_packet2_header *)&data[size >> 2];
	header->eof = 1;
	size += 8;
	return size;
}

int loopcheck_send_data(char *buffer, int size)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_port *port;
	int ret, count;

	port = &sdio_ports[LOOPCHECK_PORT];
	count = (size + 3) & 0xFFFFFFFC;
	if (count + 8 < port->length) {
		if (skw_cp_ver == SKW_SDIO_V10) {
			count = setup_sdio_packet(port->write_buffer, port->channel, buffer, count);
		} else{
			count = setup_sdio2_packet(port->write_buffer, port->channel, buffer, count);
		}
		try_to_wakeup_modem(LOOPCHECK_PORT);
		ret = skw_sdio_sdma_write(port->write_buffer, count);
		if (!ret) {
			port->total += count;
			port->sent_packet++;
			ret = size;
		}
		skw_sdio->tx_req_map &= ~(1 << LOOPCHECK_PORT);
		return ret;
	}
	return -ENOMEM;
}

static int skw_sdio_suspend_send_data(int portno, char *buffer, int size)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_port *port;
	int ret, count, i;
	u32 *data = (u32 *)buffer;

	if (size == 0)
		return 0;
	if (portno >= max_ch_num)
		return -EINVAL;
	port = &sdio_ports[portno];
	if (!port->state || skw_sdio->cp_state)
		return -EIO;

	if (port->state == PORT_STATE_CLSE) {
		port->state = PORT_STATE_IDLE;
		return -EIO;
	}

	count = (size + 3) & 0xFFFFFFFC;
	if (count + 8 < port->length) {
		if (skw_cp_ver == SKW_SDIO_V10) {
			count = setup_sdio_packet(port->write_buffer, port->channel, buffer, count);
		} else{
			count = setup_sdio2_packet(port->write_buffer, port->channel, buffer, count);
		}
		skw_reinit_completion(port->tx_done);
		try_to_wakeup_modem(portno);

		if (skw_sdio->cp_state)
			return -EIO;

		ret = skw_sdio_sdma_write(port->write_buffer, count);
		if (!ret) {
			port->tx_flow_ctrl++;
			if (sdio_ports[portno].state != PORT_STATE_ASST) {
				ret = wait_for_completion_interruptible_timeout(&port->tx_done,
						msecs_to_jiffies(100));
				if (!ret && port->tx_flow_ctrl) {
					try_to_wakeup_modem(portno);
					port->tx_flow_ctrl--;
				}
			}
			port->total += count;
			port->sent_packet++;
			ret = size;
		} else {
			skw_sdio_info("%s ret=%d\n", __func__, ret);
		}
		skw_sdio->tx_req_map &= ~(1 << portno);
		skw_port_log(portno, "%s port%d size=%d 0x%x 0x%x\n",
			__func__, portno, size, data[0], data[1]);
		return ret;
	} else {
		for (i = 0; i < 2; i++) {
			try_to_wakeup_modem(portno);
			ret = skw_sdio_sdma_write(buffer, count);
			if (!ret) {
				port->total += count;
				port->sent_packet++;
				ret = size;
				break;
			} else {
				skw_sdio_info("%s ret=%d\n", __func__, ret);
				if (ret == -ETIMEDOUT && !skw_sdio->device_active)
					continue;
			}
		}
		skw_sdio->tx_req_map &= ~(1 << portno);
		skw_port_log(portno, "%s port%d size=%d 0x%x 0x%x\n",
			__func__, portno, size, data[0], data[1]);
		return ret;
	}
	return -ENOMEM;
}

static int send_data(int portno, char *buffer, int size)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_port *port;
	int ret, count, i;
	u32 *data = (u32 *)buffer;

	if (size == 0)
		return 0;
	if (portno >= max_ch_num)
		return -EINVAL;
	port = &sdio_ports[portno];
	if (!port->state || skw_sdio->cp_state)
		return -EIO;

	if (port->state == PORT_STATE_CLSE) {
		port->state = PORT_STATE_IDLE;
		return -EIO;
	}

	count = (size + 3) & 0xFFFFFFFC;
	if (count + 8 < port->length) {
		if (skw_cp_ver == SKW_SDIO_V10) {
			count = setup_sdio_packet(port->write_buffer, port->channel, buffer, count);
		} else{
			count = setup_sdio2_packet(port->write_buffer, port->channel, buffer, count);
		}
		skw_reinit_completion(port->tx_done);
		try_to_wakeup_modem(portno);

		if (skw_sdio->cp_state)
			return -EIO;

		ret = skw_sdio_sdma_write(port->write_buffer, count);
		if (!ret) {
			port->tx_flow_ctrl++;
			if (sdio_ports[portno].state != PORT_STATE_ASST) {
				ret = wait_for_completion_interruptible_timeout(&port->tx_done,
						msecs_to_jiffies(100));
				if (!ret && port->tx_flow_ctrl) {
					try_to_wakeup_modem(portno);
					port->tx_flow_ctrl--;
				}
			}
			port->total += count;
			port->sent_packet++;
			ret = size;
		} else {
			skw_sdio_info("%s ret=%d\n", __func__, ret);
		}
		skw_sdio->tx_req_map &= ~(1 << portno);
		skw_port_log(portno, "%s port%d size=%d 0x%x 0x%x\n",
			__func__, portno, size, data[0], data[1]);
		return ret;
	} else {
		for (i = 0; i < 2; i++) {
			try_to_wakeup_modem(portno);
			ret = skw_sdio_sdma_write(buffer, count);
			if (!ret) {
				port->total += count;
				port->sent_packet++;
				ret = size;
				break;
			} else {
				skw_sdio_info("%s ret=%d\n", __func__, ret);
				if (ret == -ETIMEDOUT && !skw_sdio->device_active)
					continue;
			}
		}
		skw_sdio->tx_req_map &= ~(1 << portno);
		skw_port_log(portno, "%s port%d size=%d 0x%x 0x%x\n",
			__func__, portno, size, data[0], data[1]);
		return ret;
	}
	return -ENOMEM;
}

static int sdio_read(struct sdio_port *port, char *buffer, int size)
{
	int data_size;
	int	ret = 0;
	int buffer_size;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	skw_sdio_dbg("%s buffer size = %d , (wp, rp) = (%d, %d), state %d\n",
			__func__, size, port->rx_wp, port->rx_rp, port->state);
	if (port->state == PORT_STATE_ASST) {
		skw_sdio_err("Line:%d The CP assert  portno =%d error code =%d cp_state=%d !!\n", __LINE__,
				port->channel, ENOTCONN, skw_sdio->cp_state);
		if (skw_sdio->cp_state != 0) {
			if (port->channel == 1)
					port->state = PORT_STATE_OPEN;
			return -ENOTCONN;
		}
	}
try_again0:
	skw_reinit_completion(port->rx_done);
	if (port->rx_wp == port->rx_rp) {
		if ((port->state == PORT_STATE_CLSE) ||
			(port->channel > 1 && !(skw_sdio->service_state_map & (1 << BT_SERVICE)))) {
			skw_sdio_err("the portno %d the state %d\n", port->channel, port->state);
			return -EIO;
		}
		ret = wait_for_completion_interruptible(&port->rx_done);
		if (ret)
			return ret;
		if (port->state == PORT_STATE_CLSE) {
			port->state = PORT_STATE_IDLE;
			return -EAGAIN;
		} else if (port->state == PORT_STATE_ASST) {
			skw_sdio_err("The CP assert  portno =%d error code =%d!!!!\n", port->channel, ENOTCONN);
			if (skw_sdio->cp_state != 0) {
				if (port->channel == 1)
					port->state = PORT_STATE_OPEN;
				return -ENOTCONN;
			}
		}
	}
	mutex_lock(&port->rx_mutex);
	data_size = (port->length + port->rx_wp - port->rx_rp) % port->length;
	if (data_size == 0) {
		skw_sdio_info("%s buffer size = %d , (wp, rp) = (%d, %d)\n",
			__func__, size, port->rx_wp, port->rx_rp);
		mutex_unlock(&port->rx_mutex);
		goto try_again0;
	}
	if (size > data_size)
		size = data_size;
	data_size = port->length - port->rx_rp;
	if (size > data_size) {
		memcpy(buffer, &port->read_buffer[port->rx_rp], data_size);
		memcpy(buffer + data_size, &port->read_buffer[0], size - data_size);
		port->rx_rp = size - data_size;
	} else {
		skw_sdio_dbg("size1 = %d , (wp, rp) = (%d, %d) (packet, total)=(%d, %d)\n",
				size, port->rx_wp, port->rx_rp, port->rx_packet, port->rx_count);
		memcpy(buffer, &port->read_buffer[port->rx_rp], size);
		port->rx_rp += size;
	}

	if (port->rx_rp == port->length)
		port->rx_rp = 0;

	if (port->rx_rp == port->rx_wp) {
		port->rx_rp = 0;
		port->rx_wp = 0;
	}
	if (port->rx_flow_ctrl) {
		buffer_size = (port->length + port->rx_wp - port->rx_rp) % port->length;
		buffer_size = port->length - 1 - buffer_size;

		if (buffer_size > (port->length * 2 / 3)) {
			port->rx_flow_ctrl = 0;
			skw_sdio_rx_port_follow_ctl(port->channel, port->rx_flow_ctrl);
		}
	}
	mutex_unlock(&port->rx_mutex);
	return size;
}

int recv_data(int portno, char *buffer, int size)
{
	struct sdio_port *port;
	int ret;

	if (size == 0)
		return 0;
	if (portno >= max_ch_num)
		return -EINVAL;
	port = &sdio_ports[portno];
	if (!port->state)
		return -EIO;
	if (port->state == PORT_STATE_CLSE) {
		port->state = PORT_STATE_IDLE;
		return -EIO;
	}
	ret = sdio_read(port, buffer, size);
	return ret;
}

int skw_sdio_suspend_adma_cmd(int portno, struct scatterlist *sg, int sg_num, int total)
{
	struct sdio_port *port;
	int ret, i;
	int irq_state = 0;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	u32 *data;

	if (total == 0)
		return 0;
	if (portno >= max_ch_num)
		return -EINVAL;
	port = &sdio_ports[portno];
	if (!port->state)
		return -EIO;
	data = (u32 *)sg_virt(sg);
	irq_state = skw_sdio_irq_ops(0);
	for (i = 0; i < 2; i++) {
		try_to_wakeup_modem(portno);
		ret = skw_sdio_adma_write(portno, sg, sg_num, total);
		if (!ret) {
			skw_sdio_info(" gpioin value=%d\n", gpio_get_value(skw_sdio->gpio_in));
			break;
		}
		if (skw_sdio->gpio_in >= 0)
			skw_sdio_info("timeout gpioin value=%d\n", gpio_get_value(skw_sdio->gpio_in));
	}
	if (!irq_state) {
		skw_sdio_irq_ops(1);
	}
	skw_sdio->tx_req_map &= ~(1 << portno);
	skw_port_log(portno, "%s port%d sg_num=%d total=%d 0x%x 0x%x\n",
			__func__, portno, sg_num, total, data[0], data[1]);
	if (portno == WIFI_CMD_PORT) {
		memcpy(debug_infos.last_sent_wifi_cmd, data, 12);
		debug_infos.last_sent_time = jiffies;
		if (skw_sdio->gpio_in >= 0 && !gpio_get_value(skw_sdio->gpio_in)) {
			skw_sdio_info("modem is sleep and wakeup it\n");
			try_to_wakeup_modem(portno);
		}
	}
	port->total += total;
	port->sent_packet += sg_num;
	return ret;
}

static int skw_sdio_irq_ops(int irq_enable)
{
	int ret =  -1;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
#if 0//def CONFIG_SKW_DL_TIME_STATS
	ktime_t cur_time, last_time;
#endif
	//struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	if (skw_sdio->gpio_in < 0) {
		skw_sdio_info("gpio_in < 0 no need the cls the irq ops !!\n");
		return ret;
	}
	skw_sdio_info("gpio_in num %d the value %d !!\n", skw_sdio->gpio_in, gpio_get_value(skw_sdio->gpio_in));
	if (irq_enable) {
		skw_sdio_info("enable irq\n");
		skw_sdio->suspend_wake_unlock_enable = 1;
		enable_irq(skw_sdio->irq_num);
		ret = 0;
		//enable_irq_wake(skw_sdio->irq_num);
		//last_time = ktime_get();
		//skw_sdio_info("line %d start time %llu and the over time %llu ,the usertime=%llu\n",__LINE__,
		//cur_time, last_time,(last_time-cur_time));
	} else {
		if (gpio_get_value(skw_sdio->gpio_in) == 0) {
			udelay(10);
			if (gpio_get_value(skw_sdio->gpio_in) == 0) {
				disable_irq(skw_sdio->irq_num);
				ret = 0;
#if 0//def CONFIG_SKW_DL_TIME_STATS
				cur_time = ktime_get();
#endif
				skw_sdio_info("disable irq\n");
			} else {
				skw_sdio_info("NO disable irq cp wake !the value %d !!\n", gpio_get_value(skw_sdio->gpio_in));
				ret = -2;
			}
		}
		//disable_irq_wake(skw_sdio->irq_num);
		//disable_irq(skw_sdio->irq_num);
	}

	return ret;
};

int wifi_send_cmd(int portno, struct scatterlist *sg, int sg_num, int total)
{
	struct sdio_port *port;
	int ret, i;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	u32 *data;

	if (total == 0)
		return 0;
	if (portno >= max_ch_num)
		return -EINVAL;
	port = &sdio_ports[portno];
	if (!port->state)
		return -EIO;
	data = (u32 *)sg_virt(sg);
	for (i = 0; i < 2; i++) {
		try_to_wakeup_modem(portno);
		ret = skw_sdio_adma_write(portno, sg, sg_num, total);
		if (!ret)
			break;

		if (skw_sdio->gpio_in >= 0)
			skw_sdio_info("timeout gpioin value=%d\n", gpio_get_value(skw_sdio->gpio_in));
	}
	skw_sdio->tx_req_map &= ~(1 << portno);
	skw_port_log(portno, "%s port%d sg_num=%d total=%d 0x%x 0x%x\n",
			__func__, portno, sg_num, total, data[0], data[1]);
	if (portno == WIFI_CMD_PORT) {
		memcpy(debug_infos.last_sent_wifi_cmd, data, 12);
		debug_infos.last_sent_time = skw_local_clock();
		if (skw_sdio->gpio_in >= 0 && !gpio_get_value(skw_sdio->gpio_in)) {
			skw_sdio_info("modem is sleep and wakeup it\n");
			try_to_wakeup_modem(portno);
		}
	}
	port->total += total;
	port->sent_packet += sg_num;
	return ret;
}

static int register_rx_callback(int id, void *func, void *para)
{
	struct sdio_port *port;

	if (id >= max_ch_num)
		return -EINVAL;
	port = &sdio_ports[id];
	if (port->state && func)
		return -EBUSY;
	port->rx_submit = func;
	port->rx_data = para;
	if (func) {
		port->sg_rx = kcalloc(MAX_SG_COUNT, sizeof(struct scatterlist), GFP_KERNEL);
		if (!port->sg_rx)
			return -ENOMEM;
		port->state = PORT_STATE_OPEN;
	} else {
		if (port->sg_rx) {
			kfree(port->sg_rx);
			port->sg_rx = NULL;
		}

		port->state = PORT_STATE_IDLE;
	}
	return 0;
}

static int wifi_get_credit(void)
{
	char val;
	int err;

	err = skw_sdio_readb(SDIOHAL_PD_DL_CP2AP_SIG4, &val);
	if (err)
		return err;
	return val;
}

static int wifi_store_credit_to_cp(unsigned char val)
{
	int err;

	err = skw_sdio_writeb(SKW_SDIO_CREDIT_TO_CP, val);

	return err;
}

void kick_rx_thread(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	debug_infos.cmd_timeout_cnt++;
	if (skw_sdio->gpio_out < 0) {
		skw_sdio_rx_up(skw_sdio);
	} else {
		skw_sdio->device_active = gpio_get_value(skw_sdio->gpio_in);
		if (skw_sdio->device_active) {
			skw_sdio_rx_up(skw_sdio);
		} else {
			try_to_wakeup_modem(LOOPCHECK_PORT);
		}
	}
}

struct sv6160_platform_data wifi_pdata = {
	.data_port =  WIFI_DATA_PORT,
	.cmd_port =  WIFI_CMD_PORT,
	.bus_type = SDIO_LINK | TX_ADMA | RX_ADMA | CP_DBG,
	.max_buffer_size = ((MAX_PAC_COUNT * MAX2_PAC_SIZE) / MAX_TX_PAC_SIZE) * MAX_TX_PAC_SIZE,
	.align_value = 256,
	.hw_adma_tx = wifi_send_cmd,
	.hw_sdma_tx = send_data,
	.callback_register = register_rx_callback,
	.modem_assert = send_modem_assert_command,
	.modem_register_notify = modem_register_notify,
	.modem_unregister_notify = modem_unregister_notify,
	.wifi_power_on = skw_sdio_wifi_power_on,
	.at_ops = {
		.port = 0,
		.open = open_sdio_port,
		.close = close_sdio_port,
		.read = recv_data,
		.write = send_data,
	},
	.wifi_get_credit = wifi_get_credit,
	.wifi_store_credit = wifi_store_credit_to_cp,
	.debug_info = assert_context,
	.rx_thread_wakeup = kick_rx_thread,
	.suspend_adma_cmd = skw_sdio_suspend_adma_cmd,
	.suspend_sdma_cmd  = skw_sdio_suspend_send_data,

};

struct sv6160_platform_data ucom_pdata = {
	.data_port = 2,
	.cmd_port  = 3,
	.audio_port = 4,
	.bus_type = SDIO_LINK,
	.max_buffer_size = 0x1000,
	.align_value = 4,
	.hw_sdma_rx = recv_data,
	.hw_sdma_tx = send_data,
	.open_port = open_sdio_port,
	.close_port = close_sdio_port,
	.modem_assert = send_modem_assert_command,
	.modem_register_notify = modem_register_notify,
	.modem_unregister_notify = modem_unregister_notify,
	.skw_dump_mem = skw_sdio_dt_read,
};

int skw_sdio_bind_platform_driver(struct sdio_func *func)
{
	struct platform_device *pdev;
	char	pdev_name[32];
	struct sdio_port *port;
	int ret = 0;

	memset(sdio_ports, 0, sizeof(struct sdio_port) * MAX_CH_NUM);
	sprintf(pdev_name, "skw_ucom");
/*
 *	creaete AT device
 */
	pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
	if (!pdev)
		return -ENOMEM;
	pdev->dev.parent = &func->dev;
	pdev->dev.dma_mask = &port_dmamask;
	pdev->dev.coherent_dma_mask = port_dmamask;
	ucom_pdata.port_name = "ATC";
	if (skw_cp_ver == SKW_SDIO_V10)
		ucom_pdata.data_port = 0;
	else
		ucom_pdata.data_port = SDIO2_BSP_ATC_PORT;
	ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));
	if (ret) {
		dev_err(&func->dev, "failed to add platform data\n");
		platform_device_put(pdev);
		return ret;
	}
	port = &sdio_ports[ucom_pdata.data_port];
	port->state = PORT_STATE_IDLE;
	port->next_seqno = 1;
	ret = platform_device_add(pdev);
	if (ret) {
		dev_err(&func->dev, "failt to register platform device\n");
		platform_device_put(pdev);
		return ret;
	}
	port->pdev = pdev;
	port->channel = ucom_pdata.data_port;
	port->length = SDIO_BUFFER_SIZE >> 2;
	port->read_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->read_buffer) {
		dev_err(&func->dev, "failed to allocate %s RX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}
	port->write_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->write_buffer) {
		dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}
/*
 *	creaete log device
 */
	pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
	if (!pdev)
		return -ENOMEM;
	pdev->dev.parent = &func->dev;
	pdev->dev.dma_mask = &port_dmamask;
	pdev->dev.coherent_dma_mask = port_dmamask;
	ucom_pdata.port_name = "LOG";
	if (skw_cp_ver == SKW_SDIO_V10)
		ucom_pdata.data_port = 1;
	else
		ucom_pdata.data_port = SDIO2_BSP_LOG_PORT;
	ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));
	if (ret) {
		dev_err(&func->dev, "failed to add %s device\n", ucom_pdata.port_name);
		platform_device_put(pdev);
		return ret;
	}
	port = &sdio_ports[ucom_pdata.data_port];
	port->state = PORT_STATE_IDLE;
	port->next_seqno = 1;
	ret = platform_device_add(pdev);
	if (ret) {
		dev_err(&func->dev, "failt to register platform device\n");
		platform_device_put(pdev);
		return ret;
	}

	port->pdev = pdev;
	port->channel = ucom_pdata.data_port;
	port->length = SDIO_BUFFER_SIZE >> 2;
	port->read_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->read_buffer) {
		dev_err(&func->dev, "failed to allocate %s RX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}
	port->write_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->write_buffer) {
		dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}
/*
 *	creaete LOOPCHECK device
 */
	pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
	if (!pdev)
		return -ENOMEM;
	pdev->dev.parent = &func->dev;
	pdev->dev.dma_mask = &port_dmamask;
	pdev->dev.coherent_dma_mask = port_dmamask;
	ucom_pdata.port_name = "LOOPCHECK";
	if (skw_cp_ver == SKW_SDIO_V10)
		ucom_pdata.data_port = 7;
	else
		ucom_pdata.data_port = SDIO2_LOOPCHECK_PORT;
	ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));
	if (ret) {
		dev_err(&func->dev, "failed to add platform data\n");
		platform_device_put(pdev);
		return ret;
	}
	port = &sdio_ports[ucom_pdata.data_port];
	port->state = PORT_STATE_IDLE;
	ret = platform_device_add(pdev);
	if (ret) {
		dev_err(&func->dev, "failt to register platform device\n");
		platform_device_put(pdev);
		return ret;
	}

	port->pdev = pdev;
	port->channel = ucom_pdata.data_port;
	port->length = SDIO_BUFFER_SIZE >> 2;
	port->read_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->read_buffer) {
		dev_err(&func->dev, "failed to allocate %s RX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}
	port->write_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->write_buffer) {
		dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}
	if (skw_cp_ver == SKW_SDIO_V20) {
	/*
	 *	create BSPUPDATE device
	 */
		pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
		if (!pdev)
			return -ENOMEM;
		pdev->dev.parent = &func->dev;
		pdev->dev.dma_mask = &port_dmamask;
		pdev->dev.coherent_dma_mask = port_dmamask;
		ucom_pdata.port_name = "BSPUPDATE";
		ucom_pdata.data_port = SDIO2_BSP_UPDATE_PORT;
		ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));
		if (ret) {
			dev_err(&func->dev, "failed to add platform data\n");
			platform_device_put(pdev);
			return ret;
		}
		port = &sdio_ports[ucom_pdata.data_port];
		port->state = PORT_STATE_IDLE;
		ret = platform_device_add(pdev);
		if (ret) {
			dev_err(&func->dev, "failt to register platform device\n");
			platform_device_put(pdev);
			return ret;
		}

		port->pdev = pdev;
		port->channel = ucom_pdata.data_port;
		port->length = SDIO_BUFFER_SIZE >> 2;
		port->read_buffer = kzalloc(port->length, GFP_KERNEL);
		if (!port->read_buffer) {
			dev_err(&func->dev, "failed to allocate %s RX buffer\n", ucom_pdata.port_name);
			return -ENOMEM;
		}
		port->write_buffer = kzalloc(port->length, GFP_KERNEL);
		if (!port->write_buffer) {
			dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
			return -ENOMEM;
		}
	}
	return ret;
}

int skw_sdio_bind_WIFI_driver(struct sdio_func *func)
{
	struct platform_device *pdev;
	char	pdev_name[32];
	struct sdio_port *port;
	int ret = 0;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	if (sdio_ports[WIFI_DATA_PORT].pdev)
		return 0;
	sprintf(pdev_name, "%s%d", SV6160_WIRELESS, func->num);
	pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
	if (!pdev)
		return -ENOMEM;
	pdev->dev.parent = &func->dev;
	pdev->dev.dma_mask = &port_dmamask;
	pdev->dev.coherent_dma_mask = port_dmamask;
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
	wifi_pdata.bus_type |= CP_RLS;
#else
	if (!strncmp((char *)skw_sdio->chip_id, "SV6160", 6)) {
		wifi_pdata.bus_type |= CP_RLS;
	}
#endif
	/*support the sdma type bus*/
	if (!skw_sdio->adma_rx_enable) {
		if (skw_cp_ver == SKW_SDIO_V10)
			wifi_pdata.bus_type = SDIO_LINK | TX_ADMA | RX_SDMA;
		else
			wifi_pdata.bus_type = SDIO2_LINK | TX_ADMA | RX_SDMA;
	} else{
		if (skw_cp_ver == SKW_SDIO_V10)
			wifi_pdata.bus_type = SDIO_LINK | TX_ADMA | RX_ADMA | CP_DBG;
		else
			wifi_pdata.bus_type = SDIO2_LINK | TX_ADMA | RX_ADMA | CP_DBG;
	}
	skw_sdio_info(" wifi_pdata bus_type:0x%x\n", wifi_pdata.bus_type);
	if (skw_cp_ver == SKW_SDIO_V20) {
		wifi_pdata.data_port = (SDIO2_WIFI_DATA1_PORT << 4) | SDIO2_WIFI_DATA_PORT;
		wifi_pdata.cmd_port = SDIO2_WIFI_CMD_PORT;
	}
	memcpy(wifi_pdata.chipid, skw_sdio->chip_id, SKW_CHIP_ID_LENGTH);
	ret = platform_device_add_data(pdev, &wifi_pdata, sizeof(wifi_pdata));
	if (ret < 0) {
		dev_err(&func->dev, "failed to add platform data  ret=%d\n", ret);
		platform_device_put(pdev);
		return ret;
	}
	if (skw_cp_ver == SKW_SDIO_V20) {
		port = &sdio_ports[(wifi_pdata.data_port >> 4) & 0x0F];
		port->pdev = pdev;
		port->channel = (wifi_pdata.data_port >> 4) & 0x0F;
		port->rx_wp = 0;
		port->rx_rp = 0;
		port->sg_index = 0;
		port->state = 0;
	}

	port = &sdio_ports[wifi_pdata.data_port & 0x0F];
	port->pdev = pdev;
	port->channel = wifi_pdata.data_port & 0x0F;
	port->rx_wp = 0;
	port->rx_rp = 0;
	port->sg_index = 0;
	port->state = 0;

	port = &sdio_ports[wifi_pdata.cmd_port];
	port->pdev = pdev;
	port->channel = wifi_pdata.cmd_port;
	port->rx_wp = 0;
	port->rx_rp = 0;
	port->sg_index = 0;
	port->state = 0;

	ret = platform_device_add(pdev);
	if (ret < 0) {
		dev_err(&func->dev, "failt to register platform device\n");
		platform_device_put(pdev);
	}
	return ret;
}

int skw_sdio_wifi_status(void)
{
	struct sdio_port *port = &sdio_ports[wifi_pdata.cmd_port];

	if (!port->pdev)
		return 0;
	return 1;
}

int skw_sdio_wifi_power_on(int power_on)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int ret;

	if (power_on) {
		if (skw_sdio->power_off)
			skw_recovery_mode();
		ret = skw_sdio_bind_WIFI_driver(skw_sdio->sdio_func[FUNC_1]);
	} else {
		ret = skw_sdio_unbind_WIFI_driver(skw_sdio->sdio_func[FUNC_1]);
	}
	return ret;
}

#ifdef CONFIG_BT_SEEKWAVE
int skw_sdio_bind_btseekwave_driver(struct sdio_func *func)
{
	struct platform_device *pdev;
	char	pdev_name[32];
	struct sdio_port *port;
	int ret = 0;

	sprintf(pdev_name, "btseekwave");
/*
 *	creaete BT DATA device
 */
	pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
	if (!pdev)
		return -ENOMEM;
	pdev->dev.parent = &func->dev;
	pdev->dev.dma_mask = &port_dmamask;
	pdev->dev.coherent_dma_mask = port_dmamask;
	ucom_pdata.data_port = 2;

	ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));
	if (ret) {
		dev_err(&func->dev, "failed to add platform data\n");
		platform_device_put(pdev);
		return ret;
	}
	port = &sdio_ports[ucom_pdata.data_port];
	port->state = PORT_STATE_IDLE;
	ret = platform_device_add(pdev);
	if (ret) {
		dev_err(&func->dev, "failt to register platform device\n");
		platform_device_put(pdev);
		return ret;
	}
	port->pdev = pdev;
	port->channel = ucom_pdata.data_port;
	port->length = SDIO_BUFFER_SIZE;
	port->write_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->write_buffer) {
		dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}

/*
 *	creaete BT COMMAND device
 */
	ucom_pdata.data_port = ucom_pdata.cmd_port;

	port = &sdio_ports[ucom_pdata.data_port];
	port->state = PORT_STATE_IDLE;
	port->pdev = NULL;
	port->channel = ucom_pdata.data_port;
	port->length = SDIO_BUFFER_SIZE;
	port->write_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->write_buffer) {
		dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}

/*
 *	creaete BT audio device
 */
	ucom_pdata.data_port = ucom_pdata.audio_port;
	port = &sdio_ports[ucom_pdata.data_port];
	port->state = PORT_STATE_IDLE;
	port->pdev = NULL;
	port->channel = ucom_pdata.data_port;
	port->length = SDIO_BUFFER_SIZE;
	port->write_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->write_buffer) {
		dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}

	return ret;
}
#else
int skw_sdio_bind_BT_driver(struct sdio_func *func)
{
	struct platform_device *pdev;
	char	pdev_name[32];
	struct sdio_port *port;
	int ret = 0;

	sprintf(pdev_name, "skw_ucom");
/*
 *	creaete BT DATA device
 */
	pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
	if (!pdev)
		return -ENOMEM;
	pdev->dev.parent = &func->dev;
	pdev->dev.dma_mask = &port_dmamask;
	pdev->dev.coherent_dma_mask = port_dmamask;
	ucom_pdata.port_name = "BTDATA";
	if (skw_cp_ver == SKW_SDIO_V20)
		ucom_pdata.data_port = 5;
	else
		ucom_pdata.data_port = 2;
	ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));
	if (ret) {
		dev_err(&func->dev, "failed to add platform data\n");
		platform_device_put(pdev);
		return ret;
	}
	port = &sdio_ports[ucom_pdata.data_port];
	port->state = PORT_STATE_IDLE;
	ret = platform_device_add(pdev);
	if (ret) {
		dev_err(&func->dev, "failt to register platform device\n");
		platform_device_put(pdev);
		return ret;
	}
	port->pdev = pdev;
	port->channel = ucom_pdata.data_port;
	port->length = SDIO_BUFFER_SIZE;
	port->read_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->read_buffer) {
		dev_err(&func->dev, "failed to allocate %s RX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}
	port->write_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->write_buffer) {
		dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}

/*
 *	creaete BT COMMAND device
 */
	pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
	if (!pdev)
		return -ENOMEM;
	pdev->dev.parent = &func->dev;
	pdev->dev.dma_mask = &port_dmamask;
	pdev->dev.coherent_dma_mask = port_dmamask;
	ucom_pdata.port_name = "BTCMD";
	if (skw_cp_ver == SKW_SDIO_V20)
		ucom_pdata.data_port = 2;
	else
		ucom_pdata.data_port = ucom_pdata.cmd_port;
	ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));
	if (ret) {
		dev_err(&func->dev, "failed to add %s device\n", ucom_pdata.port_name);
		platform_device_put(pdev);
		return ret;
	}
	port = &sdio_ports[ucom_pdata.data_port];
	port->state = PORT_STATE_IDLE;
	ret = platform_device_add(pdev);
	if (ret) {
		dev_err(&func->dev, "failt to register platform device\n");
		platform_device_put(pdev);
		return ret;
	}

	port->pdev = pdev;
	port->channel = ucom_pdata.data_port;
	port->length = SDIO_BUFFER_SIZE >> 2;
	port->read_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->read_buffer) {
		dev_err(&func->dev, "failed to allocate %s RX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}
	port->write_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->write_buffer) {
		dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}

/*
 *	creaete BT audio device
 */
	pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
	if (!pdev)
		return -ENOMEM;
	pdev->dev.parent = &func->dev;
	pdev->dev.dma_mask = &port_dmamask;
	pdev->dev.coherent_dma_mask = port_dmamask;
	ucom_pdata.port_name = "BTAUDIO";
	if (skw_cp_ver == SKW_SDIO_V20)
		ucom_pdata.data_port = 3;
	else
		ucom_pdata.data_port = ucom_pdata.audio_port;
	ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));
	if (ret) {
		dev_err(&func->dev, "failed to add platform data\n");
		platform_device_put(pdev);
		return ret;
	}
	port = &sdio_ports[ucom_pdata.data_port];
	port->state = PORT_STATE_IDLE;
	ret = platform_device_add(pdev);
	if (ret) {
		dev_err(&func->dev, "failt to register platform device\n");
		platform_device_put(pdev);
		return ret;
	}

	port->pdev = pdev;
	port->channel = ucom_pdata.data_port;
	port->length = SDIO_BUFFER_SIZE >> 2;
	port->read_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->read_buffer) {
		dev_err(&func->dev, "failed to allocate %s RX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}
	port->write_buffer = kzalloc(port->length, GFP_KERNEL);
	if (!port->write_buffer) {
		dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
		return -ENOMEM;
	}

	if (skw_cp_ver == SKW_SDIO_V20) {
		/*
		*	create BTISOC device
		*/
		pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
		if (!pdev)
			return -ENOMEM;
		pdev->dev.parent = &func->dev;
		pdev->dev.dma_mask = &port_dmamask;
		pdev->dev.coherent_dma_mask = port_dmamask;
		ucom_pdata.port_name = "BTISOC";
		ucom_pdata.data_port = SDIO2_BT_ISOC_PORT;
		ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));
		if (ret) {
			dev_err(&func->dev, "failed to add platform data\n");
			platform_device_put(pdev);
			return ret;
		}
		port = &sdio_ports[ucom_pdata.data_port];
		port->state = PORT_STATE_IDLE;
		ret = platform_device_add(pdev);
		if (ret) {
			dev_err(&func->dev, "failt to register platform device\n");
			platform_device_put(pdev);
			return ret;
		}

		port->pdev = pdev;
		port->channel = ucom_pdata.data_port;
		port->length = SDIO_BUFFER_SIZE >> 2;
		port->read_buffer = kzalloc(port->length, GFP_KERNEL);
		if (!port->read_buffer) {
			dev_err(&func->dev, "failed to allocate %s RX buffer\n", ucom_pdata.port_name);
			return -ENOMEM;
		}
		port->write_buffer = kzalloc(port->length, GFP_KERNEL);
		if (!port->write_buffer) {
			dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
			return -ENOMEM;
		}

		/*
		*	create BTLOG device
		*/
		pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
		if (!pdev)
			return -ENOMEM;
		pdev->dev.parent = &func->dev;
		pdev->dev.dma_mask = &port_dmamask;
		pdev->dev.coherent_dma_mask = port_dmamask;
		ucom_pdata.port_name = "BTLOG";
		ucom_pdata.data_port = SDIO2_BT_LOG_PORT;
		ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));
		if (ret) {
			dev_err(&func->dev, "failed to add platform data\n");
			platform_device_put(pdev);
			return ret;
		}
		port = &sdio_ports[ucom_pdata.data_port];
		port->state = PORT_STATE_IDLE;
		ret = platform_device_add(pdev);
		if (ret) {
			dev_err(&func->dev, "failt to register platform device\n");
			platform_device_put(pdev);
			return ret;
		}

		port->pdev = pdev;
		port->channel = ucom_pdata.data_port;
		port->length = SDIO_BUFFER_SIZE >> 2;
		port->read_buffer = kzalloc(port->length, GFP_KERNEL);
		if (!port->read_buffer) {
			dev_err(&func->dev, "failed to allocate %s RX buffer\n", ucom_pdata.port_name);
			return -ENOMEM;
		}
		port->write_buffer = kzalloc(port->length, GFP_KERNEL);
		if (!port->write_buffer) {
			dev_err(&func->dev, "failed to allocate %s TX buffer\n", ucom_pdata.port_name);
			return -ENOMEM;
		}
	}
	return ret;
}
#endif
static int skw_sdio_unbind_sdio_port_driver(struct sdio_func *func, int portno)
{
	int i;
	void *pdev;
	struct sdio_port *port;

	for (i = portno; i < max_ch_num;) {
		port = &sdio_ports[i];
		pdev = port->pdev;
		port->pdev = NULL;
		kfree(port->read_buffer);
		kfree(port->write_buffer);
		kfree(port->sg_rx);
		if (pdev)
			platform_device_unregister(pdev);
		port->sg_rx = NULL;
		port->read_buffer = NULL;
		port->write_buffer = NULL;
		port->pdev = NULL;
		port->rx_wp = 0;
		port->rx_rp = 0;
		port->sg_index = 0;
		port->state = 0;
		break;
	}
	return 0;
}

int skw_sdio_unbind_platform_driver(struct sdio_func *func)
{
	int ret;

	ret = skw_sdio_unbind_sdio_port_driver(func, 0);
	ret |= skw_sdio_unbind_sdio_port_driver(func, 1);
	ret |= skw_sdio_unbind_sdio_port_driver(func, 7);
	return ret;
}

int skw_sdio_unbind_WIFI_driver(struct sdio_func *func)
{
	int ret;

	if (skw_cp_ver == SKW_SDIO_V20)
		ret = skw_sdio_unbind_sdio_port_driver(func, SDIO2_WIFI_CMD_PORT);
	else
		ret = skw_sdio_unbind_sdio_port_driver(func, WIFI_DATA_PORT);
	return ret;
}

int skw_sdio_unbind_BT_driver(struct sdio_func *func)
{
	int ret;

	ret = skw_sdio_unbind_sdio_port_driver(func, 2);
	ret |= skw_sdio_unbind_sdio_port_driver(func, 3);
	ret |= skw_sdio_unbind_sdio_port_driver(func, 4);
	return ret;
}
===== ./drivers/seekwaveplatform/sdio/skw_sdio_main.c =====
/*
 * Copyright (C) 2021 Seekwave Tech Inc.
 *
 * Filename : skw_sdio.c
 * Abstract : This file is a implementation for Seekwave sdio  function
 *
 * Authors	:
 *
 * This software is licensed under the terms of the GNU General Public
 * License version 2, as published by the Free Software Foundation, and
 * may be copied, distributed, and modified under those terms.

 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 */

#include <linux/interrupt.h>
#include <linux/irq.h>
#include <linux/gpio.h>
#include <linux/kthread.h>
#include <linux/ktime.h>
#include <linux/module.h>
#include <linux/of_device.h>
#include <linux/of_gpio.h>
#include <linux/pm_runtime.h>
#include <linux/mmc/card.h>
#include <linux/mmc/core.h>
#include <linux/mmc/host.h>
#include <linux/mmc/sdio.h>
#include <linux/mmc/sdio_func.h>
#include "skw_sdio_log.h"
#include "skw_sdio_debugfs.h"
#include "skw_sdio.h"
//#include "skw_power_ctrl_config.h"
int bind_device = 0;

module_param(bind_device, int, 0444);
#ifndef MMC_CAP2_SDIO_IRQ_NOTHREAD
#define MMC_CAP2_SDIO_IRQ_NOTHREAD BIT(17)
#endif

#define skw_sdio_transfer_enter() mutex_lock(&skw_sdio->transfer_mutex)
#define skw_sdio_transfer_exit() mutex_unlock(&skw_sdio->transfer_mutex)

int g_irq_init;
static int cp_log_status;
irqreturn_t skw_gpio_irq_handler(int irq, void *dev_id); //interrupt
//int (*skw_dloader)(unsigned int subsys);
int skw_get_chipid(unsigned int address, void *buf, unsigned int len);
int check_chipid(void);
int skw_sdio_cp_reset(void);
int skw_sdio_cp_service_ops(int service_ops);
int skw_sdio_cpdebug_boot(void);
int skw_sdio_host_irq_init(unsigned int irq_gpio_num);
struct skw_sdio_data_t *g_skw_sdio_data;
static struct sdio_driver skw_sdio_driver;

static int skw_WIFI_service_start(void);
static int skw_WIFI_service_stop(void);
static int skw_BT_service_start(void);
static int skw_BT_service_stop(void);
extern int sdio_reset_comm(struct mmc_card *card);
extern void kernel_restart(char *cmd);
extern void skw_sdio_exception_work(struct work_struct *work);
int skw_sdio_gpio_irq_pre_ops(void);
extern char skw_cp_ver;
extern int max_ch_num;
extern char assert_context[];
extern int  assert_context_size;
extern int  cp_detect_sleep_mode;
extern struct debug_vars debug_infos;
static int skw_sdio_reg_reset(void);
static int skw_sdio_reg_reset_cp(void);
extern int extern_wifi_set_enable(int is_on);
extern void sdio_reinit(void);
extern void set_wifi_power(int ch);

struct skw_sdio_data_t *skw_sdio_get_data(void)
{
	return g_skw_sdio_data;
}

void skw_sdio_unlock_rx_ws(struct skw_sdio_data_t *skw_sdio)
{
	if (!atomic_read(&skw_sdio->rx_wakelocked))
		return;
	atomic_set(&skw_sdio->rx_wakelocked, 0);
#ifdef CONFIG_WAKELOCK
	__pm_relax(&skw_sdio->rx_wl.ws);
#else
	__pm_relax(skw_sdio->rx_ws);
#endif
}

static void skw_sdio_lock_rx_ws(struct skw_sdio_data_t *skw_sdio)
{
	if (atomic_read(&skw_sdio->rx_wakelocked))
		return;
	atomic_set(&skw_sdio->rx_wakelocked, 1);
#ifdef CONFIG_WAKELOCK
	__pm_stay_awake(&skw_sdio->rx_wl.ws);
#else
	__pm_stay_awake(skw_sdio->rx_ws);
#endif
}

static void skw_sdio_wakeup_source_init(struct skw_sdio_data_t *skw_sdio)
{
	if (skw_sdio) {
#ifdef CONFIG_WAKELOCK
	wake_lock_init(&skw_sdio->rx_wl, WAKE_LOCK_SUSPEND, "skw_sdio_r_wakelock");
#else
	skw_sdio->rx_ws = skw_wakeup_source_register(NULL, "skw_sdio_r_wakelock");
#endif
	}
}

static void skw_sdio_wakeup_source_destroy(struct skw_sdio_data_t *skw_sdio)
{
	if (skw_sdio) {
#ifdef CONFIG_WAKELOCK
	wake_lock_destroy(&skw_sdio->rx_wl);
#else
	wakeup_source_unregister(skw_sdio->rx_ws);
#endif
	}
}

void skw_resume_check(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	unsigned int timeout;

	timeout = 0;
	while ((!atomic_read(&skw_sdio->resume_flag)) && (timeout++ < 20000))
		usleep_range(1500, 2000);
}

static void skw_sdio_abort(int error_code)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func0 = skw_sdio->sdio_func[FUNC_0];
	unsigned char value;
	int ret;
	int err_code = error_code;

	if (err_code == EBUSY) {
		skw_sdio_err("EBUSY error code\n");
		schedule_delayed_work(&skw_sdio->skw_except_work, msecs_to_jiffies(3000));
	}

	sdio_claim_host(func0);

	value = sdio_readb(func0, SDIO_VER_CCCR, &ret);

	sdio_writeb(func0, SDIO_ABORT_TRANS, SKW_SDIO_CCCR_ABORT, &ret);

	value = sdio_readb(func0, SDIO_VER_CCCR, &ret);
	skw_sdio_err("SDIO Abort, SDIO_VER_CCCR:0x%x\n", value);

	sdio_release_host(func0);
}

int skw_sdio_sdma_write(unsigned char *src, unsigned int len)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func = skw_sdio->sdio_func[FUNC_1];
	int blksize = func->cur_blksize;
	int ret = 0;

	if (!src || len % 4) {
		skw_sdio_err("%s invalid para %p, %d\n", __func__, src, len);
		return -1;
	}

	len = (len + blksize - 1) / blksize * blksize;

	skw_resume_check();
	skw_sdio_transfer_enter();
	sdio_claim_host(func);
	ret = sdio_writesb(func, SKW_SDIO_PK_MODE_ADDR, src, len);
	if (ret < 0)
		skw_sdio_err("%s  ret = %d\n", __func__, ret);
	sdio_release_host(func);
	if (ret)
		skw_sdio_abort(ret);
	skw_sdio_transfer_exit();

	return ret;
}

int skw_sdio_sdma_read(unsigned char *src, unsigned int len)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func = skw_sdio->sdio_func[FUNC_1];
	int ret = 0;

	skw_resume_check();
	skw_sdio_transfer_enter();
	sdio_claim_host(func);
	ret = sdio_readsb(func, src, SKW_SDIO_PK_MODE_ADDR, len);
	sdio_release_host(func);
	if (ret != 0)
		skw_sdio_abort(ret);
	skw_sdio_transfer_exit();
	return ret;
}

void *skw_get_bus_dev(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int time_count = 0;

	if ((!skw_sdio->sdio_dev_host) || (!skw_sdio)) {
		skw_sdio_err("%d try again get sdio bus dev \n", __LINE__);
		do {
			msleep(10);
			time_count++;
		} while (!skw_sdio->sdio_dev_host && time_count < 50);
	}
	if ((!skw_sdio->sdio_dev_host) || (!skw_sdio)) {
		skw_sdio_err("sdio_dev_host is NULL!\n");
		return NULL;
	}
	return &skw_sdio->sdio_func[FUNC_1]->dev;
}
EXPORT_SYMBOL_GPL(skw_get_bus_dev);

int skw_sdio_gpio_irq_pre_ops(void)
{
	int ret = 0;
	struct sdio_func *func;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	if (!skw_sdio->sdio_bootdata)
		return -1;

	switch (cp_detect_sleep_mode) {
	case 0:
			skw_sdio_info("cp_detect_sleep_mode is 0\n");
		break;
		case 1:
		case 2:
			skw_sdio_info("cp_detect_sleep_mode is 1 or 2\n");
			func = skw_sdio->sdio_func[FUNC_1];
			sdio_claim_host(func);
			sdio_release_irq(func);
			sdio_release_host(func);
			skw_sdio->gpio_in = skw_sdio->sdio_bootdata->gpio_in;
			skw_sdio->gpio_out = skw_sdio->sdio_bootdata->gpio_out;
			ret = skw_sdio_host_irq_init(skw_sdio->gpio_in);
		break;
		case 3:
			skw_sdio_info("cp_detect_sleep_mode is 3\n");
			if (skw_sdio->sdio_bootdata->gpio_out < 0) {
				skw_sdio_err("gpio_out is invalid\n");
				return -1;
			}
			gpio_set_value(skw_sdio->sdio_bootdata->gpio_out, 0);
			msleep(100);
			loopcheck_send_data("APGPIORDY", 9);
			func = skw_sdio->sdio_func[FUNC_1];
			sdio_claim_host(func);
			sdio_release_irq(func);
			sdio_release_host(func);
			skw_sdio->gpio_in = skw_sdio->sdio_bootdata->gpio_in;
			skw_sdio->gpio_out = skw_sdio->sdio_bootdata->gpio_out;
			ret = skw_sdio_host_irq_init(skw_sdio->gpio_in);
		break;
		default:
			skw_sdio_info("cp_detect_sleep_mode is %d\n", cp_detect_sleep_mode);
		break;
	}
	if (ret)
		skw_sdio_err("gpio irq init fail\n");
	return ret;
}

static int skw_sdio_start_transfer(struct scatterlist *sgs, int sg_count,
	int total, struct sdio_func *sdio_func, uint fix_inc, bool dir, uint addr)
{
	struct mmc_request mmc_req;
	struct mmc_command mmc_cmd;
	struct mmc_data mmc_dat;
	struct mmc_host *host = sdio_func->card->host;
	bool fifo = (fix_inc == SKW_SDIO_DATA_FIX);
	uint fn_num = sdio_func->num;
	uint blk_num, blk_size, max_blk_count, max_req_size;
	int err_ret = 0;
	u64 write_time[2];

	blk_size = SKW_SDIO_BLK_SIZE;
	max_blk_count = min_t(unsigned int, host->max_blk_count, (uint)MAX_IO_RW_BLK);
	max_req_size = min_t(unsigned int, max_blk_count * blk_size, host->max_req_size);

	memset(&mmc_req, 0, sizeof(struct mmc_request));
	memset(&mmc_cmd, 0, sizeof(struct mmc_command));
	memset(&mmc_dat, 0, sizeof(struct mmc_data));

	if (total % blk_size != 0) {
		skw_sdio_err("total %d not aligned to blk size\n", total);
		return -1;
	}

	blk_num = total / blk_size;
	mmc_dat.sg = sgs;
	mmc_dat.sg_len = sg_count;
	mmc_dat.blksz = blk_size;
	mmc_dat.blocks = blk_num;
	mmc_dat.flags = dir ? MMC_DATA_WRITE : MMC_DATA_READ;
	mmc_cmd.opcode = 53; /* SD_IO_RW_EXTENDED */
	mmc_cmd.arg = dir ? 1 << 31 : 0;
	mmc_cmd.arg |= (fn_num & 0x7) << 28;
	mmc_cmd.arg |= 1 << 27;
	mmc_cmd.arg |= fifo ? 0 : 1 << 26;
	mmc_cmd.arg |= (addr & 0x1FFFF) << 9;
	mmc_cmd.arg |= blk_num & 0x1FF;
	mmc_cmd.flags = MMC_RSP_SPI_R5 | MMC_RSP_R5 | MMC_CMD_ADTC;
	mmc_req.cmd = &mmc_cmd;
	mmc_req.data = &mmc_dat;
	if (!fifo)
		addr += total;
	write_time[0] = jiffies;
	sdio_claim_host(sdio_func);
	mmc_set_data_timeout(&mmc_dat, sdio_func->card);
	write_time[1] = jiffies;
	mmc_wait_for_req(host, &mmc_req);
	skw_sdio_dbg("total:%d sg_count:%d cmd_arg 0x%x, 0x%x 0x%x 0x%x\n", total, sg_count, mmc_cmd.arg,
			(u32)write_time[0], (u32)write_time[1], (u32)jiffies);
	sdio_release_host(sdio_func);

	err_ret = mmc_cmd.error ? mmc_cmd.error : mmc_dat.error;
	if (err_ret != 0) {
		skw_sdio_err("%s:CMD53 %s failed error=%d\n", __func__,
				  dir ? "write" : "read", err_ret);
	}
	return err_ret;
}

int skw_sdio_adma_write(int portno, struct scatterlist *sgs, int sg_count, int total)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int ret = 0;

	skw_resume_check();
	skw_sdio_transfer_enter();
	if (skw_sdio->resume_com == 0)
		skw_sdio->resume_com = 1;
	ret = skw_sdio_start_transfer(sgs, sg_count, SKW_SDIO_ALIGN_BLK(total),
				  skw_sdio->sdio_func[FUNC_1], SKW_SDIO_DATA_FIX,
				  SKW_SDIO_WRITE, SKW_SDIO_PK_MODE_ADDR);
	if (ret) {
		skw_sdio_abort(ret);
	} else {
		if (skw_sdio->device_active == 0 && skw_sdio->irq_type)
			skw_sdio->device_active = gpio_get_value(skw_sdio->gpio_in);
	}
	skw_sdio_transfer_exit();

	return ret;
}

int skw_sdio_adma_read(struct skw_sdio_data_t *skw_sdio, struct scatterlist *sgs, int sg_count, int total)
{
	int ret = 0;

	skw_resume_check();
	skw_sdio_transfer_enter();
	ret = skw_sdio_start_transfer(sgs, sg_count, total,
				  skw_sdio->sdio_func[FUNC_1], SKW_SDIO_DATA_FIX,
				  SKW_SDIO_READ, SKW_SDIO_PK_MODE_ADDR);
	if (ret)
		skw_sdio_abort(ret);
	skw_sdio_transfer_exit();
	return ret;
}

static int skw_sdio_dt_set_address(unsigned int address)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func = skw_sdio->sdio_func[FUNC_0];
	unsigned char value;
	int err = 0;
	int i;

	sdio_claim_host(func);
	for (i = 0; i < 4; i++) {
		value = (address >> (8 * i)) & 0xFF;
		sdio_writeb(func, value, SKW_SDIO_FBR_REG + i, &err);
		if (err != 0)
			break;
	}
	sdio_release_host(func);

	return err;
}

int skw_sdio_writel(unsigned int address, void *data)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func = skw_sdio->sdio_func[FUNC_1];
	int ret = 0;

	skw_resume_check();
	skw_sdio_transfer_enter();

	ret = skw_sdio_dt_set_address(address);
	if (ret != 0) {
		skw_sdio_transfer_exit();
		return ret;
	}

	sdio_claim_host(func);
	sdio_writel(func, *(unsigned int *)data, SKW_SDIO_DT_MODE_ADDR, &ret);
	sdio_release_host(func);
	skw_sdio_transfer_exit();

	if (ret) {
		skw_sdio_err("%s fail ret:%d, addr=0x%x\n", __func__,
				ret, address);
		skw_sdio_abort(ret);
	}

	return ret;
}

int skw_sdio_readl(unsigned int address, void *data)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func = skw_sdio->sdio_func[FUNC_1];
	int ret = 0;

	skw_resume_check();
	skw_sdio_transfer_enter();
	ret = skw_sdio_dt_set_address(address);
	if (ret != 0) {
		skw_sdio_transfer_exit();
		return ret;
	}

	sdio_claim_host(func);

	*(unsigned int *)data = sdio_readl(func, SKW_SDIO_DT_MODE_ADDR, &ret);

	sdio_release_host(func);
	skw_sdio_transfer_exit();
	if (ret) {
		skw_sdio_err("%s fail ret:%d, addr=0x%x\n", __func__, ret, address);
		skw_sdio_abort(ret);
	}

	return ret;
}

/*
 *command = 0: service_start else service stop
 *service = 0: WIFI_service else BT service.
 */
int send_modem_service_command(u16 service, u16 command)
{
	u16 cmd;
	int ret = 0;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	if (command)
		skw_sdio->service_state_map &= ~(1 << service);
		//command = 1;
	cmd = (service << 1) | command;
	cmd = 1 << cmd;
	if (cmd >> 8) {
		skw_sdio_err("service command error 0x%x!", cmd);
			return -EINVAL;
	}
	if (skw_sdio->cp_state)
		return -EINVAL;

	ret = skw_sdio_writeb(SKW_AP2CP_IRQ_REG, cmd & 0xff);
	skw_sdio_info("ret = %d command %x\n", ret, command);
	return ret;
}

static unsigned int max_bytes(struct sdio_func *func)
{
	unsigned int mval = func->card->host->max_blk_size;

	if (func->card->quirks & MMC_QUIRK_BLKSZ_FOR_BYTE_MODE)
		mval = min(mval, func->cur_blksize);
	else
		mval = min(mval, func->max_blksize);

	if (func->card->quirks & MMC_QUIRK_BROKEN_BYTE_MODE_512)
		return min(mval, 511u);

	/* maximum size for byte mode */
	return min(mval, 512u);
}

int skw_sdio_dt_write(unsigned int address,	void *buf, unsigned int len)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func = skw_sdio->sdio_func[FUNC_1];
	unsigned int remainder = len;
	unsigned int trans_len;
	int ret = 0;
	char *data = skw_sdio->next_size_buf;

	skw_resume_check();
	skw_sdio_transfer_enter();

	ret = skw_sdio_dt_set_address(address);
	if (ret != 0) {
		skw_sdio_err("%s set address error!!!", __func__);
		skw_sdio_transfer_exit();
		return ret;
	}

	if (skw_sdio->resume_com == 0)
		skw_sdio->resume_com = 1;
	sdio_claim_host(func);
	while (remainder > 0) {
		if (remainder >= func->cur_blksize)
			trans_len = func->cur_blksize;
		else
			trans_len = min(remainder, max_bytes(func));

		memcpy(data, buf, trans_len);
		ret = sdio_memcpy_toio(func, SKW_SDIO_DT_MODE_ADDR, data, trans_len);
		if (ret) {
			skw_sdio_err("%s sdio_memcpy_toio failed!!!", __func__);
			break;
		}
		remainder -= trans_len;
		buf += trans_len;
	}
	sdio_release_host(func);
	skw_sdio_transfer_exit();
	if (ret) {
		skw_sdio_err("dt write fail ret:%d, address=0x%x\n", ret, address);
		skw_sdio_abort(ret);
	}

	return ret;
}

int skw_sdio_dt_read(unsigned int address, void *buf, unsigned int len)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func = skw_sdio->sdio_func[FUNC_1];
	unsigned int remainder = len;
	unsigned int trans_len;
	int ret = 0;

	ret = skw_sdio_dt_set_address(address);
	if (ret != 0) {
		skw_sdio_err("set address error ret=%d !!!", ret);
		return ret;
	}
	if (skw_sdio->resume_com == 0)
		skw_sdio->resume_com = 1;
	skw_sdio_transfer_enter();
	sdio_claim_host(func);
	while (remainder > 0) {
		if (remainder >= func->cur_blksize)
			trans_len = func->cur_blksize;
		else
			trans_len = min(remainder, max_bytes(func));
		ret = sdio_memcpy_fromio(func, buf, SKW_SDIO_DT_MODE_ADDR, trans_len);
		if (ret) {
			skw_sdio_err("sdio_memcpy_fromio: %p 0x%x ret=%d\n", buf, *(uint32_t *)buf, ret);
			break;
		}
		remainder -= trans_len;
		buf += trans_len;
	}
	sdio_release_host(func);
	skw_sdio_transfer_exit();
	if (ret) {
		skw_sdio_err("dt read fail ret:%d, address=0x%x\n", ret, address);
		skw_sdio_abort(ret);
	}

	return ret;
}

int skw_sdio_readb(unsigned int address, unsigned char *value)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func = skw_sdio->sdio_func[FUNC_0];
	unsigned char reg = 0;
	int err = 0;

	sdio_claim_host(func);
	reg = sdio_readb(func, address, &err);
	if (value)
		*value = reg;
	sdio_release_host(func);
	return err;
}

int skw_sdio_writeb(unsigned int address, unsigned char value)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func = skw_sdio->sdio_func[FUNC_0];
	int err = 0;

	try_to_wakeup_modem(8);
	sdio_claim_host(func);
	sdio_writeb(func, value, address, &err);
	sdio_release_host(func);

	return err;
}

int skw_sdio_host_irq_init(unsigned int irq_gpio_num)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int ret = 0;

	skw_sdio->irq_type = SKW_SDIO_EXTERNAL_IRQ;
	skw_sdio->device_active = gpio_get_value(skw_sdio->gpio_in);
	skw_sdio->irq_num = gpio_to_irq(skw_sdio->gpio_in);
	skw_sdio->irq_trigger_type = IRQF_TRIGGER_RISING;
	skw_sdio_info("gpio_In:%d,gpio_out:%d irq %d\n", skw_sdio->gpio_in,
		skw_sdio->gpio_out, skw_sdio->irq_num);
	if (skw_sdio->irq_num) {
		ret = request_irq(skw_sdio->irq_num, skw_gpio_irq_handler,
				skw_sdio->irq_trigger_type | IRQF_ONESHOT, "skw-gpio-irq", NULL);
		if (ret != 0) {
			free_irq(skw_sdio->irq_num, NULL);
			skw_sdio_err("%s request gpio irq fail ret=%d\n", __func__, ret);
			return -1;
		} else {
			skw_sdio_dbg("gpio request_irq=%d  GPIO value %d!\n",
					skw_sdio->irq_num, skw_sdio->device_active);
		}
	}
	enable_irq_wake(skw_sdio->irq_num);
	skw_sdio_rx_up(skw_sdio);
	return ret;
}

static int skw_sdio_get_dev_func(struct sdio_func *func)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	if (func->num >= MAX_FUNC_NUM) {
		skw_sdio_err("func num err!!! func num is %d!!!",
			func->num);
		return -1;
	}
	skw_sdio_dbg("func num is %d.", func->num);

	if (func->num == 1) {
		skw_sdio->sdio_func[FUNC_0] = kmemdup(func, sizeof(*func),
							 GFP_KERNEL);
		skw_sdio->sdio_func[FUNC_0]->num = 0;
		skw_sdio->sdio_func[FUNC_0]->max_blksize = SKW_SDIO_BLK_SIZE;
	}

	skw_sdio->sdio_func[FUNC_1] = func;

	return 0;
}

extern u64 skw_local_clock(void);
void skw_sdio_inband_irq_handler(struct sdio_func *func)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func0 = skw_sdio->sdio_func[FUNC_0];
	int ret;

	if (!debug_infos.cp_assert_time) {
		debug_infos.last_irq_time = skw_local_clock();
		debug_infos.last_irq_times[debug_infos.rx_inband_irq_cnt % CHN_IRQ_RECORD_NUM] = debug_infos.last_irq_time;
		skw_sdio_dbg("irq coming %d\n", debug_infos.rx_inband_irq_cnt);
	}
	if (!SKW_CARD_ONLINE(skw_sdio)) {
		skw_sdio_err("%s  card offline\n", __func__);
		return;
	}

	skw_resume_check();

	/* send cmd to clear cp int status */
	sdio_claim_host(func0);
	try_to_wakeup_modem(8);
	sdio_f0_readb(func0, SDIO_CCCR_INTx, &ret);
	if (!debug_infos.cp_assert_time) {
		debug_infos.last_clear_irq_times[debug_infos.rx_inband_irq_cnt % CHN_IRQ_RECORD_NUM] = debug_infos.last_irq_time;
		debug_infos.rx_inband_irq_cnt++;
	}
	sdio_release_host(func0);
	if (ret < 0)
		skw_sdio_err("%s error %d\n", __func__, ret);

	skw_sdio_lock_rx_ws(skw_sdio);
	skw_sdio_rx_up(skw_sdio);
}

int skw_sdio_enable_async_irq(void)
{
	int ret = 0;
	u8 reg;

	ret = skw_sdio_readb(SDIO_INT_EXT, &reg);
	if (ret)
		return ret;

	reg |= 1 << 1; /* Enable Asynchronous Interrupt */

	ret = skw_sdio_writeb(SDIO_INT_EXT, reg & 0xff);
	if (ret)
		return ret;
	ret = skw_sdio_readb(SDIO_INT_EXT, &reg);
	if (ret)
		return ret;

	if (!(reg & (1 << 1)))
		skw_sdio_err("enable sdio async irq fail reg = 0x%x\n", reg);

	return ret;
}

#ifdef CONFIG_PM_SLEEP
static int skw_sdio_suspend(struct device *dev)
{
	struct sdio_func *func = container_of(dev, struct sdio_func, dev);
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int  ret = 0;


	if (skw_sdio->cp_state != 0)
		return -EBUSY;
	atomic_set(&skw_sdio->resume_flag, 0);

	if (SKW_CARD_ONLINE(skw_sdio))
		func->card->host->pm_flags |= MMC_PM_KEEP_POWER;

	func = skw_sdio->sdio_func[FUNC_1];
	send_host_suspend_indication(skw_sdio);
	if ((skw_sdio->irq_type == SKW_SDIO_INBAND_IRQ) && skw_sdio->resume_com) {
		sdio_claim_host(func);
		try_to_wakeup_modem(8);
		msleep(1);
		ret = sdio_release_irq(func);
		sdio_release_host(func);
		skw_sdio_dbg("%s sdio_release_irq ret = %d\n", __func__, ret);
	}
	atomic_set(&skw_sdio->suspending, 1);
	skw_sdio->resume_com = 0;
	return ret;
}

static int skw_sdio_resume(struct device *dev)
{
	struct sdio_func *func = container_of(dev, struct sdio_func, dev);
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int ret = 0;

#if defined(SKW_BOOT_DEBUG)
	skw_dloader(2);
#endif
	skw_sdio->suspend_wake_unlock_enable = 0;
	if (SKW_CARD_ONLINE(skw_sdio))
		func->card->host->pm_flags &= ~MMC_PM_KEEP_POWER;

	func = skw_sdio->sdio_func[FUNC_1];
	send_host_resume_indication(skw_sdio);
	if (!func->irq_handler && (skw_sdio->irq_type == SKW_SDIO_INBAND_IRQ)) {
		sdio_claim_host(func);
		ret = sdio_claim_irq(func, skw_sdio_inband_irq_handler);
		sdio_release_host(func);
		if (ret < 0) {
			skw_sdio_err("%s sdio_claim_irq ret = %d\n", __func__, ret);
		} else {
			ret = skw_sdio_enable_async_irq();
			if (ret < 0)
				skw_sdio_err("enable sdio async irq fail ret = %d\n", ret);
		}
	}
	atomic_set(&skw_sdio->resume_flag, 1);
	return ret;
}
#endif
irqreturn_t skw_gpio_irq_handler(int irq, void *dev_id) //interrupt
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int	value = gpio_get_value(skw_sdio->gpio_in);

	if (!debug_infos.cp_assert_time) {
		debug_infos.last_irq_time = skw_local_clock();
		debug_infos.last_irq_times[debug_infos.rx_gpio_irq_cnt % CHN_IRQ_RECORD_NUM] = debug_infos.last_irq_time;
		debug_infos.rx_gpio_irq_cnt++;
		skw_sdio_dbg("irq coming %d\n", debug_infos.rx_gpio_irq_cnt);
	}
	if (skw_sdio->power_off)
		return IRQ_HANDLED;
	if (!SKW_CARD_ONLINE(skw_sdio)) {
		skw_sdio_err("%s card offline\n", __func__);
		return IRQ_HANDLED;
	}
	if (!skw_sdio->suspend_wake_unlock_enable) {
		skw_sdio_dbg("suspend wake lock enable!!!!\n");
		skw_sdio_lock_rx_ws(skw_sdio);
	}

	if (value && (skw_sdio->irq_type == SKW_SDIO_EXTERNAL_IRQ))
			skw_sdio_rx_up(skw_sdio);
	host_gpio_in_routine(value);

	return IRQ_HANDLED;
}

static int skw_check_cp_ready(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	if (wait_for_completion_timeout(&skw_sdio->download_done,
		msecs_to_jiffies(2000)) == 0) {
		skw_sdio_err("check CP-ready time out\n");
		return -ETIME;
	}
	skw_sdio_dbg("CHECK CP PASS!\n");
	return 0;
}

static int skw_sdio_probe(struct sdio_func *func, const struct sdio_device_id *id)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct mmc_host *host = func->card->host;
	int ret;

	skw_sdio_log(SKW_SDIO_INFO,"%s: func->class=%x, vendor=0x%04x, device=0x%04x, func_num=0x%04x, clock=%d blksize=0x%x max_blkcnt %d\n",
		__func__,
		func->class, func->vendor, func->device, func->num, host->ios.clock,
		func->cur_blksize, func->card->host->max_blk_count);

	ret = skw_sdio_get_dev_func(func);
	if (ret < 0) {
		skw_sdio_err("get func err\n");
		return ret;
	}

	skw_sdio->sdio_dev_host = skw_sdio->sdio_func[FUNC_1]->card->host;
	if (!skw_sdio->sdio_dev_host) {
		skw_sdio_err("get host failed!!!");
		return -1;
	}

	if (!skw_sdio->pwrseq) {
		struct sdio_func *func1 = skw_sdio->sdio_func[FUNC_1];
		/* Enable Function 1 */
		sdio_claim_host(func1);
		ret = sdio_enable_func(func1);

		skw_sdio_info("sdio_enable_func ret=%d type %d\n", ret, skw_sdio->irq_type);
		if (!ret) {
			sdio_set_block_size(func1, SKW_SDIO_BLK_SIZE);
			func1->max_blksize = SKW_SDIO_BLK_SIZE;
			if (skw_sdio->irq_type == SKW_SDIO_INBAND_IRQ) {
				if (sdio_claim_irq(func1, skw_sdio_inband_irq_handler)) {
					skw_sdio_err("sdio_claim_irq failed\n");
				} else {
					ret = skw_sdio_enable_async_irq();
					if (ret < 0)
						skw_sdio_err("enable sdio async irq fail ret = %d\n", ret);
				}
			}
			sdio_release_host(func1);
		} else {
			sdio_release_host(func1);
			skw_sdio_err("enable func1 err!!! ret is %d\n", ret);
			return ret;
		}
		skw_sdio->resume_com = 1;
		skw_sdio_info("enable func1 done\n");
	} else
		pm_runtime_put_noidle(&func->dev);
	if (!SKW_CARD_ONLINE(skw_sdio))
		atomic_sub(SKW_SDIO_CARD_OFFLINE, &skw_sdio->online);

	complete(&skw_sdio->scan_done);

	check_chipid();
	/* the card is nonremovable */
	skw_sdio->sdio_dev_host->caps |= MMC_CAP_NONREMOVABLE;
	if (bind_device == 1) {
		ret = skw_sdio_writeb(SKW_SDIO_PLD_DMA_TYPE, ADMA);
		skw_sdio->adma_rx_enable = 1;
		if (ret != 0) {
			skw_sdio_err("the dma type write fail ret:%d\n", ret);
			return -1;
		}
		skw_sdio_info("line%d,adma type\n",  __LINE__);
		send_modem_service_command(WIFI_SERVICE, SERVICE_START);
	} else if (bind_device == 2) {
		ret = skw_sdio_writeb(SKW_SDIO_PLD_DMA_TYPE, SDMA);
		skw_sdio->adma_rx_enable = 0;
		if (ret != 0) {
			skw_sdio_err("the dma type write fail: %d\n", ret);
			return -1;
		}
		send_modem_service_command(WIFI_SERVICE, SERVICE_START);
		skw_sdio_info("the skw_sdio sdma write the pass\n");
	}
	skw_sdio_bind_platform_driver(skw_sdio->sdio_func[FUNC_1]);

#ifdef CONFIG_BT_SEEKWAVE
	skw_sdio_bind_btseekwave_driver(skw_sdio->sdio_func[FUNC_1]);
#endif
	skw_sdio->service_state_map = 0;
	skw_sdio->power_off = 0;
	skw_sdio->host_active = 1;
	return 0;
}

static void skw_sdio_remove(struct sdio_func *func)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	skw_sdio_info("Enter\n");

	complete(&skw_sdio->remove_done);

	if (skw_sdio->irq_type == SKW_SDIO_INBAND_IRQ) {
		sdio_claim_host(skw_sdio->sdio_func[FUNC_1]);
		sdio_release_irq(skw_sdio->sdio_func[FUNC_1]);
		sdio_release_host(skw_sdio->sdio_func[FUNC_1]);
	} else	if (skw_sdio->irq_num)
		free_irq(skw_sdio->irq_num, NULL);

	skw_sdio->host_active = 0;
	skw_sdio_unbind_platform_driver(skw_sdio->sdio_func[FUNC_1]);
	skw_sdio_unbind_WIFI_driver(skw_sdio->sdio_func[FUNC_1]);
	skw_sdio_unbind_BT_driver(skw_sdio->sdio_func[FUNC_1]);
	kfree(skw_sdio->sdio_func[FUNC_0]);
}

void skw_sdio_launch_thread(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	init_completion(&skw_sdio->rx_completed);
	skw_sdio_wakeup_source_init(skw_sdio);
	skw_sdio->rx_thread =
		kthread_create(skw_sdio_rx_thread, NULL, "skw_sdio_rx_thread");
	if (skw_sdio->rx_thread) {
#if KERNEL_VERSION(5, 9, 0) <= LINUX_VERSION_CODE
		sched_set_fifo_low(skw_sdio->rx_thread);
#else
		struct sched_param param;

		param.sched_priority = 1;
		sched_setscheduler(skw_sdio->rx_thread, SCHED_FIFO, &param);
#endif
		kthread_bind(skw_sdio->rx_thread, cpumask_first(cpu_online_mask));
		set_user_nice(skw_sdio->rx_thread, SKW_MIN_NICE);
		wake_up_process(skw_sdio->rx_thread);
	} else
		skw_sdio_err("creat skw_sdio_rx_thread fail\n");
}

void skw_sdio_stop_thread(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	if (skw_sdio->rx_thread) {
		skw_sdio->threads_exit = 1;
		skw_sdio_rx_up(skw_sdio);
		kthread_stop(skw_sdio->rx_thread);
		skw_sdio->rx_thread = NULL;
		skw_sdio_wakeup_source_destroy(skw_sdio);
	}
	skw_sdio_info("done\n");
}

static const struct dev_pm_ops skw_sdio_pm_ops = {
	SET_SYSTEM_SLEEP_PM_OPS(skw_sdio_suspend, skw_sdio_resume)
};

static const struct sdio_device_id skw_sdio_ids[] = {
	//{ .compatible = "seekwave-sdio", },
	{SDIO_DEVICE(0, 0)},
	{SDIO_DEVICE(0xABCD, 0x1234)},
	{SDIO_DEVICE(0x3607, 0x6160)},
	{},
};

static struct sdio_driver skw_sdio_driver = {
	.probe = skw_sdio_probe,
	.remove = skw_sdio_remove,
	.name = "skw_sdio",
	.id_table = skw_sdio_ids,
	.drv = {
		.pm = &skw_sdio_pm_ops,
	},
};

void skw_sdio_remove_card(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	init_completion(&skw_sdio->remove_done);
	sdio_unregister_driver(&skw_sdio_driver);
	skw_sdio_info(" sdio_unregister_driver\n");
	if (wait_for_completion_timeout(&skw_sdio->remove_done,
					msecs_to_jiffies(5000)) == 0)
		skw_sdio_err("remove card time out\n");
	else
		skw_sdio_info("remove card end\n");
}

int skw_sdio_scan_card(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int ret = 0;

	skw_sdio_info("sdio_scan_card\n");

	if (SKW_CARD_ONLINE(skw_sdio)) {
		skw_sdio_info("card already online!, 0x%x\n", atomic_read(&skw_sdio->online));
		skw_sdio_remove_card();
		msleep(100);
	}

	init_completion(&skw_sdio->scan_done);
	init_completion(&skw_sdio->download_done);
	init_completion(&skw_sdio->device_wakeup);
	init_waitqueue_head(&skw_sdio->wq);
	//skw_sdio->irq_type = SKW_SDIO_EXTERNAL_IRQ;
	skw_sdio->irq_type = SKW_SDIO_INBAND_IRQ;
	ret = sdio_register_driver(&skw_sdio_driver);
	if (ret != 0) {
		skw_sdio_err("sdio_register_driver error :%d\n", ret);
		return ret;
	}
	if (wait_for_completion_timeout(&skw_sdio->scan_done, msecs_to_jiffies(2000)) == 0) {
		skw_sdio_err("wait scan card time out\n");
		return -ENODEV;
	}
	if (!skw_sdio->sdio_dev_host) {
		skw_sdio_err("sdio_dev_host is NULL!\n");
		return -ENODEV;
	}
	skw_sdio_info("scan end!\n");

	return ret;
}

/****************************************************************
 *Description:sleep feature support en api
 *Author:junwei.jiang
 *Date:2023-06-14
 * ************************************************************/
int skw_sdio_slp_feature_en(unsigned int address, unsigned int slp_en)
{
	int ret = 0;

	ret = skw_sdio_writeb(address, slp_en);
	if (ret != 0) {
		skw_sdio_err("no-sleep support en write fail, ret=%d\n", ret);
		return -1;
	}
	skw_sdio_info("no-sleep_support_enable:%d\n ", slp_en);
	return 0;
}

/****************************************************************
 *Description:set the dma type SDMA, AMDA
 *Author:junwei.jiang
 *Date:2021-11-23
 * ************************************************************/
int skw_sdio_set_dma_type(unsigned int address, unsigned int dma_type)
{
	int ret = 0;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	if (dma_type == SDMA) {
		/*support the sdma so adma_rx_enable set 0*/
		skw_sdio->adma_rx_enable = 0;
	}
	if (!bind_device) {
		ret = skw_sdio_writeb(address, dma_type);
		if (ret != 0) {
			skw_sdio_err("dma type write fail, ret=%d\n", ret);
			return -1;
		}
	}
	skw_sdio_info("dma_type=%d,adma_rx_enable:%d\n ", dma_type, skw_sdio->adma_rx_enable);
	return 0;
}

/****************************************************************
*Description:
*Func:used the ap boot cp interface;
*Output:the dloader the bin to cp
*Return：0:pass; other : fail
*Author：JUNWEI.JIANG
*Date:2021-09-07
****************************************************************/
int skw_sdio_boot_cp(int boot_mode)
{
	int ret = 0;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
#ifdef CONFIG_SKW_DL_TIME_STATS
	 ktime_t cur_time, last_time;

	 cur_time = ktime_get();
#endif
	if (skw_sdio->irq_num == 0) {
		skw_sdio->gpio_in = -1;
		skw_sdio->gpio_out = -1;
	}
	skw_sdio_set_dma_type(skw_sdio->sdio_bootdata->dma_type_addr,
		skw_sdio->sdio_bootdata->dma_type);
	skw_sdio_slp_feature_en(skw_sdio->sdio_bootdata->slp_disable_addr,
		skw_sdio->sdio_bootdata->slp_disable);
	//2:download the boot bin 1CPALL 2, wifi 3,bt
	skw_sdio_info("DOWNLOAD BIN TO CP\n");
	memset(skw_sdio->next_size_buf, 0, 16);
	ret = skw_sdio_dt_write(SKW_BT_CONFIG_ADDR, skw_sdio->next_size_buf, 16);
	if (skw_sdio->sdio_bootdata->dram_dl_size)
		ret = skw_sdio_dt_write(skw_sdio->sdio_bootdata->dram_dl_addr,
				skw_sdio->sdio_bootdata->dram_img_data, skw_sdio->sdio_bootdata->dram_dl_size);
	if (skw_sdio->sdio_bootdata->iram_dl_size)
		ret = skw_sdio_dt_write(skw_sdio->sdio_bootdata->iram_dl_addr,
				skw_sdio->sdio_bootdata->iram_img_data, skw_sdio->sdio_bootdata->iram_dl_size);
	if (ret != 0)
		goto FAIL;
	//first boot need the setup cp first_dl_flag=0 is first
	skw_sdio_info("line:%d write the download done flag\n", __LINE__);
	ret = skw_sdio_writeb(skw_sdio->sdio_bootdata->save_setup_addr, BIT(0));
	if (ret != 0)
		goto FAIL;
	if (!skw_sdio->cp_state) {
		ret = skw_check_cp_ready();
#if 0
		if ((ret == -ETIME) && (boot_mode == SKW_FIRST_BOOT))
			skw_sdio_rx_up(skw_sdio);
		else if (!ret && boot_mode == SKW_FIRST_BOOT) {
			if ((cp_detect_sleep_mode == 2 || cp_detect_sleep_mode == 1) &&
				(skw_sdio->irq_type == SKW_SDIO_INBAND_IRQ) &&
				(skw_sdio->sdio_bootdata->gpio_in >= 0)) {
				func = skw_sdio->sdio_func[FUNC_1];
				sdio_claim_host(func);
				sdio_release_irq(func);
				sdio_release_host(func);
				skw_sdio->gpio_in = skw_sdio->sdio_bootdata->gpio_in;
				skw_sdio->gpio_out = skw_sdio->sdio_bootdata->gpio_out;
				ret = skw_sdio_host_irq_init(skw_sdio->gpio_in);
			}
		}
#endif
	}
	if (ret != 0)
		goto FAIL;

#ifdef CONFIG_SKW_DL_TIME_STATS
	 last_time = ktime_get();
	 skw_sdio_info("the download time start time %llu and the over time %llu ,the usertime=%llu\n",
				cur_time, last_time, (last_time - cur_time));
#endif

	if (!ret && boot_mode == SKW_FIRST_BOOT) {
		if (skw_sdio->chip_en < 0) {
			skw_sdio_err("chip_en:%d Invalid Pls check HW !!\n", skw_sdio->chip_en);
			ret = -1;
			goto FAIL;
		}
		skw_sdio_bind_WIFI_driver(skw_sdio->sdio_func[FUNC_1]);
#ifndef CONFIG_BT_SEEKWAVE
		skw_sdio_bind_BT_driver(skw_sdio->sdio_func[FUNC_1]);
#endif
	}
	return ret;
FAIL:
	skw_sdio_err("fail ret=%d\n", ret);
	return ret;
}

/************************************************************************
 *Decription:release CP close the CP log
 *Author:junwei.jiang
 *Date:2023-02-16
 *Modfiy:
 *
 ********************************************************************* */
int skw_sdio_cp_log(int disable)
{
	int ret = 0;

	skw_sdio_info("Enter\n");
	ret = skw_sdio_writeb(SDIOHAL_CPLOG_TO_AP_SWITCH, disable);
	if (ret < 0) {
		skw_sdio_err("close the log signal send fail ret=%d\n", ret);
		return ret;
	}
	skw_sdio_writeb(SKW_AP2CP_IRQ_REG, BIT(5));
	if (!disable)
		skw_sdio_info("line:%d enable the CP log TO AP!!\n", __LINE__);
	else
		skw_sdio_info("line:%d disable the CP log !!\n", __LINE__);

	return 0;
}

int skw_sdio_cp_log_status(void)
{
	if (!cp_log_status)
		skw_sdio_info("enable the CP log %d	!!\n", cp_log_status);
	else
		skw_sdio_info("disable the CP log %d!!\n", cp_log_status);

	return cp_log_status;
}

int skw_sdio_debug_log_open(void)
{
	skw_sdio_info("enable log TO AP!\n");
	cp_log_status = 0;
	return cp_log_status;
}


int skw_sdio_debug_log_close(void)
{
	skw_sdio_info("disable CP log !!\n");
	cp_log_status = 1;
	return cp_log_status;
}

/************************************************************************
 *Decription:send WIFI start command to modem.
 *Author:junwei.jiang
 *Date:2022-10-27
 *Modfiy:
 *
 ********************************************************************* */
static int skw_WIFI_service_start(void)
{
	int ret;

	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	skw_sdio_info("Enter STARTWIFI cp_state:%d\n", skw_sdio->cp_state);
	if (skw_sdio->service_state_map & (1 << WIFI_SERVICE))
		return 0;

	mutex_lock(&skw_sdio->except_mutex);
	if (skw_sdio->service_state_map == 0 && skw_sdio->power_off) {
	skw_reinit_completion(skw_sdio->download_done);
		skw_recovery_mode();
    }
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
	if (!cp_log_status) {
		skw_sdio_cp_log(1);
	}
#else
	if (cp_log_status) {
		skw_sdio_cp_log(1);
	}
#endif
	skw_sdio_cp_log(1);
	skw_reinit_completion(skw_sdio->download_done);
	ret = send_modem_service_command(WIFI_SERVICE, SERVICE_START);
	if (ret == 0)
		ret = skw_check_cp_ready();
	mutex_unlock(&skw_sdio->except_mutex);
	return ret;
}

/************************************************************************
 *Decription: send WIFI stop command to modem.
  *Author:junwei.jiang
 *Date:2022-10-27
 *Modfiy:
 *
 ********************************************************************* */
static int skw_WIFI_service_stop(void)
{
	int ret = 0;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	skw_sdio_info("Enter,STOPWIFI  cp_state:%d", skw_sdio->cp_state);
	mutex_lock(&skw_sdio->except_mutex);
	if (skw_sdio->service_state_map & (1 << WIFI_SERVICE))
		ret = send_modem_service_command(WIFI_SERVICE, SERVICE_STOP);
	if (!skw_sdio->cp_state && ret == 0 && skw_sdio->service_state_map == 0) {
		if (skw_sdio->chip_en >= 0 && !skw_sdio->power_off) {
#ifdef CONFIG_NO_SERVICE_PD
			skw_sdio_reg_reset_cp();
			msleep(50);
			SKW_CHIP_POWEROFF(skw_sdio->chip_en);
			skw_sdio->power_off = 1;
			skw_sdio_info("power off");
#endif
		}
	}
	mutex_unlock(&skw_sdio->except_mutex);
	return ret;
}

/************************************************************************
 *Decription:send BT start command to modem.
 *Author:junwei.jiang
 *Date:2022-10-27
 *Modfiy:
 *
 ********************************************************************* */
static int skw_BT_service_start(void)
{
	int ret;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	skw_sdio_info("Enter cpstate=%d\n", skw_sdio->cp_state);
	if (assert_context_size)
		skw_sdio_info("%s\n", assert_context);
	if (skw_sdio->service_state_map & (1 << BT_SERVICE))
		return 0;

	mutex_lock(&skw_sdio->except_mutex);
	if (skw_sdio->service_state_map == 0 && skw_sdio->power_off) {
	skw_reinit_completion(skw_sdio->download_done);
		skw_recovery_mode();
    }
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
	if (!cp_log_status) {
		skw_sdio_cp_log(1);
	}
#else
	if (cp_log_status) {
		skw_sdio_cp_log(1);
	}
#endif
	skw_reinit_completion(skw_sdio->download_done);
	ret = send_modem_service_command(BT_SERVICE, SERVICE_START);
	if (!ret)
		ret = skw_check_cp_ready();
	mutex_unlock(&skw_sdio->except_mutex);
	return ret;
}

/************************************************************************
 *Decription:send BT stop command to modem.
 *Author:junwei.jiang
 *Date:2022-10-27
 *Modfiy:
 *
 ********************************************************************* */
static int skw_BT_service_stop(void)
{
	int ret = 0;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	skw_sdio_info("Enter cpstate=%d\n", skw_sdio->cp_state);

	mutex_lock(&skw_sdio->except_mutex);
	if (skw_sdio->service_state_map & (1 << BT_SERVICE) && !skw_sdio->cp_state) {
		skw_reinit_completion(skw_sdio->download_done);
		ret = send_modem_service_command(BT_SERVICE, SERVICE_STOP);
		if (!ret)
			skw_check_cp_ready();
	}
	if (!skw_sdio->cp_state && ret == 0 && skw_sdio->service_state_map == 0) {
		if (skw_sdio->chip_en >= 0 && !skw_sdio->power_off) {
#ifdef CONFIG_NO_SERVICE_PD
			skw_sdio_reg_reset_cp();
			msleep(50);
			SKW_CHIP_POWEROFF(skw_sdio->chip_en);
			skw_sdio->power_off = 1;
			skw_sdio_info("power off");
#endif
		}
	}
	mutex_unlock(&skw_sdio->except_mutex);
	return ret;
}

/****************************************************************
*Description:
*Func:used the ap boot cp interface;
*Output:the dloader the bin to cp
*Return：0:pass; other : fail
*Author：JUNWEI.JIANG
*Date:2021-09-07
****************************************************************/
int skw_sdio_cp_service_ops(int service_ops)
{
	int ret = 0;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	switch (service_ops)
	{
		case SKW_WIFI_START:
			wait_event_interruptible_timeout(skw_sdio->wq,
				!skw_sdio->cp_state, msecs_to_jiffies(2000));
			ret = skw_WIFI_service_start();
			skw_sdio_dbg("-----WIFI SERIVCE START\n");
		break;
		case SKW_WIFI_STOP:
			ret = skw_WIFI_service_stop();
			skw_sdio_dbg("----WIFI SERVICE---STOP\n");
		break;
		case SKW_BT_START:
		{
			wait_event_interruptible_timeout(skw_sdio->wq,
				!skw_sdio->cp_state, msecs_to_jiffies(2000));
			ret = skw_BT_service_start();
			skw_sdio_dbg("-----BT SERIVCE --START\n");
		}
		break;
		case SKW_BT_STOP:
			ret = skw_BT_service_stop();
			skw_sdio_dbg("-----BT SERVICE --STOP\n");
		break;
		default:
			skw_sdio_warn("service not support!\n");
		break;
	}
	return ret;
}

/****************************************************************
*Description:skw_boot_loader
*Func:used the ap boot cp interface;
*Output:the dloader the bin to cp
*Return：0:pass; other : fail
*Author：JUNWEI.JIANG
*Date:2021-09-07
****************************************************************/
int skw_boot_loader(struct seekwave_device *boot_data)
{
	int ret = 0;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	skw_sdio->sdio_bootdata = boot_data;

	if (skw_sdio->power_off)
		boot_data->dl_module = RECOVERY_BOOT;
	/*--------CP RESET RESCAN------------*/
	if (boot_data->dl_module == RECOVERY_BOOT) {
		skw_sdio_info("rescan and reset CHIP\n");
		skw_recovery_mode();
	} else {
	/*-------FIRST AP BOOT--------------*/
	if (!skw_sdio->sdio_bootdata->first_dl_flag) {
		if (!strncmp((char *)skw_sdio->chip_id, "SV6160", 6)) {
			boot_data->chip_id = 0x6160;
			skw_sdio_info("boot chip id 0x%x\n", boot_data->chip_id);
		}
		skw_sdio->chip_en = boot_data->chip_en;
		if (skw_sdio->sdio_bootdata->iram_dl_size && 
				skw_sdio->sdio_bootdata->dram_dl_size){
			ret = skw_sdio_boot_cp(SKW_FIRST_BOOT);
		} else
			ret = skw_sdio_cpdebug_boot();
		}
	}
	/*------CP SERVICE OPS----------*/
	ret = skw_sdio_cp_service_ops(skw_sdio->sdio_bootdata->service_ops);
	if (ret != 0)
		goto FAIL;
	skw_sdio_info("boot loader ops end!!!\n");
	return 0;
FAIL:
	skw_sdio_err("line:%d  fail ret=%d\n", __LINE__, ret);
	return ret;
}
EXPORT_SYMBOL_GPL(skw_boot_loader);

/****************************************************************
*Description:check dev ready
*Func:used the ap boot cp interface;
*Calls:sdio or usb
*Call By:host dev ready
*Input:NULL
*Output:pass :0 or fail ENODEV
*Others:
*Author：JUNWEI.JIANG
*Date:2022-06-09
****************************************************************/
int skw_reset_bus_dev(void)
{
	return 0;
}
EXPORT_SYMBOL_GPL(skw_reset_bus_dev);

/****************************************************************
*Description:skw_get_chipid
*Func:used the ap boot cp interface;
*Calls:boot data
*Call By:the ap host
*Input:the boot data informations
*Output:the dloader the bin to cp
*Return：0:pass; other : fail
*Others:
*Author：JUNWEI.JIANG
*Date:2021-10-11
****************************************************************/
static int skw_sdio_reset_card(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int ret = 0;

	skw_sdio_info("the reset card cp_state =%d\n", skw_sdio->cp_state);
#if (KERNEL_VERSION(5, 10, 0) <= LINUX_VERSION_CODE && LINUX_VERSION_CODE <= KERNEL_VERSION(5, 18, 19))
	SKW_CHIP_POWEROFF(skw_sdio->chip_en);
	msleep(50);
	SKW_CHIP_POWERON(skw_sdio->chip_en);
	msleep(5);
#elif (KERNEL_VERSION(5, 19, 0) <= LINUX_VERSION_CODE)
	SKW_CHIP_POWEROFF(skw_sdio->chip_en);
	msleep(50);
	SKW_CHIP_POWERON(skw_sdio->chip_en);
	msleep(5);
#else
	skw_sdio_info(" kernel version no need support chip en config\n");
#endif
	ret = skw_sdio_reg_reset();
	if (ret < 0) {
		skw_sdio_err("the reset sdio host fail\n");
		return ret;
	}
	skw_sdio_info("the reset sdio host pass\n");
	return ret;
}

static int skw_sdio_reg_reset_cp(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int ret;
	/*reset CP register set value:0x4010001C 0x20:CP sys hif reset*/
	skw_sdio_info("the ==Enter==\n");
	//cia force chip reset
	if (!strncmp((char *)skw_sdio->chip_id, "SV6160", 12)) {
		skw_sdio_info("cia SV6160 force chip reset\n");
		ret = skw_sdio_writeb(0x125, BIT(0));
	} else {
		skw_sdio_info("cia SV6316 force chip reset\n");
		ret = skw_sdio_writeb(0x125, BIT(7));
	}
	if (ret < 0) {
		skw_sdio_err("cia the chip %s force chip reset fail\n", (char *)skw_sdio->chip_id);
		return ret;
	}
	skw_sdio_info("cia the chip %s force chip reset pass\n", (char *)skw_sdio->chip_id);
	return ret;
}

static int skw_sdio_reg_reset(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int ret;
	/*reset CP register set value:0x4010001C 0x20:CP sys hif reset*/
	skw_sdio_info("the Enter\n");
    //cia force chip reset
	skw_sdio_reg_reset_cp();
	msleep(50);
	sdio_claim_host(skw_sdio->sdio_func[FUNC_0]);
#if (KERNEL_VERSION(5, 10, 0) <= LINUX_VERSION_CODE && LINUX_VERSION_CODE <= KERNEL_VERSION(5, 18, 19))
	ret = mmc_sw_reset(skw_sdio->sdio_dev_host);
#elif (KERNEL_VERSION(5, 19, 0) <= LINUX_VERSION_CODE)
	ret = mmc_sw_reset(skw_sdio->sdio_dev_host->card);
#else
	ret = sdio_reset_comm((skw_sdio->sdio_dev_host->card));
#endif
	sdio_release_host(skw_sdio->sdio_func[FUNC_0]);
	skw_sdio_info("the reset sdio host and CP  pass\n");
	msleep(10);
	/*skw sdio rst apb */
	if (0) {
		skw_sdio_writeb(0x02, SKW_SDIO_DT_MODE_ADDR);
		skw_sdio_writeb(0x02, SDIO_VER_CCCR);
	}
	return 0;
}

int skw_sdio_cp_reset(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	struct sdio_func *func = skw_sdio->sdio_func[FUNC_1];
	int ret;

	if (skw_sdio->irq_type == SKW_SDIO_INBAND_IRQ) {
		sdio_claim_host(func);
		ret = sdio_release_irq(func);
		sdio_release_host(func);
		if (ret < 0)
			skw_sdio_err("%s sdio_release_irq ret = %d\n", __func__, ret);
	}

	ret = skw_sdio_reset_card();
	if (ret < 0) {
		skw_sdio_info("reset sdio host fail, wait 100ms and try again\n");
		msleep(100);
		ret = skw_sdio_reset_card();
		if (ret < 0) {
			skw_sdio_info("the reset sdio host fail\n");
		} else {
			skw_sdio_info("the reset sdio host pass\n");
		}
	} else {
		skw_sdio_info("the reset sdio host pass\n");
	}
	msleep(5);
	/* Enable Function 1 */
	sdio_claim_host(func);
	ret = sdio_enable_func(func);
	sdio_set_block_size(func, SKW_SDIO_BLK_SIZE);
	func->max_blksize = SKW_SDIO_BLK_SIZE;

	if (skw_sdio->irq_type == SKW_SDIO_INBAND_IRQ) {
		ret = sdio_claim_irq(func, skw_sdio_inband_irq_handler);
		if (ret < 0) {
			skw_sdio_err("%s sdio_claim_irq ret = %d\n", __func__, ret);
		} else {
			ret = skw_sdio_enable_async_irq();
			if (ret < 0)
				skw_sdio_err("enable sdio async irq fail ret = %d\n", ret);
		}
	}
	sdio_release_host(skw_sdio->sdio_func[FUNC_1]);
	if (ret < 0) {
		skw_sdio_err("enable func1 err!!! ret is %d\n", ret);
		return -1;
	}
	skw_sdio_info("CP RESET OK!\n");
	return 0;
}

/****************************************************************
*Description:skw_sdio_cpdebug_boot
*Func:used the ap boot cp interface;
*Others:
*Author：JUNWEI.JIANG
*Date:2022-07-15
****************************************************************/
int skw_sdio_cpdebug_boot(void)
{
	int ret = 0;
	struct sdio_func *func;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	skw_sdio_info("not download CP from AP!!!!\n");
	skw_sdio_set_dma_type(skw_sdio->sdio_bootdata->dma_type_addr,
			skw_sdio->sdio_bootdata->dma_type);
	skw_sdio_slp_feature_en(skw_sdio->sdio_bootdata->slp_disable_addr,
			skw_sdio->sdio_bootdata->slp_disable);

	if (!skw_sdio->cp_state && !skw_sdio->sdio_bootdata->first_dl_flag) {
		if ((cp_detect_sleep_mode == 2 || cp_detect_sleep_mode == 1) &&
				(skw_sdio->irq_type == SKW_SDIO_INBAND_IRQ) &&
				(skw_sdio->sdio_bootdata->gpio_in >= 0)) {
			skw_sdio->irq_type = SKW_SDIO_EXTERNAL_IRQ;
			func = skw_sdio->sdio_func[FUNC_1];
			sdio_claim_host(func);
			sdio_release_irq(func);
			sdio_release_host(func);
			skw_sdio_host_irq_init(skw_sdio->gpio_in);
			//try_to_wakeup_modem(8);
		}
		skw_sdio_bind_WIFI_driver(skw_sdio->sdio_func[FUNC_1]);
#ifndef CONFIG_BT_SEEKWAVE
		skw_sdio_bind_BT_driver(skw_sdio->sdio_func[FUNC_1]);
#endif
	}
	skw_sdio_info(" CP DUEBGBOOT Done!!!\n");
	return ret;
}

/****************************************************************
*Description:skw_recovery_mode
*Func:used the ap boot cp interface;
*Calls:boot data
*Call By:the ap host
*Input:the boot data informations
*Output:reset cp
*Return：0:pass; other : fail
*Others:
*Author：JUNWEI.JIANG
*Date:2022-07-15
****************************************************************/
int skw_recovery_mode(void)
{
	int ret;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	if (!skw_sdio->sdio_bootdata->dram_dl_size || !skw_sdio->sdio_bootdata->iram_dl_size ||
			(skw_sdio_recovery_debug_status() && skw_sdio->cp_state)) {
		skw_sdio_err("CP DEBUG BOOT,AND NO NEED RECOVERY!!!\n");
		return -1;
	}
	ret = skw_sdio_cp_reset();
	if (ret != 0) {
		skw_sdio_err("CP RESET fail\n");
		return -1;
	}
	skw_sdio->power_off = 0;
	ret = skw_sdio_boot_cp(RECOVERY_BOOT);
	if (ret != 0) {
		skw_sdio_err("CP RESET fail\n");
		return -1;
	}
	skw_sdio_info("Recovery ok\n");
	return ret;
}

int check_chipid(void)
{
	int ret;
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();

	ret = skw_sdio_dt_read(SKW_CHIP_ID0, skw_sdio->chip_id, SKW_CHIP_ID_LENGTH);
	if (!strncmp((char *)skw_sdio->chip_id, "SV6160", 6)) {
		skw_cp_ver = SKW_SDIO_V10;
		max_ch_num = MAX_CH_NUM;
		skw_sdio_info("Chip id:%s used SDIO10", (char *)skw_sdio->chip_id);
		//print_hex_dump(KERN_ERR, "CHIP ID: ", 0, 16, 1,skw_sdio->chip_id, 32, 1);
	} else {
		skw_cp_ver = SKW_SDIO_V20;
		max_ch_num = SDIO2_MAX_CH_NUM;
		skw_sdio_info("Chip id:%s used SDIO20 ", (char *)skw_sdio->chip_id);
	}

	if (ret < 0) {
		skw_sdio_err("Get the chip id fail!!\n");
		return ret;
	}
	return 0;
}

static int __init skw_sdio_io_init(void)
{
	struct skw_sdio_data_t *skw_sdio;

	memset(&debug_infos, 0, sizeof(struct debug_vars));
	skw_sdio_debugfs_init();
	skw_sdio_log_level_init();
	extern_wifi_set_enable(0);
	mdelay(200);
	extern_wifi_set_enable(1);
	mdelay(80);
	skw_sdio_info("reinit");
	//skw_sdio->sdio_dev_host->card=NULL;
	sdio_reinit();
	mdelay(20);

	//skw_chip_set_power(1);
	skw_sdio = kzalloc(sizeof(struct skw_sdio_data_t), GFP_KERNEL);
	if (!skw_sdio) {
		WARN_ON(1);
		return -ENOMEM;
	}

	/* card not ready */
	g_skw_sdio_data = skw_sdio;
	mutex_init(&skw_sdio->transfer_mutex);
	mutex_init(&skw_sdio->except_mutex);
	atomic_set(&skw_sdio->resume_flag, 1);
	skw_sdio->next_size_buf = kzalloc(SKW_BUF_SIZE, GFP_KERNEL);
	if (!skw_sdio->next_size_buf) {
		kfree(skw_sdio);
		return -ENOMEM;
	}
	skw_sdio->eof_buf = kzalloc(SKW_BUF_SIZE, GFP_KERNEL);
	if (!skw_sdio->eof_buf) {
		kfree(skw_sdio->next_size_buf);
		kfree(skw_sdio);
		return -ENOMEM;
	}
	atomic_set(&skw_sdio->online, SKW_SDIO_CARD_OFFLINE);
	if (!bind_device) {
		skw_sdio->adma_rx_enable = 1;
	}
	INIT_DELAYED_WORK(&skw_sdio->skw_except_work, skw_sdio_exception_work);
	skw_sdio_launch_thread();
	skw_sdio_scan_card();
	skw_sdio_info(" OK\n");
	return seekwave_boot_init();
}

static void __exit skw_sdio_io_exit(void)
{
	struct skw_sdio_data_t *skw_sdio = skw_sdio_get_data();
	int ret = 0;

	seekwave_boot_exit();
	skw_sdio_debugfs_deinit();
	skw_sdio_stop_thread();
	if (!skw_sdio->suspend_wake_unlock_enable) {
		//skw_sdio_dbg("suspend wake lock enable!!!!\n");
		skw_sdio_unlock_rx_ws(skw_sdio);
	}
	ret = skw_sdio_reset_card();
	if (ret < 0) {
		skw_sdio_info("reset sdio host fail, wait 100ms and try again\n");
		msleep(100);
		ret = skw_sdio_reset_card();
		if (ret < 0) {
			skw_sdio_info("the reset sdio host fail\n");
		} else {
			skw_sdio_info("the reset sdio host pass\n");
		}
	} else {
		skw_sdio_info("the reset sdio host pass\n");
	}
	if (SKW_CARD_ONLINE(skw_sdio)) {
		skw_sdio_remove_card();
	}
	extern_wifi_set_enable(0);
	mdelay(100);
	extern_wifi_set_enable(1);
	mdelay(200);
	cancel_delayed_work_sync(&skw_sdio->skw_except_work);
	mutex_destroy(&skw_sdio->transfer_mutex);
	mutex_destroy(&skw_sdio->except_mutex);
	if (skw_sdio) {
		kfree(skw_sdio->next_size_buf);
		kfree(skw_sdio->eof_buf);
		skw_sdio->sdio_bootdata = NULL;
		skw_sdio->sdio_dev_host = NULL;
		kfree(skw_sdio);
		skw_sdio = NULL;
	}
	skw_sdio_info(" OK\n");
}
module_init(skw_sdio_io_init)
module_exit(skw_sdio_io_exit)
MODULE_LICENSE("GPL v2");
===== ./drivers/seekwaveplatform/skwutil/skw_user_com.c =====
#include <linux/kernel.h>
#include <linux/cdev.h>
#include <linux/module.h>
#include <linux/fs.h>
#include <linux/slab.h>
#include <linux/delay.h>
#include <linux/compat.h>
#include <linux/uaccess.h>
#include <linux/workqueue.h>
#include <linux/scatterlist.h>
 #include <linux/notifier.h>
#include <linux/platform_device.h>
#include "skw_boot.h"
#include "skw_log_to_file.h"
#define UCOM_PORTNO_MAX		13
#define UCOM_DEV_PM_OPS NULL
int cp_exception_sts = 0;
unsigned int tmp_chipid;
extern int skw_reset_bootloader_cp(void);
static unsigned int skw_major;

static struct class *skw_com_class;
struct ucom_dev	{
	atomic_t open;
	spinlock_t lock;
	int	rx_busy;
	int	tx_busy;
	int	devno;
	int	portno;
	struct sv6160_platform_data *pdata;
	wait_queue_head_t wq;
	wait_queue_head_t dumpq;
	struct cdev cdev;
	char	*rx_buf;
	char	*tx_buf;
	struct notifier_block notifier;
};

static struct ucom_dev *ucoms[UCOM_PORTNO_MAX];

static int bt_state_event_notifier(struct notifier_block *nb, unsigned long action, void *data)
{
	//int ret = 0;
	skwboot_log("%s event = %d\n", __func__, (int)action);
	switch (action)
	{
		case DEVICE_ASSERT_EVENT:
		{
			skwboot_log("BT BSPASSERT EVENT Comming in !!!!\n");
			cp_exception_sts = 1;
		}
		break;
		case DEVICE_BSPREADY_EVENT:
		{
			cp_exception_sts = 0;
			skwboot_log("BT BSPREADY EVENT Comming in !!!!\n");
		}
		break;
		case DEVICE_DUMPDONE_EVENT:
		{
			cp_exception_sts = 2;
			skwboot_log("BT DUMPDONE EVENT Comming in !!!!\n");
		}
		break;
		case DEVICE_BLOCKED_EVENT:
		{
			cp_exception_sts = 3;
			skwboot_log("BT BLOCKED EVENT Comming in !!!!\n");
		}
		break;
		default:
		{
			cp_exception_sts = action;
		}
		break;
	}
	return NOTIFY_OK;
}

static int skw_bt_state_event_init(struct ucom_dev *ucom)
{
	int ret = 0;

	if (ucom->pdata->modem_register_notify && !ucom->notifier.notifier_call) {
		ucom->notifier.notifier_call = bt_state_event_notifier;
		ucom->pdata->modem_register_notify(&ucom->notifier);
	} else {
		skwlog_log("%s have registered !! %d \n", __func__, __LINE__);
	}

	return ret;
}

static int skw_bt_state_event_deinit(struct ucom_dev *ucom)
{
	int ret = 0;

	if (ucom) {
		if ((ucom->notifier.notifier_call)) {
			skwboot_log("%s :%d release the notifier\n", __func__, __LINE__);
			ucom->notifier.notifier_call = NULL;
			ucom->pdata->modem_unregister_notify(&ucom->notifier);
		}
	}
	return ret;
}

static int user_boot_open(struct inode *ip, struct file *fp)
{
	struct cdev *char_dev;
	int ret = -EIO, i;
	struct ucom_dev *ucom = NULL;
	int count = 100;

	while (cp_exception_sts && count--)
		msleep(10);

	char_dev = ip->i_cdev;
	for (i = 0; i < UCOM_PORTNO_MAX; i++) {
		if (ucoms[i] && (ucoms[i]->devno == char_dev->dev)) {
			ucom = ucoms[i];
			ret = 0;
			break;
		}
	}

	if (ucom) {
		if (atomic_read(&ucom->open)) {
			skwboot_log("device busy!!!");
			return -EBUSY;
		}
		atomic_inc(&ucom->open);
		fp->private_data = ucom;
		if (!cp_exception_sts)
			ret = ucom->pdata->open_port(ucom->portno, NULL, NULL);

		printk("Open user_boot ret=%d: pid=%d\n", ret, (int)current->pid);
		if (ret < 0)
			atomic_dec(&ucom->open);
	}
	return ret;
}

static int user_boot_release(struct inode *ip, struct file *fp)
{
	struct ucom_dev *ucom = fp->private_data;
	int count = 100;

	while (cp_exception_sts && count--)
		msleep(10);

	if (ucom) {
		if (!cp_exception_sts)
			ucom->pdata->close_port(ucom->portno);

		atomic_dec(&ucom->open);
	}
	return 0;
}

static int ucom_open(struct inode *ip, struct file *fp)
{
	struct cdev *char_dev;
	int ret = -EIO, i;
	struct ucom_dev *ucom = NULL;

	if (cp_exception_sts) {
		skwboot_log("%s line:%d the modem assert\n", __func__, __LINE__);
		return ret;
	}
	char_dev = ip->i_cdev;
	for (i = 0; i < UCOM_PORTNO_MAX; i++) {
		if (ucoms[i] && (ucoms[i]->devno == char_dev->dev)) {
			ucom = ucoms[i];
			ret = 0;
			break;
		}
	}

	if (ucom) {
		if (atomic_read(&ucom->open) > 1) {
			printk("%s ,%d\n", __func__, __LINE__);
			return -EBUSY;
		}
		atomic_inc(&ucom->open);
		init_waitqueue_head(&ucom->wq);
		spin_lock_init(&ucom->lock);
		ucom->pdata->open_port(ucom->portno, NULL, NULL);
		fp->private_data = ucom;
		if (!strncmp((char *)ucom->pdata->chipid, "SV6160", 6))
			tmp_chipid = 0x6160;
		else if (!strncmp((char *)ucom->pdata->chipid, "SV6316", 6))
			tmp_chipid = 0x6316;
		printk("%s: chipid= [0x%x], ucom[%d] %s(0x%x)\n", __func__, tmp_chipid, i,
			ucom->pdata->port_name, ucom->portno);
	}
	return ret;
}

static int ucom_release(struct inode *ip, struct file *fp)
{
	struct ucom_dev *ucom = fp->private_data;
	int i;

	for (i = 0; i < UCOM_PORTNO_MAX; i++) {
		if (ucoms[i] == ucom)
			break;
	}
	fp->private_data = NULL;
	if (ucom && (i < UCOM_PORTNO_MAX)) {
		printk("%s: ucom%p %s(0x%x)\n", __func__, ucom, ucom->pdata->port_name, ucom->devno);
		if (atomic_read(&ucom->open)) {
			atomic_dec(&ucom->open);
			if (strncmp(ucom->pdata->port_name, "LOG", 3) && strncmp(ucom->pdata->port_name, "ATC", 3))
				ucom->pdata->close_port(ucom->portno);
			wake_up(&ucom->wq);
		} else
			kfree(ucom);
	}
	return 0;
}

static ssize_t ucom_read(struct file *fp, char __user *buf, size_t count, loff_t *pos)
{
	struct ucom_dev *ucom = fp->private_data;
	ssize_t r;
	int ret;
	unsigned long flags;

	if (cp_exception_sts || atomic_read(&ucom->open) == 0)
		return -EIO;
	spin_lock_irqsave(&ucom->lock, flags);
	if (ucom->rx_busy) {
		spin_unlock_irqrestore(&ucom->lock, flags);
		return -EAGAIN;
	}
	ucom->rx_busy = 1;
	if (count > ucom->pdata->max_buffer_size)
		count = ucom->pdata->max_buffer_size;
	spin_unlock_irqrestore(&ucom->lock, flags);
	ret = ucom->pdata->hw_sdma_rx(ucom->portno, ucom->rx_buf, count);
	ucom->rx_busy = 0;

	if (ret > 0) {
		r = ret;
		if (ret > count)
			ret = copy_to_user(buf, ucom->rx_buf, count);
		else
			ret = copy_to_user(buf, ucom->rx_buf, ret);
		if (ret > 0)
			return -EFAULT;
	} else	r = ret;
	pr_debug("%s %s ret = %d\n", __func__, current->comm, (int)r);
	return r;
}

static ssize_t ucom_write(struct file *fp, const char __user *buf, size_t count, loff_t *pos)
{
	struct ucom_dev *ucom = fp->private_data;
	int ret = 0;
	ssize_t r = count;
	ssize_t size;
	unsigned long flags;

	if (cp_exception_sts || atomic_read(&ucom->open) == 0)
		return -EIO;
	spin_lock_irqsave(&ucom->lock, flags);
	if (ucom->tx_busy) {
		spin_unlock_irqrestore(&ucom->lock, flags);
		printk("%s error 0\n", __func__);
		return -EAGAIN;
	}
	ucom->tx_busy = 1;
	spin_unlock_irqrestore(&ucom->lock, flags);
	while (count) {
		if (count > ucom->pdata->max_buffer_size)
			size =  ucom->pdata->max_buffer_size;
		else
			size = count;
		if (copy_from_user(ucom->tx_buf, buf, size))
			return -EFAULT;

		if (!strncmp(ucom->pdata->port_name, "LOG", 3)) {
			if (!strncmp(ucom->tx_buf, "START", 5)) {
				skwboot_log("%s START log to file\n", __func__);
				skw_modem_log_init(ucom->pdata, NULL, (void *)ucom);
			} else if(!strncmp(ucom->tx_buf, "STOP", 4)){
				skwboot_log("%s STOP log to file\n", __func__);
				skw_modem_log_exit();
			} else
				skwboot_log("%s LOG write string:%s\n", __func__, ucom->tx_buf);
			ucom->tx_busy = 0;
			return r;
		}
		if (ucom->pdata->port_name && !strncmp(ucom->pdata->port_name, "ATC", 3)) {
			 ucom->tx_buf[size++] = 0x0D;
			 ucom->tx_buf[size++] = 0x0A;
			 count += 2;
		}
		ret = ucom->pdata->hw_sdma_tx(ucom->portno, ucom->tx_buf, size);

		if (ret < 0) {
			printk("the close the ucom tx_busy=0");
			ucom->tx_busy = 0;
			return ret;
		}
		count -= ret;
		buf += ret;
	}
	ucom->tx_busy = 0;
	pr_debug("%s %s ret = %d\n", __func__, current->comm, (int)r);
	return r;
}

static long ucom_ioctl(struct file *fp, unsigned int cmd, unsigned long arg)
{
	struct ucom_dev *ucom = fp->private_data;
	int i;

	for (i = 0; i < UCOM_PORTNO_MAX; i++) {
		if (ucoms[i] == ucom)
			break;
	}
	if ((i < UCOM_PORTNO_MAX) && atomic_read(&ucom->open)) {
		printk("%s ucom_%p rx_busy=%d\n", __func__, ucom, ucom->rx_busy);
		if (ucom->pdata)
			ucom->pdata->close_port(ucom->portno);
	}
	return 0;
}

#ifdef CONFIG_COMPAT
static long ucom_compat_ioctl(struct file *fp, unsigned int cmd, unsigned long arg)
{
	return ucom_ioctl(fp, cmd, (unsigned long)compat_ptr(arg));
}
#endif
static ssize_t boot_read(struct file *fp, char __user *buf, size_t count, loff_t *pos)
{
	u32 status;
	struct ucom_dev *ucom = fp->private_data;
	int ret = 0;

	ret = ucom->pdata->hw_sdma_rx(ucom->portno, (char *)&status, 4);
	if (ret > 0)
		ret = copy_to_user(buf, &status, ret);
	return ret;
}

static ssize_t boot_write(struct file *fp, const char __user *buf, size_t count, loff_t *pos)
{
	struct ucom_dev *ucom = fp->private_data;
	int ret = 0;

	ret = ucom->pdata->hw_sdma_tx(ucom->portno, "WAKE", 4);
	if (ret > 0)
		return count;
	return ret;
}

static long boot_ioctl(struct file *fp, unsigned int cmd, unsigned long arg)
{
	struct ucom_dev *ucom = fp->private_data;
	unsigned char cp_log_state = 0;
	int ret = 0;

	switch (cmd) {
		case 0:
			ret = copy_to_user((char *)arg, (char *)&tmp_chipid, 4);
			skwboot_log("the orgchip = %s ,the chipid = 0x%x\n", (char *)ucom->pdata->chipid, tmp_chipid);
			break;
		case _IOWR('S', 1, uint8_t *):
			break;
		case _IOWR('S', 2, uint8_t *):
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
			cp_log_state = 1; //close log
			//skw_sdio_cp_log(1);
#else
			cp_log_state = 2;//open log
#endif
			ret = copy_to_user((char *)arg, (char *)&cp_log_state, 1);
			skwboot_log("the cp_log_state = %d\n", cp_log_state);
			break;
	}
	return 0;
}

#ifdef CONFIG_COMPAT
static long boot_compat_ioctl(struct file *fp, unsigned int cmd, unsigned long arg)
{
	return boot_ioctl(fp, cmd, (unsigned long)compat_ptr(arg));
}
#endif

static const struct file_operations skw_ucom_ops = {
	.owner	= THIS_MODULE,
	.open	= ucom_open,
	.read	= ucom_read,
	.write	= ucom_write,
	.unlocked_ioctl = ucom_ioctl,
#ifdef CONFIG_COMPAT
	.compat_ioctl = ucom_compat_ioctl,
#endif
	.release = ucom_release,
};

static const struct file_operations skw_user_boot_ops = {
	.owner	= THIS_MODULE,
	.open	= user_boot_open,
	.read	= boot_read,
	.write	= boot_write,
	.unlocked_ioctl  = boot_ioctl,
#ifdef CONFIG_COMPAT
	.compat_ioctl = boot_compat_ioctl,
#endif
	.release = user_boot_release,
};

static int skw_ucom_probe(struct platform_device *pdev)
{
	struct device *dev = &pdev->dev;
	struct sv6160_platform_data *pdata = dev->platform_data;
	struct ucom_dev	*ucom;
	int ret = 0;

	if (!skw_com_class) {
		skw_com_class = class_create(THIS_MODULE, "btcom");
		dev_info(&pdev->dev, "class name %s,major = %d\n", skw_com_class->name, skw_major);
		if (IS_ERR(skw_com_class)) {
			printk("skw_ucom_probe: class prt = %p, name = %s\n", skw_com_class, skw_com_class->name);
			ret =  PTR_ERR(skw_com_class);
			printk("skw_ucom_probe:ret = %d\n", ret);
			skw_com_class = NULL;
			return ret;
		} else {
			printk("skw_ucom_probe:class prt = %p, name = %s\n", skw_com_class, skw_com_class->name);
		}
	}

	if (pdata) {
		ucom = kzalloc(sizeof(struct ucom_dev), GFP_KERNEL);
		if (!ucom)
			return -ENOMEM;
		if (strncmp(pdata->port_name, "BTBOOT", 6)) {
			ucom->rx_buf = kzalloc(pdata->max_buffer_size, GFP_KERNEL);
			if (ucom->rx_buf) {
				ucom->tx_buf = kzalloc(pdata->max_buffer_size, GFP_KERNEL);
				if (!ucom->tx_buf) {
					kfree(ucom->rx_buf);
					kfree(ucom);
					return -ENOMEM;
				}
			} else {
				kfree(ucom);
				return -ENOMEM;
			}
			ret = __register_chrdev(skw_major, pdata->data_port + 1, 1, pdata->port_name, &skw_ucom_ops);
		} else {
			pdata->data_port = UCOM_PORTNO_MAX - 1;
			ret = __register_chrdev(skw_major, UCOM_PORTNO_MAX, 1,
					pdata->port_name, &skw_user_boot_ops);
		}
		if (ret < 0) {
			kfree(ucom->rx_buf);
			kfree(ucom->tx_buf);
			kfree(ucom);
			return ret;
		}
		if (skw_major == 0)
			skw_major = ret;
		ucom->devno = MKDEV(skw_major, pdata->data_port + 1);
		printk("register char device:%s %d:%d\n",
				pdata->port_name, skw_major, pdata->data_port);
		ucom->pdata = pdata;
		ucom->portno = pdata->data_port;
		atomic_set(&ucom->open, 0);
		platform_set_drvdata(pdev, ucom);
		ucoms[ucom->portno] = ucom;

		device_create(skw_com_class, NULL, ucom->devno, NULL, "%s", pdata->port_name);

		if (!strncmp(ucom->pdata->port_name, "BTCMD", 5))
			skw_bt_state_event_init(ucom);
#ifndef CONFIG_SEEKWAVE_PLD_RELEASE
		if (!strncmp(ucom->pdata->port_name, "LOG", 5))
			skw_modem_log_init(ucom->pdata, NULL, (void *)ucom);
#endif
		return 0;
	}
	return -EINVAL;
}

static int skw_ucom_remove(struct platform_device *pdev)
{
	struct device *dev = &pdev->dev;
	struct sv6160_platform_data *pdata = dev->platform_data;
	struct ucom_dev *ucom;
	int ret, i;
	unsigned long devno;

	ucom = platform_get_drvdata(pdev);
	if (ucom && ucom->pdata) {
		if (!strncmp(ucom->pdata->port_name, "LOG", 3)) {
			skw_modem_log_exit();
		}
	
		if (!strncmp(ucom->pdata->port_name, "BTCMD", 5)) {
			if (ucom->rx_busy) {
				ucom->pdata->close_port(ucom->portno);
			}
			skw_bt_state_event_deinit(ucom);
		}
		ret = wait_event_interruptible_timeout(ucom->wq,
				(!atomic_read(&ucom->open)),
				msecs_to_jiffies(1000));

		printk("%s: %s -- open_count=%d\n", __func__,  ucom->pdata->port_name, atomic_read(&ucom->open));

		ucom->pdata = NULL;
		devno = ucom->devno;
		device_destroy(skw_com_class, devno);
		ucoms[ucom->portno] = NULL;
		kfree(ucom->rx_buf);
		ucom->rx_buf = NULL;
		kfree(ucom->tx_buf);
		ucom->tx_buf = NULL;

		if (!atomic_read(&ucom->open)) {
			printk("dbg ptr[%d]\n", __LINE__);
			kfree(ucom);
			ucom = NULL;
		} else {
			printk("dbg ptr[%d]\n", __LINE__);
			atomic_set(&ucom->open, 0);
		}

		__unregister_chrdev(MAJOR(devno), MINOR(devno), 1,  pdata->port_name);
		platform_set_drvdata(pdev, NULL);
	}
	for (i = 0; i < UCOM_PORTNO_MAX; i++) {
		if (ucoms[i])
			break;
	}

	if (i >= UCOM_PORTNO_MAX) {
		printk("class name %s destroy\n", skw_com_class->name);
		class_destroy(skw_com_class);
		skw_com_class = NULL;
	}

	return 0;
}

static struct platform_driver skw_ucom_driver = {
	.driver = {
		.name	= (char *)"skw_ucom",
		.bus	= &platform_bus_type,
		.pm	= UCOM_DEV_PM_OPS,
	},
	.probe = skw_ucom_probe,
	.remove = skw_ucom_remove,
};

int skw_ucom_init(void)
{
	platform_driver_register(&skw_ucom_driver);
	return 0;
}

void skw_ucom_exit(void)
{
	cp_exception_sts = 0;
	tmp_chipid = 0;
	platform_driver_unregister(&skw_ucom_driver);
}
===== ./drivers/seekwaveplatform/skwutil/skw_boot.c =====
/*****************************************************************
 *Copyright (C) 2021 Seekwave Tech Inc.
 *Filename : skw_boot.c
 *Authors:seekwave platform
 *
 * This software is licensed under the terms of the GNU
 * General Public License version 2, as published by the Free
 * Software Foundation, and may be copied, distributed, and
 * modified under those terms.
 *
 * This program is distributed in the hope that it will be usefull,
 * but without any warranty;without even the implied warranty of
 * merchantability or fitness for a partcular purpose. See the
 * GUN General Public License for more details.
 * **************************************************************/

#include <linux/kernel.h>
#include <linux/irq.h>
#include <linux/interrupt.h>
#include <linux/module.h>
#include <linux/gpio.h>
#include <linux/delay.h>
#include <linux/slab.h>
#include <linux/of_gpio.h>
#include <linux/completion.h>
#include <linux/moduleparam.h>
#include <linux/of.h>
#include <linux/device.h>
#include <linux/version.h>
#include <linux/debugfs.h>
#include <linux/fs.h>
#include <linux/ctype.h>
#include <linux/errno.h>
#include <linux/firmware.h>
#include <linux/mmc/sdio_func.h>
#include <linux/dma-mapping.h>
#include <linux/cdev.h>
#include <linux/uaccess.h>
#include <linux/workqueue.h>
#include <linux/scatterlist.h>
#include <linux/platform_device.h>
#include "sv6160_addr_map.h"
#include "skw_boot.h"
#include "boot_config.h"
/**************************sdio boot start******************************/
extern int cp_exception_sts;
int test_debug;
module_param(test_debug, int, 0444);
unsigned char dl_signal_acount = 0;
struct platform_device *btboot_pdev;
static u64 port_dmamask = DMA_BIT_MASK(32);
static int usb_chip_enable_gpio = -1;//32*4 + 8*3 + 4; //GPIO4_D4
static struct mutex boot_mutex;

//#define SDIO_BUFFER_SIZE	 (16*1024)
enum skw_sub_sys {
	SKW_BSP = 1,
	SKW_WIFI,
	SKW_BLUETOOTH,
	SKW_ALL,
};

/*
 *add the little endian
 * */
#define _LITTLE_ENDIAN  1

#define CP_IMG_HEAD0	"kees"		 //"6B656573"
#define CP_IMG_HEAD1	"0616"		//"30363136"
#define CP_IMG_TAIL0	"evaw"		//"65766177"
#define CP_IMG_TAIL1	"0616"		//"30363136" //ASCII code 36 31 36 30
#define CP_NV_HEAD	  "TSVN"		//"5453564E" //ASCII code 36 31 36 30
#define CP_NV_TAIL		 "DEVN"		//"4445564E" //ASCII code 36 31 36 30

#define IMG_HEAD_OPS_LEN	4
#define RAM_ADDR_OPS_LEN	8
#define MODULE_INFO_LEN		12

#define IMG_HEAD_INFOR_RANGE	0x200  //10K Byte

unsigned int EndianConv_32(unsigned int value);
int skw_bind_boot_driver(struct device *dev);
/***********sdio drv extern interface **************/
/* driect mode,reg access.etc */
extern int skw_get_chipid(unsigned int system_addr, void *buf, unsigned int len);
extern int skw_boot_loader(struct seekwave_device *boot_data);
extern void *skw_get_bus_dev(void);
extern int skw_reset_bus_dev(void);
int skw_first_boot(struct seekwave_device *boot_data);
int skw_boot_init(struct seekwave_device *boot_data);
int skw_start_wifi_service(void);
int skw_start_bt_service(void);
int skw_stop_wifi_service(void);
int skw_stop_bt_service(void);
/**************************sdio boot end********************************/
struct seekwave_device *boot_data;
/***************************************************************************
 *Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 **************************************************************************/
#if !defined(CONFIG_SEEKWAVE_FIRMWARE_LOAD)
static unsigned int crc_16_l_calc(char *buf_ptr, unsigned int len)
{
	unsigned int i;
	unsigned short crc = 0;

	while (len-- != 0)
	{
		for (i = CRC_16_L_SEED; i != 0; i = i >> 1)
		{
			if ((crc & CRC_16_L_POLYNOMIAL) != 0)
			{
				crc = crc << 1;
				crc = crc ^ CRC_16_POLYNOMIAL;
			} else {
				crc = crc << 1;
			}

			if ((*buf_ptr & i) != 0)
			{
				crc = crc ^ CRC_16_POLYNOMIAL;
			}
		}
		buf_ptr++;
	}
	return (crc);
}

static int skw_request_firmwares(struct seekwave_device *boot_data,
	const char *dram_image_name, const char *iram_image_name, const char *nv_mem_name)
{
	int ret;
	const struct firmware *fw;

	skwboot_log("firmware: %s %s\n", dram_image_name, iram_image_name);
	ret = request_firmware(&fw, dram_image_name, NULL);
	if (ret) {
		pr_err("request_firmware %s fail\n", dram_image_name);
		goto ret;
	}

	if (fw->size <= 0) {
		ret = -EINVAL;
		goto relese_fw;
	}

	boot_data->dram_img_data = (char *)vmalloc(fw->size);
	if (!boot_data->dram_img_data) {
		pr_err("alloc dram memory failed\n");
		ret = -ENOMEM;
		goto relese_fw;
	}
	skwboot_log("boot data dram_img_data %p\n", boot_data->dram_img_data);
	memcpy(boot_data->dram_img_data, fw->data, fw->size);
	boot_data->dram_dl_size = fw->size;
	release_firmware(fw);
	//dram crc16
	boot_data->dram_crc_en = 1;
	boot_data->dram_crc_offset = 0;
	boot_data->dram_crc_val = crc_16_l_calc(boot_data->dram_img_data + boot_data->dram_crc_offset, boot_data->dram_dl_size);

	ret = request_firmware(&fw, iram_image_name, NULL);
	if (ret) {
		pr_err("request_firmware %s fail ret %d\n", iram_image_name, ret);
		if (!fw) {
			vfree(boot_data->dram_img_data);
			boot_data->dram_img_data = NULL;
			boot_data->dram_dl_size = 0;
			return ret;
		}
	}

	if (fw->size <= 0) {
		ret = -EINVAL;
		goto relese_fw;
	}

	boot_data->iram_img_data = (char *)vmalloc(fw->size);
	if (!boot_data->iram_img_data) {
		pr_err("alloc iram memory failed\n");
		ret = -ENOMEM;
		goto relese_fw;
	}
	memcpy(boot_data->iram_img_data, fw->data, fw->size);
	boot_data->iram_dl_size = fw->size;
	release_firmware(fw);
	ret = 0;
	//iram crc16
	boot_data->iram_crc_en = 1;
	boot_data->iram_crc_offset = 0;
	boot_data->iram_crc_val = crc_16_l_calc(boot_data->iram_img_data + boot_data->iram_crc_offset, boot_data->iram_dl_size);
	skwboot_log("boot data iram_img_data %p\n", boot_data->iram_img_data);

	ret = request_firmware(&fw, nv_mem_name, NULL);
	if (ret) {
		skwboot_err(" NV image request_firmware %s fail\n", nv_mem_name);
		ret = 0;
		goto ret;
	}

	boot_data->nv_mem_data = (char *)kzalloc(fw->size, GFP_KERNEL);
	if (!boot_data->nv_mem_data) {
		skwboot_err("alloc nv memory failed\n");
		goto relese_fw;
	}
	memcpy(boot_data->nv_mem_data, fw->data, fw->size);
	boot_data->nv_mem_size = fw->size;
	ret = 0;
	boot_data->nvmem_crc_en = 1;
	boot_data->nvmem_crc_offset = 0;
	boot_data->nvmem_crc_val = crc_16_l_calc(boot_data->nv_mem_data + boot_data->nvmem_crc_offset, boot_data->nv_mem_size);

relese_fw:
	release_firmware(fw);
ret:
	return ret;
}
#endif

static int seekwave_boot_parse_dt(struct platform_device *pdev, struct seekwave_device *boot_data)
{
	int ret = 0;
	enum of_gpio_flags flags;
	struct device_node *np = pdev->dev.of_node;
	/*add the dma type dts config*/
	if (of_property_read_u32(np, "bt_antenna", &boot_data->bt_antenna)) {
		skwboot_warn("no BT_antenna setting\n");
		boot_data->bt_antenna = 0;
	} else
		skwboot_log("BT_antenna setting: %d\n", boot_data->bt_antenna);

	if (of_property_read_u32(np, "dma_type", &boot_data->dma_type)) {
		boot_data->dma_type = ADMA;
		boot_data->chip_en = MODEM_ENABLE_GPIO;
		boot_data->host_gpio =  HOST_WAKEUP_GPIO_IN;
		boot_data->chip_gpio =  MODEM_WAKEUP_GPIO_OUT;
		boot_data->skw_nv_name =  SEEKWAVE_NV_NAME;
		boot_data->iram_file_path =  SKW_IRAM_FILE_PATH;
		boot_data->dram_file_path =  SKW_DRAM_FILE_PATH;

		if (boot_data->chip_en >= 0)
			boot_data->chip_en = (boot_data->chip_en << 1) | SKW_POWER_OFF_VALUE;
		skwboot_warn("no DTS setting\n");
	} else {
		/*-add the iram img file path dts-*/
		ret = of_property_read_string(np, "skw_iram_path", (const char **)&boot_data->iram_file_path);
		if (ret < 0) {
			skwboot_err("%s:iram path fail ret=%d\n", __func__, ret);
		}
		/*-add the dram img file path dts-*/
		ret = of_property_read_string(np, "skw_dram_path", (const char **)&boot_data->dram_file_path);
		if (ret < 0) {
			skwboot_err("%s: dram path fail ret=%d\n", __func__, ret);
		}

		boot_data->host_gpio = of_get_named_gpio_flags(np, "gpio_host_wake", 0, &flags);
		boot_data->chip_gpio = of_get_named_gpio_flags(np, "gpio_chip_wake", 0, &flags);
		boot_data->chip_en = of_get_named_gpio_flags(np, "gpio_chip_en", 0, &flags);
		ret = of_property_read_string(np, "seekwave_nv_name", (const char **)&boot_data->skw_nv_name);
		if (ret < 0) {
			skwboot_err("%s:nv name get fail ret=%d\n", __func__, ret);
		}
		if (boot_data->chip_en >= 0)
			boot_data->chip_en = (boot_data->chip_en << 1) | (flags & 1);
	}
	if (test_debug == 1) {//test debug inband irq and nosleep en
		boot_data->chip_gpio =  -1;
		boot_data->host_gpio =  -1;
	}
	if (boot_data->host_gpio >= 0) {
		ret = devm_gpio_request_one(&pdev->dev, boot_data->host_gpio, GPIOF_IN, "HOST_WAKE");
		if (ret < 0) {
			gpio_free(boot_data->host_gpio);
			devm_gpio_request_one(&pdev->dev, boot_data->host_gpio, GPIOF_IN, "HOST_WAKE");
		}
		if (boot_data->chip_gpio >= 0) {
			ret = devm_gpio_request_one(&pdev->dev, boot_data->chip_gpio, GPIOF_OUT_INIT_HIGH, "CHIP_WAKE");
			if (ret < 0)
				skwboot_err("%s:gpio_chip request fail ret=%d\n", __func__, ret);
			else
				gpio_set_value(boot_data->host_gpio, 1);
		}
	}

	if (boot_data->chip_gpio >= 0 && boot_data->host_gpio >= 0) {
		boot_data->slp_disable = 0;
	} else {
		boot_data->slp_disable = 1;
	}
	if (boot_data->chip_en >= 0) {
		if (flags & 0x01)
			ret = devm_gpio_request_one(&pdev->dev, boot_data->chip_en >> 1, GPIOF_OUT_INIT_LOW, "CHIP_EN");
		else
			ret = devm_gpio_request_one(&pdev->dev, boot_data->chip_en >> 1, GPIOF_OUT_INIT_HIGH, "CHIP_EN");
	}

	skwboot_log("%s, chipen:%d gpio_out:%d gpio_in:%d ret=%d\n", __func__, boot_data->chip_en,
			boot_data->chip_gpio, boot_data->host_gpio, ret);
	return ret;
}

/************************************************************************/
//Description: BT start service
//Func: BT start service
//Call：
//Author:junwei.jiang
//Date:2021-11-1
//Modify:
/************************************************************************/
static int bt_start_service(int id, void *callback, void *data)
{
	int ret = 0;

	if (cp_exception_sts)
		return -1;

	ret = skw_start_bt_service();
	if (ret < 0) {
		skwboot_err("%s boot bt fail\n", __func__);
		return -1;
	}
	skwboot_log("%s line:%d  boot sucessfuly\n", __func__, __LINE__);
	return 0;
}

/************************************************************************/
//Description: BT stop service
//Func: BT stop service
//Call：
//Author:junwei.jiang
//Date:2021-11-1
//Modify:
/************************************************************************/
static int bt_stop_service(int id)
{
	int ret = 0;

	if (cp_exception_sts)
		return 0;

	ret = skw_stop_bt_service();
	if (ret < 0) {
		skwboot_err("%s boot bt fail\n", __func__);
		return -1;
	}
	skwboot_log("bt_stop_service OK\n");
	return 0;
}

/****************************************************************
 *Description:iram read the double img file
 *Func:
 *Calls:
 *Call By:sdio_dloader
 *Input:the file path
 *Output:download data and the data size dl_data image_size
 *Return：0:pass other fail
 *Others:
 *Author：JUNWEI.JIANG
 *Date:2022-02-07
 * **************************************************************/
#if defined(CONFIG_SEEKWAVE_FIRMWARE_LOAD)
static int skw_iram_img_read(struct seekwave_device *boot_data)
{
	struct file *filep = NULL;

	mm_segment_t old_fs;
	int err = 0;

	if (!boot_data->iram_file_path) {
		skwboot_err("iram_file_path NULL!!\n");
		return -1;
	}

	old_fs = get_fs();
	set_fs(KERNEL_DS);
	filep = filp_open(boot_data->iram_file_path, O_RDONLY, 0);
	if (IS_ERR(filep)) {
		skwboot_err("%s: Failed to open the file %s\n", __func__, boot_data->iram_file_path);
		filep = filp_open(boot_data->iram_file_path, O_RDONLY, 0664);
		if (IS_ERR(filep)) {
			err = PTR_ERR(filep);
			skwboot_err("open file error, err = %d\n", err);
			goto fail;
		}
		skwboot_log("file bin path = %s\n", boot_data->iram_file_path);
	}
#if  LINUX_VERSION_CODE <= KERNEL_VERSION(4, 10, 0)
	struct kstat stat;

	err = vfs_stat(boot_data->iram_file_path, &stat);
	if (err) {
		skwboot_err("%s:%s vfs_stat fail !\n", __func__, boot_data->iram_file_path);
		goto fail;
	}
	boot_data->iram_dl_size = (int)stat.size;
	if (boot_data->iram_dl_size == 0) {
		skwboot_err("%s:iram dl size fail ! imgsize=0x%x\n", __func__,
				boot_data->iram_dl_size);
		goto fail;
	}
#else
	boot_data->iram_dl_size = filep->f_inode->i_size;
	if (boot_data->iram_dl_size == 0) {
		skwboot_err("%s:iram dl size fail ! imgsize=0x%x\n", __func__,
				boot_data->iram_dl_size);
		goto fail;
	}
	skwboot_log("file bin iram_dl_size = %d\n", boot_data->iram_dl_size);
#endif

	boot_data->iram_img_data = (char *)vmalloc(boot_data->iram_dl_size);
	if (!boot_data->iram_img_data) {
		goto fail1;
	}
	if (skw_read_file(filep, boot_data->iram_img_data, boot_data->iram_dl_size, &filep->f_pos) != boot_data->iram_dl_size) {
		goto fail1;
	}

	set_fs(old_fs);
	filp_close(filep, NULL);
	return 0;
fail:
	if (!IS_ERR(filep) && filep) {
		filp_close(filep, NULL);
		skwboot_err("%s: analysis the done - '%s'\n", __func__, boot_data->iram_file_path);
	}
	set_fs(old_fs);
	return -3;
fail1:
	if (!IS_ERR(filep)) {
		filp_close(filep, NULL);
	}
	set_fs(old_fs);
	return -1;
}
#endif
/****************************************************************
 *Description:dram read the double img file
 *Func:
 *Calls:
 *Call By:sdio_dloader
 *Input:the file path
 *Output:download data and the data size dl_data image_size
 *Return：0:pass other fail
 *Others:
 *Author：JUNWEI.JIANG
 *Date:2022-02-07
 * **************************************************************/
#if defined(CONFIG_SEEKWAVE_FIRMWARE_LOAD)
static int skw_dram_img_read(struct seekwave_device *boot_data)
{
	struct file *filep = NULL;
	mm_segment_t old_fs;
	int error = 0;

	if (!boot_data->dram_file_path) {
		skwboot_err("dram_file_path NULL!!\n");
		return -1;
	}

	old_fs = get_fs();
	set_fs(KERNEL_DS);

	filep = filp_open(boot_data->dram_file_path, O_RDONLY, 0);
	if (IS_ERR(filep)) {
		skwboot_err("%s: Failed to open the file %s\n", __func__, boot_data->dram_file_path);
		filep = filp_open(boot_data->dram_file_path, O_RDONLY, 0664);
		if (IS_ERR(filep)) {
			error = PTR_ERR(filep);
			skwboot_err("open file error, err = %d\n", error);
			goto fail;
		}
		skwboot_log("file bin path = %s\n", boot_data->dram_file_path);
	}
#if  LINUX_VERSION_CODE <= KERNEL_VERSION(4, 10, 0)
	struct kstat stat;

	error = vfs_stat(boot_data->dram_file_path, &stat);
	if (error) {
		skwboot_err("%s: get the img size fail the vfs_stat fail -- %s\n", __func__, boot_data->dram_file_path);
		goto fail;
	}
	boot_data->dram_dl_size = (int)stat.size;
	if (boot_data->dram_dl_size == 0) {
		skwboot_err("%s:dram dl size fail ! imgsize=0x%x\n", __func__,
				boot_data->dram_dl_size);
		goto fail;
	}
#else
	boot_data->dram_dl_size = filep->f_inode->i_size;
	if (boot_data->dram_dl_size == 0) {
		skwboot_err("%s:iram dl size fail ! imgsize=0x%x\n", __func__,
				boot_data->dram_dl_size);
		goto fail;
	}
#endif
	skwboot_log("file bin dram_dl_size = %d\n", boot_data->dram_dl_size);
	boot_data->dram_img_data = (char *)vmalloc(boot_data->dram_dl_size);
	if (!boot_data->dram_img_data) {
		goto fail1;
	}
	if (skw_read_file(filep, boot_data->dram_img_data, boot_data->dram_dl_size, &filep->f_pos) != boot_data->dram_dl_size) {
		goto fail1;
	}

	set_fs(old_fs);
	filp_close(filep, NULL);
	return 0;
fail:
	if (!IS_ERR(filep) && filep) {
		filp_close(filep, NULL);
		skwboot_err("%s: analysis the done - '%s'\n", __func__, boot_data->dram_file_path);
	}
	set_fs(old_fs);
	return -3;
fail1:
	if (!IS_ERR(filep)) {
		filp_close(filep, NULL);
	}
	set_fs(old_fs);
	return -1;
}
#endif
/***************************************************************************
 *Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 **************************************************************************/
static int seekwave_boot_probe(struct  platform_device *pdev)
{
	int ret;
	int time_count = 0;
	void *io_bus;
	struct device *dev = NULL;

	boot_data = devm_kzalloc(&pdev->dev, sizeof(struct seekwave_device), GFP_KERNEL);
	if (!boot_data) {
		skwboot_err("%s :kzalloc error !\n", __func__);
		return -ENOMEM;
	}
	mutex_init(&boot_mutex);
	seekwave_boot_parse_dt(pdev, boot_data);
	io_bus = skw_get_bus_dev();
	if (!io_bus) {
		skwboot_log("%s :CHIP_RESET AGAIN!\n", __func__);
		SKW_CHIP_POWEROFF(boot_data->chip_en);
		msleep(20);
		SKW_CHIP_POWERON(boot_data->chip_en);
		do {
			msleep(10);
			io_bus = skw_get_bus_dev();
		} while (!io_bus && time_count++ < 50);
	} else
		usb_chip_enable_gpio = -1;
	if (!io_bus) {
		skwboot_err("%s get bus dev fail !\n", __func__);
		return -ENODEV;
	}
	dev = io_bus;
	if (!strncmp(dev->bus->name, "usb", 3)) {
		boot_data->iram_file_path = "SWT6621_IRAM_USB.bin";
		boot_data->dram_file_path = "SWT6621_DRAM_USB.bin";
	} else {
		boot_data->iram_file_path = "SWT6621_IRAM_SDIO.bin";
		boot_data->dram_file_path = "SWT6621_DRAM_SDIO.bin";
	}
	skw_boot_init(boot_data);
#ifdef STR_MODE_REINITBUS
	boot_data->pdev = pdev;
#endif
	printk("bus type: %s\n", dev->bus->name);
	if (usb_chip_enable_gpio >= 0 && dev->type->name &&
	    !strncmp(dev->bus->name, "usb", 3))
		boot_data->chip_en = usb_chip_enable_gpio;
	ret = skw_first_boot(boot_data);
	if (strncmp(dev->bus->name, "usb", 3))
		skw_bind_boot_driver(io_bus);
	return ret;
}
/***************************************************************************
 *Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 **************************************************************************/
static int seekwave_boot_remove(struct  platform_device *pdev)
{
	skwboot_log("%s the Enter\n", __func__);

	if (btboot_pdev) {
		platform_device_unregister(btboot_pdev);
		btboot_pdev = NULL;
	}
	if (boot_data) {
		if (boot_data->iram_img_data) {
			vfree(boot_data->iram_img_data);
			boot_data->iram_img_data = NULL;
		}
		if (boot_data->dram_img_data) {
			vfree(boot_data->dram_img_data);
			boot_data->dram_img_data = NULL;
		}

		boot_data->iram_file_path = NULL;
		boot_data->dram_file_path = NULL;
		devm_kfree(&pdev->dev, boot_data);
		boot_data = NULL;
	}
	mutex_destroy(&boot_mutex);
	return 0;
}

extern void skw_modem_log_stop_rec(void);
static void seekwave_boot_shutdown(struct platform_device *pdev)
{
	skw_modem_log_stop_rec();
	skw_reset_bus_dev();
}

static const struct of_device_id seekwave_match_table[] = {
	{ .compatible = "seekwave,sv6160"},
	{ },
};

static struct platform_driver seekwave_driver = {
	.driver = {
		.owner = THIS_MODULE,
		.name  = "sv6160",
		.of_match_table = seekwave_match_table,
	},
	.probe = seekwave_boot_probe,
	.remove = seekwave_boot_remove,
	.shutdown = seekwave_boot_shutdown,
};

/***********************************************************************
 *Description:BT download boot pdata
 *Seekwave tech LTD
 *Author:junwei.jiang
 *Date:2021-11-3
 *Modify:
 ***********************************************************************/
struct sv6160_platform_data boot_pdata = {
	.data_port = 8,
	.bus_type = SDIO_LINK,
	.max_buffer_size = 0x800,
	.align_value = 4,
	.open_port = bt_start_service,
	.close_port = bt_stop_service,
};

/***************************************************************
 *Description:BT bind boot driver
 *Seekwave tech LTD
 *Author:junwei.jiang
 *Date:2021-11-3
 *Modify:
***************************************************************/
int skw_bind_boot_driver(struct device *dev)
{
	struct platform_device *pdev;
	char	pdev_name[32];
	int ret = 0;

	sprintf(pdev_name, "skw_ucom");
/*
 *	creaete BT DATA device
 */
	if (!dev) {
		skwboot_err("%s the dev fail\n", __func__);
		return -1;
	}
	pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
	if (!pdev)
		return -ENOMEM;
	pdev->dev.parent = dev;
	pdev->dev.dma_mask = &port_dmamask;
	pdev->dev.coherent_dma_mask = port_dmamask;
	boot_pdata.port_name = "BTBOOT";
	boot_pdata.data_port = 8;
	ret = platform_device_add_data(pdev, &boot_pdata, sizeof(boot_pdata));
	if (ret) {
		dev_err(dev, "failed to add boot data\n");
		platform_device_put(pdev);
		return ret;
	}
	ret = platform_device_add(pdev);
	if (ret) {
		platform_device_put(pdev);
		skwboot_err("%s,line:%d the device add fail\n", __func__, __LINE__);
		return ret;
	}
	btboot_pdev = pdev;
	return ret;
}

/****************************************************************
 *Description:the data Little Endian process interface
 *Func:EndianConv_32
 *Calls:None
 *Call By:The img data process
 *Input:value
 *Output:the Endian data
 *Return：value
 *Others:
 *Author：JUNWEI.JIANG
 *Date:2021-08-26
 * **************************************************************/
unsigned int EndianConv_32(unsigned int value)
{
#ifdef _LITTLE_ENDIAN
	unsigned int nTmp = (value >> 24 | value << 24);

	nTmp |= ((value >> 8) & 0x0000FF00);
	nTmp |= ((value << 8) & 0x00FF0000);
	return nTmp;
#else
	return value;
#endif
}

/****************************************************************
 *Description:dram read the double img file
 *Func:
 *Calls:
 *Call By:
 *Input:the file path
 *Output:download data and the data size dl_data image_size
 *Return：0:pass other fail
 *Others:
 *Author：JUNWEI.JIANG
 *Date:2022-02-07
 * **************************************************************/
int skw_download_signal_ops(void)
{
	unsigned int tmp_signal = 0;
	//download done flag ++
	dl_signal_acount++;
	tmp_signal = dl_signal_acount;
	boot_data->dl_done_signal = 0xff & tmp_signal;
	boot_data->dl_acount_addr = SKW_SDIO_PD_DL_AP2CP_BSP;

	//gpio need set high or low power interrupt to cp wakeup
	boot_data->gpio_out = boot_data->chip_gpio;
	if (boot_data->gpio_val)
		boot_data->gpio_val = 0;
	else
		boot_data->gpio_val = 1;
	skwboot_log("%s line:%d download data ops done\n", __func__, __LINE__);
	return 0;
}

/****************************************************************
 *Description:analysis the double img dram iram
 *Func:
 *Calls:
 *Call By:
 *Input:the file path
 *Output:download data and the data size dl_data image_size
 *Return：0:pass other fail
 *Others:
 *Author：JUNWEI.JIANG
 *Date:2022-02-07
 * **************************************************************/
int skw_boot_init(struct seekwave_device *boot_data)
{
	int i = 0;
	int k = 0;
	unsigned int head_offset = 0;
	unsigned int tail_offset = 0;
	int ret = 0;
	struct img_head_data_t dl_data_info;
	unsigned int *data = NULL;
	unsigned int *nvdata = NULL;
	unsigned int *dl_addr_data = NULL;
#if defined(CONFIG_SEEKWAVE_FIRMWARE_LOAD)
	//read the iram data from file
	//boot_data->iram_file_path = "/vendor/etc/firmware/ROM_EXEC_KERNEL_IRAM.bin";
	ret = skw_iram_img_read(boot_data);
	if (ret != 0) {
		skwboot_err("%s:read iram file fail\n", __func__);
		//return -1;
		boot_data->iram_img_data = NULL;
		boot_data->iram_dl_size = 0;
	}
	//read the dram data from file
	//boot_data->dram_file_path = "/vendor/etc/firmware/RAM_RW_KERNEL_DRAM.bin";
	ret = skw_dram_img_read(boot_data);
	if (ret != 0) {
		skwboot_err("%s:read dram file fail\n", __func__);
		boot_data->dram_img_data = NULL;
		boot_data->dram_dl_size = 0;
	}
#else
	ret = skw_request_firmwares(boot_data, boot_data->dram_file_path,
		boot_data->iram_file_path, boot_data->skw_nv_name);
	if (ret < 0) {
		ret = skw_request_firmwares(boot_data, "RAM_RW_KERNEL_DRAM.bin",
			"ROM_EXEC_KERNEL_IRAM.bin", boot_data->skw_nv_name);
		if (ret < 0)
			return ret;
	}
	skwboot_log("image_size=%d,%d, ret=%d\n", boot_data->iram_dl_size, boot_data->dram_dl_size, ret);
#endif
	boot_data->head_addr = 0;
	boot_data->tail_addr = 0;
	boot_data->bsp_head_addr = 0;
	boot_data->bsp_tail_addr = 0;
	boot_data->wifi_head_addr = 0;
	boot_data->wifi_tail_addr = 0;
	boot_data->bt_head_addr = 0;
	boot_data->bt_tail_addr = 0;
	boot_data->nv_head_addr = 0;
	boot_data->nv_tail_addr = 0;
	boot_data->nv_data_size = 0;

	if (boot_data->iram_img_data) {
		/*analysis the img*/
		for (i = 0; i * IMG_HEAD_OPS_LEN < IMG_HEAD_INFOR_RANGE; i++)
		{
			if (!head_offset)
			{
				if ((0 == memcmp(CP_IMG_HEAD0, boot_data->iram_img_data + i * IMG_HEAD_OPS_LEN, IMG_HEAD_OPS_LEN)) && 
						(0 == memcmp(CP_IMG_HEAD1, boot_data->iram_img_data + (i + 1) * IMG_HEAD_OPS_LEN, IMG_HEAD_OPS_LEN)))
					head_offset = (i + 1) * IMG_HEAD_OPS_LEN;
			} else if (!tail_offset) {
				if ((0 == memcmp(CP_IMG_TAIL0, boot_data->iram_img_data + i * IMG_HEAD_OPS_LEN, IMG_HEAD_OPS_LEN)) && 
						(0 == memcmp(CP_IMG_TAIL1, boot_data->iram_img_data + (i + 1) * IMG_HEAD_OPS_LEN, IMG_HEAD_OPS_LEN))) {
					tail_offset = (i - 1) * IMG_HEAD_OPS_LEN;
					break;
				}
			}
		}

		/*analysis the nv*/
		for (k = 0; k * IMG_HEAD_OPS_LEN < IMG_HEAD_INFOR_RANGE; k++)
		{
			if (!boot_data->nv_head_addr)
			{
				if (0 == memcmp(CP_NV_HEAD, boot_data->iram_img_data + k * IMG_HEAD_OPS_LEN, IMG_HEAD_OPS_LEN))
					boot_data->nv_head_addr = k * IMG_HEAD_OPS_LEN;
			} else if (!boot_data->nv_tail_addr) {
				if ((0 == memcmp(CP_NV_TAIL, boot_data->iram_img_data + k * IMG_HEAD_OPS_LEN, IMG_HEAD_OPS_LEN))) {
					boot_data->nv_tail_addr = k * IMG_HEAD_OPS_LEN;
					boot_data->nv_data_size = boot_data->nv_tail_addr - boot_data->nv_head_addr - IMG_HEAD_OPS_LEN;
					nvdata = (u32 *)&boot_data->iram_img_data[boot_data->nv_head_addr];
					print_hex_dump(KERN_ERR, "nv data ", 0, 16, 1, nvdata, boot_data->nv_data_size + 8, 1);
					break;
				}
			}
		}
		if (!tail_offset) {
			skwboot_err("%s,%d,the iram_img not need analysis!!! or Fail!!\n", __func__, __LINE__);
			//boot_data->iram_img_data = NULL;
			return -1;
		} else {
			//get the iram img addr and dram img addr
			dl_addr_data = (unsigned int *)(boot_data->iram_img_data + head_offset + IMG_HEAD_OPS_LEN);
			boot_data->iram_dl_addr = dl_addr_data[0];
			boot_data->dram_dl_addr = dl_addr_data[1];
			head_offset = head_offset + RAM_ADDR_OPS_LEN;//jump the ram addr data;

			skwboot_log("%s line:%d,the tail_offset ---0x%x, the head_offset --0x%x ,iram_addr=0x%x,dram_addr=0x%x, \
					nv_head_addr:0x%x,nv_tail_addr:0x%x,nv_size=%d\n", __func__, __LINE__, tail_offset, head_offset,
					boot_data->iram_dl_addr, boot_data->dram_dl_addr, boot_data->nv_head_addr, boot_data->nv_tail_addr,
					boot_data->nv_data_size);
		}
		/*need download the img bin for WIFI or BT service dl_module >0*/
		head_offset = head_offset + IMG_HEAD_OPS_LEN;
		/*get the img head tail offset*/
		boot_data->head_addr = head_offset;
		boot_data->tail_addr = tail_offset;

		skwboot_log("%s line:%d analysis the img module\n", __func__, __LINE__);
		for (i = 0; i * MODULE_INFO_LEN <= (tail_offset - head_offset); i++)
		{
			data = (unsigned int *)(boot_data->iram_img_data + head_offset + i * MODULE_INFO_LEN);
			dl_data_info.dl_addr = data[0];
			dl_data_info.write_addr = data[2];
			dl_data_info.index = 0x000000FF & EndianConv_32(data[1]);
			dl_data_info.data_size = 0x00FFFFFF & data[1];
			skwboot_log("%s line:%d dl_addr=0x%x, write_addr=0x%x, index=0x%x,data_size=0x%x\n", __func__,
					__LINE__, dl_data_info.dl_addr, dl_data_info.write_addr, dl_data_info.index, dl_data_info.data_size);
		}
		if (boot_data->nv_mem_size && (boot_data->nv_mem_size <= boot_data->nv_data_size)) {
			memcpy((boot_data->iram_img_data + boot_data->nv_head_addr + 4), boot_data->nv_mem_data, boot_data->nv_mem_size);
			kfree(boot_data->nv_mem_data);
			boot_data->nv_mem_data = NULL;
		}
	}
	return 0;
}

/***************************************************************************
 *Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 **************************************************************************/
int skw_start_wifi_service(void)
{
	int ret = 0;

	skwboot_log("%s Enter cp_state =%d\n", __func__, cp_exception_sts);
	mutex_lock(&boot_mutex);
	boot_data->service_ops = SKW_WIFI_START;
	boot_data->dl_module = SKW_WIFI_BOOT;
	boot_data->first_dl_flag = 1;
	//download done flag ++
	skw_download_signal_ops();
	ret = skw_boot_loader(boot_data);
	mutex_unlock(&boot_mutex);
	if (ret != 0)
	{
		skwboot_err("%s,line:%d boot fail\n", __func__, __LINE__);
		return -1;
	}

	skwboot_log("%s wifi boot sucessfull\n", __func__);
	return 0;
}
EXPORT_SYMBOL_GPL(skw_start_wifi_service);

/***************************************************************************
 *Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 **************************************************************************/
int skw_stop_wifi_service(void)
{
	int ret = 0;

	skwboot_log("%s Enter cp_state =%d\n", __func__, cp_exception_sts);
	mutex_lock(&boot_mutex);
	boot_data->service_ops = SKW_WIFI_STOP;
	boot_data->dl_module = 0;
	boot_data->first_dl_flag = 1;
	//download done flag ++
	//gpio need set high or low power interrupt to cp wakeup
	boot_data->gpio_out = boot_data->chip_gpio;
	if (boot_data->gpio_val)
		boot_data->gpio_val = 0;
	else
		boot_data->gpio_val = 1;
	ret = skw_boot_loader(boot_data);
	mutex_unlock(&boot_mutex);
	if (ret != 0)
	{
		skwboot_err("dload the img fail\n");
		return -1;
	}
	skwboot_log("seekwave boot stop done:%s\n", __func__);
	return 0;
}
EXPORT_SYMBOL_GPL(skw_stop_wifi_service);

/***************************************************************************
 *Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 **************************************************************************/
int skw_start_bt_service(void)
{
	int ret = 0;

	skwboot_log("%s Enter cp_state =%d\n", __func__, cp_exception_sts);
	mutex_lock(&boot_mutex);
	boot_data->service_ops = SKW_BT_START;
	boot_data->first_dl_flag = 1;
	boot_data->dl_module = SKW_BT_BOOT;
	//download done flag ++
	skw_download_signal_ops();
	ret = skw_boot_loader(boot_data);
	mutex_unlock(&boot_mutex);
	if (ret != 0)
	{
		skwboot_err("%s boot fail\n", __func__);
		return -1;
	}

	skwboot_log("%s line:%d , boot bt sucessfully!\n", __func__, __LINE__);
	return 0;
}
EXPORT_SYMBOL_GPL(skw_start_bt_service);

/***************************************************************************
 *Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 **************************************************************************/

int skw_stop_bt_service(void)
{
	int ret = 0;

	skwboot_log("%s Enter cp_state =%d\n", __func__, cp_exception_sts);
	mutex_lock(&boot_mutex);
	boot_data->service_ops = SKW_BT_STOP;
	boot_data->first_dl_flag = 1;
	//download done flag ++
	boot_data->dl_module = 0;
	//gpio need set high or low power interrupt to cp wakeup
	boot_data->gpio_out = boot_data->chip_gpio;
	if (boot_data->gpio_val)
		boot_data->gpio_val = 0;
	else
		boot_data->gpio_val = 1;
	ret = skw_boot_loader(boot_data);
	mutex_unlock(&boot_mutex);
	if (ret < 0)
	{
		skwboot_err("dload the img fail\n");
		return -1;
	}
	skwboot_log("seekwave boot stop done:%s\n", __func__);
	return 0;
}
EXPORT_SYMBOL_GPL(skw_stop_bt_service);

/****************************************************************
 *Description:double iram dram img first boot cp
 *Func:
 *Calls:
 *Call By:skw_first_boot
 *Input:the file path
 *Output:download data and the data size dl_data image_size
 *Return：0:pass other fail
 *Others:
 *Author：JUNWEI.JIANG
 *Date:2022-02-07
 * **************************************************************/
int skw_first_boot(struct seekwave_device *boot_data)
{
	int ret = 0;
	//get the img data
#ifdef DEBUG_SKWBOOT_TIME
	ktime_t cur_time, last_time;

	cur_time = ktime_get();
#endif
	//set download the value;
	boot_data->service_ops = SKW_NO_SERVICE;
	boot_data->save_setup_addr = SKW_SDIO_PD_DL_AP2CP_BSP; //160
	boot_data->gpio_out = boot_data->chip_gpio;
	boot_data->gpio_val = 0;
	boot_data->dl_module = 0;
	boot_data->first_dl_flag = 0;
	boot_data->gpio_in  = boot_data->host_gpio;
	boot_data->dma_type_addr = SKW_SDIO_PLD_DMA_TYPE;
	boot_data->slp_disable_addr = SKW_SDIO_CP_SLP_SWITCH;

	ret = skw_boot_loader(boot_data);
	if (ret < 0) {
		skwboot_err("%s firt boot cp fail\n", __func__);
		return -1;
	}
	//download done set the download flag;
	boot_data->first_dl_flag = 1;

	//download done tall cp acount;
	boot_data->dl_done_signal &= 0xFF;
	boot_data->dl_done_signal += 1;
	skwboot_log("%s first boot pass\n", __func__);
#ifdef DEBUG_SKWBOOT_TIME
	last_time = ktime_get();
	skwboot_log("%s,the download time start time %llu and the over time %llu\n",
			__func__, cur_time, last_time);
#endif
	return ret;
}

#ifdef CONFIG_NO_DTS
//#undef CONFIG_OF
#endif

//#ifndef CONFIG_OF
static void seekwave_release(struct device *dev)
{
}

static struct platform_device seekwave_device = {
	.name = "sv6160",
	.dev = {
		.release = seekwave_release,
	}
};

//#endif
int seekwave_boot_init(void)
{
	btboot_pdev = NULL;
	skw_ucom_init();
//#ifndef CONFIG_OF
	printk("NO DTS CONFIG BOOT INIT !!!\n");
	platform_device_register(&seekwave_device);
//#endif
	return platform_driver_register(&seekwave_driver);
}

void seekwave_boot_exit(void)
{
	skw_ucom_exit();
//#ifndef CONFIG_OF
	platform_device_unregister(&seekwave_device);
//#endif
	platform_driver_unregister(&seekwave_driver);
}

===== ./drivers/seekwaveplatform/skwutil/skw_log_to_file.c =====
/*****************************************************************
 *Copyright (C) 2021 Seekwave Tech Inc.
 *Filename : skw_log_process.c
 *Authors:seekwave platform
 *
 * This software is licensed under the terms of the GNU
 * General Public License version 2, as published by the Free
 * Software Foundation, and may be copied, distributed, and
 * modified under those terms.
 *
 * This program is distributed in the hope that it will be usefull,
 * but without any warranty;without even the implied warranty of
 * merchantability or fitness for a partcular purpose. See the
 * GUN General Public License for more details.
 * **************************************************************/

/* #define DEBUG */
/* #define VERBOSE_DEBUG */

#include <linux/kernel.h>
#include <linux/cdev.h>
#include <linux/fs.h>
#include <linux/slab.h>
#include <linux/uaccess.h>
#include <linux/workqueue.h>
#include <linux/scatterlist.h>
#include <linux/platform_device.h>
#include <linux/poll.h>
#include <linux/delay.h>
#include <linux/wait.h>
#include <linux/err.h>
#include <linux/version.h>
#include <linux/types.h>
#include <linux/file.h>
#include <linux/device.h>
#include <linux/miscdevice.h>
#include "skw_boot.h"

#include "skw_log_to_file.h"
#include "sv6160_mem_map.h"
extern int cp_exception_sts;
static char *log_path = "/data";
module_param(log_path, charp, 0644);

int skw_log_num = 2;
#ifdef MIN_LOG_SIZE
int skw_log_size = (1 * 1024 * 1024);
#else
int skw_log_size = (100 * 1024 * 1024);
#endif
#define SKW_LOG_READ_BUFFER_SIZE (8 * 1024)

#ifndef CONFIG_NO_GKI
//#define CONFIG_NO_GKI
#endif

module_param(skw_log_size, int, 0644);
module_param(skw_log_num, int, 0644);

struct skw_log_data	{
	spinlock_t lock;

	int state;

	/* synchronize access to our device file */
	atomic_t open_excl;
	/* to enforce only one ioctl at a time */
	atomic_t ioctl_excl;

	int rx_done;
	/* for processing MTP_SEND_FILE, MTP_RECEIVE_FILE and
	 * MTP_SEND_FILE_WITH_HEADER ioctls on a work queue
	 */
	struct workqueue_struct *wq;
	struct workqueue_struct *dumpq;
	struct work_struct log_to_file_work;
	struct file *xfer_file;
	loff_t xfer_file_offset;
	s64 xfer_file_length;
	unsigned int xfer_send_header;
	u16 xfer_command;
	u32 xfer_transaction_id;
	int xfer_result;
};

struct log_com_dev	{
	atomic_t open;
	spinlock_t lock;
	int	rx_busy;
	int	tx_busy;
	int	devno;
	int	portno;
	struct sv6160_platform_data *pdata;
	wait_queue_head_t wq;
	wait_queue_head_t dumpq;
	struct cdev cdev;
	char	*rx_buf;
	char	*tx_buf;
	struct notifier_block notifier;
};

struct skw_log_read_buffer	{
	int	lenth;
	char	*buffer;
};

void skw_modem_log_to_file_work(struct work_struct *data);
extern int skw_cp_exception_reboot(void);

int skw_modem_save_dumpmem(void);
static u32 record_flag;
static u32 dumpmodem_flag;
static u32 cp_assert_status;
struct file *log_fp;
struct log_com_dev *log_com;
struct sv6160_platform_data *port_data;
struct skw_log_data *skw_log_dev;
struct skw_log_read_buffer log_read_buffer;

char *log0_file = "log000";
char *log1_file = "log111";
char *log_file;

char *skw_code_mem = "code_mem_100000_7a000";
char *skw_data_mem = "data_mem_20200000_40000";
char *skw_cscb_mem = "cscb_mem_e000ed00_300";
char *skw_wreg_mem = "wreg_mem_40820000_4000";
char *skw_phyr_mem = "phyr_mem_40830000_4000";
char *skw_smem_mem = "smem_mem_40a00000_58000";
char *skw_umem_mem = "umem_mem_40b00000_c000";
char *skw_modem_mem = "sdio_mem_401e0000_800";
char *skw_btdm_mem = "btdm_mem_41000000_400";
char *skw_btbt_mem = "btbt_mem_41000400_400";
char *skw_btle_mem = "btle_mem_41000800_400";
char *skw_btem_mem = "btem_mem_41022000_c000";

int modem_event_notifier(struct notifier_block *nb, unsigned long action, void *data)
{
	skwboot_log("%s event = %d\n", __func__, (int)action);
	switch (action)
	{
		case DEVICE_ASSERT_EVENT:
		{
			struct log_com_dev *ucom = log_com;
			unsigned long flags;
			int ret = 0;

			skwboot_log("the BSPASSERT EVENT Comming in !!!!\n");
			skw_modem_log_start_rec();
			spin_lock_irqsave(&ucom->lock, flags);
			if (ucom->tx_busy) {
				spin_unlock_irqrestore(&ucom->lock, flags);
				skwboot_err("%s error 0\n", __func__);
				return NOTIFY_OK;
			}
			ucom->tx_busy = 1;
			spin_unlock_irqrestore(&ucom->lock, flags);

			*ucom->tx_buf = 0x33;
			*(ucom->tx_buf + 1) = 0x0D;

			if (ucom->portno != 1)
				ret = ucom->pdata->hw_sdma_tx(ucom->portno, ucom->tx_buf, 2);
			skw_modem_log_set_assert_status(1);
		}
		break;
		case DEVICE_BSPREADY_EVENT:
		{
			skwboot_log("the BSPREADY EVENT Comming in !!!!\n");
			skw_modem_log_start_rec();
			skw_modem_dumpmodem_stop_rec();
		}
		break;
		case DEVICE_DUMPDONE_EVENT:
		{
			skwboot_log("the DUMPDONE EVENT Comming in !!!!\n");
			skw_modem_log_stop_rec();
			skw_modem_log_set_assert_status(0);
		}
		break;
		case DEVICE_BLOCKED_EVENT:
		{
			skwboot_log("the BLOCKED EVENT Comming in !!!!\n");
			skw_modem_dumpmodem_start_rec();
		}
		break;
		case DEVICE_DUMPMEM_EVENT:
		{
			skw_modem_dumpmodem_start_rec();
			msleep(1000);
			skw_modem_dumpmodem_stop_rec();
			skwboot_log("DUMP MEM EVENT Comming in !!!!\n");
		}
		break;
		default:
		{
		}
		break;
	}
	return NOTIFY_OK;
}

void skw_modem_log_to_file_work(struct work_struct *data)
{
#ifdef CONFIG_NO_GKI
	//int log_len = 0;
	struct file *fp = log_fp;
	struct file *log_store_fp = NULL;
	loff_t offset = 0;
	loff_t log_store_offset = 0;
	unsigned long flags;
	u32 *rx_data;
	size_t count = 0;
	int ret = 0;
	int i = 0;
	int log_cnt = 0;
	int sdma_rx_error_cnt = 0;
	char *log_store;
	int  log_path_len;
	char rd_buff[50];

	if (record_flag)
		return;
	record_flag = 1;

	skwlog_log("log path = %s\n", log_path);
	log_path_len = strlen(log_path);

	log_file = kzalloc(log_path_len + 16, GFP_KERNEL);

	if (!log_file)
		return;
	log_store = kzalloc(log_path_len + 16, GFP_KERNEL);
	if (!log_store) {
		kfree(log_file);
		return;
	}
	log_read_buffer.lenth = 0;

	sprintf(log_store, "%s/log_store", log_path);
	log_store_fp = filp_open(log_store, O_RDWR, 0777);
	while (IS_ERR(log_store_fp))
	{
		skwlog_err("open log_store %s failed:%d\n", log_store, (int)PTR_ERR(log_store_fp));
		msleep(1000);
		i++;
		if (i > 8) {
			kfree(log_store);
			kfree(log_file);
			return;
		}
		if (i > 5) {
			skwlog_err("%s open log_store file failed, create file:%s\n", __func__, log_store);
			log_store_fp = filp_open(log_store, O_CREAT | O_RDWR | O_TRUNC, 0777);
		} else{
			log_store_fp = filp_open(log_store, O_RDWR, 0777);
		}
	}

	ret = skw_read_file(log_store_fp, rd_buff, 30, &log_store_offset);
	if (ret < 0) {
		skwlog_err("%s Read file:%s failed, err:%d\n", __func__, log_store, ret);
	}

	rd_buff[0] = rd_buff[0] + 1;
	if (rd_buff[0] > skw_log_num) {
		rd_buff[0] = 0;
	}
	sprintf(log_file, "%s/%s", log_path, log0_file);
	log_path_len = strlen(log_file);
	*(log_file + log_path_len - 1) = ((rd_buff[0] % 10) | 0x30);
	*(log_file + log_path_len - 2) = (((rd_buff[0] / 10) % 10) | 0x30);

	log_store_offset = 0;
	ret = skw_write_file(log_store_fp, rd_buff, 1, &log_store_offset);
	if (ret < 0) {
		skwlog_err("%s write file:%s failed, err:%d\n", __func__, log_store, ret);
	}
	ret = skw_write_file(log_store_fp, log_file, strlen(log_file), &log_store_offset);
	if (ret < 0) {
		skwlog_err("%s write f name to file:%s failed, err:%d\n", __func__, log_store, ret);
	}

	log_fp = filp_open(log_file, O_CREAT | O_RDWR | O_TRUNC, 0777);
	fp = log_fp;

	while (IS_ERR(fp))
	{
		skwlog_err("open rec file %s failed :%d\n", log_file, (int)PTR_ERR(fp));
		msleep(500);
		i++;
		if (i > 10) {
			kfree(log_store);
			kfree(log_file);
			return;
		}

		log_fp = filp_open(log_file, O_CREAT | O_RDWR | O_TRUNC, 0777);
		fp = log_fp;
	}
	atomic_inc(&log_com->open);
	spin_lock_init(&log_com->lock);

	skwlog_log(" open %s for CP log record\n", log_file);
	log_com->pdata->open_port(log_com->portno, NULL, NULL);
	while (record_flag || cp_assert_status)
	{
		ret = 0;
		if (log_com) {
check_rx_busy:
			spin_lock_irqsave(&log_com->lock, flags);
			if (log_com->rx_busy) {
				spin_unlock_irqrestore(&log_com->lock, flags);
				mdelay(5);
				goto check_rx_busy;
			}
			log_com->rx_busy = 1;
			count = log_com->pdata->max_buffer_size;
			spin_unlock_irqrestore(&log_com->lock, flags);
			ret = log_com->pdata->hw_sdma_rx(log_com->portno, (log_read_buffer.buffer + log_read_buffer.lenth), count);

			if (ret > 0) {
				log_cnt++;
				sdma_rx_error_cnt = 0;
				log_read_buffer.lenth = log_read_buffer.lenth + ret;
				//skwlog_log("hw_sdma_rx:%s read len:%d buffer len:%d\n", skw_log, ret, log_read_buffer.lenth);
				if (ret >= 0x1000)
					skwlog_err("%s get too long data , err:%d\n", __func__, ret);

				if (log_cnt > 1000) {
					skwlog_log("%s log_file:%s offset:%lld data:0x%x 0x%x 0x%x 0x%x 0x%x\n", __func__, log_file, offset, *log_read_buffer.buffer,
						*(log_read_buffer.buffer + 1), *(log_read_buffer.buffer + 2), *(log_read_buffer.buffer + 3), *(log_read_buffer.buffer + 4));
					log_cnt = 0;
				}
			} else{
				skwlog_err("%s read log data err:%d\n", __func__, ret);
				sdma_rx_error_cnt++;
				if (sdma_rx_error_cnt > 5) {
					skwlog_err("%s sdma_rx_error_cnt over:%d, stop log work\n", __func__, sdma_rx_error_cnt);
					skw_modem_log_set_assert_status(0);
					skw_modem_log_stop_rec();
				}
			}

			if (port_data->bus_type == USB_LINK) {
				if (ret < 0) {
					skwlog_err("%s read log data err:%d, stop log work\n", __func__, ret);
					skw_modem_log_set_assert_status(0);
					skw_modem_log_stop_rec();
				}
			} else if (port_data->bus_type == SDIO_LINK) {
				if (ret == -ENOTCONN) {
					skw_modem_log_set_assert_status(0);
					skw_modem_log_stop_rec();
				}
			}
			//skwlog_log("read log from SDIO len:%d  -----\n", log_read_buffer.lenth);
			log_com->rx_busy = 0;
			rx_data = (uint32_t *)log_read_buffer.buffer;
		}

		if (((log_read_buffer.lenth > 0) && cp_assert_status)
			((SKW_LOG_READ_BUFFER_SIZE - log_read_buffer.lenth) <= (log_com->pdata->max_buffer_size))) {
			//skwlog_log("skw_write_file:%s offset:%lld lenth:%d\n", skw_log, offset, log_read_buffer.lenth);
			ret = skw_write_file(fp, log_read_buffer.buffer, log_read_buffer.lenth, &offset);
			if (ret < 0) {
				skwlog_err("%s write file failed, err:%d\n", __func__, ret);
			}

			log_read_buffer.lenth = 0;
			if (ret == -ENOSPC) {
				skwlog_err("%s no space, stop CP log record\n", __func__);
				skw_modem_log_stop_rec();
			}

			if (offset > skw_log_size && (!cp_assert_status)) {
				if (!IS_ERR(fp))
					filp_close(fp, NULL);

				rd_buff[0] = rd_buff[0] + 1;
				if (rd_buff[0] > skw_log_num) {
					rd_buff[0] = 0;
				}
				sprintf(log_file, "%s/%s", log_path, log0_file);
				log_path_len = strlen(log_file);
				*(log_file + log_path_len - 1) = ((rd_buff[0] % 10) | 0x30);
				*(log_file + log_path_len - 2) = (((rd_buff[0] / 10) % 10) | 0x30);

				log_store_offset = 0;
				ret = skw_write_file(log_store_fp, rd_buff, 1, &log_store_offset);
				if (ret < 0) {
					skwlog_err("%s write file:%s failed, err:%d\n", __func__, log_store, ret);
				}
				ret = skw_write_file(log_store_fp, log_file, strlen(log_file), &log_store_offset);
				if (ret < 0) {
					skwlog_err("%s write f name to file:%s failed, err:%d\n", __func__, log_store, ret);
				}

				log_fp = filp_open(log_file, O_CREAT | O_RDWR | O_TRUNC, 0777);
				fp = log_fp;
				if (IS_ERR(fp)) {
					skwlog_err("%s switch record file to:%s failed: %d\n", __func__, log_file, (int)PTR_ERR(fp));
					return;
				} else{
					skwlog_err("%s switch record file to:%s sucess\n", __func__, log_file);
				}

				offset = 0;
			}
#if 0
			ret = vfs_fssync(fp, 0);
			if (ret < 0) {
				skwlog_err("%s fssync file failed, err:%d\n", __func__, ret);
			}
#endif
		}
	}
	atomic_dec(&log_com->open);
	log_com->pdata->close_port(log_com->portno);

	if (!IS_ERR(fp)) {
		filp_close(fp, NULL);
		skwlog_log("%s close file %s before stop work.\n", __func__, log_file);
		log_fp = NULL;
		fp = log_fp;
	}

	if (!IS_ERR(log_store_fp)) {
		filp_close(log_store_fp, NULL);
		skwlog_log("%s close file %s before stop work.\n", __func__, log_store);
		log_store_fp = NULL;
	}
	kfree(log_file);
	kfree(log_store);
	skwlog_log("%s work exit\n", __func__);
#else
	skwlog_log("THE GKI VERSION NO LOG FILE!!!\n");
#endif
	return;
}

/***************************************************************************
 *Description:dump modem memory
 *Seekwave tech LTD
 *Author:JunWei Jiang
 *Date:2022-11-14
 *Modify:
 **************************************************************************/
int skw_modem_save_mem(char *mem_path, unsigned int mem_len, unsigned int mem_addr)
{
	int ret = 0;
#ifdef CONFIG_NO_GKI
	char dump_mem_file[128];
	//dump code data
	char *data_mem = NULL;
	struct file *fp = NULL;
	loff_t pos = 0;
	int nwrite = 0;
	unsigned int read_len = 0;
	unsigned int mem_size = mem_len;

	memset(dump_mem_file, 0, sizeof(dump_mem_file));
	sprintf(dump_mem_file, "%s/%s", log_path, mem_path);
	data_mem = kzalloc(SKW_MAX_BUF_SIZE, GFP_KERNEL);
	if (!data_mem) {
		skwlog_log("the kzalloc dump buffer fail");
		return -2;
	}
	/* open file to write */
	fp = filp_open(dump_mem_file, O_CREAT | O_RDWR | O_TRUNC, 0777);
	if (IS_ERR(fp)) {
		skwlog_log("open file %s fail try again!!!\n", dump_mem_file);
		fp = filp_open(mem_path, O_CREAT | O_RDWR | O_TRUNC, 0777);
		if (IS_ERR(fp)) {
			skwlog_log("open file error\n");
			ret = -1;
			goto exit;
		}
	}

	while (mem_size)
	{
		if (mem_size < SKW_MAX_BUF_SIZE)
		{
			read_len = mem_size;
		} else {
			read_len = SKW_MAX_BUF_SIZE;
		}
		//skwlog_log("the read_len =0x%x mem_size= 0x%x\n", read_len, mem_size);
		ret = log_com->pdata->skw_dump_mem(mem_addr + (mem_len - mem_size), (void *)data_mem, read_len);
		if (ret < 0)
			break;

		//print_hex_dump(KERN_ERR, "img data ", 0, 16, 1,data_mem, 32, 1);
		//pos=(unsigned long)offset;
		/* Write buf to file */
		nwrite = skw_write_file(fp, data_mem, read_len, &pos);
		//offset +=nwrite;

		if (mem_size >= SKW_MAX_BUF_SIZE)
		{
			mem_size = mem_size - SKW_MAX_BUF_SIZE;
		} else {
			mem_size = 0;
		}
	}
	skwlog_log("Dump %s memory done !!\n", mem_path);
	if (fp)
	{
		filp_close(fp, NULL);
		skwlog_log("the file close!!!\n");
	}
exit:
	kfree(data_mem);
#endif
	return ret;
}

/***************************************************************************
 *Description:dump modem memory
 *Seekwave tech LTD
 *Author:JunWei Jiang
 *Date:2022-11-14
 *Modify:
 **************************************************************************/
int skw_modem_save_dumpmem(void)
{
	int ret = 0;

	skwlog_log("The ------Enter ----\n");
	//DATA MEM
	ret = skw_modem_save_mem(skw_data_mem, DATA_MEM_SIZE, DATA_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_data_mem, ret);
		return -1;
	}
	//CODE MEM
	ret = skw_modem_save_mem(skw_code_mem, CODE_MEM_SIZE, CODE_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_code_mem, ret);
		return -1;
	}
	//CSCB MEM
	ret = skw_modem_save_mem(skw_cscb_mem, CSCB_MEM_SIZE, CSCB_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_cscb_mem, ret);
		return -1;
	}

	//UMEM MEM
	ret = skw_modem_save_mem(skw_umem_mem, UMEM_MEM_SIZE, UMEM_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_umem_mem, ret);
		return -1;
	}
	//SDIO MEM
	ret = skw_modem_save_mem(skw_modem_mem, SDIO_MEM_SIZE, SDIO_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_modem_mem, ret);
		return -1;
	}
	//BTDM MEM
	ret = skw_modem_save_mem(skw_btdm_mem, BTDM_MEM_SIZE, BTDM_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_btdm_mem, ret);
		return -1;
	}
	//BTBT MEM
	ret = skw_modem_save_mem(skw_btbt_mem, BTBT_MEM_SIZE, BTBT_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_btbt_mem, ret);
		return -1;
	}
	//BTLE MEM
	ret = skw_modem_save_mem(skw_btle_mem, BTLE_MEM_SIZE, BTLE_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_btle_mem, ret);
		return -1;
	}
	//BTEM MEM
	ret = skw_modem_save_mem(skw_btem_mem, BTEM_MEM_SIZE, BTEM_MEM_BASE_ADDR);
	if (ret != 0) {
		skwlog_log("dump %s mem fail ret: %d\n", skw_btem_mem, ret);
		return -1;
	}
	//WREG MEM
	ret = skw_modem_save_mem(skw_wreg_mem, WREG_MEM_SIZE, WREG_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_wreg_mem, ret);
		return -1;
	}
	//PHYR MEM
	ret = skw_modem_save_mem(skw_phyr_mem, PHYR_MEM_SIZE, PHYR_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_phyr_mem, ret);
		return -1;
	}
	//SMEM MEM
	ret = skw_modem_save_mem(skw_smem_mem, SMEM_MEM_SIZE, SMEM_MEM_BASE_ADDR);
	if (ret != 0)
	{
		skwlog_log("dump %s mem fail ret: %d\n", skw_smem_mem, ret);
		return -1;
	}
	return ret;
}

int skw_modem_log_init(struct sv6160_platform_data *p_data, struct file *fp, void *ucom)
{
	int ret = 0;
#ifdef CONFIG_NO_GKI
	if (skw_log_dev)
		return ret;
	if (skw_log_size > (200 * 1024 * 1024))
		skw_log_size = (200 * 1024 * 1024);
	if (skw_log_size < (512 * 1024))
		skw_log_size = (512 * 1024);
	if ((skw_log_size * skw_log_num) > (1024 * 1024 * 1024))
		skw_log_num = (1024 * 1024 * 1024) / skw_log_size;
	if (skw_log_num > 99)
		skw_log_num = 99;

	skwlog_log("%s enter skw_log_num:%d skw_log_size:%d  \n", __func__, skw_log_num, skw_log_size);
	log_fp = fp;
	log_com = ucom;
	port_data = p_data;

	log_read_buffer.lenth = 0;
	log_read_buffer.buffer = kzalloc(SKW_LOG_READ_BUFFER_SIZE, GFP_KERNEL);
	if (!log_read_buffer.buffer) {
		ret = -ENOMEM;
		skwlog_err("%s can't malloc log_read_buffer,%d\n", __func__, __LINE__);
		goto err1;
	}

	skw_log_dev = (struct skw_log_data *)kzalloc(sizeof(*skw_log_dev), GFP_KERNEL);
	if (!skw_log_dev) {
		ret = -ENOMEM;
		skwlog_err("%s can't malloc skw_log_dev,%d\n", __func__, __LINE__);
		goto err1;
	}

	spin_lock_init(&skw_log_dev->lock);
	atomic_set(&skw_log_dev->open_excl, 0);
	atomic_set(&skw_log_dev->ioctl_excl, 0);
	//INIT_LIST_HEAD(&skw_log_dev->tx_idle);

	skw_log_dev->wq = create_singlethread_workqueue("skw_log");
	if (!skw_log_dev->wq) {
		ret = -ENOMEM;
		goto err1;
	}
	INIT_WORK(&skw_log_dev->log_to_file_work, skw_modem_log_to_file_work);

	if (log_com->pdata->modem_register_notify) {
		if (!log_com->notifier.notifier_call) {
			log_com->notifier.notifier_call = modem_event_notifier;
			log_com->pdata->modem_register_notify(&log_com->notifier);
		}
	}

	if (ret)
		goto err2;

	skw_modem_log_start_rec();
	return 0;

err2:
	destroy_workqueue(skw_log_dev->wq);
err1:
	kfree(skw_log_dev);
	printk(KERN_ERR "mtp gadget driver failed to initialize\n");
#endif
	return ret;
}

void skw_modem_log_set_assert_status(uint32_t cp_assert)
{
	cp_assert_status = cp_assert;
	if (cp_assert_status) {
		skwlog_log("%s CP in ASSERT, dump log in %s\n", __func__, log_file);
	}
}

void skw_modem_log_start_rec(void)
{
#ifdef CONFIG_NO_GKI
	if (atomic_read(&log_com->open) > 1) {
		skwlog_log("log port is busy\n");
		return;
	}
	if (!skw_log_dev) {
		skwlog_log("%s no mem ready, can't start\n", __func__);
		return;
	}
	if (record_flag) {
		skwlog_log("%s lof2file already start\n", __func__);
		return;
	}
	cp_assert_status = 0;
	queue_work(skw_log_dev->wq, &skw_log_dev->log_to_file_work);
#endif
}

/***************************************************************************
 *Description:dump modem memory
 *Seekwave tech LTD
 *Author:JunWei Jiang
 *Date:2022-11-14
 *Modify:
 **************************************************************************/
void skw_modem_dumpmodem_start_rec(void)
{
#ifdef CONFIG_NO_GKI
	if (!skw_log_dev) {
		skwlog_log("%s no mem ready, can't start\n", __func__);
		return;
	}
	if (dumpmodem_flag) {
		skwlog_log("%s dump modem mem already start\n", __func__);
		return;
	}
	dumpmodem_flag = 1;
	skw_modem_save_dumpmem();
#endif
}

/***************************************************************************
 *Description:dump modem memory
 *Seekwave tech LTD
 *Author:JunWei Jiang
 *Date:2022-11-14
 *Modify:
 **************************************************************************/
void skw_modem_dumpmodem_stop_rec(void)
{
	skwlog_log("%s enter %d \n", __func__, cp_assert_status);

	if (dumpmodem_flag)
		dumpmodem_flag = 0;

	return;
}

void skw_modem_log_stop_rec(void)
{
	skwlog_log("%s enter %d\n", __func__, cp_assert_status);

	if (record_flag)
		record_flag = 0;
	if (log_com && log_com->pdata && log_com->pdata->close_port)
		log_com->pdata->close_port(log_com->portno);
	return;
}

void skw_modem_log_exit(void)
{
#ifdef CONFIG_NO_GKI
	if (!log_com)
		return;
	log_com->pdata->modem_unregister_notify(&log_com->notifier);
	skw_modem_log_stop_rec();
	skw_modem_dumpmodem_stop_rec();
	destroy_workqueue(skw_log_dev->wq);
	kfree(skw_log_dev);
	skw_log_dev = NULL;
	log_com = NULL;
	kfree(log_read_buffer.buffer);
#endif
}

//DECLARE_USB_FUNCTION_INIT(mtp, mtp_alloc_inst, mtp_alloc);
MODULE_LICENSE("GPL");
===== ./drivers/seekwaveplatform/usb/skw_usb_debugfs.c =====
/*****************************************************************************
 * Copyright(c) 2020-2030  Seekwave Corporation.
 * SEEKWAVE TECH LTD..CO
 *Seekwave Platform the usb log debug fs
 *FILENAME:skw_usb_debugfs.c
 *DATE:2022-04-11
 *MODIFY:
 *
 **************************************************************************/

#include "skw_usb_debugfs.h"
#include "skw_usb_log.h"
#include "skw_usb.h"

static struct dentry *skw_usb_root_dir;

static ssize_t skw_usb_default_read(struct file *fp, char __user *buf, size_t len,
				loff_t *offset)
{
	return 0;
}

static ssize_t skw_usb_state_write(struct file *fp, const char __user *buffer,
				size_t len, loff_t *offset)
{
	return len;
}

static const struct file_operations skw_usb_state_fops = {
	.open = skw_usb_default_open,
	.read = skw_usb_default_read,
	.write = skw_usb_state_write,
};

struct dentry *skw_usb_add_debugfs(const char *name, umode_t mode, void *data,
			       const struct file_operations *fops)
{
	skw_usb_dbg("%s:name: %s\n", __func__, name);

	return debugfs_create_file(name, mode, skw_usb_root_dir, data, fops);
}

int skw_usb_debugfs_init(void)
{
	skw_usb_root_dir = debugfs_create_dir("skwusb", NULL);
	if (IS_ERR(skw_usb_root_dir))
		return PTR_ERR(skw_usb_root_dir);

	// skw_usb_add_debugfs("state", 0666, wiphy, &skw_usb_state_fops);
	// skw_usb_add_debugfs("log_level", 0444, wiphy, &skw_usb_log_fops);

	return 0;
}

void skw_usb_debugfs_deinit(void)
{
	skw_usb_dbg("%s :traced\n", __func__);

	debugfs_remove_recursive(skw_usb_root_dir);
}
===== ./drivers/seekwaveplatform/usb/skw_usb_io.c =====
/************************************************************************
 *Copyright(C) 2020-2021: Seekwave tech LTD		China
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
#include <linux/platform_device.h>
#include <linux/interrupt.h>
#include <linux/irq.h>
#include <linux/scatterlist.h>
#include <linux/dma-mapping.h>
#include <linux/version.h>
#include <linux/notifier.h>
#include <linux/semaphore.h>
#include <linux/pm_runtime.h>
#include <linux/kthread.h>
#include <linux/module.h>
#include <linux/list.h>
#include <linux/err.h>
#include <linux/wait.h>
#include <linux/gpio.h>
#include "skw_usb.h"
#include "skw_usb_log.h"
#include "skw_usb_debugfs.h"
//#define CONFIG_SEEKWAVE_PLD_RELEASE 1
#define MAX_BUFFER_SIZE 23 * 1024
#define MAX_MSG_SIZE	MAX_BUFFER_SIZE

#define VENDOR_MSG_MODEM_ASSERT 0xA5
#define VENDOR_MSG_SERVICE_CTRL 0xA6
#define VENDOR_MSG_PACKET_COUNT 0xA7
#define VENDOR_MSG_LOG_SWITCH   0xA8
#define VENDOR_MSG_MODEM_RESET  0xA9
#define	WIFI_SERVICE	0
#define BT_SERVICE	  1

#define SERVICE_START	0
#define SERVICE_STOP	1

#define MODEM_OFF		0
#define MODEM_ON		1
#define MODEM_HALT		2
#define MODEM_DOWNLOAD_FAILED   3

#define WIFI_PORT_SHARE_FLAG	0x4000
#define HIF_POWER_OFF_FLAG      0x2000
#define USB_HOST_RESUME_SUPPORT 0x20

#define MAX_USB_PORT MAX_PORT_COUNT
#define MAX_PACKET_COUNT 20
struct delayed_work skw_except_work;
static struct work_struct add_device_work;
static struct work_struct dump_memory_worker;
static struct platform_device *wifi_data_pdev;
static u64 port_dmamask = DMA_BIT_MASK(32);
static u32 service_state_map;
static int cp_log_status;
static char *firmware_data;
static int   firmware_size;
static int   firmware_addr;
struct seekwave_device *usb_boot_data;
struct completion download_done;
static struct completion loop_completion;
static BLOCKING_NOTIFIER_HEAD(modem_notifier_list);
int chip_en_gpio;
int modem_status;
int recovery_debug_status;
char *skw_chipid;
static u32 last_sent_wifi_cmd[3];
static u32 last_recv_wifi_evt[3];
static u32 last_recv_wifi_ack[3];
static u64 last_sent_time, last_ack_time;
static int start_service_flag;
static struct scatterlist *sgs;
static int nr_sgs;
static int bulk_async_read;
static int dump_memory_done;
static char* dump_memory_buffer = NULL;
static int dump_buffer_size = 0;
static int* dump_log_size = NULL;
/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */

static const struct usb_device_id skw_usb_io_id_table[] = {
	{USB_VENDOR_AND_INTERFACE_INFO(0x3607, 0x02, 0x02, 0)},
	{ USB_DEVICE(0x0483, 0x5720) },
	{ USB_DEVICE(0x0483, 0x5721) },
	{ USB_DEVICE(0x3607, 0x6316) },
	{ USB_DEVICE(0x3607, 0x6160) },
	{}	/* Terminating entry */
};

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static struct recovery_data{
	struct mutex except_mutex;
	int cp_state;
} g_recovery_data;

#ifdef CONFIG_SKW_DL_TIME_STATS
	ktime_t cur_time, last_time;
#endif

#define SKW_USB_GET_RECOVERY_DATA() &g_recovery_data

struct usb_port_struct {
	struct work_struct work;
	struct platform_device *pdev;
	int	portno;
	struct usb_interface *interface;
	struct usb_device *udev;
	struct urb *read_urb;
	struct usb_endpoint_descriptor *epin;
	struct urb *write_urb;
	struct usb_endpoint_descriptor *epout;
	char *read_buffer;
	char   *write_buffer;
	int	   buffer_size;
	struct usb_anchor read_submitted;
	struct usb_anchor write_submitted;
	struct task_struct *thread;
	rx_submit_fn rx_submit;
	adma_callback adma_tx_callback;
	sdma_callback sdma_tx_callback;
	void *rx_data;
	void *tx_data;
	int	state;
	int  ep_mps;
	int  max_packet_count;
	struct semaphore sem;
	int	is_dloader;
	int	sent_packet_count;
	int	req_tx_packet;
	wait_queue_head_t   rx_wait;
	wait_queue_head_t	tx_wait;
	struct tasklet_struct tasklet;
	struct list_head rx_urb_list;
	struct list_head tx_urb_list;
	struct list_head rx_done_urb_list;
	struct list_head suspend_urb_list;
	spinlock_t rx_urb_lock;
	spinlock_t tx_urb_lock;
	int	tx_urb_count;
	int	 rx_packet_count;
	int	suspend;
} *usb_ports[MAX_USB_PORT];

int modem_assert(void);
static int skw_recovery_mode(void);
static struct usb_port_struct *log_port;
extern void kernel_restart(char *cmd);
static int bulkin_read_timeout(int portno, char *buffer, int size, int *actual, int timeout);
static int bulkout_write_timeout(int portno, char *buffer, int size, int *actual, int timeout);
static void bulkout_async_complete(struct urb *urb);
static void bulkin_async_complete(struct urb *urb);
static int assert_info_print;
#ifdef CONFIG_WAKELOCK
static	struct wake_lock usb_wakelock;
#else
static	struct wakeup_source *usb_wakelock;
#endif
int    wakelocked;
static int usb_bt_rx_entry(void *para);
char firmware_version[128];
int	bt_audio_port;
struct platform_device *bluetooth_pdev;
static int wifi_port_share;
int    host_wake_gpio;

void skw_get_port_statistic(char *buffer, int size)
{
	int ret = 0;
	int i;

	if (!buffer)
		return;

	for (i = 0; i < 2; i++) {
		if (ret >= size)
			break;

		ret += sprintf(&buffer[ret], "port%d: req_tx %d tx_done %d, rx %d async_read %d\n",
				i, usb_ports[i]->req_tx_packet, usb_ports[i]->sent_packet_count,
				usb_ports[i]->rx_packet_count, bulk_async_read);
	}
}

#include "usb_boot.c"
void modem_register_notify(struct notifier_block *nb)
{
	blocking_notifier_chain_register(&modem_notifier_list, nb);
}

void modem_unregister_notify(struct notifier_block *nb)
{
	blocking_notifier_chain_unregister(&modem_notifier_list, nb);
}

static void modem_notify_event(int event)
{
	blocking_notifier_call_chain(&modem_notifier_list, event, NULL);
}

static void skw_usb_wakeup_source_init(void)
{
#ifdef CONFIG_WAKELOCK
	wake_lock_init(&usb_wakelock, WAKE_LOCK_SUSPEND, "skw_usb_wakelock");
#else
	usb_wakelock =  skw_wakeup_source_register(NULL, "skw_usb_wakelock");
#endif
	wakelocked = 0;
}

static void skw_usb_wakeup_source_destroy(void)
{
#ifdef CONFIG_WAKELOCK
	wake_lock_destroy(&usb_wakelock);
#else
	wakeup_source_unregister(usb_wakelock);
#endif
}

static void skw_usb_wake_lock(void)
{
	if (wakelocked)
		return;
#ifdef CONFIG_WAKELOCK
	__pm_stay_awake(&usb_wakelock.ws);
#else
	__pm_stay_awake(usb_wakelock);
#endif
	wakelocked = 1;
}

static void skw_usb_wake_unlock(void)
{
	if (!wakelocked)
		return;
#ifdef CONFIG_WAKELOCK
	__pm_relax(&usb_wakelock.ws);
#else
	__pm_relax(usb_wakelock);
#endif
	wakelocked = 0;
}

void skw_usb_exception_work(struct work_struct *work)
{
	struct recovery_data *recovery = SKW_USB_GET_RECOVERY_DATA();

	mutex_lock(&recovery->except_mutex);
	if (recovery->cp_state != 1)
	{
		mutex_unlock(&recovery->except_mutex);
		return;
	}
	skw_usb_info(" enter cp_state=%d...\n", recovery->cp_state);
	skw_usb_wake_lock();
	recovery->cp_state = DEVICE_BLOCKED_EVENT;
	mutex_unlock(&recovery->except_mutex);
	modem_notify_event(DEVICE_BLOCKED_EVENT);
	service_state_map = 0;
	skw_recovery_mode();
}

int skw_usb_recovery_debug(int disable)
{
	recovery_debug_status = disable;
	skw_usb_info("the recovery status =%d\n", recovery_debug_status);
	return 0;
}

int skw_usb_recovery_debug_status(void)
{
	skw_usb_info("the recovery val =%d\n", recovery_debug_status);
	return recovery_debug_status;
}

static void usb_setup_service_devices(void)
{
	struct usb_port_struct *bt_port;
	int ret;

	skw_bind_boot_driver(&usb_ports[0]->udev->dev);
	if (usb_ports[1]->pdev) {
		if (!wifi_data_pdev) {
			ret = platform_device_add(usb_ports[1]->pdev);
			if (ret) {
				skw_usb_err("the fail to register WIFI device\n");
				platform_device_put(usb_ports[1]->pdev);
			} else {
				wifi_data_pdev = usb_ports[1]->pdev;
				skw_usb_info("add WIFI devices done\n");
			}
		}
	} else
		 skw_usb_err("NOT suppport WIFI service\n");

	if (bluetooth_pdev) {
		bt_port = usb_ports[bt_audio_port];
		bt_port->pdev = bluetooth_pdev;
		bluetooth_pdev = NULL;
		ret = platform_device_add(bt_port->pdev);
		if (ret) {
			dev_err(&bt_port->udev->dev, "failt to register Bluetooth device\n");
			platform_device_put(bt_port->pdev);
			bt_port->pdev = NULL;
		} else
			skw_usb_info("add Bluetooth devices done\n");
	}
}

void add_devices_work(struct work_struct *work)
{
	usb_setup_service_devices();
}

static void usb_port_alloc_recv_urbs(struct usb_port_struct *port, struct usb_endpoint_descriptor *epd, int count, int buffer_size)
{
	int i;
	struct urb *urb;

	for (i = 0; i < count; i++) {
		urb = usb_alloc_urb(0, GFP_KERNEL);
		if (!urb)
			break;
		if (!buffer_size) {
			urb->transfer_buffer = NULL;
			urb->transfer_buffer_length = 0;
		} else {
			urb->transfer_buffer = kzalloc(buffer_size, GFP_KERNEL);
			if (!urb->transfer_buffer) {
				usb_free_urb(urb);
				break;
			}
			urb->transfer_buffer_length = buffer_size;
		}
		usb_fill_bulk_urb(urb, port->udev, usb_rcvbulkpipe(port->udev, epd->bEndpointAddress),
			urb->transfer_buffer, buffer_size, bulkin_async_complete, NULL);
		list_add_tail(&urb->urb_list, &port->rx_urb_list);
	}
	skw_usb_dbg("%s urb cout %d\n", __func__, i);
}

static void usb_port_alloc_xmit_urbs(struct usb_port_struct *port, struct usb_endpoint_descriptor *epd, int count, int buffer_size)
{
	int i;
	struct urb *urb;

	for (i = 0; i < count; i++) {
		urb = usb_alloc_urb(0, GFP_KERNEL);
		if (!urb)
			break;
		if (!buffer_size) {
			urb->transfer_buffer = NULL;
			urb->transfer_buffer_length = 0;
		} else {
			urb->transfer_buffer = kzalloc(buffer_size, GFP_KERNEL);
			if (!urb->transfer_buffer) {
				usb_free_urb(urb);
				break;
			}
			urb->transfer_buffer_length = buffer_size;
		}
		usb_fill_bulk_urb(urb, port->udev, usb_sndbulkpipe(port->udev, epd->bEndpointAddress),
			urb->transfer_buffer, buffer_size, bulkout_async_complete, NULL);
		list_add_tail(&urb->urb_list, &port->tx_urb_list);
	}
	skw_usb_dbg("%s urb cout %d\n", __func__, i);
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
int open_usb_port(int id, void *callback, void *data)
{
	struct usb_port_struct *port;

	if (id >= MAX_USB_PORT)
		return -EINVAL;

	port = usb_ports[id];
	if (port->state == 0)
		return -EIO;
	if (port->state == 1) {
		if (port->read_urb && !port->read_urb->context) {
			init_usb_anchor(&port->read_submitted);
		}
		if (port->write_urb && !port->write_urb->context) {
			init_usb_anchor(&port->write_submitted);
		}
	}
	port->state = 2;
	port->rx_submit = callback;
	port->rx_data = data;
	if (callback && data && !port->thread) {
		sema_init(&port->sem, 0);
		port->thread = kthread_create(usb_bt_rx_entry, port, port->interface->cur_altsetting->string);
		if (port->thread)
			wake_up_process(port->thread);
	}
	return 0;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
int  bulkin_read(struct usb_port_struct *port, void *buffer, int size)
{
	int retval = -1;
	DECLARE_COMPLETION_ONSTACK(done);

	if (port->state == 0)
		return -EIO;

	if (port == log_port)
		memset(buffer, 0, size);

	if (port && port->read_urb) {
		port->read_urb->transfer_buffer = buffer;
		port->read_urb->transfer_buffer_length = size;
		port->read_urb->context = &done;
		usb_anchor_urb(port->read_urb, &port->read_submitted);
		retval = usb_submit_urb(port->read_urb, GFP_KERNEL);
		if (retval == 0) {
			retval = wait_for_completion_interruptible(&done);
			if (retval == -ERESTARTSYS)
				usb_kill_urb(port->read_urb);
			else if (port->read_urb->status)
				retval = port->read_urb->status;
			else if (retval == 0)
				retval = port->read_urb->actual_length;
			port->read_urb->context = NULL;
		} else {
			if (retval < 0) {
				usb_unanchor_urb(port->read_urb);
				skw_usb_info("is error= %d!!!\n", retval);
			}
			port->read_urb->context = NULL;
		}
	}
	if (port == log_port) {
		if (assert_info_print && assert_info_print < 28 && retval < 100) {
			assert_info_print++;
			if (retval > 4)
				printk("%s", (char *)buffer);
		}
		if (retval == 4)
			assert_info_print = 28;
	}
	return retval;
}
EXPORT_SYMBOL(bulkin_read);
int bulkin_read_async(struct usb_port_struct *port)
{
	int	 retval = -1;
	unsigned long flags;
	struct urb *urb;

	if (port->suspend) {
		skw_usb_info("port%d is suspended!!!\n", port->portno);
		return -EOPNOTSUPP;
	}
	spin_lock_irqsave(&port->rx_urb_lock, flags);
	urb = list_first_entry(&port->rx_urb_list, struct urb, urb_list);
	list_del_init(&urb->urb_list);
	spin_unlock_irqrestore(&port->rx_urb_lock, flags);
	if (urb->context) {
		skw_usb_info("port is busy!!!\n");
		return -EBUSY;
	}

	if (urb) {
		urb->complete = bulkin_async_complete;
		urb->context = port;
		usb_anchor_urb(urb, &port->read_submitted);
		retval = usb_submit_urb(urb, GFP_ATOMIC);
		bulk_async_read++;
		if (retval < 0) {
			bulk_async_read--;
			usb_unanchor_urb(urb);
			skw_usb_info("is failed! %d\n", retval);
			spin_lock_irqsave(&port->rx_urb_lock, flags);
			list_add_tail(&urb->urb_list, &port->rx_urb_list);
			spin_unlock_irqrestore(&port->rx_urb_lock, flags);
			msleep(100);
		}
	}
	return retval;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
int bulkout_write(struct usb_port_struct *port, void *buffer, int size)
{
	int retval = -1;
	DECLARE_COMPLETION_ONSTACK(done);

	if (port->suspend) {
		skw_usb_info("port%d is suspended!!!\n", port->portno);
		return -EOPNOTSUPP;
	}
	if (port && port->write_urb) {
		port->write_urb->transfer_buffer = buffer;
		port->write_urb->transfer_buffer_length = size;
		if (size % port->ep_mps == 0)
			port->write_urb->transfer_flags |= URB_ZERO_PACKET;
		port->write_urb->context = &done;
		usb_anchor_urb(port->write_urb, &port->write_submitted);
		retval = usb_submit_urb(port->write_urb, GFP_KERNEL);
		dev_dbg(&port->udev->dev, "%s wait done %d\n", __func__, retval);
		if (retval == 0) {
			retval = wait_for_completion_interruptible_timeout(&done, msecs_to_jiffies(3000));
			if (retval ==  -ERESTARTSYS || !retval) {
				if (port->write_urb && port->write_urb->context)
					usb_kill_urb(port->write_urb);
			} else if (port->write_urb->status)
				retval = port->write_urb->status;
			else
				retval = port->write_urb->actual_length;
			port->write_urb->context = NULL;
		} else {
			if (retval < 0) {
				usb_unanchor_urb(port->write_urb);
				skw_usb_info("%s is error!!! %d\n", __func__, retval);
			}
			port->write_urb->context = NULL;
		}
	}
	return retval;
}

int bulkout_write_async(struct usb_port_struct *port, void *buffer, int size)
{
	int retval = -1;
	struct urb *urb;
	unsigned long flags;

	if (port->suspend) {
		skw_usb_info("port%d is suspended!!!\n", port->portno);
		return -EOPNOTSUPP;
	}
	spin_lock_irqsave(&port->tx_urb_lock, flags);
	if (list_empty(&port->tx_urb_list)) {
		spin_unlock_irqrestore(&port->tx_urb_lock, flags);
		retval = wait_event_interruptible(port->tx_wait, (!list_empty(&port->tx_urb_list)));
		spin_lock_irqsave(&port->tx_urb_lock, flags);
	}
	urb = list_first_entry(&port->tx_urb_list, struct urb, urb_list);
	list_del_init(&urb->urb_list);
	port->tx_urb_count++;
	spin_unlock_irqrestore(&port->tx_urb_lock, flags);

	if (port && urb) {
		usb_fill_bulk_urb(urb, port->udev, usb_sndbulkpipe(port->udev, port->epout->bEndpointAddress),
			buffer, size, bulkout_async_complete, port);
		if (size % port->ep_mps == 0)
			urb->transfer_flags |= URB_ZERO_PACKET;

		usb_anchor_urb(urb, &port->write_submitted);
		retval = usb_submit_urb(urb, GFP_KERNEL);
		if (retval < 0) {
			usb_unanchor_urb(urb);
			dev_info(&port->pdev->dev, "%s is error!!! %d\n", __func__, retval);
		}
		dev_dbg(&port->udev->dev, "%s %d wait done %d %d\n", __func__, port->portno, retval, port->tx_urb_count);
	}
	return retval;
}

EXPORT_SYMBOL(bulkout_write);

int bulkout_write_sg_async(struct usb_port_struct *port, struct scatterlist *sgs, int sg_num, int total)
{
	struct urb *urb;
	unsigned long flags;
	int retval = -1;

	if (port->suspend) {
		skw_usb_info("port%d is suspended!!!\n", port->portno);
		return -EOPNOTSUPP;
	}
	spin_lock_irqsave(&port->tx_urb_lock, flags);
	if (list_empty(&port->tx_urb_list)) {
		spin_unlock_irqrestore(&port->tx_urb_lock, flags);
		retval = wait_event_interruptible(port->tx_wait, (!list_empty(&port->tx_urb_list)));
		spin_lock_irqsave(&port->tx_urb_lock, flags);
	}
	urb = list_first_entry(&port->tx_urb_list, struct urb, urb_list);
	port->tx_urb_count++;
	list_del_init(&urb->urb_list);
	port->req_tx_packet += sg_num;
	spin_unlock_irqrestore(&port->tx_urb_lock, flags);
	urb->transfer_buffer = NULL;
	urb->transfer_buffer_length = 0;
	usb_fill_bulk_urb(urb, port->udev, usb_sndbulkpipe(port->udev, port->epout->bEndpointAddress),
		NULL, 0, bulkout_async_complete, port);
	urb->sg = sgs;
	urb->num_sgs = sg_num;
	urb->transfer_buffer_length = total;
	if (total % port->ep_mps == 0)
		urb->transfer_flags |= URB_ZERO_PACKET;
	usb_anchor_urb(urb, &port->write_submitted);
	//dev_info(&port->udev->dev,"%s %d submit  %d\n",__func__, port->portno,  port->tx_urb_count);
	return usb_submit_urb(urb, GFP_ATOMIC);
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static int bulkout_write_sg(struct usb_port_struct *port, struct scatterlist *sgs, int sg_num, int total)
{
	int	 retval = -1;
	DECLARE_COMPLETION_ONSTACK(done);

	if (!port->write_urb)
		return -ENODEV;
	if (port->write_urb->context) {
		dev_dbg(&port->pdev->dev, "%s is busy!!!\n", __func__);
		return -EBUSY;
	}
	if (port && port->write_urb) {
		port->write_urb->sg = sgs;
		port->write_urb->num_sgs = sg_num;
		port->write_urb->transfer_buffer_length = total;
		if (total % port->ep_mps == 0)
			port->write_urb->transfer_flags |= URB_ZERO_PACKET;
		port->write_urb->context = &done;
		skw_port_log(port->portno, "%s port%d size = %d\n", __func__, port->portno, total);
		port->req_tx_packet += port->write_urb->num_sgs;
		usb_anchor_urb(port->write_urb, &port->write_submitted);
		retval = usb_submit_urb(port->write_urb, GFP_KERNEL);
		if (retval == 0) {
			retval = wait_for_completion_interruptible(&done);
			if (retval == 0)
				retval = port->write_urb->actual_length;
			port->write_urb->context = NULL;
			port->sent_packet_count += sg_num;

		} else {
			skw_port_log(port->portno, "%s retval = %d\n", __func__, retval);
			usb_unanchor_urb(port->write_urb);
			port->write_urb->context = NULL;
		}
	}
	if (retval > 0)
		return 0;
	return retval;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static int send_data(int portno, char *buffer, int total)
{
	struct usb_port_struct *port;
	//u32 *data = (u32 *)buffer;

	if (total == 0)
		return 0;
	if (modem_status != MODEM_ON)
		return -EIO;
	port = usb_ports[portno];
	if (!port || !port->state)
		return -EIO;
	//if (total % port->epout->wMaxPacketSize == 0)
	//	total++;
	return bulkout_write(port, buffer, total);
}

static int send_data_async(int portno, char *buffer, int total)
{
	struct usb_port_struct *port;

	if (total == 0)
		return 0;
	if (modem_status != MODEM_ON)
		return -EIO;
	port = usb_ports[portno];
	if (!port || !port->state)
		return -EIO;
	return bulkout_write_async(port, buffer, total);
}

int recv_data(int portno, char *buffer, int total)
{
	struct usb_port_struct *port;

	if (total == 0)
		return 0;

	port = usb_ports[portno];
	if (!port || !port->state)
		return -EIO;
	return bulkin_read(port, buffer, total);
}

int close_usb_port(int portno)
{
	struct usb_port_struct *port;

	port = usb_ports[portno];

	if (port) {
		port->state = 1;
		if (port->write_urb && port->write_urb->context)
			usb_kill_urb(port->write_urb);
		if (port->read_urb && port->read_urb->context)
			usb_kill_urb(port->read_urb);
		if (port->thread && down_timeout(&port->sem, 3000))
			skw_usb_info("port%d rx thread exit\n", portno);
		port->thread = NULL;
	}
	return 0;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
int wifi_send_cmd(int portno, struct scatterlist *sg, int sg_num, int total)
{
	struct usb_port_struct *port;
	u32 *data;
	int ret;

	if (total == 0)
		return 0;
	if (modem_status != MODEM_ON)
		return -EIO;
	if (portno >= MAX_USB_PORT)
		return -EINVAL;
	port = usb_ports[portno];
	if (!port || !port->state)
		return -EIO;
	if (port->suspend)
		skw_usb_info("port%d is suspended\n", portno);
	if (portno == 0) {
		data = (u32 *)sg_virt(sg);
		memcpy(last_sent_wifi_cmd, data, 12);
		last_sent_time = jiffies;
		last_sent_wifi_cmd[0] =  bulk_async_read;
	}
	ret = bulkout_write_sg(port, sg, sg_num, total);
	return ret;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
int wifi_send_cmd_async(int portno, struct scatterlist *sg, int sg_num, int total)
{
	struct usb_port_struct *port;
	u32 *data;
	int ret;

	if (total == 0)
		return 0;
	if (modem_status != MODEM_ON)
		return -EIO;
	if (portno >= MAX_USB_PORT)
		return -EINVAL;
	port = usb_ports[portno];
	if (!port || !port->state)
		return -EIO;

	if (port->suspend)
		skw_usb_info("port%d is suspended\n", portno);
	if (portno == 0) {
		data = (u32 *)sg_virt(sg);
		memcpy(last_sent_wifi_cmd, data, 12);
		last_sent_time = jiffies;
		last_sent_wifi_cmd[0] =  bulk_async_read;
	}
	ret = bulkout_write_sg_async(port, sg, sg_num, total);
	return ret;
}

/************************************************************************
 *Decription: manual assert modem
 *Author:jiayong.yang
 *Date:2021-08-03
 *Modfiy:
 *Notes: this function must not be invoked in IRQ context.
 ************************************************************************/
int modem_assert(void)
{
	struct usb_port_struct *port;
	struct recovery_data *recovery = SKW_USB_GET_RECOVERY_DATA();
	int ret = -1;
	u32 *cmd = last_sent_wifi_cmd;

	if (modem_status == MODEM_HALT) {
		skw_usb_info("modem in recovery mode\n");
		return 0;
	}
	skw_usb_wake_lock();
	port = usb_ports[0];
	if (port && port->state && !recovery->cp_state) {
		recovery->cp_state = 1;
		ret = usb_control_msg(port->udev, usb_sndctrlpipe(port->udev, 0),
				VENDOR_MSG_MODEM_ASSERT, USB_DIR_OUT | USB_TYPE_VENDOR | USB_RECIP_DEVICE,
				0, 0, NULL, 0, 1000);
		skw_usb_err("SND ASSERT CMD ret = %d cmd: 0x%x 0x%x 0x%x :%x-%x:%x\n",
				ret, cmd[0], cmd[1], cmd[2], (u32)last_sent_time, (u32)jiffies,
				(u32)last_ack_time);
		modem_status = MODEM_HALT;
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
		schedule_delayed_work(&skw_except_work, msecs_to_jiffies(2000));
#else
		schedule_delayed_work(&skw_except_work, msecs_to_jiffies(6000));
#endif
	}
	return ret;
}

EXPORT_SYMBOL(modem_assert);
static int send_modem_service_command(u16 service, u16 command)
{
	struct usb_port_struct *port;
	int ret = -1;
	int timeout = 1000;

	port = usb_ports[1];
	if (port)
		skw_usb_dbg("%s (%d,%d) state= %d\n", __func__,
			service, command, port->state);
	if (port && port->state) {
		skw_reinit_completion(download_done);
		ret = usb_control_msg(port->udev, usb_sndctrlpipe(port->udev, 0),
				VENDOR_MSG_SERVICE_CTRL, USB_DIR_OUT | USB_TYPE_VENDOR | USB_RECIP_DEVICE,
				service, command, NULL, 0, 1000);
	}
	if ((command & 0x01) == SERVICE_START) {
		complete(&loop_completion);
		start_service_flag = 1;
		service_state_map |= (1 << service);
		wait_for_completion_interruptible_timeout(&download_done, msecs_to_jiffies(timeout + 1000 * service));
	} else {
		if (service == BT_SERVICE && modem_status == MODEM_ON)
			wait_for_completion_interruptible_timeout(&download_done, msecs_to_jiffies(50));
		service_state_map &= ~(1 << service);
	}
	return ret;
}

static int skw_get_packet_count(u8 portno)
{
	struct usb_port_struct *port;
	int ret = -1;
	u16 *packet_count, size = 2;

	port = usb_ports[portno];
	if (port && port->state) {
		ret = usb_control_msg(port->udev, usb_rcvctrlpipe(port->udev, 0),
				VENDOR_MSG_PACKET_COUNT, USB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE,
				portno, 0, port->read_buffer, size, 1000);

		packet_count = (u16 *)port->read_buffer;
		if (ret < 0)
			skw_port_log(portno, "%s (%d,%d) ret = %d\n", __func__, portno, *packet_count, ret);
		if (ret == size)
			port->max_packet_count = *packet_count;
		else
			port->max_packet_count = MAX_PACKET_COUNT;
	}
	return ret;
}

void skw_usb_cp_log(int disable)
{
	struct usb_port_struct *port;
	int ret = -1;

	skw_usb_info("Enter\n");
	port = usb_ports[0];
	if (port && port->state) {
		ret = usb_control_msg(port->udev, usb_rcvctrlpipe(port->udev, 0),
				VENDOR_MSG_LOG_SWITCH, USB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE,
				disable, 0, NULL, 0, 1000);

		skw_usb_info("%s (disable=%d) ret = %d\n", __func__, disable, ret);
	}
	if (!disable)
		skw_usb_info(" enable the CP log\n");
	else
		skw_usb_info(" disable the CP log !!\n");
}

int skw_usb_cp_log_status(void)
{
	return cp_log_status;
}

int skw_usb_debug_log_open(void)
{
	skw_usb_info("enable log TO AP!\n");
	cp_log_status = 0;
	return cp_log_status;
}

int skw_usb_debug_log_close(void)
{
	skw_usb_info("disable CP log !!\n");
	cp_log_status = 1;
	return cp_log_status;
}

/************************************************************************
 *Decription:send BT start command to modem.
 *Author:jiayong.yang
 *Date:2021-08-30
 *Modfiy:
 *
 ********************************************************************* */
int skw_BT_service_start(void)
{
	skw_usb_info("Enter modem_status=%d\n", modem_status);
	if (service_state_map & (1 << BT_SERVICE))
		return 0;

#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
	if (!cp_log_status)
		skw_usb_cp_log(1);
#else
	if (cp_log_status)
		skw_usb_cp_log(1);
#endif

	return send_modem_service_command(BT_SERVICE, SERVICE_START);
}

EXPORT_SYMBOL(skw_BT_service_start);

/************************************************************************
 *Decription:send BT stop command to modem.
 *Author:jiayong.yang
 *Date:2021-08-30
 *Modfiy:
 *
 ********************************************************************* */
int skw_BT_service_stop(void)
{
	skw_usb_info("Enter modem_status=%d\n", modem_status);
	if (service_state_map & (1 << BT_SERVICE)) {
		return send_modem_service_command(BT_SERVICE, SERVICE_STOP);
	}
	return 0;
}

EXPORT_SYMBOL(skw_BT_service_stop);
/************************************************************************
 *Decription:send WIFI start command to modem.
 *Author:jiayong.yang
 *Date:2021-08-30
 *Modfiy:
 *
 ********************************************************************* */
int skw_WIFI_service_start(void)
{
	int count = 90;
	u16 cmd = SERVICE_START;

	if (modem_status == MODEM_HALT) {
		while (!usb_ports[1] && count--)
			msleep(10);
	}
	if (service_state_map & (1 << WIFI_SERVICE))
		return 0;
	if (wifi_port_share)
		cmd |= WIFI_PORT_SHARE_FLAG;
	if (!usb_boot_data->pdev)
		cmd |= USB_HOST_RESUME_SUPPORT;

#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
	if (!cp_log_status)
		skw_usb_cp_log(1);
#else
	if (cp_log_status)
		skw_usb_cp_log(1);
#endif
	skw_usb_info("Enter STARTWIFI---modem_status=%d, 0x%x cmd=%d\n",
			modem_status, service_state_map, cmd);
	return send_modem_service_command(WIFI_SERVICE, cmd);
}
EXPORT_SYMBOL(skw_WIFI_service_start);

/************************************************************************
 *Decription: send WIFI stop command to modem.
 *Author:jiayong.yang
 *Date:2021-08-30
 *Modfiy:
 *
 ********************************************************************* */
int skw_WIFI_service_stop(void)
{
	int count = 70;

	if (modem_status == MODEM_HALT) {
		service_state_map &= ~(1 << WIFI_SERVICE);
		while (!usb_ports[1] && count--)
			msleep(10);
		return 0;
	}
	skw_usb_info("Enter,STOPWIFI--- modem status %d, 0x%x\n",
			modem_status, service_state_map);
	if (service_state_map & (1 << WIFI_SERVICE))
		return send_modem_service_command(WIFI_SERVICE, SERVICE_STOP);
	return 0;
}
EXPORT_SYMBOL(skw_WIFI_service_stop);
/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-08-30
 *Modfiy:
 *
 ********************************************************************* */
static void bulkin_complete(struct urb *urb)
{
	struct usb_port_struct *port;
	int portno = usb_pipeendpoint(urb->pipe) - 1;

	port = usb_ports[portno];
	if (urb) {
		if (urb->status) {
			skw_usb_info("endpoint%d actual = %d status %d\n",
				usb_pipeendpoint(urb->pipe), urb->actual_length, urb->status);
		}
		if (urb->status == -ENOENT && !usb_boot_data->pdev && port->suspend)
			list_add_tail(&urb->urb_list, &port->suspend_urb_list);
		else if (urb->context)
			complete(urb->context);
	}
}

static void bulkin_async_complete(struct urb *urb)
{
	struct usb_port_struct *port = urb->context;

	if (urb->status) {
		skw_usb_info("endpoint%d actual = %d status %d\n",
			usb_pipeendpoint(urb->pipe), urb->actual_length, urb->status);
	}
	if (urb->status == -ENOENT && port->suspend)
		list_add_tail(&urb->urb_list, &port->suspend_urb_list);
	else if (port) {
		bulk_async_read--;
		urb->context = NULL;
		spin_lock(&port->rx_urb_lock);
		list_add_tail(&urb->urb_list, &port->rx_done_urb_list);
		spin_unlock(&port->rx_urb_lock);
		tasklet_hi_schedule(&port->tasklet);
		wake_up_interruptible(&port->rx_wait);
	}
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static void bulkout_complete(struct urb *urb)
{
	if (urb->status) {
		u32 *data = urb->transfer_buffer;

		skw_usb_info("endpoint%d actual = %d status %d: 0x%x 0x%x 0x%x\n",
			usb_pipeendpoint(urb->pipe),  urb->actual_length, urb->status,
			data[0], data[1], data[2]);
	}
	if (urb->context)
		complete(urb->context);
}

static void bulkout_async_complete(struct urb *urb)
{
	struct usb_port_struct *port = urb->context;
	//unsigned long flags;

	if (urb->status) {
		if (urb->sg && port->adma_tx_callback) {
			u32 *data;

			data = (u32 *)sg_virt(urb->sg);
			if ((data[0] >> 7) > 0x600 && port->portno)
				skw_usb_info("%s invalid packet size: 0x%x\n", __func__, data[0] >> 7);
			port->adma_tx_callback(port->portno, urb->sg, urb->num_sgs, port->tx_data, urb->status);
		} else if(urb->transfer_buffer && port->sdma_tx_callback)
			port->sdma_tx_callback(port->portno, urb->transfer_buffer, urb->transfer_buffer_length, port->tx_data, urb->status);
		skw_usb_info("port%d endpoint%d actual = %d status %d\n", port->portno,
				usb_pipeendpoint(urb->pipe), urb->actual_length, urb->status);
	} else if (urb->sg && port->adma_tx_callback) {
		port->adma_tx_callback(port->portno, urb->sg, urb->num_sgs, port->tx_data, 0);
		port->sent_packet_count += urb->num_sgs;
	} else if (urb->transfer_buffer && port->sdma_tx_callback)
		port->sdma_tx_callback(port->portno, urb->transfer_buffer, urb->transfer_buffer_length, port->tx_data, 0);
	urb->context = NULL;
	spin_lock(&port->tx_urb_lock);
	list_add_tail(&urb->urb_list, &port->tx_urb_list);
	port->tx_urb_count--;
	if (port->tx_urb_count == 0 && port->sent_packet_count != port->req_tx_packet)
		skw_usb_info("%s port[%d]= %d %d\n", __func__, port->portno, port->sent_packet_count, port->req_tx_packet);
	spin_unlock(&port->tx_urb_lock);
	wake_up_interruptible(&port->tx_wait);
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
int bulkin_read_timeout(int portno, char *buffer, int size, int *actual, int timeout)
{
	struct usb_port_struct *port;
	unsigned int pipe;
	int	ret;

	if (portno >= MAX_USB_PORT || !buffer || !size)
		return -EINVAL;
	port = usb_ports[portno];
	if (!port->state)
		return -EIO;
	if (actual)
		*actual = 0;
	pipe = usb_rcvbulkpipe(port->udev, port->epin->bEndpointAddress);
	ret = usb_bulk_msg(port->udev, pipe, buffer, size, actual, timeout);

	if (port == log_port) {
		if (assert_info_print && assert_info_print < 28 && *actual < 100) {
			assert_info_print++;
			if (*actual > 4)
				printk("%s", (char *)buffer);
		}
		if (*actual == 4)
			assert_info_print = 28;
	}
	if (ret)
		return ret;

	if (actual)
		return *actual;
	return ret;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
int bulkout_write_timeout(int portno, char *buffer, int size, int *actual, int timeout)
{
	struct usb_port_struct *port;
	unsigned int pipe;
	int	ret;

	if (portno >= MAX_USB_PORT || !buffer || !size)
		return -EINVAL;
	port = usb_ports[portno];

	if (!port->state)
		return -EIO;
	if (actual)
		*actual = 0;
	pipe = usb_sndbulkpipe(port->udev, port->epout->bEndpointAddress);
	ret = usb_bulk_msg(port->udev, pipe, buffer, size, actual, timeout);
	if (ret)
		return ret;
	if (actual)
		return *actual;
	return ret;
}

static void kick_rx_thread(void)
{
	struct usb_port_struct *port;

	skw_usb_info("submitted urb %d\n", bulk_async_read);
	port = usb_ports[1];
	if ((bulk_async_read == 0) && port &&
	    (!list_empty(&port->rx_urb_list)))
		bulkin_read_async(port);
	else if (list_empty(&port->rx_urb_list)) {
		skw_usb_info("urb list is empty\n");
	}
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static int register_rx_callback(int id, void *func, void *para);
static int register_tx_callback(int id, void *func, void *para);
static struct sv6160_platform_data wifi_pdata = {
	.data_port = 0,
	.cmd_port = 1,
#ifdef CONFIG_SEEKWAVE_PLD_RELEASE
	.bus_type = USB_LINK | TX_DMA_TYPE | RX_SDMA | TX_ASYN | CP_RLS,
#else
	.bus_type = USB_LINK | TX_DMA_TYPE | RX_SDMA | TX_ASYN | CP_DBG,
#endif
	.max_buffer_size = MAX_BUFFER_SIZE,
	.align_value = 512,
	.hw_adma_tx = wifi_send_cmd,
	.hw_sdma_tx = send_data,
	.hw_adma_tx_async = wifi_send_cmd_async,
	.hw_sdma_tx_async = send_data_async,
	.callback_register = register_rx_callback,
	.modem_assert = modem_assert,
	.modem_register_notify = modem_register_notify,
	.modem_unregister_notify = modem_unregister_notify,
	.at_ops = {
		.port = 2,
		.open = open_usb_port,
		.close = close_usb_port,
		.read = recv_data,
		.write = send_data,
	},
	.tx_callback_register = register_tx_callback,
	.rx_thread_wakeup = kick_rx_thread,
};

void usb_handle(unsigned long tsk_data)
{
	struct usb_port_struct *port = (struct usb_port_struct *)tsk_data;
	struct scatterlist *sg;
	struct urb *urb;
	unsigned long flags;
	int   size, read, ret;
	char *buffer;
	int  *data, sg_count, offset;
	u16  data_flag = 0x8000;

	if (!strncmp(skw_chipid, "SV6316", 6) ||
		!strncmp(skw_chipid, "SV6160LITE", 10))
		data_flag = 2;

	while (!list_empty(&port->rx_done_urb_list)) {
		spin_lock_irqsave(&port->rx_urb_lock, flags);
		urb = list_first_entry(&port->rx_done_urb_list, struct urb, urb_list);
		list_del_init(&urb->urb_list);
		list_add_tail(&urb->urb_list, &port->rx_urb_list);
		spin_unlock_irqrestore(&port->rx_urb_lock, flags);

		sg_init_table(sgs, nr_sgs);
		read = urb->actual_length;
		buffer = urb->transfer_buffer;
		if (urb->status < 0 || !port->state) {
			dev_err(&port->udev->dev, "%s bulkin read status=%d state=%d\n", __func__, urb->status, port->state);
			return;
		}

		if (port->rx_submit) {
			int is_cmd, i;
			u32 d32;

			data = (int *)buffer;
			d32 = data[0];
			offset = 0;
			sg_count = 0;
			sg = sgs;
			is_cmd = 0;
			while (offset + 12 < read) {
				sg_count++;
				if (sg_count > nr_sgs) {
					skw_usb_warn("packet count is overflow %d : %d : %d : %d!!!\n",
							offset, read, sg_count, nr_sgs);
					sg_count--;
					break;
				}
				size = data[2] >> 16;
				size += 3;
				size = size & 0xfffffffc;
				if (data[2] & data_flag) {
					if (sg_count > 1 && !is_cmd)
						size = -1;
					else
						is_cmd = 1;
				}
				if (size + offset > read || size > 2048 || size < 12) {
					skw_usb_warn("Invalid packet size=%d: %d : %d :%d  0x%x:0x%x!!!\n",
						size, offset, read, sg_count, d32, data[2]);
					if (recovery_debug_status) {
						print_hex_dump(KERN_ERR, "PACKET ERR:", 0, 16, 1,
						      urb->transfer_buffer, urb->actual_length, 1);
						modem_assert();
					}
					sg_count--;

					if (sg_count > 1)
						sg_count--;
					break;
				}
				sg_set_buf(sg,  &buffer[offset], size);
				sg++;
				offset  += size;
				if (is_cmd) {
					skw_usb_dbg("rx_submit:command:0x%x 0x%x 0x%x 0x%x len=%d\n",
							 data[0], data[1], data[2], data[3], read);
					if ((data[3] & 0xff) == 0x10)
						memcpy(last_recv_wifi_ack, &data[1], 12);
					else
						memcpy(last_recv_wifi_evt, &data[1], 12);
					last_ack_time = jiffies;
				}
				data = (int *)&buffer[offset];
			}
			if (sg_count > 15)
				dev_info(&port->udev->dev, "rx_submit: port%d packet count %d\n",
					port->portno, sg_count);
			if (is_cmd) {
				port = usb_ports[wifi_pdata.cmd_port];
			} else
				port = usb_ports[wifi_pdata.data_port];
			if (port) {
				if (port->suspend)
					dev_info(&port->udev->dev, "submit command(%d) in suspend status", is_cmd);
				port->rx_submit(port->portno, sgs, sg_count, port->rx_data);
				port->rx_packet_count += sg_count;
			} else {
				pr_err("%s port = NULL!!!\n", __func__);
			}
			if (modem_status != MODEM_ON)
				break;
			port = (struct usb_port_struct *)tsk_data;
			for (i = 0; i < 3; i++) {
				ret = bulkin_read_async(port);
				if (ret || list_empty(&port->rx_urb_list))
					break;
			}
		}
	}
}

/**********************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 **********************************************************************/
int usb_port_async_entry(void *para)
{
	struct usb_port_struct *port = para;
	struct sched_param param;
	unsigned long flags;
	//int   size, read, ret;
	u16	mpc;
	//char *buffer;
	struct urb *urb;
	u16  data_flag = 0x8000;

	if (port->portno == 0) {
		param.sched_priority = USB_RX_TASK_PRIO;
#if KERNEL_VERSION(5, 9, 0) <= LINUX_VERSION_CODE
		sched_set_fifo_low(current);
#else
		sched_setscheduler(current, SCHED_FIFO, &param);
#endif
	}
	if (port->max_packet_count)
		mpc = port->max_packet_count;
	else
		mpc = 2;

	bulk_async_read = 0;
	if (!strncmp(skw_chipid, "SV6316", 6) ||
	    !strncmp(skw_chipid, "SV6160LITE", 10))
		data_flag = 2;
	sgs = kzalloc((mpc + 1) * sizeof(struct scatterlist), GFP_KERNEL);
	if (!sgs)
		return -ENOMEM;
	nr_sgs = mpc + 1;
	usb_port_alloc_recv_urbs(port, port->epin, 3, 32 * 1024);
	usb_port_alloc_xmit_urbs(port, port->epout, 3, 0);
	skw_usb_info("%s %d running packet %d %s %d...\n", __func__, port->portno, mpc, skw_chipid, data_flag);
	while (!list_empty(&port->rx_urb_list)) {
		bulkin_read_async(port);
	}

	wait_event_interruptible(port->rx_wait, (!port->state));

	dev_info(&port->udev->dev, "%s-port%d is stopped\n", __func__, port->portno);
	kfree(sgs);

	if (port->write_urb && port->write_urb->context) {
		usb_kill_anchored_urbs(&port->write_submitted);
	}
	if (port->read_urb && port->read_urb->context) {
		usb_kill_anchored_urbs(&port->read_submitted);
	}

	skw_usb_info("%s port%d exit context = %p\n",
			__func__, port->portno, port->write_urb->context);
	if (port->write_urb && port->write_urb->context)
		wait_for_completion_interruptible(port->write_urb->context);

	spin_lock_irqsave(&port->rx_urb_lock, flags);
	while (!list_empty(&port->rx_urb_list)) {
		urb = list_first_entry(&port->rx_urb_list, struct urb, urb_list);
		list_del_init(&urb->urb_list);
		kfree(urb->transfer_buffer);
		skw_usb_info("%s release rx  urb %p\n", __func__, urb);
		usb_free_urb(urb);
	}
	spin_unlock_irqrestore(&port->rx_urb_lock, flags);
	while (!list_empty(&port->tx_urb_list)) {
		urb = list_first_entry(&port->tx_urb_list, struct urb, urb_list);
		list_del_init(&urb->urb_list);
		skw_usb_info("%s release tx urb %p\n", __func__, urb);
		usb_free_urb(urb);
	}
	up(&port->sem);
	return 0;
}

int usb_port_entry(void *para)
{
	struct usb_port_struct *port = para;
	struct scatterlist *sgs, *sg;
	struct sched_param param;
	int   size, read, buf_size;
	u16	mpc;
	char *buffer;
	u16  data_flag = 0x8000;

	if (port->portno == 0) {
		param.sched_priority = USB_RX_TASK_PRIO;
#if KERNEL_VERSION(5, 9, 0) <= LINUX_VERSION_CODE
		sched_set_fifo_low(current);
#else
		sched_setscheduler(current, SCHED_FIFO, &param);
#endif
	}

	if (port->max_packet_count)
		mpc = port->max_packet_count;
	else
		mpc = 2;

	if (!strncmp(wifi_pdata.chipid, "SV6160LITE", 10))
		data_flag = 2;
	sgs = kzalloc((mpc + 1) * sizeof(struct scatterlist), GFP_KERNEL);
	if (!sgs)
		return -ENOMEM;
	buf_size = 1568 * mpc;
	buffer = kzalloc(buf_size, GFP_KERNEL);
	if (!buffer)
		return -ENOMEM;
	skw_usb_info("%s%d (MPC %d buffer_size 0x%x )is runninng\n",
			__func__, port->portno, mpc, buf_size);
	while (port->state) {
		int  *data, sg_count, offset;

		sg_init_table(sgs, mpc + 1);
		read = 0;
read_msg:
		do {
			if (port->state == 0)
				break;
			read = bulkin_read(port, buffer, buf_size);

		} while (!read);

		if (read < 0 || !port->state) {
			dev_err(&port->udev->dev, "bulkin read_len=%d state = %d\n", read, port->state);
			break;
		}
		if (modem_status != MODEM_ON)
			break;
		if (port->rx_submit) {
			int is_cmd;

			data = (int *)buffer;
			offset = 0;
			sg_count = 0;
			sg = sgs;
			is_cmd = 0;
			while (offset < read) {
				sg_count++;
				if (sg_count > mpc) {
					skw_usb_warn("packet count is overflow %d : %d : %d : %d!!!\n",
							offset, read, sg_count, mpc);
					sg_count--;
					break;
				}
				size = data[2] >> 16;
				size += 3;
				size = size & 0xfffffffc;
				if (size + offset > read)
					size = read  - offset;
				dev_dbg(&port->udev->dev, "submit len=%d size =%d msg: 0x%x 0x%x 0x%x\n",
					 read, size, data[0], data[1], data[2]);
				if ((data[2] & 0xff) == 0x10)
					memcpy(last_recv_wifi_ack, &data[2], 12);
				else
					memcpy(last_recv_wifi_evt, &data[2], 12);
				last_ack_time = jiffies;
				if (data[2] & data_flag)
					is_cmd = 1;
				sg_set_buf(sg,  &buffer[offset], size);
				sg++;
				offset  += size;
				data = (int *)&buffer[offset];
			}
			if (sg_count > 15)
				dev_info(&port->udev->dev, "rx_submit: port%d packet count %d\n",
					port->portno, sg_count);
			if (is_cmd)
				port = usb_ports[wifi_pdata.cmd_port];
			port->rx_submit(port->portno, sgs, sg_count, port->rx_data);
			port->rx_packet_count += sg_count;
			port = para;
		} else if(port->state)
			goto read_msg;
	}
	kfree(buffer);
	dev_info(&port->udev->dev, "%s-port%d is stopped\n", __func__, port->portno);
	kfree(sgs);

	if (port->read_urb && port->read_urb->context) {
		usb_kill_anchored_urbs(&port->read_submitted);
	}
	if (port->write_urb && port->write_urb->context) {
		usb_kill_anchored_urbs(&port->write_submitted);
	if (port->write_urb->context)
	    wait_for_completion_interruptible(port->write_urb->context);
    }
	up(&port->sem);
	return 0;
}

static void skw_usb_kill_wifi_threads(struct usb_port_struct *p)
{
	int i;
	struct usb_port_struct *port;

	for (i = 0; i < 3; i++) {
		port = usb_ports[i];
		if (!port)
			break;
		if (port && port->thread) {
			port->state = 0;
			//usb_kill_anchored_urbs(&port->write_submitted);
			//usb_kill_anchored_urbs(&port->read_submitted);
		}
	}
}

static void skw_usb_dump_memory(char *buffer, int size, int *log_size)
{
	if (size && buffer && log_size) {
		dump_memory_buffer = buffer;
		dump_buffer_size = size;
		dump_log_size = log_size;
		skw_usb_info("dump_memory : %p-%d\n", buffer, size);
		schedule_work(&dump_memory_worker);
	}
}

static void show_assert_context(void)
{
	int read;
	int error_count;
	int total_size;
	int dump_memory_size = 0;

	if (log_port && log_port->state != 2) {
		char *buffer;

		buffer = kzalloc(1024, GFP_KERNEL);
		if (!buffer)
			return;
		open_usb_port(log_port->portno, 0, 0);
		dump_memory_done = 0;
		error_count = 0;
		total_size = 0;
		do {
			read = bulkin_read_timeout(log_port->portno, buffer, 1024, &read, 10);
			if (read > 0) {
				if (total_size + read < dump_buffer_size) {
					memcpy(&dump_memory_buffer[total_size], buffer, read);
					dump_memory_size = total_size + read;
				}
				total_size += read;
				memset(buffer, 0, read);
			}
			if (read == 4 || read < 0) {
				close_usb_port(log_port->portno);
				break;
			}
		} while (assert_info_print < 100);
		while (!dump_memory_done) {
			read = bulkin_read_timeout(log_port->portno, buffer, 1024, &read, 10);
			if (read <= 0) {
				error_count++;
				skw_usb_info("%s read = %d : total %d\n", current->comm, read, total_size);
				if (error_count > 3)
					break;
			} else {
				if (total_size + read < dump_buffer_size) {
					memcpy(&dump_memory_buffer[total_size], buffer, read);
					dump_memory_size = total_size + read;
				}
				total_size += read;
			}
		}
		skw_usb_info("dump memory size: %d buffer_size: %d\n", dump_memory_size, dump_buffer_size);
		if (dump_log_size)
			*dump_log_size = dump_memory_size;
		kfree(buffer);
	}
}

static void dump_memory_work(struct work_struct *work)
{
	show_assert_context();
}

static int usb_loopcheck_entry(void *para)
{
	struct usb_port_struct *port = para;
	char *buffer;
	int read, size;
	int count = 0, timeout = 100;
	struct recovery_data *recovery = SKW_USB_GET_RECOVERY_DATA();

	size = 512;
	buffer = kzalloc(size, GFP_KERNEL);
	schedule_delayed_work(&skw_except_work, msecs_to_jiffies(6000));//update241101
	while (port->state && buffer) {
		read = 0;
		memset(buffer, 0, size);
		do {
			if (port->state == 0)
				break;
			read = bulkin_read(port, buffer, 256);
		} while (!read);
		if (!usb_boot_data->pdev && port->suspend) {
			msleep(500);
			continue;
		}
		if (read < 0 || !port->state) {
			dev_err(&port->udev->dev, "bulkin read_len=%d\n", read);
			break;
		}
		if (strncmp(buffer, "BSPREADY", read))
			skw_usb_info("recv(%d): %s\n", read, buffer);
		memcpy(buffer + 256, "LOOPCHECK", 9);
		if (read == 8 && !strncmp(buffer, "BSPREADY", read)) {
			if (start_service_flag)
				continue;
			bulkout_write(port, buffer + 256, 9);
		} else if (read == 9 && !strncmp(buffer, "WIFIREADY", read)) {
			start_service_flag = 0;
			service_state_map |= (1 << WIFI_SERVICE);
			complete(&download_done);
			timeout = 200;
			bulkout_write(port, buffer + 256, 9);
		} else if (read == 6 && !strncmp(buffer, "BTEXIT", read)) {
			complete(&download_done);
		} else if (read == 7 && !strncmp(buffer, "BTREADY", read)) {
			start_service_flag = 0;
			service_state_map |= (1 << BT_SERVICE);
			complete(&download_done);
			bulkout_write(port, buffer + 256, 9);
		} else if (!strncmp(buffer, "BSPASSERT", 9)) {
			if (recovery->cp_state == 1)
				cancel_delayed_work_sync(&skw_except_work);
			recovery->cp_state = 1;
			skw_usb_err("cmd:0x%x 0x%x 0x%x ack:%x %x:%x event:0x%x:0x%x:0x%x time:0x%x:0x%x:0x%x: read_async:%d\n",
				last_sent_wifi_cmd[0], last_sent_wifi_cmd[1], last_sent_wifi_cmd[2],
				last_recv_wifi_ack[0], last_recv_wifi_ack[1], last_recv_wifi_ack[2],
				last_recv_wifi_evt[0], last_recv_wifi_evt[1], last_recv_wifi_evt[2],
				(u32)jiffies, (u32)last_sent_time, (u32)last_ack_time, bulk_async_read);
			mutex_lock(&recovery->except_mutex);
			if (recovery->cp_state == DEVICE_BLOCKED_EVENT) {
				mutex_unlock(&recovery->except_mutex);
				break;
			}
			skw_usb_wake_lock();
			mutex_unlock(&recovery->except_mutex);

			assert_info_print = 1;
			memset(buffer, 0, read);
			skw_usb_kill_wifi_threads(port);
			modem_status = MODEM_HALT;
#ifndef CONFIG_SEEKWAVE_PLD_RELEASE
			if (dump_buffer_size == 0)
				schedule_work(&dump_memory_worker);
#endif
			modem_notify_event(DEVICE_ASSERT_EVENT);
			memset(buffer, 0, 256);
			read = bulkin_read_timeout(port->portno, buffer, 256, &read, 1000);
			if (read > 0)
				skw_usb_info(" bspassert after recv(%d): %s\n", read, buffer);
			dump_memory_done = 1;
			msleep(10);
			modem_notify_event(DEVICE_DUMPDONE_EVENT);
			msleep(10);

			skw_recovery_mode();
			service_state_map = 0;

			break;
		} else if (!strncmp("trunk_W", buffer, 7)) {
#ifdef CONFIG_SKW_DL_TIME_STATS
			last_time = ktime_get();
			skw_usb_info("%s,the download time start time %llu and lasttime %llu ,lose_time=%llu\n",
				__func__, cur_time, last_time, (last_time - cur_time));
#endif
			cancel_delayed_work_sync(&skw_except_work);
			recovery->cp_state = 0;
			assert_info_print = 0;
			modem_status = MODEM_ON;
			memset(firmware_version, 0, sizeof(firmware_version));
			strncpy(firmware_version, buffer, read);
			modem_notify_event(DEVICE_BSPREADY_EVENT);
			count = 0;
			skw_usb_wake_unlock();
			schedule_work(&add_device_work);
			bulkout_write(port, buffer + 256, 9);
		}
		//msleep(timeout);
		wait_for_completion_interruptible_timeout(&loop_completion, msecs_to_jiffies(timeout));
		skw_reinit_completion(loop_completion);
	}
	dev_info(&port->udev->dev, "%s-port%d is stopped\n", __func__, port->portno);

	if (port->read_urb && port->read_urb->context) {
		usb_kill_anchored_urbs(&port->read_submitted);
	}

	if (port->write_urb && port->write_urb->context) {
		usb_kill_anchored_urbs(&port->write_submitted);
	if (port->write_urb->context)
	    wait_for_completion_interruptible(port->write_urb->context);
	}

	kfree(buffer);
	up(&port->sem);
	return 0;
}

static int usb_bt_rx_entry(void *para)
{
	struct usb_port_struct *port = para;
	char *buffer;
	int read, size;

	size = 2048;
	buffer = kzalloc(size, GFP_KERNEL);
	while (port->state == 2 && buffer) {
		read = 0;
		memset(buffer, 0, size);
		do {
			if (port->state != 2)
				break;
			read = bulkin_read(port, buffer, size);
		} while (!read);

		if (read < 0) {
			dev_err(&port->udev->dev, "bulkin read_len=%d\n", read);
			break;
		}
		if (port->rx_submit)
			port->rx_submit(port->portno, port->rx_data, read, buffer);
	}
	dev_info(&port->udev->dev, "%s-port%d is stopped\n", __func__, port->portno);
	if (port->write_urb && port->write_urb->context) {
		usb_kill_anchored_urbs(&port->write_submitted);
	}
	if (port->read_urb && port->read_urb->context) {
		usb_kill_anchored_urbs(&port->read_submitted);
	}

	kfree(buffer);
	up(&port->sem);
	return 0;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static struct sv6160_platform_data ucom_pdata = {
	.max_buffer_size = 0x800,
	.bus_type = USB_LINK,
	.hw_sdma_tx = send_data,
	.hw_sdma_rx = recv_data,
	.open_port = open_usb_port,
	.close_port = close_usb_port,
	.modem_assert = modem_assert,
	.modem_register_notify = modem_register_notify,
	.modem_unregister_notify = modem_unregister_notify,
	.dump_modem_memory = skw_usb_dump_memory,
};

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static int register_rx_callback(int id, void *func, void *para)
{
	if (id >= MAX_USB_PORT)
		return -EINVAL;

	if (!usb_ports[id])
		return -EIO;
	if (func && !usb_ports[id]->rx_submit) {
		if (id == 1)
			skw_WIFI_service_start();
		usb_ports[id]->rx_submit = func;
		usb_ports[id]->rx_data = para;
		return 0;
	} else if (!func && usb_ports[id]->rx_submit) {
		if (id == 1)
			skw_WIFI_service_stop();

		usb_ports[id]->rx_submit = func;
		usb_ports[id]->rx_data = para;
		return 0;
	}
	if (wifi_pdata.bus_type & TX_ASYN) {
		if (wifi_pdata.bus_type & TX_SDMA)
			usb_ports[id]->sdma_tx_callback = func;
		else
			usb_ports[id]->adma_tx_callback = func;
	}
	usb_ports[id]->tx_data = para;
	return 0;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static int register_tx_callback(int id, void *func, void *para)
{
	if (id >= MAX_USB_PORT)
		return -EINVAL;

	if (!usb_ports[id])
		return -EIO;
	if (wifi_pdata.bus_type & TX_ASYN) {
		if (wifi_pdata.bus_type & TX_SDMA)
			usb_ports[id]->sdma_tx_callback = func;
		else
			usb_ports[id]->adma_tx_callback = func;
	}
	usb_ports[id]->tx_data = para;
	return 0;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static int skw_usb_io_probe(struct usb_interface *interface,
				const struct usb_device_id *id)
{
	struct usb_port_struct *port;
	struct usb_host_interface *iface_desc;
	struct usb_endpoint_descriptor *epd;
	struct platform_device *pdev;
	struct usb_device *udev = interface_to_usbdev(interface);
	char	pdev_name[32], names[32];
	int	i, ret, dloader = 0;

	memset(names, 0, sizeof(names));
	iface_desc = interface->cur_altsetting;
	if (!iface_desc->string)
		return -EINVAL;
	sprintf(names, "%s", iface_desc->string);

	if (!strncmp(names, "Boot", 4))
		dloader = 1;

	port = kzalloc(sizeof(*port), GFP_KERNEL);
	if (!port)
		return -ENOMEM;

	pdev = NULL;
	if (!strncmp(names, "WIFITCMD", 8))
		wifi_port_share = 1;
	usb_ports[iface_desc->desc.bInterfaceNumber] = port;
	INIT_LIST_HEAD(&port->rx_urb_list);
	INIT_LIST_HEAD(&port->tx_urb_list);
	INIT_LIST_HEAD(&port->rx_done_urb_list);
	INIT_LIST_HEAD(&port->suspend_urb_list);
	spin_lock_init(&port->rx_urb_lock);
	spin_lock_init(&port->tx_urb_lock);
	port->tx_urb_count = 0;
	init_waitqueue_head(&port->rx_wait);
	init_waitqueue_head(&port->tx_wait);
	if (dloader)
		dloader = 1;
	else if (iface_desc->desc.bInterfaceNumber == 1) {
		sprintf(pdev_name, "%s%d", SV6160_WIRELESS,
			iface_desc->desc.bInterfaceNumber);
		if (!wifi_data_pdev)
			pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
		else
			pdev = wifi_data_pdev;
		if (!pdev)
			return -ENOMEM;
	} else {
#ifdef CONFIG_BT_SEEKWAVE
		pdev = NULL;
		if (!strncmp(names, "DATA", 4)) {
			ucom_pdata.data_port = 0;
		} else	if (!strncmp(names, "BTDATA", 6))
			ucom_pdata.data_port = iface_desc->desc.bInterfaceNumber;
		else	if (!strncmp(names, "BTCMD", 5))
			ucom_pdata.cmd_port = iface_desc->desc.bInterfaceNumber;
		else	if (!strncmp(names, "BTAUDIO", 7)) {
			ucom_pdata.audio_port = iface_desc->desc.bInterfaceNumber;
			sprintf(pdev_name, "%s", "btseekwave");
			ucom_pdata.port_name = "BTHCI";
			bluetooth_pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
			if (!bluetooth_pdev)
				return -ENOMEM;
			bluetooth_pdev->dev.parent = &udev->dev;
			bluetooth_pdev->dev.dma_mask = &port_dmamask;
			bluetooth_pdev->dev.coherent_dma_mask = port_dmamask;
			bt_audio_port = iface_desc->desc.bInterfaceNumber;
			platform_device_add_data(bluetooth_pdev, &ucom_pdata, sizeof(ucom_pdata));
		} else if (!strncmp(names, "AUDIO", 5)) {
			ucom_pdata.audio_port = 0;
			sprintf(pdev_name, "%s", "btseekwave");
			ucom_pdata.port_name = "BTHCI";
			bluetooth_pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
			if (!bluetooth_pdev)
				return -ENOMEM;
			bluetooth_pdev->dev.parent = &udev->dev;
			bluetooth_pdev->dev.dma_mask = &port_dmamask;
			bluetooth_pdev->dev.coherent_dma_mask = port_dmamask;
			bt_audio_port = iface_desc->desc.bInterfaceNumber;
			platform_device_add_data(bluetooth_pdev, &ucom_pdata, sizeof(ucom_pdata));
		} else
#endif
		if (iface_desc->desc.bInterfaceNumber && strncmp(names, "LOOP", 4)) {
			sprintf(pdev_name, "%s", "skw_ucom");
			ucom_pdata.port_name = iface_desc->string;
			ucom_pdata.data_port = iface_desc->desc.bInterfaceNumber;
			pdev = platform_device_alloc(pdev_name, PLATFORM_DEVID_AUTO);
			if (!pdev)
				return -ENOMEM;
		}
	}
	if (!dloader) {
		if (1 == iface_desc->desc.bInterfaceNumber && wifi_data_pdev) {
			pdev = wifi_data_pdev;
			pdev->dev.parent = NULL;
			port->pdev = pdev;
		} else if (iface_desc->desc.bInterfaceNumber && pdev) {
			if (1 == iface_desc->desc.bInterfaceNumber &&
			    usb_boot_data && usb_boot_data->pdev) {
				pdev->dev.parent = &usb_boot_data->pdev->dev;
				wifi_pdata.bus_type |= REINIT_USB_STR;
			} else
				pdev->dev.parent = &udev->dev;
			pdev->dev.dma_mask = &port_dmamask;
			pdev->dev.coherent_dma_mask = port_dmamask;

			if (iface_desc->desc.bInterfaceNumber == 1) {
				wifi_pdata.align_value = iface_desc->endpoint[0].desc.wMaxPacketSize;
				if (usb_boot_data && usb_boot_data->iram_dl_size > 0x70000)
					wifi_pdata.at_ops.port = 5;
				else
					wifi_pdata.at_ops.port = 2;
				if (udev->config->string && !strncmp(udev->config->string, "ECOM", 4)) {
					wifi_pdata.bus_type &= ~TYPE_MASK;
					wifi_pdata.bus_type |= USB2_LINK;
				}
				skw_usb_info("bustype = 0x%x\n", wifi_pdata.bus_type);
				ret = platform_device_add_data(pdev, &wifi_pdata, sizeof(wifi_pdata));
				modem_status = MODEM_ON;
			} else
				ret = platform_device_add_data(pdev, &ucom_pdata, sizeof(ucom_pdata));

			if (ret) {
				dev_err(&udev->dev, "failed to add platform data\n");
				platform_device_put(pdev);
				kfree(port);
				return ret;
			}
			if (iface_desc->desc.bInterfaceNumber > 1) {
				ret = platform_device_add(pdev);
				if (ret) {
					dev_err(&udev->dev, "failt to register platform device\n");
					platform_device_put(pdev);
					kfree(port);
					return ret;
				}
			}
			port->pdev = pdev;
		}
	}
	usb_set_intfdata(interface, port);

	port->interface = usb_get_intf(interface);
	port->udev = usb_get_dev(udev);
	/* register struct wcn_usb_intf */
	dev_info(&port->udev->dev, "intf[%x] is registerred: ep count %d %s\n",
			iface_desc->desc.bInterfaceNumber,
			iface_desc->desc.bNumEndpoints,
			iface_desc->string);
	ret = -ENOMEM;
	for (i = 0; i < iface_desc->desc.bNumEndpoints; i++) {
		epd = &iface_desc->endpoint[i].desc;
		port->buffer_size = MAX_BUFFER_SIZE;
		port->ep_mps = epd->wMaxPacketSize;
		if (usb_endpoint_is_bulk_in(epd)) {
			port->epin = epd;
			port->read_urb = usb_alloc_urb(0, GFP_KERNEL);
			if (!port->read_urb)
				goto err0;
			if (iface_desc->desc.bInterfaceNumber > 1) {
				port->read_buffer = NULL;
				port->buffer_size = 0;
			} else {
				port->read_buffer = kzalloc(port->buffer_size, GFP_KERNEL);
				if (!port->read_buffer)
					goto err0;
			}
			usb_fill_bulk_urb(port->read_urb, udev,
				usb_rcvbulkpipe(udev, epd->bEndpointAddress),
				port->read_buffer, port->buffer_size,
				bulkin_complete, port);
			port->read_urb->context = NULL;
			init_usb_anchor(&port->read_submitted);
			dev_dbg(&pdev->dev, "BulkinEP = 0x%x rp=%p\n",
					epd->bEndpointAddress, port->read_buffer);
		} else if (usb_endpoint_is_bulk_out(epd)) {
			port->epout = epd;
			port->write_urb = usb_alloc_urb(0, GFP_KERNEL);
			if (!port->write_urb)
				goto err0;
			if (iface_desc->desc.bInterfaceNumber > 1) {
				port->write_buffer = NULL;
				port->buffer_size = 0;
			} else {
				port->write_buffer = kzalloc(port->buffer_size, GFP_KERNEL);
				if (!port->write_buffer)
					goto err0;
			}
			usb_fill_bulk_urb(port->write_urb, udev,
				usb_sndbulkpipe(udev, epd->bEndpointAddress),
				port->write_buffer, port->buffer_size, bulkout_complete, port);
			port->write_urb->context = NULL;
			init_usb_anchor(&port->write_submitted);
			dev_dbg(&pdev->dev, "BulkoutEP = 0x%x wp =%p context %p\n",
					epd->bEndpointAddress, port->write_buffer, port->write_urb->context);
		}
	}
	if (!dloader) {
		port->portno = iface_desc->desc.bInterfaceNumber;
		port->state = 1;
		if (port->portno <= 1) {
			if (!strncmp(names, "WIFIDATA", 8)) {
				skw_get_packet_count(port->portno);
				wifi_pdata.cmd_port = 1 - port->portno;
				wifi_pdata.data_port = port->portno;
				port->thread = kthread_create(usb_port_async_entry, port, iface_desc->string);
				tasklet_init(&port->tasklet, usb_handle, (unsigned long)port);
			} else {
				wifi_pdata.cmd_port = port->portno;
				wifi_pdata.data_port = 1 - port->portno;
				if (!strncmp(names, "WIFICMD", 7))
					port->thread = kthread_create(usb_port_entry, port, iface_desc->string);
			}
			if (port->thread) {
				sema_init(&port->sem, 0);
				wake_up_process(port->thread);
			} else
				sema_init(&port->sem, 1);
		} else if (!strncmp(names, "LOOP", 4)) {
			sema_init(&port->sem, 0);
			port->thread = kthread_create(usb_loopcheck_entry, port, iface_desc->string);
			if (port->thread)
				wake_up_process(port->thread);
		} else	sema_init(&port->sem, 1);
	} else {
		port->state = 1;
		assert_info_print = 0;
		INIT_WORK(&port->work, dloader_work);
		if (usb_boot_data &&
		    usb_boot_data->iram_dl_size &&
		    usb_boot_data->dram_dl_size) {
			dev_info(&udev->dev, "schedule dloader work to recovery modem\n");
			skw_usb_wake_lock();
			schedule_work(&port->work);
		}
		port->is_dloader = 1;
	}
	if (!strncmp(names, "LOG", 3))
		log_port = port;
	return 0;
err0:
	dev_err(&udev->dev, "no memory  to register device\n");
	kfree(port->write_buffer);
	kfree(port->read_buffer);
	usb_free_urb(port->write_urb);
	usb_free_urb(port->read_urb);
	if (port->pdev)
		platform_device_unregister(port->pdev);
	usb_ports[iface_desc->desc.bInterfaceNumber] = NULL;
	kfree(port);
	return ret;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static int launch_download_work(char *data, int size, int addr)
{
	int chk_ports = 0;

	firmware_size = size;//link to usb_download size
	firmware_data	= data;//link to usb_download dl_data
	firmware_addr = addr;
	do {
		if ((usb_ports[0]) && (usb_ports[0]->state)) {
			chk_ports = 1;
			break;
		}
		msleep(10);
	} while (!chk_ports);
	schedule_work(&usb_ports[0]->work);
	return 0;
}

static int skw_recovery_mode(void)
{
	int ret;

	skw_usb_info("------enter recovery mode\n");
	if (chip_en_gpio >= 0 && !recovery_debug_status) {
		SKW_CHIP_POWEROFF(chip_en_gpio);
		skw_usb_info("set chip enable reset\n");
		msleep(60);
		SKW_CHIP_POWERON(chip_en_gpio);

	} else if (!recovery_debug_status) {
		/*
		 *  call power  API here: power-off  delay-X-ms power-on
		 */
		if (usb_ports[0] && usb_ports[0]->udev) {
			skw_usb_info("vendor reset start\n");
			ret = usb_control_msg(usb_ports[0]->udev,
					usb_sndctrlpipe(usb_ports[0]->udev, 0),
					VENDOR_MSG_MODEM_RESET,
					USB_DIR_OUT | USB_TYPE_VENDOR | USB_RECIP_DEVICE,
					0, 0, NULL, 0, 100);
			skw_usb_info("reset ret = %d\n", ret);
		}
	}
	return 0;
}

/************************************************************************
 *Decription:
 *Author:JUNWEI.JIANG
 *Date:2021-12-20
 *Modfiy:
 *
 ********************************************************************* */
static irqreturn_t skw_gpio_irq_handler(int irq, void *dev_id)
{
	int value = gpio_get_value(host_wake_gpio);

	printk("gpio value = %d\n", value);
	return IRQ_HANDLED;
}

int skw_boot_loader(struct seekwave_device *boot_data)
{
	int ret = 1;

	usb_boot_data = boot_data;
	skw_usb_info("status:%d , dms_type =0x%08x,chip_en_gpio=%d host_wake_gpio=%d service=0x%x", modem_status,
		TX_DMA_TYPE, usb_boot_data->chip_en, usb_boot_data->gpio_in, service_state_map);
	chip_en_gpio = usb_boot_data->chip_en;

#ifdef CONFIG_SKW_DL_TIME_STATS
	cur_time = ktime_get();
#endif
	if (host_wake_gpio < 0 && usb_boot_data->gpio_in >= 0) {
		int irq_num;

		host_wake_gpio = usb_boot_data->gpio_in;
		irq_num = gpio_to_irq(host_wake_gpio);
		ret = request_irq(irq_num, skw_gpio_irq_handler,
			IRQF_TRIGGER_RISING | IRQF_ONESHOT, "skw-gpio-irq", NULL);
		skw_usb_info("request_gpio_irq ret=%d\n", ret);
		if (ret == 0)
			enable_irq_wake(irq_num);
	}
	if (!boot_data->first_dl_flag) {
		if (usb_ports[0] && !usb_ports[0]->is_dloader) {
			schedule_work(&add_device_work);
		} else if (boot_data->iram_img_data && boot_data->dram_img_data) {
			skw_usb_info("USB FIRST BOOT...\n");
			ret = launch_download_work(boot_data->iram_img_data, boot_data->iram_dl_size, boot_data->iram_dl_addr);
		} else {
			skw_usb_info("The CPBOOT not download from AP!!!!\n");
		}
	}
	if (boot_data->dl_module == RECOVERY_BOOT) {
		skw_recovery_mode();
		return 0;
	}
	if (boot_data->service_ops == SKW_WIFI_START) {
		//skw_WIFI_service_start();
		//skw_usb_info("----WIFI-SERVICE-----START!!!\n");
	} else if (boot_data->service_ops == SKW_WIFI_STOP &&
			(service_state_map & (1 << WIFI_SERVICE))) {
		ret = skw_WIFI_service_stop();
		//skw_usb_info("----WIFI-SERVICE-----STOP!!!\n");
	} else if (boot_data->service_ops == SKW_BT_START) {
		skw_usb_info("----BT-SERVICE-----START!!!\n");
		ret = skw_BT_service_start();
	} else if (boot_data->service_ops == SKW_BT_STOP &&
			(service_state_map & (1 << BT_SERVICE))) {
		skw_usb_info("----BT-SERVICE-----STOP!!!\n");
		ret = skw_BT_service_stop();
	}
	if (ret < 0) {
		skw_usb_err("the boot fail !!!\n");
		return ret;
	} else {
		skw_usb_info("the boot sucessfully !!!\n");
	}
	return 0;
}
EXPORT_SYMBOL_GPL(skw_boot_loader);
void *skw_get_bus_dev(void)
{
	if (!usb_ports[0] || !usb_ports[0]->state || !usb_ports[0]->udev) {
		skwusb_err("%s the port open device fail !!!\n", __func__);
		return NULL;
	}
	return &usb_ports[0]->udev->dev;
}
EXPORT_SYMBOL_GPL(skw_get_bus_dev);

/************************************************************************
 *Decription:check dev ready for boot
 *Author:junwei.jiang
 *Date:2022-06-07
 *Modfiy:
 *
 ********************************************************************* */
int skw_reset_bus_dev(void)
{
	struct usb_port_struct *port;
	int ret = -1;

	if (chip_en_gpio > 0) {
		SKW_CHIP_POWEROFF(chip_en_gpio);
		msleep(50);
		SKW_CHIP_POWERON(chip_en_gpio);
		return 0;
	}
	port = usb_ports[0];
	if (!port)
		return ret;
	ret = usb_control_msg(port->udev, usb_sndctrlpipe(port->udev, 0),
			VENDOR_MSG_MODEM_RESET, USB_DIR_OUT | USB_TYPE_VENDOR | USB_RECIP_DEVICE,
			0, 0, NULL, 0, 100);
	skw_usb_info("ret = %d\n", ret);
	modem_status = MODEM_HALT;
	return ret;
}
EXPORT_SYMBOL_GPL(skw_reset_bus_dev);

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static int skw_usb_io_free_suspend_urbs(struct usb_interface *interface)
{
	struct usb_port_struct *port;
	struct urb *urb;

	port = usb_get_intfdata(interface);

	skw_usb_info("port%d enter...\n", port->portno);
	port->suspend = 0;
	while (!list_empty(&port->suspend_urb_list)) {
		urb = list_first_entry(&port->suspend_urb_list, struct urb, urb_list);
		list_del_init(&urb->urb_list);
		skw_usb_info("free urb %p\n", urb);
		if (!list_empty(&port->suspend_urb_list))
			list_add_tail(&urb->urb_list, &port->rx_urb_list);
		else {
			urb->status = -EIO;
			urb->complete(urb);
		}
	}
	return 0;
}

static void skw_usb_io_disconnect(struct usb_interface *interface)
{
	int infno = interface->cur_altsetting->desc.bInterfaceNumber;
	struct recovery_data *recovery = SKW_USB_GET_RECOVERY_DATA();
	struct usb_port_struct *port;
	unsigned long flags;
	struct urb *urb;

	skw_usb_info("interface[%x] disconnected %d\n", infno, modem_status);
	port = usb_get_intfdata(interface);
	if (!port)
		return;
	log_port = NULL;
	port->state = 0;
	if (!port->is_dloader) {
		if (infno > 1)
			platform_device_unregister(port->pdev);
		if (infno == 1)
		wake_up_interruptible(&port->rx_wait);
		if (modem_status == MODEM_ON) {
			if (wifi_data_pdev && &port->udev->dev == wifi_data_pdev->dev.parent) {
				//platform_device_unregister(port->pdev);
				platform_device_unregister(wifi_data_pdev);
				wifi_data_pdev = NULL;
			}
		}
		if (port->pdev == wifi_data_pdev && port->suspend) {
			skw_usb_wake_lock();
			modem_notify_event(DEVICE_DISCONNECT_EVENT);
			tasklet_kill(&port->tasklet);
			if (!recovery->cp_state) {
				recovery->cp_state = 1;
				schedule_delayed_work(&skw_except_work, msecs_to_jiffies(10000));
			}
		}
		skw_usb_io_free_suspend_urbs(interface);
		if (port->read_urb && port->read_urb->context)
			usb_kill_anchored_urbs(&port->read_submitted);
		if (port->write_urb && port->write_urb->context)
			usb_kill_anchored_urbs(&port->write_submitted);
		if (port->thread && !port->suspend && down_timeout(&port->sem, 1000))
			skw_usb_info("start  to unregister interface[%x]\n", infno);

	} else
		flush_work(&port->work);
	if (port->read_urb && !port->read_urb->context) {
		kfree(port->read_urb);
		port->read_urb = NULL;
	} else skw_usb_info("%s memory leak port.r%d!!!!!!!!\n", __func__, infno);
	if (port->write_urb && !port->write_urb->context) {
		kfree(port->write_urb);
		port->write_urb = NULL;
	} else skw_usb_info("%s memory leak port.w%d!!!!!!!!\n", __func__, infno);
	kfree(port->read_buffer);
	kfree(port->write_buffer);
	spin_lock_irqsave(&port->rx_urb_lock, flags);
	while (!list_empty(&port->rx_done_urb_list)) {
		urb = list_first_entry(&port->rx_done_urb_list, struct urb, urb_list);
		list_del_init(&urb->urb_list);
		kfree(urb->transfer_buffer);
		usb_free_urb(urb);
	}
	spin_unlock_irqrestore(&port->rx_urb_lock, flags);
	/* this lock must give me! */
	usb_set_intfdata(interface, NULL);
	usb_put_dev(port->udev);
	usb_put_intf(interface);
	kfree(port);
	if (chip_en_gpio > 0 && MODEM_DOWNLOAD_FAILED == modem_status) {
		modem_status = MODEM_HALT;
		SKW_CHIP_POWERON(chip_en_gpio);
		skw_usb_info("%s poweron device\n", __func__);
	}
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static int skw_usb_io_pre_reset(struct usb_interface *interface)
{
	/* there is a lock to prevent we reset a interface when
	 * urb submit
	 */
	struct usb_port_struct *port;

	port = usb_get_intfdata(interface);

	return 0;
}

/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static int skw_usb_io_post_reset(struct usb_interface *interface)
{
	struct usb_port_struct *port;

	port = usb_get_intfdata(interface);
	return 0;
}

#ifdef CONFIG_PM
static int skw_usb_io_suspend(struct usb_interface *interface, pm_message_t message)
{
	struct usb_port_struct *port;

	if (service_state_map & (1 << BT_SERVICE))
		skw_BT_service_stop();
	port = usb_get_intfdata(interface);

	if (usb_ports[0] && usb_ports[0]->write_urb->context) {
		msleep(10);
		skw_usb_info("port%d  message discard\n", port->portno);
	}
	if (port->tx_urb_count) {
		skw_usb_info("cancle port%d  suspended message\n", port->portno);
		usb_kill_anchored_urbs(&port->write_submitted);
	}
	port->suspend = 1;
	skw_usb_info("port%d recv %s MSG\n", port->portno, PMSG_IS_AUTO(message) ? "Auto" : "None-auto");

	if (port->portno == 1 || port->read_urb->context)
		usb_kill_anchored_urbs(&port->read_submitted);
	if (port->write_urb->context)
		usb_kill_anchored_urbs(&port->write_submitted);
	skw_usb_info("done\n");
	return 0;
}

static int skw_usb_io_resume(struct usb_interface *interface)
{
	struct usb_port_struct *port;
	struct urb *urb;

	port = usb_get_intfdata(interface);

	skw_usb_info("port%d enter...\n", port->portno);
	port->suspend = 0;
	while (!list_empty(&port->suspend_urb_list)) {
		urb = list_first_entry(&port->suspend_urb_list, struct urb, urb_list);
		list_del_init(&urb->urb_list);
		if (port->portno == wifi_pdata.data_port)
			urb->context = port;
		usb_anchor_urb(urb, &port->read_submitted);
		usb_submit_urb(urb, GFP_KERNEL);
	}
	return 0;
}
#endif
/************************************************************************
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
struct usb_driver skw_usb_io_driver = {
	.name = "skw_usb_io",
	.probe = skw_usb_io_probe,
	.disconnect = skw_usb_io_disconnect,
#ifdef CONFIG_PM
	.suspend   = skw_usb_io_suspend,
	.resume    = skw_usb_io_resume,
#endif
	.pre_reset = skw_usb_io_pre_reset,
	.post_reset = skw_usb_io_post_reset,
	.id_table = skw_usb_io_id_table,
	.supports_autosuspend = 1,
};

/**
 * wcn_usb_io_init() - init wcn_usb_io's memory and register this driver.
 * @void: void.
 */
static int __init skw_usb_io_init(void)
{
	wifi_data_pdev = NULL;
	bluetooth_pdev = NULL;
	log_port = NULL;
	usb_boot_data = NULL;
	wifi_port_share = 0;
#ifndef CONFIG_SEEKWAVE_PLD_RELEASE
	recovery_debug_status = 1;
#else
	recovery_debug_status = 0;
#endif

	memset(usb_ports, 0, sizeof(usb_ports));
	init_completion(&download_done);
	init_completion(&loop_completion);
	skw_usb_wakeup_source_init();
	skw_usb_debugfs_init();
	skw_usb_log_level_init();
	chip_en_gpio = -1;
	modem_status = MODEM_OFF;
	skw_chipid = wifi_pdata.chipid;
	mutex_init(&g_recovery_data.except_mutex);
	INIT_DELAYED_WORK(&skw_except_work, skw_usb_exception_work);
	INIT_WORK(&add_device_work, add_devices_work);
	INIT_WORK(&dump_memory_worker, dump_memory_work);
	dump_memory_buffer = NULL;
	dump_buffer_size = 0;
	usb_register(&skw_usb_io_driver);
	return seekwave_boot_init();
}

/************************************************************************
 *Copyright(C) 2020-2021: Seekwave tech LTD		China
 *Decription:
 *Author:jiayong.yang
 *Date:2021-05-27
 *Modfiy:
 *
 ********************************************************************* */
static void __exit skw_usb_io_exit(void)
{
	int ret;

	skw_usb_info("exit\n");
	if (chip_en_gpio >= 0) {
		gpio_set_value(chip_en_gpio, 0);
		msleep(50);
	}
	if (usb_ports[0] && usb_ports[0]->udev) {
		skw_usb_info("reset SKWUSB device");
		skw_reset_bus_dev();
	}
	if (usb_boot_data && usb_boot_data->pdev && wifi_data_pdev &&
	    wifi_data_pdev->dev.parent == &usb_boot_data->pdev->dev) {
		skw_usb_info("unregister WIFI device\n");
		platform_device_unregister(wifi_data_pdev);
		wifi_data_pdev = NULL;
		ret = 0;
	}
	seekwave_boot_exit();
	skw_usb_debugfs_deinit();
	cancel_delayed_work_sync(&skw_except_work);
	cancel_work_sync(&add_device_work);
	cancel_work_sync(&dump_memory_worker);
	dump_memory_buffer = NULL;
	dump_log_size = NULL;
	mutex_destroy(&g_recovery_data.except_mutex);
	skw_usb_wakeup_source_destroy();
	if (bluetooth_pdev)
		platform_device_put(bluetooth_pdev);
	usb_deregister(&skw_usb_io_driver);
	if (wifi_data_pdev)
		platform_device_put(wifi_data_pdev);
}
module_init(skw_usb_io_init)
module_exit(skw_usb_io_exit)
MODULE_LICENSE("GPL v2");
===== ./drivers/seekwaveplatform/usb/usb_boot.c =====
/*************************************************************************************
 *Description: usb download
 *Seekwave tech LTD
 *Author: jiayong.yang/junwei.jiang
 *Date:20210527
 *Modify:
 * ***********************************************************************************/
#include <linux/kernel.h>
#include <linux/version.h>
#include <linux/module.h>
#include <linux/moduleparam.h>
#include <linux/slab.h>
#include <linux/proc_fs.h>
#include <linux/errno.h>
#ifdef CONFIG_DEBUG_FS
#include <linux/debugfs.h>
#endif
#include <linux/fs.h>
#include <linux/buffer_head.h>
#include <linux/ctype.h>
#include "skw_usb_log.h"
#include "usb_boot.h"
/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
static int dl_mps;
static int dloader_port;

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
static int check_modem_status_from_connect_message(void)
{
	struct connect_ack *ack = (void *)&connect_ack[12];

	memcpy(skw_chipid, ack->chip_id, 16);
	dl_mps = ack->packet_size;
	if (ack->flags.bitmap.boot)
		return NORMAL_BOOT;
	else
		return NORMAL_BOOT;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
static int dloader_write(char *msg, int msg_len, int *actual, int timeout)
{
	return bulkout_write_timeout(dloader_port, msg, msg_len, actual, timeout);
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
static int dloader_read(char *msg, int msg_len, int *actual, int timeout)
{
	return bulkin_read_timeout(dloader_port, msg, msg_len, actual, timeout);
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
static int compare_msg(const char *src, const char *dst, size_t count)
{
	unsigned char c1, c2;

	while (count) {
		c1 = *src++;
		c2 = *dst++;
		if (c1 != c2)
			return c1 < c2 ? -1 : 1;
		count--;
	}
	return 0;
}

static int dloader_send_data(const char *command, int command_len, const char *ack, int ack_len)
{
	int actual_len = 0;
	int ret;
	void *data;
	int data_size = 128;

	data = kzalloc(data_size, GFP_KERNEL);

	if (!data)
		return -ENOMEM;
	/* send command */
	ret = dloader_write((char *)command, command_len, &actual_len, 3000);
	if (ret < 0 || actual_len != command_len) {
		printk("%s send cmd error ret %d actual_len %d command_len %d\n",
				__func__, ret, actual_len, command_len);
	} else {
		if (!ack)
			goto OUT;

		/* read ack and check it */
		ret = dloader_read(data, data_size, &actual_len, 3000);
		if (ret < 0 || ack_len > actual_len || compare_msg(ack, data, ack_len)) {
			printk("%s ack is NACK:ret-- %d\n", __func__, ret);
			ret = -EIO;
		}
	}
OUT:
	kfree(data);
	return ret;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
static int dloader_send_command(const char *command,  int command_len, const char *ack, int ack_len)
{
	int actual_len = 0;
	int ret;
	void *data;
	int data_size = 128;

	data = kzalloc(data_size, GFP_KERNEL);
	if (!data)
		return -ENOMEM;
	/* send command */
	memcpy(data, (char *)command, command_len);
	ret = dloader_write(data, command_len, &actual_len, 3000);
	if (ret < 0 || actual_len != command_len) {
		printk("%s send cmd error ret %d actual_len %d command_len %d\n",
				__func__, ret, actual_len, command_len);
	} else {
		/* read ack */
		ret = dloader_read(data, data_size, &actual_len, 3000);
		if (ret < 0) {
			printk("%s ack is NACK: acklen ===%d- actual_len ==%d--ret == %d\n",
				__func__, ret, ack_len, actual_len);
		}
	}
	if ((command_len > 8) && (command[8] == 0))
		memcpy(connect_ack, data, actual_len);
	kfree(data);
	return ret;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
static unsigned short crc16_calculate(unsigned char *buf, int len)
{
	unsigned int i;
	unsigned short crc = 0;

	while (len-- != 0) {
		for (i = 0x80; i != 0; i = i >> 1) {
			if ((crc & 0x8000) != 0) {
				crc = crc << 1;
				crc = crc ^ 0x1021;
			} else {
				crc = crc << 1;
			}
			if ((*buf & i) != 0)
				crc = crc ^ 0x1021;
		}
		buf++;
	}
	return crc;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
int dloader_command_start_download(unsigned int addr, unsigned int len)
{
	int command_len = 20;
	char command[20] = {0x7E, 0x7E, 0x7E, 0x7E,/* head */
		0x08, 0x00, 0x00, 0x00, /*length */
		0x01, 0x00, /* message type, 01: start command */
		0x00, 0x00, /*crc for data body, excludes message header */
		0x00, 0x00, 0x10, 0x00,/*addr*/
		0x60, 0xb3, 0x06, 0x00 /*image size*/};

	*((u32 *)&command[12]) = addr;
	*((u32 *)&command[16]) = len;

	*((u16 *)&command[10]) = cpu_to_be16(crc16_calculate(&command[12], command_len - 12));
	return dloader_send_command(command, command_len, common_ack, sizeof(common_ack));
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
int dloader_command_exec(unsigned int addr)
{
	unsigned short command_len = 16;

	char command[16] = {0x7E, 0x7E, 0x7E, 0x7E, /* head */
		0x04, 0x00, 0x00, 0x00,
		0x04, 0x00, /*command type */
		0x43, 0x63, /*command len */
		0x00, 0x00, 0x10, 0x00 /*addr*/
		};
	*((u32 *)&command[12]) = addr;
	*((u16 *)&command[10]) = crc16_calculate(&command[12], 4);
	return dloader_send_command(command, command_len, exec_ack, sizeof(exec_ack));
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
int dloader_setup_usb_connection(struct usb_port_struct *port)
{
	int ret;

	dloader_command_client_probe();
	if (ret < 0) {
		dev_err(&port->udev->dev, "get version error\n");
		return ret;
	}
	dloader_command_connect();
	if (ret < 0) {
		dev_err(&port->udev->dev, "connection  error\n");
		return ret;
	}
	dev_info(&port->udev->dev, "dloader connect susscess...\n");
	return 0;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
int dloader_execute_image(struct usb_port_struct *port, unsigned int addr)
{
	int ret;

	ret = dloader_command_exec(addr);
	if (ret < 0) {
		dev_err(&port->udev->dev, "exec command is error\n");
		return ret;
	}
	return 0;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:junwei.jiang
 *Date:
 *Modify:
 * ************************************************************************/
static unsigned int dloader_send_pdata(char *buf, const void *pdata, unsigned int len)
{
	PACKET_T *packet_ptr = (PACKET_T *)buf;
	int command_len = len + PACKET_HEADER_SIZE;

	packet_ptr->magic = PACKET_MAGIC;
	packet_ptr->type = 0x0002;
	packet_ptr->size = len;
	packet_ptr->crc = 0x0000;
	memset(packet_ptr->content, 0, len);
	memcpy(packet_ptr->content, pdata, len);

	//crc check sum
	packet_ptr->crc = cpu_to_be16(crc16_calculate((char *)(&packet_ptr->content), command_len));

	return command_len;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
int usb_download_image(struct usb_port_struct *port, unsigned int addr, unsigned int len)
{
	int ret;
	int size;
	int offset = 0;
	int img_size = 0;
	int temp_size = 0;

	/*the first command connect*/
	ret = dloader_command_start_download(addr, len);
	if (ret < 0) {
		dev_err(&port->udev->dev, "start download command failed\n");
		return ret;
	}
	/*get the data and the sv6160.bin size*/
	img_size = len;

	while (img_size > 0) {
		temp_size = MIN(dl_mps, img_size - offset);
		if (!temp_size)
			return 0;
		size  = dloader_send_pdata(port->read_buffer, (void*)(firmware_data) + offset, temp_size);
		if (size % 512 == 0 && temp_size <= dl_mps) {
			temp_size = temp_size >> 1;
			size  = dloader_send_pdata(port->read_buffer, (void*)(firmware_data) + offset, temp_size);
		}
		ret = dloader_send_data(port->read_buffer, size, common_ack, sizeof(common_ack));
		if (ret < 0) {
			dev_err(&port->udev->dev, "donwload img  error\n");
			return ret;
		}
		offset += temp_size;
	}
	return 0;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
int dloader_get_chip_id(void *buf, unsigned int buf_size)
{
	int len = strlen(usb_ports[0]->udev->product);

	memcpy(buf, usb_ports[0]->udev->product, strlen(usb_ports[0]->udev->product));
	return len;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
int dloader_dump_from_romcode_usb(unsigned int addr, void *buf, int len)
{
	int ret;
	unsigned short command_len = 16;
	char command[20] = {0x7E, 0x7E, 0x7E, 0x7E,/* head */
		0x08, 0x00, 0x00, 0x00, /*for command data len */
		0x00, 0x09, /*command type */
		0x00, 0x00, /*for crc*/
		0x00, 0x00, 0x00, 0x00,/*addr*/
		0x00, 0x00, 0x00, 0x00,/*data len*/
		};
	int actual_len = 0;
	int size;

	//*((u32 *)&command[12]) = cpu_to_be32(addr);
	//*((u32 *)&command[16]) = cpu_to_be32(len);
	*((u32 *)&command[12]) = addr;
	*((u32 *)&command[16]) = len;

	*((u16 *)&command[10]) = cpu_to_be16(crc16_calculate(&command[1], command_len - 4));

	ret = dloader_send_command(command, command_len, NULL, 0);
	if (ret < 0) {
		printk("%s send command error\n", __func__);
		return -EIO;
	}

	size = dl_mps;
	while (len > 0) {
		if (len < size)
			size = len;
		ret = dloader_read(buf, size, &actual_len, 3000);
		if (ret < 0)
			printk("dloader_read_ack dump memory error\n");
		else len -= actual_len;
	}
	return ret;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
static int dloader_dump_read_usb(struct usb_port_struct *port)
{
	int ret;

	ret = dloader_dump_from_romcode_usb(START_ADDR, port->read_buffer, MAX_IMAGE_SIZE);
	return ret;
}

/***************************************************************************
 * Description:
 *Seekwave tech LTD
 *Author:
 *Date:
 *Modify:
 * ************************************************************************/
static void dloader_work(struct work_struct *work)
{
	struct usb_port_struct *port = container_of(work, struct usb_port_struct, work);
	int ret;

	dloader_port = port->portno;
	dloader_setup_usb_connection(port);

	ret = check_modem_status_from_connect_message();
	if (ret == HANG_REBOOT) {
		dloader_dump_read_usb(port);
	}
	if (usb_boot_data->dram_dl_size > 0) {
		firmware_data = usb_boot_data->dram_img_data;
		ret = usb_download_image(port, usb_boot_data->dram_dl_addr, usb_boot_data->dram_dl_size);
		if (ret < 0) {
			skw_usb_info("%s dram download img fail !!!!\n", __func__);
		}
	}

	if (!ret  && usb_boot_data->iram_dl_size > 0) {
		firmware_data = usb_boot_data->iram_img_data;
		ret = usb_download_image(port, usb_boot_data->iram_dl_addr, usb_boot_data->iram_dl_size);
	}
	if (ret == 0)
		ret = dloader_execute_image(port, START_ADDR);
	if (ret < 0) {
		modem_status = MODEM_DOWNLOAD_FAILED;

		if (chip_en_gpio >= 0) {
			skw_usb_info("download failed! power off device\n");
			SKW_CHIP_POWEROFF(chip_en_gpio);
			msleep(20);
		}
	}
}
===== ./drivers/seekwaveplatform/usb/skw_usb_log.c =====
/*****************************************************************************
 * Copyright(c) 2020-2030  Seekwave Corporation.
 * SEEKWAVE TECH LTD..CO
 *
 *Seekwave Platform the usb log debug fs
 *FILENAME:skw_usb_log.c
 *DATE:2022-04-11
 *MODIFY:
 *Author:Jones.Jiang
 **************************************************************************/
#include <linux/uaccess.h>
#include <linux/kernel.h>
#include <linux/slab.h>

#include "skw_usb_log.h"
#include "skw_usb.h"
#include "skw_usb_debugfs.h"

static unsigned long skw_usb_dbg_level;

extern char firmware_version[];
unsigned long skw_usb_log_level(void)
{
	return skw_usb_dbg_level;
}

static void skw_usb_set_log_level(int level)
{
	unsigned long dbg_level;

	dbg_level = skw_usb_log_level() & 0xffff0000;
	dbg_level |= ((level << 1) - 1);

	xchg(&skw_usb_dbg_level, dbg_level);
}

static void skw_usb_enable_func_log(int func, bool enable)
{
	unsigned long dbg_level = skw_usb_log_level();

	if (enable)
		dbg_level |= func;
	else
		dbg_level &= (~func);

	xchg(&skw_usb_dbg_level, dbg_level);
}

static int skw_usb_log_show(struct seq_file *seq, void *data)
{
#define SKW_USB_LOG_STATUS(s) (level & (s) ? "enable" : "disable")

	int i;
	u32 level = skw_usb_log_level();
	u8 *log_name[] = {"NONE", "ERROR", "WARNNING", "INFO", "DEBUG"};

	for (i = 0; i < 5; i++) {
		if (!(level & BIT(i)))
			break;
	}

	seq_printf(seq, "%s\n", log_name[i < 5 ? i : 4]);

	seq_puts(seq, "\n");
	seq_printf(seq, "port0 log: %s\n", SKW_USB_LOG_STATUS(SKW_USB_PORT0));
	seq_printf(seq, "port1 log: %s\n", SKW_USB_LOG_STATUS(SKW_USB_PORT1));
	seq_printf(seq, "port2 log: %s\n", SKW_USB_LOG_STATUS(SKW_USB_PORT2));
	seq_printf(seq, "port3 log: %s\n", SKW_USB_LOG_STATUS(SKW_USB_PORT3));
	seq_printf(seq, "port4 log: %s\n", SKW_USB_LOG_STATUS(SKW_USB_PORT4));
	seq_printf(seq, "port5 log: %s\n", SKW_USB_LOG_STATUS(SKW_USB_PORT5));
	seq_printf(seq, "port6 log: %s\n", SKW_USB_LOG_STATUS(SKW_USB_PORT6));
	seq_printf(seq, "port7 log: %s\n", SKW_USB_LOG_STATUS(SKW_USB_PORT7));
	seq_printf(seq, "savelog  : %s\n", SKW_USB_LOG_STATUS(SKW_USB_SAVELOG));
	seq_printf(seq, "dump  log: %s\n", SKW_USB_LOG_STATUS(SKW_USB_DUMP));

	return 0;
}

static int skw_usb_log_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_usb_log_show, inode->i_private);
}

static int skw_usb_log_control(const char *cmd, bool enable)
{
	if (!strcmp("dump", cmd))
		skw_usb_enable_func_log(SKW_USB_DUMP, enable);
	else if (!strcmp("port0", cmd))
		skw_usb_enable_func_log(SKW_USB_PORT0, enable);
	else if (!strcmp("port1", cmd))
		skw_usb_enable_func_log(SKW_USB_PORT1, enable);
	else if (!strcmp("port2", cmd))
		skw_usb_enable_func_log(SKW_USB_PORT2, enable);
	else if (!strcmp("port3", cmd))
		skw_usb_enable_func_log(SKW_USB_PORT3, enable);
	else if (!strcmp("port4", cmd))
		skw_usb_enable_func_log(SKW_USB_PORT4, enable);
	else if (!strcmp("port5", cmd))
		skw_usb_enable_func_log(SKW_USB_PORT5, enable);
	else if (!strcmp("port6", cmd))
		skw_usb_enable_func_log(SKW_USB_PORT6, enable);
	else if (!strcmp("port7", cmd))
		skw_usb_enable_func_log(SKW_USB_PORT7, enable);
	else if (!strcmp("savelog", cmd))
		skw_usb_enable_func_log(SKW_USB_SAVELOG, enable);
	else if (!strcmp("debug", cmd))
		skw_usb_set_log_level(SKW_USB_DEBUG);
	else if (!strcmp("info", cmd))
		skw_usb_set_log_level(SKW_USB_INFO);
	else if (!strcmp("warn", cmd))
		skw_usb_set_log_level(SKW_USB_WARNING);
	else if (!strcmp("error", cmd))
		skw_usb_set_log_level(SKW_USB_ERROR);
	else
		return -EINVAL;

	return 0;
}

static ssize_t skw_usb_log_write(struct file *fp, const char __user *buffer,
				size_t len, loff_t *offset)
{
	int i, idx;
	char cmd[32];
	bool enable = false;

	for (idx = 0, i = 0; i < len; i++) {
		char c;

		if (get_user(c, buffer))
			return -EFAULT;

		switch (c) {
		case ' ':
			break;

		case ':':
			cmd[idx] = 0;
			if (!strcmp("enable", cmd))
				enable = true;
			else
				enable = false;

			idx = 0;
			break;

		case '|':
		case '\0':
		case '\n':
			cmd[idx] = 0;
			skw_usb_log_control(cmd, enable);
			idx = 0;
			break;

		default:
			cmd[idx++] = c;
			idx %= 32;

			break;
		}

		buffer++;
	}

	return len;
}

static const struct file_operations skw_usb_log_fops = {
	.owner = THIS_MODULE,
	.open = skw_usb_log_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_usb_log_write,
};

static int skw_version_show(struct seq_file *seq, void *data)
{
	seq_printf(seq, "firmware info:\n %s\n", firmware_version);
	return 0;
}

static int skw_version_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_version_show, inode->i_private);
}

static const struct file_operations skw_version_fops = {
	.owner = THIS_MODULE,
	.open = skw_version_open,
	.read = seq_read,
	.release = single_release,
};

static int skw_cp_log_show(struct seq_file *seq, void *data)
{
	if (!skw_usb_cp_log_status())
		seq_puts(seq, "Enabled");
	else
		seq_puts(seq, "Disabled");
	return 0;
}

static int skw_cp_log_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_cp_log_show, inode->i_private);
}

static ssize_t skw_cp_log_write(struct file *fp, const char __user *buffer,
		size_t len, loff_t *offset)
{
	char cmd[16] = {0};

	if (len >= sizeof(cmd))
		return -EINVAL;
	if (copy_from_user(cmd, buffer, len))
		return -EFAULT;

	if (!strncmp("enable", cmd, 6)) {
		skw_usb_debug_log_open();
		skw_usb_cp_log(0);
	} else if (!strncmp("disable", cmd, 7)) {
		skw_usb_debug_log_close();
		skw_usb_cp_log(1);
	}
	return len;
}

static const struct file_operations skw_cp_log_fops = {
	.owner = THIS_MODULE,
	.open = skw_cp_log_open,
	.read = seq_read,
	.release = single_release,
	.write = skw_cp_log_write,
};

static int skw_port_statistic_show(struct seq_file *seq, void *data)
{
	char *statistic = kzalloc(2048, GFP_KERNEL);

	skw_get_port_statistic(statistic, 2048);
	seq_printf(seq, "Statistic:\n%s", statistic);
	kfree(statistic);
	return 0;
}

static int skw_port_statistic_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skw_port_statistic_show, inode->i_private);
}

static const struct file_operations skw_port_statistic_fops = {
	.owner = THIS_MODULE,
	.open = skw_port_statistic_open,
	.read = seq_read,
	.release = single_release,
};

static int skwusb_recovery_debug_show(struct seq_file *seq, void *data)
{
	if (skw_usb_recovery_debug_status())
		seq_puts(seq, "Disabled");
	else
		seq_puts(seq, "Enabled");

	return 0;
}

static int skwusb_recovery_debug_open(struct inode *inode, struct file *file)
{
	return single_open(file, &skwusb_recovery_debug_show, inode->i_private);
}

static ssize_t skwusb_recovery_debug_write(struct file *fp, const char __user *buffer,
				size_t len, loff_t *offset)
{
	char cmd[16] = {0};

	if (len >= sizeof(cmd))
		return -EINVAL;
	if (copy_from_user(cmd, buffer, len))
		return -EFAULT;
	if (!strncmp("disable", cmd, 7))
		skw_usb_recovery_debug(1);
	else if (!strncmp("enable", cmd, 6))
		skw_usb_recovery_debug(0);

	return len;
}

static const struct file_operations skwusb_recovery_debug_fops = {
	.owner = THIS_MODULE,
	.open = skwusb_recovery_debug_open,
	.read = seq_read,
	.release = single_release,
	.write = skwusb_recovery_debug_write,
};

void skw_usb_log_level_init(void)
{
	skw_usb_set_log_level(SKW_USB_INFO);

	skw_usb_enable_func_log(SKW_USB_DUMP, false);
	skw_usb_enable_func_log(SKW_USB_PORT0, false);
	skw_usb_enable_func_log(SKW_USB_PORT1, false);
	skw_usb_enable_func_log(SKW_USB_PORT2, false);
	skw_usb_enable_func_log(SKW_USB_PORT3, false);
	skw_usb_enable_func_log(SKW_USB_PORT4, false);
	skw_usb_enable_func_log(SKW_USB_PORT5, false);
	skw_usb_enable_func_log(SKW_USB_PORT6, false);
	skw_usb_enable_func_log(SKW_USB_SAVELOG, false);
	skw_usb_enable_func_log(SKW_USB_PORT7, false);
	skw_usb_add_debugfs("log_level", 0666, NULL, &skw_usb_log_fops);
	skw_usb_add_debugfs("Version", 0664, NULL, &skw_version_fops);
	skw_usb_add_debugfs("CPLog", 0666, NULL, &skw_cp_log_fops);
	skw_usb_add_debugfs("Statistic", 0666, NULL, &skw_port_statistic_fops);
	skw_usb_add_debugfs("recovery", 0666, NULL, &skwusb_recovery_debug_fops);
}
